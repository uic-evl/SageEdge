{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1734.796, "latencies_ms": [1734.796], "images_per_second": 0.576, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A woman is standing at the dining table, preparing food in a cozy living room with yellow walls, a wooden floor, and a green accent wall.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13229.0, "ram_available_mb": 49611.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13230.5, "ram_available_mb": 49610.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4418.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.326, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 7.475}, "timestamp": "2026-01-19T12:29:32.838966"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3775.085, "latencies_ms": [3775.085], "images_per_second": 0.265, "prompt_tokens": 21, "response_tokens_est": 48, "n_tiles": 1, "output_text": "TV: 1\nCabinet: 2\nRadiator: 1\nChair: 4\nDining table: 2\nWoman: 1\nFlowers: 2\nVase: 1\nFireplace: 1\nKitchen: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13230.5, "ram_available_mb": 49610.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13230.7, "ram_available_mb": 49610.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4418.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.94, "power_cpu_cv_mean_watts": 1.809, "power_sys_5v0_mean_watts": 6.971}, "timestamp": "2026-01-19T12:29:38.661212"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2482.697, "latencies_ms": [2482.697], "images_per_second": 0.403, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The living room is positioned to the left of the dining area. The dining area is located in the background, separated by a small gap. The living room and dining area are separated by a small gap, further emphasizing the spatial relationship.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13230.7, "ram_available_mb": 49610.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13230.9, "ram_available_mb": 49610.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4418.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.227, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.783}, "timestamp": "2026-01-19T12:29:43.183873"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3436.557, "latencies_ms": [3436.557], "images_per_second": 0.291, "prompt_tokens": 19, "response_tokens_est": 69, "n_tiles": 1, "output_text": "The scene depicts a modern, open-plan living space with a dining area, kitchen, and living room. The living area features a flat-screen TV, wooden furniture, and a green accent wall. The kitchen area has stainless steel appliances and a dining table with chairs. A woman is standing at the dining table, seemingly engaged in conversation.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13230.9, "ram_available_mb": 49610.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13232.5, "ram_available_mb": 49608.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4418.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.031, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 6.92}, "timestamp": "2026-01-19T12:29:48.654935"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1998.268, "latencies_ms": [1998.268], "images_per_second": 0.5, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The room features a warm color scheme with yellow walls and wooden flooring. Natural light streams in through multiple windows, creating a bright and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13232.5, "ram_available_mb": 49608.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13234.4, "ram_available_mb": 49606.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4418.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4418.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.629, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 6.766}, "timestamp": "2026-01-19T12:29:52.709381"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1616.576, "latencies_ms": [1616.576], "images_per_second": 0.619, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A brown bear sits in a grassy area, gazing directly at the camera with a calm and curious expression.", "error": null, "sys_before": {"cpu_percent": 11.4, "ram_used_mb": 13234.4, "ram_available_mb": 49606.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13235.6, "ram_available_mb": 49605.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.274, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.574}, "timestamp": "2026-01-19T12:29:56.407394"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2508.162, "latencies_ms": [2508.162], "images_per_second": 0.399, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "bear: 1\ngrass: 2\nfur: 2\nface: 2\nears: 2\nnose: 1\nmouth: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13235.6, "ram_available_mb": 49605.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13237.1, "ram_available_mb": 49603.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.331, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.806}, "timestamp": "2026-01-19T12:30:00.934877"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1282.206, "latencies_ms": [1282.206], "images_per_second": 0.78, "prompt_tokens": 25, "response_tokens_est": 17, "n_tiles": 1, "output_text": "The bear is positioned in the foreground, with the grassy background extending behind it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13237.1, "ram_available_mb": 49603.8, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 13245.0, "ram_available_mb": 49595.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.713, "power_cpu_cv_mean_watts": 0.801, "power_sys_5v0_mean_watts": 6.521}, "timestamp": "2026-01-19T12:30:04.258559"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1836.487, "latencies_ms": [1836.487], "images_per_second": 0.545, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A large brown bear is sitting on lush green grass, gazing directly at the camera. The scene appears to be in a natural, outdoor environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13245.0, "ram_available_mb": 49595.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13246.5, "ram_available_mb": 49594.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.734, "power_cpu_cv_mean_watts": 1.149, "power_sys_5v0_mean_watts": 6.632}, "timestamp": "2026-01-19T12:30:08.141407"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2471.612, "latencies_ms": [2471.612], "images_per_second": 0.405, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The bear's fur is a light brown color. The lighting appears to be natural, possibly sunlight, giving the bear a warm and alert appearance. The bear is situated in a grassy area, suggesting it might be in a natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13246.5, "ram_available_mb": 49594.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13246.5, "ram_available_mb": 49594.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.686, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.849}, "timestamp": "2026-01-19T12:30:12.636551"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2042.718, "latencies_ms": [2042.718], "images_per_second": 0.49, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The room features a comfortable blue-comforter bed, wooden dresser with mirror, bookshelf, and potted plants, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13246.5, "ram_available_mb": 49594.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13247.4, "ram_available_mb": 49593.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.352, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.634}, "timestamp": "2026-01-19T12:30:16.727266"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3208.914, "latencies_ms": [3208.914], "images_per_second": 0.312, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "bed: 1\ndresser: 2\nmirror: 1\nchair: 1\nbookshelf: 5\nplant: 2\nwicker basket: 1\ncarpet: 1\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13247.4, "ram_available_mb": 49593.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 7.7, "ram_used_mb": 13247.6, "ram_available_mb": 49593.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.456, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T12:30:21.970756"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2372.8, "latencies_ms": [2372.8], "images_per_second": 0.421, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned to the left of the image. The bookshelf occupies the background, extending from right to left. The window is situated in the background, offering a view of the greenery outside.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13247.6, "ram_available_mb": 49593.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13246.6, "ram_available_mb": 49594.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.658, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 6.785}, "timestamp": "2026-01-19T12:30:26.385680"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2700.193, "latencies_ms": [2700.193], "images_per_second": 0.37, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The scene depicts a cozy bedroom with a large window offering a view of lush greenery outside. The room features a comfortable bed, a wooden dresser, a bookshelf filled with books, and a chair. The room is bathed in natural light, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13246.6, "ram_available_mb": 49594.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13247.5, "ram_available_mb": 49593.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.153, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.891}, "timestamp": "2026-01-19T12:30:31.127144"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2446.205, "latencies_ms": [2446.205], "images_per_second": 0.409, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The room features a blue comforter, a wooden dresser with a mirror, and a large window that lets in natural light. The walls are covered in floral wallpaper, and the carpet is light-colored.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 13247.5, "ram_available_mb": 49593.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13247.5, "ram_available_mb": 49593.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.326, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.793}, "timestamp": "2026-01-19T12:30:35.585704"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1542.068, "latencies_ms": [1542.068], "images_per_second": 0.648, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A red stop sign is mounted on a metal pole at the corner of a street, with a white car visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 13247.5, "ram_available_mb": 49593.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13246.9, "ram_available_mb": 49594.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.915, "power_cpu_cv_mean_watts": 1.168, "power_sys_5v0_mean_watts": 6.048}, "timestamp": "2026-01-19T12:30:39.185875"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2899.273, "latencies_ms": [2899.273], "images_per_second": 0.345, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "stop sign: 1\npole: 1\ntrailer: 1\ntruck: 1\ntrailer: 1\nshrubs: 2\ntrees: 4\nbuildings: 2", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 13246.9, "ram_available_mb": 49594.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13247.5, "ram_available_mb": 49593.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.418, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 6.593}, "timestamp": "2026-01-19T12:30:44.111236"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2324.1, "latencies_ms": [2324.1], "images_per_second": 0.43, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The stop sign is positioned in the foreground, slightly to the right of the image. The background features trees, a building, and a parked vehicle. The stop sign is situated near the center of the image, slightly to the right of the center.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13247.5, "ram_available_mb": 49593.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13247.0, "ram_available_mb": 49593.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.217, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.488}, "timestamp": "2026-01-19T12:30:48.478133"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2100.952, "latencies_ms": [2100.952], "images_per_second": 0.476, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a red stop sign on a metal pole at an intersection, with trees, bushes, and a building in the background. A piece of construction equipment is visible near the stop sign.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13247.0, "ram_available_mb": 49593.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13246.8, "ram_available_mb": 49594.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.887, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 6.284}, "timestamp": "2026-01-19T12:30:52.605446"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1533.315, "latencies_ms": [1533.315], "images_per_second": 0.652, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The stop sign is red and white. The lighting appears to be natural daylight. The stop sign appears to be made of metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13246.8, "ram_available_mb": 49594.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13247.3, "ram_available_mb": 49593.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.034, "power_cpu_cv_mean_watts": 1.093, "power_sys_5v0_mean_watts": 5.974}, "timestamp": "2026-01-19T12:30:56.158528"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2384.96, "latencies_ms": [2384.96], "images_per_second": 0.419, "prompt_tokens": 8, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Three teddy bears are nestled together, with one brown bear resting its head on the shoulder of another brown bear, while a third brown bear lies down with its head resting on the shoulder of the third bear.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13247.3, "ram_available_mb": 49593.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13247.4, "ram_available_mb": 49593.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.447, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.716}, "timestamp": "2026-01-19T12:31:00.595008"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3737.799, "latencies_ms": [3737.799], "images_per_second": 0.268, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Teddy bear: 3\nTeddy bear: 2\nTeddy bear: 1\nTeddy bear: 1\nTeddy bear: 1\nTeddy bear: 1\nTeddy bear: 1\nTeddy bear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13247.4, "ram_available_mb": 49593.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13248.5, "ram_available_mb": 49592.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.198, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T12:31:06.345452"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2238.747, "latencies_ms": [2238.747], "images_per_second": 0.447, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned close together, with the light brown bear in the foreground and the light brown bear in the background. The light brown bear is partially obscured by the other bears, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13248.5, "ram_available_mb": 49592.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13245.7, "ram_available_mb": 49595.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.76, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.764}, "timestamp": "2026-01-19T12:31:10.614610"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2028.97, "latencies_ms": [2028.97], "images_per_second": 0.493, "prompt_tokens": 19, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Three teddy bears are cuddled together on a dark surface, possibly a couch or bed. The scene suggests a cozy and warm environment.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 13245.7, "ram_available_mb": 49595.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13245.8, "ram_available_mb": 49595.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.203, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.734}, "timestamp": "2026-01-19T12:31:14.680335"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2208.52, "latencies_ms": [2208.52], "images_per_second": 0.453, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The teddy bears are brown and appear to be made of a soft, plush material. The lighting in the image is soft and warm, enhancing the cozy atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13245.8, "ram_available_mb": 49595.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13245.9, "ram_available_mb": 49595.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.848, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.663}, "timestamp": "2026-01-19T12:31:18.908182"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1768.612, "latencies_ms": [1768.612], "images_per_second": 0.565, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman in a red ski jacket and black pants is skiing down a snowy slope, leaning forward and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13245.9, "ram_available_mb": 49595.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13247.1, "ram_available_mb": 49593.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.09, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.681}, "timestamp": "2026-01-19T12:31:22.701378"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3232.473, "latencies_ms": [3232.473], "images_per_second": 0.309, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "woman: 1\nskis: 2\nsnow: 2\ngloves: 2\nhat: 1\nsunglasses: 1\nski poles: 2\nskis: 2\nbib: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13247.1, "ram_available_mb": 49593.8, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13246.6, "ram_available_mb": 49594.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.567, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 6.954}, "timestamp": "2026-01-19T12:31:27.961433"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2624.397, "latencies_ms": [2624.397], "images_per_second": 0.381, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The skier is positioned in the foreground of the image, facing the camera. The snowy slope and ski poles are in the background, extending from the foreground towards the background. The skier is relatively close to the viewer, suggesting they are in the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13246.6, "ram_available_mb": 49594.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13248.7, "ram_available_mb": 49592.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.179, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T12:31:32.611949"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2214.302, "latencies_ms": [2214.302], "images_per_second": 0.452, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A woman is skiing down a snowy slope, wearing a red jacket, black pants, and a striped hat. Red poles and markers are visible in the background, indicating a designated ski area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13248.7, "ram_available_mb": 49592.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13249.4, "ram_available_mb": 49591.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.853, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T12:31:36.853250"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2326.251, "latencies_ms": [2326.251], "images_per_second": 0.43, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The skier is wearing a red and white jacket, blue ski boots, and sunglasses. The lighting is bright and clear, indicating a sunny day. The snow appears to be well-maintained and undisturbed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13249.4, "ram_available_mb": 49591.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13250.3, "ram_available_mb": 49590.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.51, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.785}, "timestamp": "2026-01-19T12:31:41.219367"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1633.148, "latencies_ms": [1633.148], "images_per_second": 0.612, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A white refrigerator stands next to a wooden cabinet in a kitchen with a white stove and beige tiled floor.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13250.0, "ram_available_mb": 49590.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 13250.0, "ram_available_mb": 49590.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.566, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.442}, "timestamp": "2026-01-19T12:31:44.914226"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3115.142, "latencies_ms": [3115.142], "images_per_second": 0.321, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "oven: 2\nstove: 1\nrange hood: 1\ncabinets: 4\nrefrigerator: 1\ncountertop: 1\ndrawers: 3\ntile floor: 8", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13249.4, "ram_available_mb": 49591.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13248.3, "ram_available_mb": 49592.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.363, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 6.873}, "timestamp": "2026-01-19T12:31:50.048320"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2243.437, "latencies_ms": [2243.437], "images_per_second": 0.446, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close and centered arrangement. The stove and oven are situated in the foreground, while the refrigerator is located in the background. The kitchen appears to be situated in a relatively open space.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13248.3, "ram_available_mb": 49592.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13246.8, "ram_available_mb": 49594.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.872, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T12:31:54.324292"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2155.432, "latencies_ms": [2155.432], "images_per_second": 0.464, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The kitchen features a white stove, oven, and refrigerator, complemented by light brown wooden cabinets. The scene suggests a clean, well-maintained space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13246.8, "ram_available_mb": 49594.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13247.0, "ram_available_mb": 49593.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.062, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.741}, "timestamp": "2026-01-19T12:31:58.517278"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1840.661, "latencies_ms": [1840.661], "images_per_second": 0.543, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The kitchen features light brown wooden cabinets and light beige tile flooring. The lighting is soft and warm, creating a welcoming atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13247.0, "ram_available_mb": 49593.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13247.0, "ram_available_mb": 49593.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.787, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.699}, "timestamp": "2026-01-19T12:32:02.393691"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1675.498, "latencies_ms": [1675.498], "images_per_second": 0.597, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Two baseball players are running on a field, one in a white uniform and the other in a green uniform, attempting to catch the ball.", "error": null, "sys_before": {"cpu_percent": 10.8, "ram_used_mb": 13247.0, "ram_available_mb": 49593.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13246.6, "ram_available_mb": 49594.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.674, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T12:32:06.124347"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4008.066, "latencies_ms": [4008.066], "images_per_second": 0.249, "prompt_tokens": 21, "response_tokens_est": 58, "n_tiles": 1, "output_text": "baseball glove: 1\nbaseball helmet: 1\nbaseball uniform: 2\nbaseball pants: 2\nbaseball cleats: 2\nbaseball field: 2\nbaseball bat: 1\nbaseball mitt: 1\ngrass: 2\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13246.6, "ram_available_mb": 49594.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13246.2, "ram_available_mb": 49594.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.066, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 7.059}, "timestamp": "2026-01-19T12:32:12.153549"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2021.94, "latencies_ms": [2021.94], "images_per_second": 0.495, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the player running towards the right. The background features the grassy field and trees, creating a natural setting for the baseball game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13246.2, "ram_available_mb": 49594.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13244.3, "ram_available_mb": 49596.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.703, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.791}, "timestamp": "2026-01-19T12:32:16.196302"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2539.284, "latencies_ms": [2539.284], "images_per_second": 0.394, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Two baseball players are running on a baseball field. One player is wearing a white uniform and helmet, while the other player is wearing a green uniform and cap. The scene takes place outdoors, with green grass and trees in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13244.3, "ram_available_mb": 49596.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13245.7, "ram_available_mb": 49595.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.746, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.859}, "timestamp": "2026-01-19T12:32:20.767236"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2306.082, "latencies_ms": [2306.082], "images_per_second": 0.434, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The players are wearing light gray uniforms. The lighting appears to be natural daylight. The uniforms appear to be made of a durable material, likely cotton or polyester. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13245.7, "ram_available_mb": 49595.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13245.2, "ram_available_mb": 49595.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.139, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.826}, "timestamp": "2026-01-19T12:32:25.116298"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2023.638, "latencies_ms": [2023.638], "images_per_second": 0.494, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A tennis player in white attire is poised to hit a forehand shot on a blue tennis court, with a red and white tennis racket in hand.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13245.2, "ram_available_mb": 49595.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13246.2, "ram_available_mb": 49594.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.402, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.785}, "timestamp": "2026-01-19T12:32:29.177156"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4842.465, "latencies_ms": [4842.465], "images_per_second": 0.207, "prompt_tokens": 21, "response_tokens_est": 69, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis player: 1\nTennis ball: 1\nTennis court: 1\nTennis ball umpire: 1\nTennis ball umpire: 1\nTennis ball umpire: 1\nTennis ball umpire: 1\nTennis ball umpire: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13246.2, "ram_available_mb": 49594.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 13245.2, "ram_available_mb": 49595.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.355, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 7.068}, "timestamp": "2026-01-19T12:32:36.055070"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2192.199, "latencies_ms": [2192.199], "images_per_second": 0.456, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground, preparing to hit the ball. The ball is in the background, slightly out of focus. The tennis court is visible in the background, extending beyond the player.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13245.2, "ram_available_mb": 49595.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13246.0, "ram_available_mb": 49594.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.693, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.781}, "timestamp": "2026-01-19T12:32:40.299589"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2992.094, "latencies_ms": [2992.094], "images_per_second": 0.334, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A tennis player is executing a forehand shot on a blue tennis court, leaning forward and holding a red and white tennis racket. A line judge stands behind the player, observing the match. Spectators are visible in the background, watching the ongoing game.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13246.0, "ram_available_mb": 49594.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13247.5, "ram_available_mb": 49593.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.538, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.887}, "timestamp": "2026-01-19T12:32:45.324048"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2532.711, "latencies_ms": [2532.711], "images_per_second": 0.395, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The tennis court is green and appears to be well-lit, likely by sunlight. The tennis racket is orange and appears to be made of metal. The background features a blue wall with the \"J.P.Morgan\" logo prominently displayed.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13247.5, "ram_available_mb": 49593.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13247.8, "ram_available_mb": 49593.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.464, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.825}, "timestamp": "2026-01-19T12:32:49.902725"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1878.707, "latencies_ms": [1878.707], "images_per_second": 0.532, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A group of young tennis players, including both boys and girls, stand together holding their tennis rackets and celebrating a victory.", "error": null, "sys_before": {"cpu_percent": 8.8, "ram_used_mb": 13247.8, "ram_available_mb": 49593.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13248.2, "ram_available_mb": 49592.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.771, "power_cpu_cv_mean_watts": 1.145, "power_sys_5v0_mean_watts": 6.667}, "timestamp": "2026-01-19T12:32:53.833208"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3396.704, "latencies_ms": [3396.704], "images_per_second": 0.294, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "Tennis racket: 2\nTennis ball: 1\nTennis outfit: 8\nTennis player: 1\nTennis trophy: 1\nTennis net: 1\nTennis court: 1\nTrees: 4", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13248.2, "ram_available_mb": 49592.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13249.7, "ram_available_mb": 49591.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.611, "power_cpu_cv_mean_watts": 1.789, "power_sys_5v0_mean_watts": 7.034}, "timestamp": "2026-01-19T12:32:59.266607"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2074.857, "latencies_ms": [2074.857], "images_per_second": 0.482, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are positioned in a line, with the children standing in the foreground and the adults in the background. The tennis court is situated in the background, separated from the children by a fence.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 13249.7, "ram_available_mb": 49591.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13251.3, "ram_available_mb": 49589.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.638, "power_cpu_cv_mean_watts": 1.273, "power_sys_5v0_mean_watts": 6.64}, "timestamp": "2026-01-19T12:33:03.391032"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2261.605, "latencies_ms": [2261.605], "images_per_second": 0.442, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A group of young tennis players, including adults and children, pose for a photo on a blue tennis court, celebrating their victory with a trophy. The setting appears to be a sunny outdoor area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13251.3, "ram_available_mb": 49589.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13252.2, "ram_available_mb": 49588.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.96, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 6.826}, "timestamp": "2026-01-19T12:33:07.681900"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2182.369, "latencies_ms": [2182.369], "images_per_second": 0.458, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The group is wearing bright, colorful clothing. The lighting appears to be natural sunlight, creating a vibrant atmosphere. The tennis court surface is blue, and the overall setting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13252.2, "ram_available_mb": 49588.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13258.5, "ram_available_mb": 49582.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.322, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T12:33:11.878388"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1909.599, "latencies_ms": [1909.599], "images_per_second": 0.524, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A couple sits under a bridge, watching a swan glide across the water, while another person captures the moment with a camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13258.5, "ram_available_mb": 49582.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13258.4, "ram_available_mb": 49582.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.281, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.673}, "timestamp": "2026-01-19T12:33:15.843903"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2665.023, "latencies_ms": [2665.023], "images_per_second": 0.375, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "bridge: 4\nswan: 1\nperson: 2\nperson: 1\nperson: 1\nperson: 1\nperson: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13258.4, "ram_available_mb": 49582.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13258.7, "ram_available_mb": 49582.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.317, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 6.936}, "timestamp": "2026-01-19T12:33:20.555440"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2740.691, "latencies_ms": [2740.691], "images_per_second": 0.365, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The swan is positioned near the center of the image, near the water's edge. The river stretches across the background, separating the swan from the people and the bridge. The swan is situated in the foreground, while the river and bridge are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13258.4, "ram_available_mb": 49582.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13258.6, "ram_available_mb": 49582.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.843, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.803}, "timestamp": "2026-01-19T12:33:25.319457"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2140.526, "latencies_ms": [2140.526], "images_per_second": 0.467, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene is set under a bridge over a river, where people are relaxing and observing a swan on the water's edge. The sun is shining brightly, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13258.6, "ram_available_mb": 49582.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13258.9, "ram_available_mb": 49582.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.944, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T12:33:29.489509"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3218.869, "latencies_ms": [3218.869], "images_per_second": 0.311, "prompt_tokens": 18, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The scene is bathed in warm sunlight, creating a golden glow on the water and the bridge. The colors are predominantly earthy tones, with greens from the trees contrasting with the lighter hues of the sky and sunlight. The lighting suggests a late afternoon or early evening setting, enhancing the overall ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13258.9, "ram_available_mb": 49582.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13260.3, "ram_available_mb": 49580.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.477, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 6.936}, "timestamp": "2026-01-19T12:33:34.736159"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1492.309, "latencies_ms": [1492.309], "images_per_second": 0.67, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A young woman is holding a Hello Kitty phone and appears to be taking a picture or selfie.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13260.3, "ram_available_mb": 49580.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 13261.1, "ram_available_mb": 49579.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.362, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.585}, "timestamp": "2026-01-19T12:33:38.295208"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2978.193, "latencies_ms": [2978.193], "images_per_second": 0.336, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "phone: 1\nphone case: 1\nphone: 1\nphone: 1\nphone: 1\nphone: 1\nphone: 1\nphone: 1\nphone: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13261.1, "ram_available_mb": 49579.8, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13260.7, "ram_available_mb": 49580.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.709, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T12:33:43.305533"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2181.241, "latencies_ms": [2181.241], "images_per_second": 0.458, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The Hello Kitty phone is held in the foreground, while the woman is positioned slightly behind and to the right of the phone. The background is blurred, indicating a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13260.7, "ram_available_mb": 49580.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13262.3, "ram_available_mb": 49578.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.156, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.812}, "timestamp": "2026-01-19T12:33:47.507864"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2979.727, "latencies_ms": [2979.727], "images_per_second": 0.336, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "A woman is holding a Hello Kitty phone and appears to be taking a picture or selfie. She is wearing a white top with a Hello Kitty design and a green beaded bracelet. The setting appears to be an outdoor event or gathering, with other people visible in the blurred background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13262.3, "ram_available_mb": 49578.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13260.4, "ram_available_mb": 49580.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.673, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 6.871}, "timestamp": "2026-01-19T12:33:52.520962"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2666.409, "latencies_ms": [2666.409], "images_per_second": 0.375, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The woman is wearing a white top with a gray and black pattern. She is holding a white Hello Kitty phone, which stands out against the background. The lighting appears to be natural, possibly outdoors, and the phone appears to be made of a smooth, plastic-like material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13260.4, "ram_available_mb": 49580.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13260.1, "ram_available_mb": 49580.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.226, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T12:33:57.218830"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1599.429, "latencies_ms": [1599.429], "images_per_second": 0.625, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A group of children is riding a red and gold train-like ride on a track in a room with wooden walls.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13260.1, "ram_available_mb": 49580.8, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13261.2, "ram_available_mb": 49579.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.149, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 6.073}, "timestamp": "2026-01-19T12:34:00.853903"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2170.623, "latencies_ms": [2170.623], "images_per_second": 0.461, "prompt_tokens": 21, "response_tokens_est": 23, "n_tiles": 1, "output_text": "train: 5\nchairs: 4\nchildren: 5\nfloor: 6\nwall: 6\nlighting: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13261.2, "ram_available_mb": 49579.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13260.6, "ram_available_mb": 49580.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.38, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 6.433}, "timestamp": "2026-01-19T12:34:05.065862"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1923.411, "latencies_ms": [1923.411], "images_per_second": 0.52, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main object is a red train car positioned in the foreground, moving away from the viewer. The background features the interior of a building with wooden walls and flooring.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13260.6, "ram_available_mb": 49580.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13261.0, "ram_available_mb": 49579.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.137, "power_cpu_cv_mean_watts": 1.389, "power_sys_5v0_mean_watts": 6.296}, "timestamp": "2026-01-19T12:34:09.021663"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2050.449, "latencies_ms": [2050.449], "images_per_second": 0.488, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A group of children are riding on a small, red train-like ride in a room with wooden walls. The setting appears to be indoors, possibly a children's play area or a similar recreational setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13261.0, "ram_available_mb": 49579.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13260.4, "ram_available_mb": 49580.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.267, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 6.363}, "timestamp": "2026-01-19T12:34:13.130765"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2111.234, "latencies_ms": [2111.234], "images_per_second": 0.474, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The train cars are red and appear to be made of plastic or metal. The lighting is warm and creates a cozy atmosphere. The floor appears to be made of a smooth, light-colored material.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13260.4, "ram_available_mb": 49580.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13259.5, "ram_available_mb": 49581.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.311, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.391}, "timestamp": "2026-01-19T12:34:17.301874"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1683.941, "latencies_ms": [1683.941], "images_per_second": 0.594, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A black and white close-up shot captures a half-eaten sandwich on a white plate, accompanied by a small white dish containing a sauce.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 13259.5, "ram_available_mb": 49581.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 13260.4, "ram_available_mb": 49580.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.4, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.645}, "timestamp": "2026-01-19T12:34:21.029565"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2683.344, "latencies_ms": [2683.344], "images_per_second": 0.373, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "sandwich: 2\nbun: 1\ncheese: 1\nmayonnaise: 1\nbacon: 1\nbread: 1\nplate: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13260.4, "ram_available_mb": 49580.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 13261.0, "ram_available_mb": 49579.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.407, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.982}, "timestamp": "2026-01-19T12:34:25.752863"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1899.344, "latencies_ms": [1899.344], "images_per_second": 0.526, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The sandwich is positioned in the foreground, partially obscuring the background. The small white dish is situated near the sandwich, closer to the foreground.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13261.0, "ram_available_mb": 49579.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13261.0, "ram_available_mb": 49579.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.135, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.773}, "timestamp": "2026-01-19T12:34:29.721273"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2368.685, "latencies_ms": [2368.685], "images_per_second": 0.422, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a close-up view of a partially eaten sandwich on a white plate. The sandwich appears to contain chocolate and cream filling. The setting seems to be a casual dining environment, possibly a restaurant or caf\u00e9.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13261.0, "ram_available_mb": 49579.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13265.3, "ram_available_mb": 49575.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.163, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T12:34:34.137421"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3193.971, "latencies_ms": [3193.971], "images_per_second": 0.313, "prompt_tokens": 18, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The sandwich appears to be made of dark-colored bread, possibly a dark rye or whole wheat roll. The lighting is soft and diffused, creating a gentle contrast between the sandwich and the plate. The sandwich is served on a white plate, which contrasts with the dark tones of the food. The overall atmosphere is calm and intimate.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13265.3, "ram_available_mb": 49575.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13273.9, "ram_available_mb": 49567.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.979, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.04}, "timestamp": "2026-01-19T12:34:39.371891"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1505.474, "latencies_ms": [1505.474], "images_per_second": 0.664, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A person in a wetsuit stands on a paddleboard, holding a paddle and gazing out at the calm ocean.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13273.9, "ram_available_mb": 49567.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13271.4, "ram_available_mb": 49569.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.033, "power_cpu_cv_mean_watts": 1.056, "power_sys_5v0_mean_watts": 6.011}, "timestamp": "2026-01-19T12:34:42.930985"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2403.825, "latencies_ms": [2403.825], "images_per_second": 0.416, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "person: 1\nboard: 1\npaddle: 1\nwater: 1\nshoreline: 1\nsky: 1\nbuildings: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13271.4, "ram_available_mb": 49569.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13271.0, "ram_available_mb": 49569.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.365, "power_cpu_cv_mean_watts": 1.624, "power_sys_5v0_mean_watts": 6.557}, "timestamp": "2026-01-19T12:34:47.387030"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1979.431, "latencies_ms": [1979.431], "images_per_second": 0.505, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The paddleboarder is positioned in the foreground of the image, moving towards the left side of the frame. The calm water extends to the background, creating a serene and expansive setting.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13271.0, "ram_available_mb": 49569.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13272.1, "ram_available_mb": 49568.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.467, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.375}, "timestamp": "2026-01-19T12:34:51.412146"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2234.103, "latencies_ms": [2234.103], "images_per_second": 0.448, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene depicts a lone paddleboarder navigating calm waters, skillfully maneuvering with a paddle. In the distance, a shoreline with buildings is visible, suggesting a coastal or lakeside location.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13272.1, "ram_available_mb": 49568.8, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13272.8, "ram_available_mb": 49568.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.507, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.58}, "timestamp": "2026-01-19T12:34:55.687189"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2422.575, "latencies_ms": [2422.575], "images_per_second": 0.413, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The water appears relatively calm and grayish-blue. The lighting suggests a daytime scene, possibly overcast. The paddleboard is white and sleek, contrasting with the darker tones of the water and the person's attire.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13272.8, "ram_available_mb": 49568.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13273.7, "ram_available_mb": 49567.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.638, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 6.562}, "timestamp": "2026-01-19T12:35:00.142115"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1674.675, "latencies_ms": [1674.675], "images_per_second": 0.597, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A white desk holds a laptop, desktop computer, keyboard, mouse, and external hard drive, creating a functional workspace.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 13273.7, "ram_available_mb": 49567.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13273.8, "ram_available_mb": 49567.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.187, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.156}, "timestamp": "2026-01-19T12:35:03.862773"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2942.899, "latencies_ms": [2942.899], "images_per_second": 0.34, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "laptop: 2\nkeyboard: 1\nmouse: 1\nprinter: 1\nspeaker: 2\nmonitor: 1\nwindow blinds: 1\ndesk: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13273.8, "ram_available_mb": 49567.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13271.9, "ram_available_mb": 49569.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.535, "power_cpu_cv_mean_watts": 1.77, "power_sys_5v0_mean_watts": 6.711}, "timestamp": "2026-01-19T12:35:08.836386"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1913.696, "latencies_ms": [1913.696], "images_per_second": 0.523, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The laptop is positioned to the left of the monitor and keyboard, closer to the viewer. The printer is situated in the background, slightly further away than the laptop and monitor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13271.9, "ram_available_mb": 49569.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13271.7, "ram_available_mb": 49569.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.431, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.316}, "timestamp": "2026-01-19T12:35:12.771409"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2616.465, "latencies_ms": [2616.465], "images_per_second": 0.382, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a well-organized workspace featuring a desktop computer with a monitor, keyboard, and mouse, along with two speakers. A laptop is also present on the desk. The setting appears to be a home office or a workspace with a window providing natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13271.7, "ram_available_mb": 49569.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13270.9, "ram_available_mb": 49570.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.37, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 6.508}, "timestamp": "2026-01-19T12:35:17.427593"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2742.329, "latencies_ms": [2742.329], "images_per_second": 0.365, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The desk is white and appears to be made of a smooth material. The lighting in the room is soft and diffused, suggesting natural light from a window with blinds. The materials include metal for the laptop, plastic for the speakers, and possibly other computer peripherals.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13270.9, "ram_available_mb": 49570.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13270.4, "ram_available_mb": 49570.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.436, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 6.625}, "timestamp": "2026-01-19T12:35:22.188926"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2185.976, "latencies_ms": [2185.976], "images_per_second": 0.457, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "Vehicles travel under a green highway overpass with directional signs for North Ventura 101, Hollywood Blvd, and Sunset Blvd.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 13270.4, "ram_available_mb": 49570.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13270.8, "ram_available_mb": 49570.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.738, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.73}, "timestamp": "2026-01-19T12:35:26.412320"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3062.687, "latencies_ms": [3062.687], "images_per_second": 0.327, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "highway overpass: 4\ngreen highway signs: 4\ntaxi: 2\nvan: 2\nSUV: 2\ncar: 2\ntrees: 2\nbuildings: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13270.8, "ram_available_mb": 49570.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13271.1, "ram_available_mb": 49569.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.609, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 6.963}, "timestamp": "2026-01-19T12:35:31.490209"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2961.269, "latencies_ms": [2961.269], "images_per_second": 0.338, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The left foreground features the left-facing traffic sign and the taxi. The background includes other vehicles and street signs. The left-facing sign is positioned in the foreground, while the taxi is on the left side of the image. The background also contains other traffic signs and street elements.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13271.1, "ram_available_mb": 49569.8, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13270.8, "ram_available_mb": 49570.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.673, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 6.846}, "timestamp": "2026-01-19T12:35:36.482012"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2974.197, "latencies_ms": [2974.197], "images_per_second": 0.336, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a busy highway intersection with multiple vehicles driving under a bridge. Green overhead signs provide directions to various locations, including Ventura, Hollywood, and Sunset Blvd. The setting appears to be in a suburban or urban area with trees and buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13270.8, "ram_available_mb": 49570.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13271.6, "ram_available_mb": 49569.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.709, "power_cpu_cv_mean_watts": 1.569, "power_sys_5v0_mean_watts": 6.883}, "timestamp": "2026-01-19T12:35:41.486633"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1773.141, "latencies_ms": [1773.141], "images_per_second": 0.564, "prompt_tokens": 18, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The highway signs are green and white. The sky is clear and blue. The highway is busy with cars and taxis.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13271.6, "ram_available_mb": 49569.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13270.4, "ram_available_mb": 49570.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.23, "power_cpu_cv_mean_watts": 1.145, "power_sys_5v0_mean_watts": 6.71}, "timestamp": "2026-01-19T12:35:45.320804"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2137.149, "latencies_ms": [2137.149], "images_per_second": 0.468, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A red double-decker bus, numbered 15 and labeled \"ALDWYCH,\" is driving down a city street lined with buildings and trees.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13270.4, "ram_available_mb": 49570.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13276.0, "ram_available_mb": 49564.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.991, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.723}, "timestamp": "2026-01-19T12:35:49.496600"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2633.015, "latencies_ms": [2633.015], "images_per_second": 0.38, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "double-decker bus: 2\nbuilding: 2\ntrees: 2\npeople: 2\nbus: 2\nroad: 2\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13276.0, "ram_available_mb": 49564.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13275.6, "ram_available_mb": 49565.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.243, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T12:35:54.163788"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2386.24, "latencies_ms": [2386.24], "images_per_second": 0.419, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main object is a red double-decker bus driving on the right side of the road. The background features other vehicles and buildings, suggesting an urban setting. The foreground is dominated by the bus, with people walking nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13275.6, "ram_available_mb": 49565.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13274.2, "ram_available_mb": 49566.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.848, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.965}, "timestamp": "2026-01-19T12:35:58.592163"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2352.494, "latencies_ms": [2352.494], "images_per_second": 0.425, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A red double-decker bus is driving down a city street, passing a green park with people walking nearby. Buildings are visible in the background, and a few other buses can be seen in the distance.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13274.2, "ram_available_mb": 49566.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13275.1, "ram_available_mb": 49565.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.741, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.816}, "timestamp": "2026-01-19T12:36:03.001839"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2499.12, "latencies_ms": [2499.12], "images_per_second": 0.4, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The red double-decker bus is brightly colored, primarily red with yellow accents. The lighting appears to be natural daylight, creating a warm and inviting atmosphere. The bus appears to be made of sturdy materials typical of older vehicles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13275.1, "ram_available_mb": 49565.8, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13276.2, "ram_available_mb": 49564.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.466, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.884}, "timestamp": "2026-01-19T12:36:07.514337"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1605.996, "latencies_ms": [1605.996], "images_per_second": 0.623, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A black and white cat with yellow eyes is lying on top of an open silver laptop, gazing at the camera.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13276.2, "ram_available_mb": 49564.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13276.5, "ram_available_mb": 49564.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.905, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.597}, "timestamp": "2026-01-19T12:36:11.166130"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3030.063, "latencies_ms": [3030.063], "images_per_second": 0.33, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "cat: 2\nlaptop: 1\nkeyboard: 1\ncord: 1\nlaptop power adapter: 1\nwall: 1\npaper: 1\ngreen pen: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13276.5, "ram_available_mb": 49564.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13277.9, "ram_available_mb": 49563.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.122, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 6.975}, "timestamp": "2026-01-19T12:36:16.215645"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1940.833, "latencies_ms": [1940.833], "images_per_second": 0.515, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The black and white cat is positioned in the foreground, partially obscuring the laptop. The laptop is situated near the cat, occupying the central portion of the image.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13277.9, "ram_available_mb": 49563.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13277.8, "ram_available_mb": 49563.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.815, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T12:36:20.174283"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1719.326, "latencies_ms": [1719.326], "images_per_second": 0.582, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A black and white cat is lying on top of an open laptop computer. The cat appears to be resting or relaxing on the laptop's surface.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13277.8, "ram_available_mb": 49563.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13277.9, "ram_available_mb": 49563.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.916, "power_cpu_cv_mean_watts": 1.145, "power_sys_5v0_mean_watts": 6.688}, "timestamp": "2026-01-19T12:36:23.939485"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2136.232, "latencies_ms": [2136.232], "images_per_second": 0.468, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The black and white cat has striking yellow eyes. The laptop is silver and appears to be made of metal. The lighting in the image is soft and diffused, suggesting indoor lighting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13277.9, "ram_available_mb": 49563.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13277.9, "ram_available_mb": 49563.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.875, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 6.801}, "timestamp": "2026-01-19T12:36:28.090170"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1799.938, "latencies_ms": [1799.938], "images_per_second": 0.556, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Two large commercial airplanes fly in formation over the iconic Sydney Harbour Bridge, passing over the iconic Sydney Opera House.", "error": null, "sys_before": {"cpu_percent": 17.4, "ram_used_mb": 13277.9, "ram_available_mb": 49563.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13279.1, "ram_available_mb": 49561.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.058, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.681}, "timestamp": "2026-01-19T12:36:31.916807"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2454.396, "latencies_ms": [2454.396], "images_per_second": 0.407, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "airplanes: 2\nbridge: 1\nsky: 1\ncity: 1\nsydney: 1\nsydney opera house: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13278.4, "ram_available_mb": 49562.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13278.1, "ram_available_mb": 49562.8, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.567, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 6.924}, "timestamp": "2026-01-19T12:36:36.429386"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2452.052, "latencies_ms": [2452.052], "images_per_second": 0.408, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The large airplane is positioned above the bridge, flying towards the right side of the image. The bridge spans across the foreground, connecting the two objects. The Sydney Opera House is visible in the background, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13278.1, "ram_available_mb": 49562.8, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13278.3, "ram_available_mb": 49562.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.743, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T12:36:40.915682"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2191.833, "latencies_ms": [2191.833], "images_per_second": 0.456, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Two large airplanes are flying over a bridge, likely Sydney Harbour Bridge, amidst a cloudy sky. The bridge spans the water, with the iconic Sydney Opera House visible in the distance.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13278.3, "ram_available_mb": 49562.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13277.7, "ram_available_mb": 49563.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.85, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.73}, "timestamp": "2026-01-19T12:36:45.146988"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2600.387, "latencies_ms": [2600.387], "images_per_second": 0.385, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The sky is mostly cloudy with patches of blue. The lighting suggests an overcast day. The planes appear to be dark-colored, possibly jetliners. The bridge is constructed of dark metal and spans a body of water.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13277.7, "ram_available_mb": 49563.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13276.9, "ram_available_mb": 49564.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.063, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 6.883}, "timestamp": "2026-01-19T12:36:49.799762"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1709.245, "latencies_ms": [1709.245], "images_per_second": 0.585, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A zebra stands tall in a field, its distinctive black and white stripes contrasting against the tall grass as it nurses from its hindquarters.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 13276.9, "ram_available_mb": 49564.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13277.5, "ram_available_mb": 49563.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.614, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T12:36:53.559986"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2107.659, "latencies_ms": [2107.659], "images_per_second": 0.474, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "zebra: 2\ngrass: 2\ntree: 0\nanimal: 1\nnursing zebra: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13277.5, "ram_available_mb": 49563.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13278.0, "ram_available_mb": 49562.9, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.249, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.717}, "timestamp": "2026-01-19T12:36:57.706087"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2494.946, "latencies_ms": [2494.946], "images_per_second": 0.401, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The zebra is positioned in the foreground, with its body partially obscuring the cow behind it. The cow is situated in the background, slightly out of focus. The zebra and cow are close together, suggesting they are in a relatively close proximity.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13278.0, "ram_available_mb": 49562.9, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13278.2, "ram_available_mb": 49562.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.607, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.834}, "timestamp": "2026-01-19T12:37:02.215382"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1998.447, "latencies_ms": [1998.447], "images_per_second": 0.5, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene depicts a zebra nursing from its mother in a grassy field. The black and white image highlights the zebra's distinctive stripes and the soft, natural environment.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13278.2, "ram_available_mb": 49562.7, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13278.4, "ram_available_mb": 49562.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.226, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.728}, "timestamp": "2026-01-19T12:37:06.247599"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2274.878, "latencies_ms": [2274.878], "images_per_second": 0.44, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The zebra's coat is predominantly black and white, creating a striking contrast against the lighter background. The lighting in the image appears to be natural daylight, enhancing the visibility of the zebra's stripes and features.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13278.4, "ram_available_mb": 49562.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13279.9, "ram_available_mb": 49561.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.626, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.764}, "timestamp": "2026-01-19T12:37:10.536082"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1765.838, "latencies_ms": [1765.838], "images_per_second": 0.566, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The room features a bed with a colorful, patterned comforter, a small round table with a chair, and a stone wall.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 13279.4, "ram_available_mb": 49561.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 13279.2, "ram_available_mb": 49561.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.885, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.666}, "timestamp": "2026-01-19T12:37:14.354039"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2727.391, "latencies_ms": [2727.391], "images_per_second": 0.367, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "bed: 1\ntable: 1\nchair: 1\nwindow: 2\nstone wall: 2\ndoor: 2\nlight fixture: 1\ncar: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13279.2, "ram_available_mb": 49561.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13280.5, "ram_available_mb": 49560.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.392, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.902}, "timestamp": "2026-01-19T12:37:19.114299"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2088.132, "latencies_ms": [2088.132], "images_per_second": 0.479, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bed occupies the foreground, while the table and chair are positioned near the left side of the image. The window and door are located in the background, offering a view outside.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13280.5, "ram_available_mb": 49560.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13280.6, "ram_available_mb": 49560.3, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.578, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T12:37:23.218210"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2378.981, "latencies_ms": [2378.981], "images_per_second": 0.42, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The room features a bed with a colorful quilt, a small round table with a chair, and a stone wall. The scene suggests a cozy and lived-in space, possibly a bedroom or a small living area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13280.6, "ram_available_mb": 49560.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13279.4, "ram_available_mb": 49561.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.637, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T12:37:27.615954"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2417.404, "latencies_ms": [2417.404], "images_per_second": 0.414, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The room features a purple bedspread, a black metal bed frame, and a purple wall. The lighting is soft and diffused, creating a cozy atmosphere. The bed appears to be made of metal and has a patterned cover.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13279.4, "ram_available_mb": 49561.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13279.7, "ram_available_mb": 49561.2, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.326, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.839}, "timestamp": "2026-01-19T12:37:32.054507"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1915.368, "latencies_ms": [1915.368], "images_per_second": 0.522, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A purple bus numbered 96, labeled \"South Tyne,\" is stopped at a bus stop, waiting for passengers.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13279.7, "ram_available_mb": 49561.2, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13281.4, "ram_available_mb": 49559.5, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.307, "power_cpu_cv_mean_watts": 1.149, "power_sys_5v0_mean_watts": 6.659}, "timestamp": "2026-01-19T12:37:36.007269"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4552.415, "latencies_ms": [4552.415], "images_per_second": 0.22, "prompt_tokens": 21, "response_tokens_est": 57, "n_tiles": 1, "output_text": "bus: 5\nperson: 1\nwindshield wipers: 2\nbus number: 96\nbus branding: South Tyne\nbus license plate: NA52 BUU\nbus windows: 10\nbus doors: 2\nbus front bumper: 1\nbus side mirrors: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13281.4, "ram_available_mb": 49559.5, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13280.5, "ram_available_mb": 49560.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.423, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 7.023}, "timestamp": "2026-01-19T12:37:42.595466"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2251.403, "latencies_ms": [2251.403], "images_per_second": 0.444, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, moving towards the viewer. The person walking nearby is positioned in the background, slightly further away. The bus is situated on a street, with buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13280.5, "ram_available_mb": 49560.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13281.8, "ram_available_mb": 49559.1, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.848, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.816}, "timestamp": "2026-01-19T12:37:46.866180"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2958.142, "latencies_ms": [2958.142], "images_per_second": 0.338, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A purple bus labeled \"South Tyne\" is driving down a city street, passing a pedestrian. A man is visible inside the bus, seemingly waiting or preparing to board. The scene suggests a typical urban environment with buildings, trees, and street infrastructure.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13281.8, "ram_available_mb": 49559.1, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13283.5, "ram_available_mb": 49557.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.753, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 6.942}, "timestamp": "2026-01-19T12:37:51.838522"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2252.759, "latencies_ms": [2252.759], "images_per_second": 0.444, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The bus is purple. The bus has a large windshield and appears to be a modern model. The bus is well-lit, suggesting it is likely in daylight. The bus appears to be made of metal.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13283.5, "ram_available_mb": 49557.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13283.3, "ram_available_mb": 49557.6, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.805, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.843}, "timestamp": "2026-01-19T12:37:56.124086"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1607.943, "latencies_ms": [1607.943], "images_per_second": 0.622, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A white bowl filled with shiny green apples sits on a table, displaying their natural shape and vibrant color.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13283.3, "ram_available_mb": 49557.6, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13281.9, "ram_available_mb": 49559.0, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.967, "power_cpu_cv_mean_watts": 1.017, "power_sys_5v0_mean_watts": 6.567}, "timestamp": "2026-01-19T12:37:59.780622"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2942.346, "latencies_ms": [2942.346], "images_per_second": 0.34, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8\ngreen apple: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13281.9, "ram_available_mb": 49559.0, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13281.2, "ram_available_mb": 49559.7, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.992, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 7.001}, "timestamp": "2026-01-19T12:38:04.739287"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1966.241, "latencies_ms": [1966.241], "images_per_second": 0.509, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The main objects are positioned close together, creating a sense of proximity and shared space. The apples are situated in the foreground, while the background is dark and out of focus.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13280.6, "ram_available_mb": 49560.3, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13281.5, "ram_available_mb": 49559.4, "ram_percent": 21.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.277, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.728}, "timestamp": "2026-01-19T12:38:08.736807"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2135.319, "latencies_ms": [2135.319], "images_per_second": 0.468, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A white bowl filled with green apples sits on a dark surface, possibly a table. The apples are piled together, showcasing their vibrant green color and smooth skin.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13281.5, "ram_available_mb": 49559.4, "ram_percent": 21.1}, "sys_after": {"cpu_percent": 10.6, "ram_used_mb": 13136.9, "ram_available_mb": 49704.0, "ram_percent": 20.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.085, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T12:38:12.917977"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1948.013, "latencies_ms": [1948.013], "images_per_second": 0.513, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The apples are bright green, indicating they are likely freshly picked. The lighting in the image is soft and warm, enhancing the vibrant green color of the apples.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13137.2, "ram_available_mb": 49703.7, "ram_percent": 20.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.155, "power_cpu_cv_mean_watts": 2.404, "power_sys_5v0_mean_watts": 7.018}, "timestamp": "2026-01-19T12:38:16.897850"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1956.149, "latencies_ms": [1956.149], "images_per_second": 0.511, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A baseball game is in progress, with a batter mid-swing, a pitcher preparing to throw, and a catcher crouched behind home plate.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.152, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T12:38:20.909468"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3819.759, "latencies_ms": [3819.759], "images_per_second": 0.262, "prompt_tokens": 21, "response_tokens_est": 52, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball: 1\nbaseball glove: 1\nbaseball: 1\nbaseball field: 1\nbaseball diamond: 1\nbaseball pitcher: 1\nbaseball umpire: 1\nbaseball catcher: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12566.8, "ram_available_mb": 50274.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.087, "power_cpu_cv_mean_watts": 1.878, "power_sys_5v0_mean_watts": 7.16}, "timestamp": "2026-01-19T12:38:26.762279"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1825.535, "latencies_ms": [1825.535], "images_per_second": 0.548, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The pitcher is on the left side of the image, while the batter is in the foreground. The background is filled with green grass, extending to the outfield.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.547, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T12:38:30.624637"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2746.413, "latencies_ms": [2746.413], "images_per_second": 0.364, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A baseball game is in progress, with a batter mid-swing, a pitcher preparing to throw, and a catcher crouched behind home plate. The scene takes place on a well-maintained baseball field with green grass and a brown dirt infield.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.409, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T12:38:35.410894"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2441.244, "latencies_ms": [2441.244], "images_per_second": 0.41, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The baseball game is played under bright, sunny lighting. The field is well-maintained and appears to be made of natural dirt. The batter is wearing a red and white uniform, and the pitcher is wearing a gray uniform.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12567.5, "ram_available_mb": 50273.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.525, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 6.93}, "timestamp": "2026-01-19T12:38:39.869270"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2290.858, "latencies_ms": [2290.858], "images_per_second": 0.437, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A table is set with an assortment of desserts, fruits, and snacks, including a large fruit-topped cake, cheese and crackers, grapes, bread, and wine glasses.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12567.5, "ram_available_mb": 50273.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.849, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.748}, "timestamp": "2026-01-19T12:38:44.185202"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3734.586, "latencies_ms": [3734.586], "images_per_second": 0.268, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "cake: 1\nraspberry: 1\nblueberry: 1\nwine glass: 2\nwater glass: 1\nbread: 2\ncheese: 2\ngrapes: 2\nbutter knife: 1\nserving spatula: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.25, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.042}, "timestamp": "2026-01-19T12:38:49.961421"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2540.117, "latencies_ms": [2540.117], "images_per_second": 0.394, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main objects are positioned in a balanced and visually appealing manner. The cake and fruit platter are in the foreground, while the table setting with plates, glasses, and cutlery extends into the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.366, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.914}, "timestamp": "2026-01-19T12:38:54.539988"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3327.31, "latencies_ms": [3327.31], "images_per_second": 0.301, "prompt_tokens": 19, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The scene depicts an outdoor gathering with a table laden with food and drinks. A large cake with fresh berries is prominently displayed, alongside a platter of cheese and crackers. Various wine glasses, plates, and cutlery are arranged on the table, ready for guests to enjoy the feast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.7, "ram_available_mb": 50274.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.381, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 6.973}, "timestamp": "2026-01-19T12:38:59.890718"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2453.083, "latencies_ms": [2453.083], "images_per_second": 0.408, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The table is covered with a red tablecloth. The food items are arranged on plates, platters, and serving dishes. The lighting appears to be natural and bright, enhancing the visual appeal of the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12566.9, "ram_available_mb": 50274.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.326, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.834}, "timestamp": "2026-01-19T12:39:04.408228"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1889.731, "latencies_ms": [1889.731], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A man wearing a black shirt is riding a wave on a blue boogie board, skillfully navigating the powerful green wave.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.147, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.632}, "timestamp": "2026-01-19T12:39:08.356094"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2242.563, "latencies_ms": [2242.563], "images_per_second": 0.446, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "person: 1\nbodyboard: 1\nwave: 1\nwater: 1\nshore: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12567.2, "ram_available_mb": 50273.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.783, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.843}, "timestamp": "2026-01-19T12:39:12.652074"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2125.651, "latencies_ms": [2125.651], "images_per_second": 0.47, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The man is positioned near the center of the image, riding a wave in the ocean. The wave is breaking towards the right side of the image, creating a dynamic and energetic scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12567.0, "ram_available_mb": 50273.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12564.9, "ram_available_mb": 50276.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.709, "power_cpu_cv_mean_watts": 1.226, "power_sys_5v0_mean_watts": 6.729}, "timestamp": "2026-01-19T12:39:16.823310"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2126.651, "latencies_ms": [2126.651], "images_per_second": 0.47, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A man is riding a wave on a blue boogie board in the ocean. He is surrounded by green water and white foam. The scene suggests a sunny day at the beach.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12564.9, "ram_available_mb": 50276.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12564.6, "ram_available_mb": 50276.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.352, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:39:20.965850"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2340.268, "latencies_ms": [2340.268], "images_per_second": 0.427, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The water is a vibrant green color, creating a striking contrast with the man's black shirt. The lighting appears to be natural and bright, suggesting an overcast day. The wave is breaking, creating a dynamic scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12564.6, "ram_available_mb": 50276.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12562.7, "ram_available_mb": 50278.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.637, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.779}, "timestamp": "2026-01-19T12:39:25.339432"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1460.08, "latencies_ms": [1460.08], "images_per_second": 0.685, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The black and white photograph shows a group of children gathered in front of a brick building, posing for a group photograph.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12562.7, "ram_available_mb": 50278.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12562.7, "ram_available_mb": 50278.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.035, "power_cpu_cv_mean_watts": 1.019, "power_sys_5v0_mean_watts": 5.947}, "timestamp": "2026-01-19T12:39:28.825036"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3001.76, "latencies_ms": [3001.76], "images_per_second": 0.333, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "child: 12\nboy: 8\ngirl: 8\nman: 2\nwoman: 1\nbuilding: 1\nsweater: 1\njacket: 1\ndress: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12562.7, "ram_available_mb": 50278.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12561.3, "ram_available_mb": 50279.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.485, "power_cpu_cv_mean_watts": 1.753, "power_sys_5v0_mean_watts": 6.648}, "timestamp": "2026-01-19T12:39:33.845933"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1982.36, "latencies_ms": [1982.36], "images_per_second": 0.504, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are arranged in a symmetrical and organized manner, creating a sense of balance and order. The children are positioned both in the foreground and background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12561.3, "ram_available_mb": 50279.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12561.2, "ram_available_mb": 50279.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.977, "power_cpu_cv_mean_watts": 1.336, "power_sys_5v0_mean_watts": 6.323}, "timestamp": "2026-01-19T12:39:37.871289"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2497.527, "latencies_ms": [2497.527], "images_per_second": 0.4, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The black and white photo depicts a group of children gathered together, possibly for a school photo session. The children are dressed in formal attire and appear to be of elementary school age. They are standing and sitting in a group, possibly in front of a brick wall or building.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12561.2, "ram_available_mb": 50279.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12561.2, "ram_available_mb": 50279.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.518, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 6.663}, "timestamp": "2026-01-19T12:39:42.399072"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3723.151, "latencies_ms": [3723.151], "images_per_second": 0.269, "prompt_tokens": 18, "response_tokens_est": 80, "n_tiles": 1, "output_text": "The black and white photograph captures a lively scene of children gathered together, likely in a school setting. The lighting is soft and diffused, creating a gentle atmosphere. The children appear to be dressed in formal attire, suggesting the photo was taken during a school event or class photo session. The materials used include clothing, paper, and possibly a backdrop, contributing to the overall vintage feel of the image.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12560.6, "ram_available_mb": 50280.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12560.7, "ram_available_mb": 50280.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.765, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 6.834}, "timestamp": "2026-01-19T12:39:48.148527"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1926.92, "latencies_ms": [1926.92], "images_per_second": 0.519, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A white rectangular platter holds a selection of grilled bread pieces, accompanied by a small white bowl and a wrapped piece of bread.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12560.7, "ram_available_mb": 50280.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12560.7, "ram_available_mb": 50280.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.467, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T12:39:52.103487"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3025.773, "latencies_ms": [3025.773], "images_per_second": 0.33, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "toast: 6\nbread: 6\nspoon: 1\nsmall bowl: 1\nwooden stick: 1\nglass of red wine: 1\nplate: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12560.7, "ram_available_mb": 50280.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12561.0, "ram_available_mb": 50279.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.657, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.003}, "timestamp": "2026-01-19T12:39:57.151452"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2634.677, "latencies_ms": [2634.677], "images_per_second": 0.38, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The foreground features the bread, butter, and sauce arranged on a white platter. The background includes a wooden table, a wine glass, and a knife. The bread and sauce are placed close to the viewer, while the butter and sauce are further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12561.0, "ram_available_mb": 50279.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12560.5, "ram_available_mb": 50280.4, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.299, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 6.996}, "timestamp": "2026-01-19T12:40:01.834404"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2567.351, "latencies_ms": [2567.351], "images_per_second": 0.39, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The scene is set on a wooden table with a white rectangular platter containing various food items, including toasted bread, a small white bowl, and a wrapped item. A glass of red wine and a knife are also present on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12560.5, "ram_available_mb": 50280.4, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12560.2, "ram_available_mb": 50280.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.407, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.993}, "timestamp": "2026-01-19T12:40:06.439564"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2474.53, "latencies_ms": [2474.53], "images_per_second": 0.404, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The bread appears golden-brown, indicating it has been toasted or grilled. The table setting includes white plates, a wine glass, and a small white bowl. The overall ambiance suggests a warm, inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12560.2, "ram_available_mb": 50280.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12560.0, "ram_available_mb": 50280.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.346, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T12:40:10.947022"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2145.863, "latencies_ms": [2145.863], "images_per_second": 0.466, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A skier wearing a colorful jacket and pants jumps high in the air, holding ski poles, while other skiers and snowboarders watch from the snowy slope below.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12560.0, "ram_available_mb": 50280.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12560.0, "ram_available_mb": 50280.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.015, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.872}, "timestamp": "2026-01-19T12:40:15.131813"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2621.839, "latencies_ms": [2621.839], "images_per_second": 0.381, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "person: 1\nskis: 2\nsnowboard: 0\npoles: 2\ntree: 6\nsnow: 6\nsky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12560.0, "ram_available_mb": 50280.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12560.0, "ram_available_mb": 50280.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.273, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.936}, "timestamp": "2026-01-19T12:40:19.779801"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3196.706, "latencies_ms": [3196.706], "images_per_second": 0.313, "prompt_tokens": 25, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, mid-jump, against a backdrop of snow-covered trees and a clear blue sky. The foreground features the skier's skis and poles, while the background includes more trees and a clear sky. The skier is relatively close to the viewer, suggesting they are in close proximity.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12560.0, "ram_available_mb": 50280.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12559.9, "ram_available_mb": 50281.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.517, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T12:40:25.037770"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2193.946, "latencies_ms": [2193.946], "images_per_second": 0.456, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A skier is performing a jump off a snow ramp in a snowy mountain area with evergreen trees in the background. Another skier is watching the action from below.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12559.9, "ram_available_mb": 50281.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12560.0, "ram_available_mb": 50280.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.969, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T12:40:29.260146"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2760.895, "latencies_ms": [2760.895], "images_per_second": 0.362, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The skier is wearing a vibrant, multicolored jacket. The scene is brightly lit, suggesting sunny weather conditions. The skis are white and appear to be made of metal. The snow is pristine white, typical of a ski resort.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12560.0, "ram_available_mb": 50280.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12560.4, "ram_available_mb": 50280.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.955, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.946}, "timestamp": "2026-01-19T12:40:34.046539"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1955.516, "latencies_ms": [1955.516], "images_per_second": 0.511, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A person in winter clothing and ski poles stands on a snowy mountain peak, facing a vast snowy landscape under a blue sky with fluffy white clouds.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12560.4, "ram_available_mb": 50280.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12560.2, "ram_available_mb": 50280.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.974, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.861}, "timestamp": "2026-01-19T12:40:38.059149"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2861.779, "latencies_ms": [2861.779], "images_per_second": 0.349, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "sky: 5\nclouds: 3\nperson: 1\nskis: 1\nsnow: 6\nrocks: 2\ntree: 1\nmountain: 4", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12560.2, "ram_available_mb": 50280.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12560.2, "ram_available_mb": 50280.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.858, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T12:40:42.960999"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2781.505, "latencies_ms": [2781.505], "images_per_second": 0.36, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, facing the snowy mountain landscape. The foreground is relatively clear of snow, while the background features snow-covered mountains. The skier is relatively close to the foreground, implying they are in a relatively close proximity to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12560.2, "ram_available_mb": 50280.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12560.4, "ram_available_mb": 50280.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.462, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 6.973}, "timestamp": "2026-01-19T12:40:47.767633"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2558.654, "latencies_ms": [2558.654], "images_per_second": 0.391, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A person is cross-country skiing across a snowy mountain landscape under a bright blue sky with fluffy white clouds. The scene captures the beauty and tranquility of winter sports amidst the vast, snow-covered terrain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12560.4, "ram_available_mb": 50280.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12560.2, "ram_available_mb": 50280.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.121, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T12:40:52.350126"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2611.734, "latencies_ms": [2611.734], "images_per_second": 0.383, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The sky is a vibrant blue with fluffy white clouds. The snow on the ground is bright white, contrasting with the darker tones of the mountains and trees. The lighting suggests a sunny day, with shadows cast by the snow-covered landscape.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12560.2, "ram_available_mb": 50280.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12559.8, "ram_available_mb": 50281.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.178, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.902}, "timestamp": "2026-01-19T12:40:56.984373"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1448.219, "latencies_ms": [1448.219], "images_per_second": 0.691, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A chocolate glazed donut and a ripe banana are placed together on a brown surface.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12559.8, "ram_available_mb": 50281.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12559.0, "ram_available_mb": 50281.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.142, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 6.066}, "timestamp": "2026-01-19T12:41:00.507134"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1758.464, "latencies_ms": [1758.464], "images_per_second": 0.569, "prompt_tokens": 21, "response_tokens_est": 20, "n_tiles": 1, "output_text": "donut: 1\nbanana: 1\nplastic bag: 1\nbrown surface: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12559.0, "ram_available_mb": 50281.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12558.9, "ram_available_mb": 50282.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.931, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 6.278}, "timestamp": "2026-01-19T12:41:04.322725"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1857.901, "latencies_ms": [1857.901], "images_per_second": 0.538, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The banana is positioned in the foreground, partially obscuring the donut. The donut is situated in the background, partially obscured by the banana.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12558.9, "ram_available_mb": 50282.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12558.9, "ram_available_mb": 50282.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.043, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.235}, "timestamp": "2026-01-19T12:41:08.217943"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2117.217, "latencies_ms": [2117.217], "images_per_second": 0.472, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A chocolate-glazed donut and a ripe banana are placed together in a plastic bag. The bag appears to be sealed and contains food items, likely prepared for a quick snack.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12558.9, "ram_available_mb": 50282.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12559.1, "ram_available_mb": 50281.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.287, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.386}, "timestamp": "2026-01-19T12:41:12.354365"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1987.928, "latencies_ms": [1987.928], "images_per_second": 0.503, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The donut is brown and appears glazed. The banana is yellow and has a slight bruise. The bag appears to be made of a clear plastic material.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12559.1, "ram_available_mb": 50281.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12559.1, "ram_available_mb": 50281.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.117, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.337}, "timestamp": "2026-01-19T12:41:16.401337"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2006.877, "latencies_ms": [2006.877], "images_per_second": 0.498, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A white mug with a skull and crossbones design and the words \"Pirates of the Caribbean\" sits on a glass countertop, accompanied by a serrated knife.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12559.1, "ram_available_mb": 50281.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12559.1, "ram_available_mb": 50281.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.291, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 6.476}, "timestamp": "2026-01-19T12:41:20.472511"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2733.074, "latencies_ms": [2733.074], "images_per_second": 0.366, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "mug: 1\nskull: 1\nknife: 1\nhandle: 1\nplate: 1\ncountertop: 1\ntable: 1\nglass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12559.1, "ram_available_mb": 50281.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12559.2, "ram_available_mb": 50281.6, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.581, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 6.698}, "timestamp": "2026-01-19T12:41:25.257206"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1560.214, "latencies_ms": [1560.214], "images_per_second": 0.641, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The mug is positioned in the foreground, while the knife is placed in the background. The mug and knife are placed close together.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12559.2, "ram_available_mb": 50281.6, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12558.6, "ram_available_mb": 50282.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.914, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.039}, "timestamp": "2026-01-19T12:41:28.837912"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2026.825, "latencies_ms": [2026.825], "images_per_second": 0.493, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A white mug with a skull and crossbones design sits on a light-colored surface. Next to it is a serrated knife with a black handle. The scene suggests a kitchen setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12558.6, "ram_available_mb": 50282.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12558.6, "ram_available_mb": 50282.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.517, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.489}, "timestamp": "2026-01-19T12:41:32.891236"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2784.282, "latencies_ms": [2784.282], "images_per_second": 0.359, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The mug is white and features a black skull and crossbones design. The knife has a black handle and a silver blade. The scene is set on a light-colored surface, possibly a countertop or table. The lighting appears to be artificial, illuminating the mug and knife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12558.6, "ram_available_mb": 50282.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12558.4, "ram_available_mb": 50282.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.545, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 6.698}, "timestamp": "2026-01-19T12:41:37.705004"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1515.809, "latencies_ms": [1515.809], "images_per_second": 0.66, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A group of people are gathered around a wooden bar, discussing and sampling various bottles of wine.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 12558.4, "ram_available_mb": 50282.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12558.6, "ram_available_mb": 50282.3, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.03, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 6.585}, "timestamp": "2026-01-19T12:41:41.273567"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2861.255, "latencies_ms": [2861.255], "images_per_second": 0.349, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "bottle: 5\ntable: 1\nwine bottle: 5\nglasses: 2\nman: 4\nwoman: 2\nman: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12558.6, "ram_available_mb": 50282.3, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12558.1, "ram_available_mb": 50282.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.252, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.003}, "timestamp": "2026-01-19T12:41:46.157508"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2666.983, "latencies_ms": [2666.983], "images_per_second": 0.375, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The wine bottles are placed in the foreground, while the people are gathered around them, interacting with the display. The background includes additional elements like a wooden cabinet and a partially visible wine barrel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12558.1, "ram_available_mb": 50282.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12557.9, "ram_available_mb": 50283.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.535, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.028}, "timestamp": "2026-01-19T12:41:50.870040"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2814.343, "latencies_ms": [2814.343], "images_per_second": 0.355, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "A group of people are gathered around a wooden bar, seemingly in a wine tasting event or similar social gathering. The bar features various wine bottles and glasses, indicating a focus on wine tasting.  The setting appears to be indoors, with a wooden barrel visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12557.9, "ram_available_mb": 50283.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12557.8, "ram_available_mb": 50283.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.303, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T12:41:55.706915"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2511.33, "latencies_ms": [2511.33], "images_per_second": 0.398, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The room has a warm color scheme with teal walls and wooden elements. The lighting is soft and diffused, creating a comfortable atmosphere. The materials appear to be natural wood and glass, contributing to the overall aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.8, "ram_available_mb": 50283.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.546, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.924}, "timestamp": "2026-01-19T12:42:00.249326"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1716.917, "latencies_ms": [1716.917], "images_per_second": 0.582, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two white birds, possibly egrets, stand in a grassy field with a harbor and boats in the background under a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.877, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 6.234}, "timestamp": "2026-01-19T12:42:04.010349"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2239.773, "latencies_ms": [2239.773], "images_per_second": 0.446, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "boats: 3\nseagulls: 2\ngrass: 8\nsky: 1\nwater: 1\nbuildings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.2, "ram_available_mb": 50283.7, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.171, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.479}, "timestamp": "2026-01-19T12:42:08.269171"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2464.562, "latencies_ms": [2464.562], "images_per_second": 0.406, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The foreground features the foreground grass, with two white birds visible. The background includes boats and a pier, indicating a marina or waterfront area. The boats are situated further back, suggesting they are further away from the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.416, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.552}, "timestamp": "2026-01-19T12:42:12.749152"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2411.071, "latencies_ms": [2411.071], "images_per_second": 0.415, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a marshy area with a harbor filled with fishing boats and a small white building nearby. Two white birds, possibly egrets, are visible in the foreground. The sky is cloudy, suggesting a potentially overcast day.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12557.1, "ram_available_mb": 50283.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.516, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T12:42:17.183238"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2000.666, "latencies_ms": [2000.666], "images_per_second": 0.5, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The sky is cloudy and gray. The grass is tall and green. The boats are predominantly white and blue. The overall scene suggests a coastal or maritime setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12557.0, "ram_available_mb": 50283.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12556.8, "ram_available_mb": 50284.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.116, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.382}, "timestamp": "2026-01-19T12:42:21.214697"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1714.736, "latencies_ms": [1714.736], "images_per_second": 0.583, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A man in work attire kneels beside a white toilet in a bathroom, appearing to inspect or repair it.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12556.8, "ram_available_mb": 50284.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12556.8, "ram_available_mb": 50284.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.275, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.683}, "timestamp": "2026-01-19T12:42:24.958771"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3150.376, "latencies_ms": [3150.376], "images_per_second": 0.317, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "toilet: 1\nsink: 1\nmirror: 1\nfaucet: 1\ntoilet paper: 1\ngloves: 2\npants: 2\nfloor: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12556.8, "ram_available_mb": 50284.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12556.7, "ram_available_mb": 50284.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.794, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.009}, "timestamp": "2026-01-19T12:42:30.133786"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2134.662, "latencies_ms": [2134.662], "images_per_second": 0.468, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main object is a person kneeling in front of a toilet. The toilet is positioned in the background, while the person is in the foreground. The image suggests a close proximity between the person and the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12556.7, "ram_available_mb": 50284.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12556.7, "ram_available_mb": 50284.2, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.18, "power_cpu_cv_mean_watts": 1.579, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T12:42:34.317231"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2592.269, "latencies_ms": [2592.269], "images_per_second": 0.386, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "A man is kneeling down in a bathroom, examining a toilet. He is wearing work clothes and gloves, suggesting he may be performing maintenance or repairs. The bathroom features black and white checkered tiles and a sink is partially visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12556.7, "ram_available_mb": 50284.2, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.445, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T12:42:38.931132"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1845.141, "latencies_ms": [1845.141], "images_per_second": 0.542, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The bathroom is black and white. The lighting appears to be artificial, likely from overhead fixtures. The materials appear to be standard bathroom fixtures. The floor is tiled.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12556.9, "ram_available_mb": 50284.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12556.0, "ram_available_mb": 50284.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.027, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T12:42:42.798856"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1513.323, "latencies_ms": [1513.323], "images_per_second": 0.661, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A group of six people stand on a snowy mountain slope, preparing to ski down the snow-covered trail.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12556.0, "ram_available_mb": 50284.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12555.9, "ram_available_mb": 50285.0, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.848, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 6.022}, "timestamp": "2026-01-19T12:42:46.366970"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2451.478, "latencies_ms": [2451.478], "images_per_second": 0.408, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "mountains: 2\nsnow: 6\nskiers: 4\nsnowboarders: 1\ntracks: 2\nsky: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12555.9, "ram_available_mb": 50285.0, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12555.4, "ram_available_mb": 50285.5, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.036, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.531}, "timestamp": "2026-01-19T12:42:50.838052"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2112.599, "latencies_ms": [2112.599], "images_per_second": 0.473, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The snow-covered mountain dominates the background, creating a sense of distance and scale.  In the foreground, a group of people is gathered, possibly preparing for a skiing activity or taking a break.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12555.4, "ram_available_mb": 50285.5, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12555.1, "ram_available_mb": 50285.8, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.548, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 6.457}, "timestamp": "2026-01-19T12:42:54.970182"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2485.339, "latencies_ms": [2485.339], "images_per_second": 0.402, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A group of people are gathered on a snowy mountain, preparing for a skiing trip. They are surrounded by tracks in the snow, indicating recent activity. The scene is set against a clear blue sky, highlighting the pristine beauty of the snow-covered landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12555.1, "ram_available_mb": 50285.8, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12554.8, "ram_available_mb": 50286.1, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.398, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 6.647}, "timestamp": "2026-01-19T12:42:59.472747"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2667.129, "latencies_ms": [2667.129], "images_per_second": 0.375, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The snow is white and appears undisturbed, creating a bright and clean backdrop. The lighting is bright and evenly distributed, illuminating the scene and highlighting the snow's texture. The materials appear to be primarily snow and ice, consistent with the mountainous environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12554.8, "ram_available_mb": 50286.1, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12555.0, "ram_available_mb": 50285.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.308, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 6.597}, "timestamp": "2026-01-19T12:43:04.191168"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1825.432, "latencies_ms": [1825.432], "images_per_second": 0.548, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white bowl contains a serving of white rice topped with a vibrant red and orange chili mixture, accompanied by steamed broccoli.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12555.0, "ram_available_mb": 50285.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12555.0, "ram_available_mb": 50285.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.285, "power_cpu_cv_mean_watts": 1.145, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T12:43:08.065538"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2940.761, "latencies_ms": [2940.761], "images_per_second": 0.34, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "chili: 2\nbroccoli: 2\nrice: 1\nbeans: 1\ncarrots: 1\nonions: 1\ntomatoes: 1\npeppers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12555.0, "ram_available_mb": 50285.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12555.0, "ram_available_mb": 50285.9, "ram_percent": 20.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.042, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.03}, "timestamp": "2026-01-19T12:43:13.050293"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1962.442, "latencies_ms": [1962.442], "images_per_second": 0.51, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bowl is positioned in the foreground, with the broccoli to the left and the red chili to the right. The rice is situated in the background, partially obscured by the bowl.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12555.0, "ram_available_mb": 50285.9, "ram_percent": 20.0}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12443.5, "ram_available_mb": 50397.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.551, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T12:43:17.044506"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1600.73, "latencies_ms": [1600.73], "images_per_second": 0.625, "prompt_tokens": 19, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A white bowl contains a meal of rice, beans, and broccoli. The dish is served on a wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12443.5, "ram_available_mb": 50397.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12444.1, "ram_available_mb": 50396.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.489, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T12:43:20.674496"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1965.018, "latencies_ms": [1965.018], "images_per_second": 0.509, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The dish features a vibrant red sauce, contrasting with the bright green broccoli and white rice. The lighting is soft and warm, creating a pleasant and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12444.1, "ram_available_mb": 50396.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12444.1, "ram_available_mb": 50396.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.627, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T12:43:24.703287"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1909.901, "latencies_ms": [1909.901], "images_per_second": 0.524, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A person in black pants and black and white Vans sneakers is riding a skateboard on a small wooden ramp in a grassy field.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12444.1, "ram_available_mb": 50396.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.601, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T12:43:28.642866"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2611.783, "latencies_ms": [2611.783], "images_per_second": 0.383, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "shoe: 2\nskateboard: 1\nboard: 1\ngrass: 2\nwood: 4\npants: 1\nground: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12445.3, "ram_available_mb": 50395.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.254, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T12:43:33.299094"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1924.182, "latencies_ms": [1924.182], "images_per_second": 0.52, "prompt_tokens": 25, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, moving towards the background. The wooden planks and grass create a natural, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.3, "ram_available_mb": 50395.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.627, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T12:43:37.243681"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1997.418, "latencies_ms": [1997.418], "images_per_second": 0.501, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A person is skateboarding on a wooden platform in a grassy area. They are wearing Vans sneakers and appear to be performing a trick or maneuver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12444.8, "ram_available_mb": 50396.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.15, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.766}, "timestamp": "2026-01-19T12:43:41.298801"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2059.599, "latencies_ms": [2059.599], "images_per_second": 0.486, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The skateboarder is wearing black and white sneakers. The scene appears to be outdoors in natural light. The skateboard is positioned on a wooden platform.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.8, "ram_available_mb": 50396.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.127, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.816}, "timestamp": "2026-01-19T12:43:45.404484"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1627.354, "latencies_ms": [1627.354], "images_per_second": 0.614, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A bunch of ripe yellow bananas is arranged on a wooden table, partially obscuring a computer keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12445.3, "ram_available_mb": 50395.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.212, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.644}, "timestamp": "2026-01-19T12:43:49.085309"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2388.124, "latencies_ms": [2388.124], "images_per_second": 0.419, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "bananas: 4\nkeyboard: 1\nlaptop: 1\ncup: 1\ntable: 1\npaper: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12445.3, "ram_available_mb": 50395.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.286, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.874}, "timestamp": "2026-01-19T12:43:53.523379"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2051.05, "latencies_ms": [2051.05], "images_per_second": 0.488, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with a computer keyboard and monitor visible in the background. The bananas are situated near the center, partially obscuring the keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.327, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T12:43:57.602296"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1848.847, "latencies_ms": [1848.847], "images_per_second": 0.541, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene is set on a wooden desk with a computer keyboard and a computer monitor in the background. A bunch of ripe bananas is prominently featured in the center of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12444.8, "ram_available_mb": 50396.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.921, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T12:44:01.497785"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2218.465, "latencies_ms": [2218.465], "images_per_second": 0.451, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The bananas are yellow, indicating they are ripe. The lighting appears to be natural, possibly from daylight, creating a warm ambiance. The bananas appear to be made of natural materials like fruit and possibly plant matter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.8, "ram_available_mb": 50396.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12444.4, "ram_available_mb": 50396.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.114, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T12:44:05.761685"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1926.401, "latencies_ms": [1926.401], "images_per_second": 0.519, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A plate of stir-fried chicken, cauliflower, broccoli, carrots, and rice is presented on a wooden table, accompanied by a fork and a glass of water.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12444.4, "ram_available_mb": 50396.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.643, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 6.464}, "timestamp": "2026-01-19T12:44:09.757724"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3249.228, "latencies_ms": [3249.228], "images_per_second": 0.308, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "chicken: 6\nrice: 1\ncarrots: 3\nbroccoli: 2\ncauliflower: 2\ncorn: 1\nsauce: 1\nfork: 1\nglass: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12444.5, "ram_available_mb": 50396.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.599, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 6.784}, "timestamp": "2026-01-19T12:44:15.026480"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2257.389, "latencies_ms": [2257.389], "images_per_second": 0.443, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The plate is positioned in the foreground of the image, with the main dish (rice and vegetables) occupying the central area. The table occupies the background, and the glass of water is situated near the top left corner.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.5, "ram_available_mb": 50396.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.306, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.468}, "timestamp": "2026-01-19T12:44:19.331913"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2462.646, "latencies_ms": [2462.646], "images_per_second": 0.406, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a plate of Asian cuisine featuring white rice, chicken, broccoli, carrots, and cauliflower, served on a colorful plate. A glass of water and a fork are also present on the wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.258, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.562}, "timestamp": "2026-01-19T12:44:23.824165"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2438.035, "latencies_ms": [2438.035], "images_per_second": 0.41, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The plate features a vibrant mix of colors, including orange, green, and white. The lighting is soft and warm, creating a pleasant atmosphere. The food appears to be made of high-quality ingredients and cooked in a way that highlights its textures and flavors.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.407, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 6.631}, "timestamp": "2026-01-19T12:44:28.285326"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1543.522, "latencies_ms": [1543.522], "images_per_second": 0.648, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A young girl in a white dress and colorful skirt is playing with a white toy in a living room, surrounded by people.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.778, "power_cpu_cv_mean_watts": 1.056, "power_sys_5v0_mean_watts": 6.039}, "timestamp": "2026-01-19T12:44:31.869483"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2934.12, "latencies_ms": [2934.12], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "woman: 2\ngirl: 1\ndress: 1\nskirt: 1\ntable: 1\nchair: 1\nrug: 1\nstairs: 1\nlight fixture: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12445.7, "ram_available_mb": 50395.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.534, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 6.715}, "timestamp": "2026-01-19T12:44:36.826873"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1729.881, "latencies_ms": [1729.881], "images_per_second": 0.578, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The girl is positioned in the foreground, interacting with the partygoers. The living room extends in the background, creating a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12445.7, "ram_available_mb": 50395.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.785, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.091}, "timestamp": "2026-01-19T12:44:40.606991"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2187.076, "latencies_ms": [2187.076], "images_per_second": 0.457, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A group of people are gathered in a living room, enjoying a casual party or gathering. A young girl is actively playing a game, possibly wii, while others socialize and watch.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.909, "power_cpu_cv_mean_watts": 1.437, "power_sys_5v0_mean_watts": 6.421}, "timestamp": "2026-01-19T12:44:44.821386"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2470.062, "latencies_ms": [2470.062], "images_per_second": 0.405, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The room is lit by natural light, creating a warm and inviting atmosphere. The colors are predominantly neutral, with pops of red and green from the decorations and clothing. The flooring appears to be polished wood, complementing the overall ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.0, "ram_available_mb": 50395.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12444.1, "ram_available_mb": 50396.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.658, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 6.733}, "timestamp": "2026-01-19T12:44:49.318399"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1745.19, "latencies_ms": [1745.19], "images_per_second": 0.573, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two men in formal attire are shaking hands at a banquet, engaging in a business or professional interaction.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12444.1, "ram_available_mb": 50396.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12443.6, "ram_available_mb": 50397.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.427, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.594}, "timestamp": "2026-01-19T12:44:53.108733"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2773.359, "latencies_ms": [2773.359], "images_per_second": 0.361, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "man: 2\ntie: 1\nglasses: 1\nsuit: 2\ntable: 2\nplate: 2\nwater: 1\nfood: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12443.6, "ram_available_mb": 50397.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12443.7, "ram_available_mb": 50397.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.991, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.937}, "timestamp": "2026-01-19T12:44:57.918225"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2137.294, "latencies_ms": [2137.294], "images_per_second": 0.468, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the man on the left shaking hands with the man on the right. The background features other individuals and tables, suggesting a larger event or gathering.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12443.7, "ram_available_mb": 50397.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12443.7, "ram_available_mb": 50397.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.298, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.836}, "timestamp": "2026-01-19T12:45:02.069058"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2809.625, "latencies_ms": [2809.625], "images_per_second": 0.356, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a formal event or conference taking place in a large, well-lit room.  Two men in suits are shaking hands, indicating a successful interaction or agreement. The setting suggests a professional gathering, possibly related to business, politics, or diplomacy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12443.7, "ram_available_mb": 50397.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12444.2, "ram_available_mb": 50396.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.938, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.915}, "timestamp": "2026-01-19T12:45:06.923545"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2749.158, "latencies_ms": [2749.158], "images_per_second": 0.364, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The room is lit with warm yellow lighting, creating a welcoming atmosphere. The walls are wood-paneled, adding a touch of elegance to the setting. The men are dressed in formal attire, further emphasizing the importance of the event.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12444.2, "ram_available_mb": 50396.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.043, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.968}, "timestamp": "2026-01-19T12:45:11.697411"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1721.631, "latencies_ms": [1721.631], "images_per_second": 0.581, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man in a white dress shirt and striped tie stands in front of a dark background, looking off to the side with a serious expression.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.305, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.73}, "timestamp": "2026-01-19T12:45:15.453607"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2585.493, "latencies_ms": [2585.493], "images_per_second": 0.387, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "shirt: 1\ntie: 1\npocket: 1\nhand: 1\nface: 1\nhair: 1\neyes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.063, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 6.916}, "timestamp": "2026-01-19T12:45:20.057921"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2156.966, "latencies_ms": [2156.966], "images_per_second": 0.464, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The man is positioned in the foreground, with the background blurred and out of focus. The man is standing near a dark object, possibly a window or door, which suggests he is indoors.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.757, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T12:45:24.260900"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1957.003, "latencies_ms": [1957.003], "images_per_second": 0.511, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A man is standing indoors, wearing a white dress shirt and a striped tie. He appears to be in a professional or business setting, possibly a meeting or office.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.501, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.765}, "timestamp": "2026-01-19T12:45:28.250389"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2640.922, "latencies_ms": [2640.922], "images_per_second": 0.379, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The man is wearing a light yellow dress shirt and a dark-colored tie with thin, light-colored stripes. His hair is dark and neatly styled. The lighting in the image is soft and somewhat dim, creating a subdued atmosphere.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.044, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.878}, "timestamp": "2026-01-19T12:45:32.904377"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1727.572, "latencies_ms": [1727.572], "images_per_second": 0.579, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The living room features a plaid couch, a wooden TV stand with a TV, a red plaid chair, and a whiteboard with writing on it.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.1, "power_cpu_cv_mean_watts": 1.259, "power_sys_5v0_mean_watts": 6.285}, "timestamp": "2026-01-19T12:45:36.692063"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2623.409, "latencies_ms": [2623.409], "images_per_second": 0.381, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "chair: 2\ncouch: 2\ntv: 1\ncabinet: 1\nwhiteboard: 1\npicture: 1\nspeakers: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12444.5, "ram_available_mb": 50396.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.33, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 6.585}, "timestamp": "2026-01-19T12:45:41.348510"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1716.926, "latencies_ms": [1716.926], "images_per_second": 0.582, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The chair is positioned to the left of the couch, closer to the viewer. The couch is situated further back in the room, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.5, "ram_available_mb": 50396.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12444.3, "ram_available_mb": 50396.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.275, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 6.296}, "timestamp": "2026-01-19T12:45:45.085613"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2842.416, "latencies_ms": [2842.416], "images_per_second": 0.352, "prompt_tokens": 19, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The scene depicts a cozy living room or common area with comfortable seating arrangements, including a plaid couch and a plaid armchair. A television set is positioned nearby, offering entertainment options. The room features a whiteboard with notes, a framed black and white photo, and a small wooden cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.3, "ram_available_mb": 50396.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12443.0, "ram_available_mb": 50397.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.51, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 6.661}, "timestamp": "2026-01-19T12:45:49.958394"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2307.627, "latencies_ms": [2307.627], "images_per_second": 0.433, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The room features a plaid couch in blue and red hues. The lighting is soft and warm, creating a cozy atmosphere. The walls are painted a pale yellow, and the floor is carpeted in a neutral tone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12443.0, "ram_available_mb": 50397.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.259, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.541}, "timestamp": "2026-01-19T12:45:54.307136"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1943.949, "latencies_ms": [1943.949], "images_per_second": 0.514, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A surfer in a yellow wetsuit rides a wave on a white surfboard with orange fins, skillfully carving through the water.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.349, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.874}, "timestamp": "2026-01-19T12:45:58.292170"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2520.708, "latencies_ms": [2520.708], "images_per_second": 0.397, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "surfboard: 1\nwetsuit: 1\nwater: 1\nwaves: 1\nsurfer: 1\nclothing: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.9, "ram_available_mb": 50396.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.525, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.894}, "timestamp": "2026-01-19T12:46:02.833701"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1953.621, "latencies_ms": [1953.621], "images_per_second": 0.512, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave. The wave is further in the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.654, "power_cpu_cv_mean_watts": 1.148, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T12:46:06.802670"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2098.55, "latencies_ms": [2098.55], "images_per_second": 0.477, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A surfer in a yellow wetsuit skillfully rides a wave on a white surfboard. The setting appears to be a river or ocean with choppy water.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12445.1, "ram_available_mb": 50395.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12445.8, "ram_available_mb": 50395.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.462, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T12:46:10.924976"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2279.485, "latencies_ms": [2279.485], "images_per_second": 0.439, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The surfer is wearing a yellow top and dark shorts. The wave is teal and white, indicating a potentially cold or stormy environment. The lighting suggests an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.8, "ram_available_mb": 50395.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12445.9, "ram_available_mb": 50395.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.079, "power_cpu_cv_mean_watts": 1.371, "power_sys_5v0_mean_watts": 6.88}, "timestamp": "2026-01-19T12:46:15.250827"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1662.72, "latencies_ms": [1662.72], "images_per_second": 0.601, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A long-haired black cat is sitting in front of a computer monitor, attentively gazing at the content displayed.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12445.9, "ram_available_mb": 50395.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.336, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.683}, "timestamp": "2026-01-19T12:46:18.991511"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2935.152, "latencies_ms": [2935.152], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "laptop: 2\nmouse: 1\nkeyboard: 1\nmousepad: 1\ncat: 1\ntelephone: 1\nmousepad: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.942, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.942}, "timestamp": "2026-01-19T12:46:23.947128"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2591.849, "latencies_ms": [2591.849], "images_per_second": 0.386, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, partially obscuring the laptop screen. The laptop is situated near the cat, occupying the left side of the image. The monitor and phone are placed in the background, extending across the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12445.3, "ram_available_mb": 50395.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.407, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T12:46:28.580947"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2070.41, "latencies_ms": [2070.41], "images_per_second": 0.483, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A cat is sitting in front of a computer monitor, seemingly observing the screen. The computer is connected to a phone, suggesting the cat is interacting with the device.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.3, "ram_available_mb": 50395.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12445.3, "ram_available_mb": 50395.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.227, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T12:46:32.678954"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2644.202, "latencies_ms": [2644.202], "images_per_second": 0.378, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The cat is primarily black with gray fur. The lighting in the image appears to be soft and warm, likely from natural light coming in from the window. The desk surface appears to be made of a light-colored material, possibly wood or plastic.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12445.3, "ram_available_mb": 50395.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12446.4, "ram_available_mb": 50394.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.897, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T12:46:37.368689"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1579.474, "latencies_ms": [1579.474], "images_per_second": 0.633, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A man and a child are cutting a red ribbon together in front of a building, accompanied by a crowd of people.", "error": null, "sys_before": {"cpu_percent": 13.8, "ram_used_mb": 12446.4, "ram_available_mb": 50394.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12448.2, "ram_available_mb": 50392.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.094, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.551}, "timestamp": "2026-01-19T12:46:40.986682"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2763.319, "latencies_ms": [2763.319], "images_per_second": 0.362, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "ribbon: 2\nhelmet: 1\nscissors: 2\nballoon: 1\nman: 2\nchild: 1\nman: 2\nwoman: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12448.2, "ram_available_mb": 50392.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12447.8, "ram_available_mb": 50393.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.322, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T12:46:45.811048"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1913.051, "latencies_ms": [1913.051], "images_per_second": 0.523, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The scissors are positioned in the foreground, cutting the red ribbon. The crowd surrounds the scissors, creating a sense of proximity and anticipation for the event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.8, "ram_available_mb": 50393.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12448.3, "ram_available_mb": 50392.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.414, "power_cpu_cv_mean_watts": 1.149, "power_sys_5v0_mean_watts": 6.733}, "timestamp": "2026-01-19T12:46:49.769011"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3008.18, "latencies_ms": [3008.18], "images_per_second": 0.332, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The scene depicts a lively outdoor event, possibly a ribbon-cutting ceremony, where a young child is cutting a red ribbon with a pair of scissors. Several adults and children surround the child, observing and participating in the event. A blue balloon adds a festive touch to the atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12448.3, "ram_available_mb": 50392.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12448.3, "ram_available_mb": 50392.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.881, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.064}, "timestamp": "2026-01-19T12:46:54.816298"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2643.363, "latencies_ms": [2643.363], "images_per_second": 0.378, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The red ribbon and the blue balloon stand out against the muted colors of the surrounding environment. The lighting appears to be natural daylight, creating a bright and celebratory atmosphere. The materials used appear to be sturdy and durable, suitable for cutting the ribbon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12448.3, "ram_available_mb": 50392.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12447.4, "ram_available_mb": 50393.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.28, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.969}, "timestamp": "2026-01-19T12:46:59.500958"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1935.645, "latencies_ms": [1935.645], "images_per_second": 0.517, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A First Group bus numbered 65745 is parked on the side of the road, displaying its free Wi-Fi and board signage.", "error": null, "sys_before": {"cpu_percent": 12.9, "ram_used_mb": 12447.4, "ram_available_mb": 50393.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12447.3, "ram_available_mb": 50393.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.077, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.879}, "timestamp": "2026-01-19T12:47:03.483546"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3448.343, "latencies_ms": [3448.343], "images_per_second": 0.29, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "bus: 1\nwindshield wipers: 2\nheadlights: 4\nbumper: 1\nside mirror: 1\ndoor: 1\nlicense plate: 1\nstreet: 1\nbuildings: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.3, "ram_available_mb": 50393.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12447.0, "ram_available_mb": 50393.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.32, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.094}, "timestamp": "2026-01-19T12:47:08.976025"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2028.7, "latencies_ms": [2028.7], "images_per_second": 0.493, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, moving towards the left side of the image. The background features buildings and a street with pedestrians, creating a sense of a typical urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.0, "ram_available_mb": 50393.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12447.0, "ram_available_mb": 50393.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.701, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.822}, "timestamp": "2026-01-19T12:47:13.048658"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2935.293, "latencies_ms": [2935.293], "images_per_second": 0.341, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a city street with a First Group bus parked at the curb. The bus is labeled \"First Group\" and has a \"Free Wi-Fi on Board\" sign displayed. The street is lined with buildings, and pedestrians can be seen walking nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.0, "ram_available_mb": 50393.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12446.3, "ram_available_mb": 50394.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.688, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 6.993}, "timestamp": "2026-01-19T12:47:18.044073"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2050.342, "latencies_ms": [2050.342], "images_per_second": 0.488, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The bus is primarily white with pink and blue accents. The bus has multiple headlights and fog lights. The sky is overcast, suggesting cloudy weather.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12446.3, "ram_available_mb": 50394.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.451, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T12:47:22.141806"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1690.355, "latencies_ms": [1690.355], "images_per_second": 0.592, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man is sitting cross-legged on a wooden floor in front of a large mirror, capturing his reflection while holding a phone.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.905, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.683}, "timestamp": "2026-01-19T12:47:25.909820"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3570.528, "latencies_ms": [3570.528], "images_per_second": 0.28, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "mirror: 1\nwooden frame: 1\nman's reflection: 1\ngreen shirt: 1\nslippers: 1\nwindow: 1\nbed: 1\ntoys: 1\nrug: 1\ncabinet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.389, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.125}, "timestamp": "2026-01-19T12:47:31.492721"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2495.5, "latencies_ms": [2495.5], "images_per_second": 0.401, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The man is sitting in front of the mirror, which reflects his image. The mirror is positioned between the man and the background, creating a sense of depth. The foreground consists of wooden flooring, while the background features the interior of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.386, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.894}, "timestamp": "2026-01-19T12:47:36.019826"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2223.627, "latencies_ms": [2223.627], "images_per_second": 0.45, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A man is sitting cross-legged in front of a large mirror, taking a selfie. He appears to be in a living room with hardwood floors, a green couch, and a wooden dresser visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.071, "power_cpu_cv_mean_watts": 1.336, "power_sys_5v0_mean_watts": 6.803}, "timestamp": "2026-01-19T12:47:40.258754"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2700.741, "latencies_ms": [2700.741], "images_per_second": 0.37, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The room has light-colored wood flooring and walls painted in a muted green hue. The lighting appears to be soft and diffused, creating a calm atmosphere. A wooden ornate mirror is prominently featured, reflecting the room's interior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.062, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.987}, "timestamp": "2026-01-19T12:47:44.983840"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1723.208, "latencies_ms": [1723.208], "images_per_second": 0.58, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A group of young men are standing next to surfboards, posing for a photo while a man takes their picture.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.058, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.645}, "timestamp": "2026-01-19T12:47:48.741113"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2526.66, "latencies_ms": [2526.66], "images_per_second": 0.396, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "surfboard: 2\nman: 3\nwoman: 1\nchild: 2\nman: 1\nman: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12445.9, "ram_available_mb": 50395.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.273, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:47:53.303366"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2820.191, "latencies_ms": [2820.191], "images_per_second": 0.355, "prompt_tokens": 25, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The man is on the left side of the image, taking a picture of the group of young boys. The boys are positioned in the foreground, partially obscured by the man's arm and camera. The surfboards are placed in the background, extending from the foreground to the far right of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.9, "ram_available_mb": 50395.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12446.5, "ram_available_mb": 50394.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.974, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.942}, "timestamp": "2026-01-19T12:47:58.159134"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1887.361, "latencies_ms": [1887.361], "images_per_second": 0.53, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A group of young men are gathered in a room with surfboards, posing for a photo. A person is taking a picture of them with a digital camera.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12446.5, "ram_available_mb": 50394.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12446.5, "ram_available_mb": 50394.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.52, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.726}, "timestamp": "2026-01-19T12:48:02.071736"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2643.603, "latencies_ms": [2643.603], "images_per_second": 0.378, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The surfboards are brightly colored, featuring yellow, red, and blue. The lighting in the room is bright, likely from overhead fluorescent fixtures, creating a well-lit atmosphere. The surfboards appear to be made of durable materials like fiberglass or plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12446.5, "ram_available_mb": 50394.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12446.0, "ram_available_mb": 50394.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.116, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T12:48:06.774688"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1985.781, "latencies_ms": [1985.781], "images_per_second": 0.504, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A gold-colored Polish Airlines Boeing 737-800, marked with the LOT logo and Polish text, is taxiing on the tarmac.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12446.0, "ram_available_mb": 50394.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.108, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 6.384}, "timestamp": "2026-01-19T12:48:10.796283"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3209.641, "latencies_ms": [3209.641], "images_per_second": 0.312, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "airplane: 1\ntwin-engine: 2\nwings: 2\ntail: 1\nwinglets: 2\nengine: 2\npainted: 2\nlogo: 2\nrunway: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12445.2, "ram_available_mb": 50395.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12445.9, "ram_available_mb": 50395.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.694, "power_cpu_cv_mean_watts": 1.833, "power_sys_5v0_mean_watts": 6.819}, "timestamp": "2026-01-19T12:48:16.026265"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2613.204, "latencies_ms": [2613.204], "images_per_second": 0.383, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main object is a large passenger airplane positioned in the foreground of the image. The airplane is situated on a runway or tarmac, facing towards the right side of the image. The background includes other aircraft and airport infrastructure, further emphasizing the airport setting.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12445.9, "ram_available_mb": 50395.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.37, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 6.662}, "timestamp": "2026-01-19T12:48:20.682619"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2222.986, "latencies_ms": [2222.986], "images_per_second": 0.45, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "An LOT Polish Airlines Boeing 737-800, painted gold, is taxiing on the tarmac. The sky is partly cloudy, and there are other aircraft visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.215, "power_cpu_cv_mean_watts": 1.578, "power_sys_5v0_mean_watts": 6.516}, "timestamp": "2026-01-19T12:48:24.920144"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2158.826, "latencies_ms": [2158.826], "images_per_second": 0.463, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The plane is primarily gold in color. The lighting appears to be natural daylight. The plane appears to be made of metal and has a polished finish. The sky is cloudy, suggesting an overcast day.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12444.7, "ram_available_mb": 50396.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12444.5, "ram_available_mb": 50396.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.325, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.563}, "timestamp": "2026-01-19T12:48:29.124829"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1391.464, "latencies_ms": [1391.464], "images_per_second": 0.719, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A person is standing in front of a white toilet with a raised lid, releasing water into the bowl.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12444.5, "ram_available_mb": 50396.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12443.6, "ram_available_mb": 50397.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.959, "power_cpu_cv_mean_watts": 1.129, "power_sys_5v0_mean_watts": 6.075}, "timestamp": "2026-01-19T12:48:32.583553"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4221.398, "latencies_ms": [4221.398], "images_per_second": 0.237, "prompt_tokens": 21, "response_tokens_est": 56, "n_tiles": 1, "output_text": "toilet: 1\ntoilet paper: 1\ntoilet seat: 1\ntoilet seat cover: 1\ntoilet handle: 1\ntoilet flushing mechanism: 1\ntoilet seat cover: 1\ntoilet seat: 1\ntoilet paper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12443.6, "ram_available_mb": 50397.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12443.6, "ram_available_mb": 50397.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.858, "power_cpu_cv_mean_watts": 1.957, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T12:48:38.840706"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1856.743, "latencies_ms": [1856.743], "images_per_second": 0.539, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, close to the person's feet. The toilet is situated next to a wall and partially obscured by a towel hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12443.6, "ram_available_mb": 50397.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12444.6, "ram_available_mb": 50396.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.136, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.296}, "timestamp": "2026-01-19T12:48:42.732869"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1859.597, "latencies_ms": [1859.597], "images_per_second": 0.538, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The scene depicts a person standing next to a toilet in a bathroom, urinating into the bowl. The toilet lid is open, revealing the interior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12444.6, "ram_available_mb": 50396.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.162, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.323}, "timestamp": "2026-01-19T12:48:46.644115"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2082.98, "latencies_ms": [2082.98], "images_per_second": 0.48, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The toilet is white and appears to be made of porcelain or ceramic. The lighting in the bathroom is dim, creating a somewhat shadowy atmosphere. The walls appear to be painted a light color.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12445.8, "ram_available_mb": 50395.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.191, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.382}, "timestamp": "2026-01-19T12:48:50.741007"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2295.504, "latencies_ms": [2295.504], "images_per_second": 0.436, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A skier dressed in blue and black, wearing a white helmet and goggles, skillfully navigates a snowy mountain slope, leaning into a turn with ski poles in hand.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12445.8, "ram_available_mb": 50395.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12445.7, "ram_available_mb": 50395.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.7, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T12:48:55.086494"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3008.468, "latencies_ms": [3008.468], "images_per_second": 0.332, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "helmet: 1\ngloves: 2\nski poles: 2\nskis: 2\nsnow: 6\ntree: 4\nsnow: 4\ngoggles: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.7, "ram_available_mb": 50395.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.929, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.035}, "timestamp": "2026-01-19T12:49:00.120553"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2002.78, "latencies_ms": [2002.78], "images_per_second": 0.499, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The skier is positioned in the foreground of the image, moving towards the left side of the frame. The snowy landscape and trees in the background create a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.528, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.873}, "timestamp": "2026-01-19T12:49:04.138933"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2333.941, "latencies_ms": [2333.941], "images_per_second": 0.428, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A skier is captured mid-turn on a snowy slope, surrounded by snow-covered trees. The skier is wearing a blue jacket and helmet, holding ski poles and navigating the terrain.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.425, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.816}, "timestamp": "2026-01-19T12:49:08.525742"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2283.357, "latencies_ms": [2283.357], "images_per_second": 0.438, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The skier is wearing a blue jacket and white helmet. The lighting is bright and appears to be natural daylight. The snow appears to be fresh and undisturbed. The overall scene conveys a serene winter atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.093, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 6.893}, "timestamp": "2026-01-19T12:49:12.826346"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1588.667, "latencies_ms": [1588.667], "images_per_second": 0.629, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A female tennis player in a yellow shirt and black shorts is poised to hit the ball during a professional match.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12446.0, "ram_available_mb": 50394.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.15, "power_cpu_cv_mean_watts": 1.102, "power_sys_5v0_mean_watts": 6.081}, "timestamp": "2026-01-19T12:49:16.460481"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4057.859, "latencies_ms": [4057.859], "images_per_second": 0.246, "prompt_tokens": 21, "response_tokens_est": 53, "n_tiles": 1, "output_text": "Tennis player: 1\nTennis racket: 1\nTennis ball: 1\nTennis court: 1\nSpectators: 1\nCrowd: 1\nCourt markings: 1\nSpectator: 1\nSpectator: 1\nSpectator: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12446.0, "ram_available_mb": 50394.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.677, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T12:49:22.552661"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1879.338, "latencies_ms": [1879.338], "images_per_second": 0.532, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the court, facing the audience. The ball court is situated in the background, extending beyond the immediate foreground of the player.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12445.5, "ram_available_mb": 50395.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12446.3, "ram_available_mb": 50394.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.324, "power_cpu_cv_mean_watts": 1.416, "power_sys_5v0_mean_watts": 6.424}, "timestamp": "2026-01-19T12:49:26.485554"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1776.968, "latencies_ms": [1776.968], "images_per_second": 0.563, "prompt_tokens": 19, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A tennis match is taking place on a blue court, with players in action and spectators in the stands. The atmosphere is lively and energetic.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12446.3, "ram_available_mb": 50394.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12446.3, "ram_available_mb": 50394.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.102, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 6.321}, "timestamp": "2026-01-19T12:49:30.286627"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2032.129, "latencies_ms": [2032.129], "images_per_second": 0.492, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The tennis court is predominantly blue. The lighting appears to be artificial, likely from spotlights. The court surface appears to be made of a synthetic material like rubber or synthetic turf.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12446.3, "ram_available_mb": 50394.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12446.0, "ram_available_mb": 50394.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.217, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.306}, "timestamp": "2026-01-19T12:49:34.335326"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1602.48, "latencies_ms": [1602.48], "images_per_second": 0.624, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A metal bowl on a plate contains cubed orange-colored vegetables, accompanied by a spoon and a bowl of brown stew.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 12446.0, "ram_available_mb": 50394.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12445.8, "ram_available_mb": 50395.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.181, "power_cpu_cv_mean_watts": 1.268, "power_sys_5v0_mean_watts": 6.14}, "timestamp": "2026-01-19T12:49:37.997229"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2643.284, "latencies_ms": [2643.284], "images_per_second": 0.378, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "bowl: 2\nspoon: 1\nplate: 1\nnapkin: 1\nbowls: 2\nonions: 6\nred onion: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12445.8, "ram_available_mb": 50395.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12446.2, "ram_available_mb": 50394.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.425, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 6.657}, "timestamp": "2026-01-19T12:49:42.674707"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2401.386, "latencies_ms": [2401.386], "images_per_second": 0.416, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The bowl containing fried onions is positioned in the foreground, while the bowl of chutney is situated in the background. The fried onions are placed closer to the viewer, while the chutney is further away, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12446.2, "ram_available_mb": 50394.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.512, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.599}, "timestamp": "2026-01-19T12:49:47.093415"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2915.605, "latencies_ms": [2915.605], "images_per_second": 0.343, "prompt_tokens": 19, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The scene depicts a table setting with a plate containing two bowls of food: one containing a meat-based dish and the other containing sliced, glazed onions. A spoon rests on the plate, ready for use. The table is covered with a yellow tablecloth, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12445.6, "ram_available_mb": 50395.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12446.4, "ram_available_mb": 50394.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.598, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 6.72}, "timestamp": "2026-01-19T12:49:52.054281"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2776.03, "latencies_ms": [2776.03], "images_per_second": 0.36, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The food in the bowls is predominantly orange and pinkish-orange. The lighting is soft and warm, creating a pleasant ambiance. The bowls appear to be made of metal and have a metallic sheen. The table setting suggests a formal or elegant dining environment.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12446.4, "ram_available_mb": 50394.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12446.4, "ram_available_mb": 50394.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.51, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 6.679}, "timestamp": "2026-01-19T12:49:56.859642"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1655.055, "latencies_ms": [1655.055], "images_per_second": 0.604, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of sheep, including one with a distinctive white face, are standing together in a grassy area near a brick building.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12446.4, "ram_available_mb": 50394.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12447.4, "ram_available_mb": 50393.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.262, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 6.829}, "timestamp": "2026-01-19T12:50:00.546844"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2856.342, "latencies_ms": [2856.342], "images_per_second": 0.35, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "sheep: 5\nbrick wall: 1\ngrass: 2\nslide: 1\nwooden structure: 1\nfence: 1\nwooden beams: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.1, "ram_available_mb": 50393.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12447.1, "ram_available_mb": 50393.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.757, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 6.993}, "timestamp": "2026-01-19T12:50:05.441584"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1959.037, "latencies_ms": [1959.037], "images_per_second": 0.51, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main sheep is positioned in the foreground, slightly to the left of the image. The brick wall and wooden structure in the background are further back, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.1, "ram_available_mb": 50393.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12447.5, "ram_available_mb": 50393.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.413, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T12:50:09.429810"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1948.895, "latencies_ms": [1948.895], "images_per_second": 0.513, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A group of sheep, including brown and white ones, are gathered in a grassy area near a brick building.  Some sheep are standing, while others appear to be interacting with each other.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.5, "ram_available_mb": 50393.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12448.1, "ram_available_mb": 50392.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.528, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T12:50:13.405555"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2465.335, "latencies_ms": [2465.335], "images_per_second": 0.406, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The sheep have thick, brown wool that appears slightly damp or dirty. The lighting suggests a sunny day, with shadows cast on the grass. The brick wall in the background adds a rustic touch to the scene.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12448.1, "ram_available_mb": 50392.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12448.9, "ram_available_mb": 50392.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.226, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.849}, "timestamp": "2026-01-19T12:50:17.890280"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1620.019, "latencies_ms": [1620.019], "images_per_second": 0.617, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A bunch of ripe bananas is arranged in a circular pattern, partially overlapping a vibrant red and yellow fruit in the center.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12448.9, "ram_available_mb": 50392.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12449.4, "ram_available_mb": 50391.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.921, "power_cpu_cv_mean_watts": 1.079, "power_sys_5v0_mean_watts": 6.745}, "timestamp": "2026-01-19T12:50:21.552462"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2864.501, "latencies_ms": [2864.501], "images_per_second": 0.349, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "bananas: 5\npomegranate: 1\nbanana: 5\nbanana: 5\nbanana: 5\nbanana: 5\nbanana: 5\nbanana: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.4, "ram_available_mb": 50391.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12450.4, "ram_available_mb": 50390.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.191, "power_cpu_cv_mean_watts": 1.586, "power_sys_5v0_mean_watts": 6.976}, "timestamp": "2026-01-19T12:50:26.463563"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2288.755, "latencies_ms": [2288.755], "images_per_second": 0.437, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The bananas are positioned in the foreground, partially overlapping the pomegranate. The pomegranate is situated near the center of the image, slightly behind and to the right of the bananas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12450.4, "ram_available_mb": 50390.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12450.4, "ram_available_mb": 50390.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.037, "power_cpu_cv_mean_watts": 1.371, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:50:30.784005"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2386.682, "latencies_ms": [2386.682], "images_per_second": 0.419, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is set against a textured, teal background with leaf-like patterns. A bunch of green bananas is arranged around a partially peeled, red and yellow apple, creating a visually striking and artistic composition.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12450.4, "ram_available_mb": 50390.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12451.1, "ram_available_mb": 50389.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.971, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.88}, "timestamp": "2026-01-19T12:50:35.188055"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2281.628, "latencies_ms": [2281.628], "images_per_second": 0.438, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The fruits are predominantly green and have a vibrant red-yellow color. The lighting creates a warm, inviting atmosphere, and the image appears to be digitally manipulated, giving it a surreal and artistic quality.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12451.1, "ram_available_mb": 50389.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12451.3, "ram_available_mb": 50389.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.294, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T12:50:39.511998"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1467.305, "latencies_ms": [1467.305], "images_per_second": 0.682, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A blue and white tram numbered 2 is traveling down a street lined with trees and buildings.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12451.3, "ram_available_mb": 50389.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12450.6, "ram_available_mb": 50390.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.777, "power_cpu_cv_mean_watts": 1.019, "power_sys_5v0_mean_watts": 5.91}, "timestamp": "2026-01-19T12:50:43.031126"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2799.57, "latencies_ms": [2799.57], "images_per_second": 0.357, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Train: 8\nTrees: 2\nSky: 1\nWires: 6\nBuildings: 1\nCars: 1\nTrolley tracks: 4", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12449.7, "ram_available_mb": 50391.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 8.3, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.38, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 6.739}, "timestamp": "2026-01-19T12:50:47.864912"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2250.045, "latencies_ms": [2250.045], "images_per_second": 0.444, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main object is a blue and white tram moving from left to right in the foreground. The background features trees, a building, and a parked car. The tram is positioned near the center of the image, moving towards the left side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12450.3, "ram_available_mb": 50390.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.549, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 6.557}, "timestamp": "2026-01-19T12:50:52.148334"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1947.503, "latencies_ms": [1947.503], "images_per_second": 0.513, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A blue and white tram is traveling down a street, carrying passengers and passing by trees and a building. The scene suggests a modern, urban transit system.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12450.3, "ram_available_mb": 50390.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.139, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.344}, "timestamp": "2026-01-19T12:50:56.134041"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2100.206, "latencies_ms": [2100.206], "images_per_second": 0.476, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The tram is primarily blue and white. The lighting is bright, illuminating the scene clearly. The tram appears to be made of metal and plastic. The weather is sunny and clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12449.4, "ram_available_mb": 50391.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.144, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.397}, "timestamp": "2026-01-19T12:51:00.297282"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2043.469, "latencies_ms": [2043.469], "images_per_second": 0.489, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The bathroom features a white bathtub, a glass shower enclosure, a red shower curtain, and two sinks with dark wood cabinets and beige countertops.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12449.4, "ram_available_mb": 50391.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12449.0, "ram_available_mb": 50391.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.349, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.778}, "timestamp": "2026-01-19T12:51:04.383201"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3772.806, "latencies_ms": [3772.806], "images_per_second": 0.265, "prompt_tokens": 21, "response_tokens_est": 51, "n_tiles": 1, "output_text": "shower curtain: 1\nbathtub: 1\nshower head: 1\ntoilet paper holder: 1\nmirrors: 2\nsink: 2\nvanity: 2\ncountertop: 2\nfloor: 1\nrug: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12449.0, "ram_available_mb": 50391.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12449.3, "ram_available_mb": 50391.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.12, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 7.124}, "timestamp": "2026-01-19T12:51:10.192648"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1907.878, "latencies_ms": [1907.878], "images_per_second": 0.524, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The bathtub is positioned to the left of the shower and partially behind the shower curtain. The sink is located in the foreground, near the mirror and light fixtures.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12449.3, "ram_available_mb": 50391.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.108, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:51:14.150356"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2613.724, "latencies_ms": [2613.724], "images_per_second": 0.383, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The bathroom features a double vanity with dark wood cabinets, a white countertop, and marble-like backsplash. A bathtub with a shower curtain is situated next to the vanity, complemented by a red rug on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.501, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.936}, "timestamp": "2026-01-19T12:51:18.782222"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3160.373, "latencies_ms": [3160.373], "images_per_second": 0.316, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The bathroom features a beige color scheme, accented by red shower curtains and dark wood cabinets. The lighting is warm and inviting, with two wall-mounted light fixtures providing illumination. The bathroom includes a glass-enclosed shower and a white bathtub, contributing to its clean and spacious appearance.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.561, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 7.052}, "timestamp": "2026-01-19T12:51:23.959750"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1809.001, "latencies_ms": [1809.001], "images_per_second": 0.553, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A surfer in a wetsuit rides a wave on a surfboard, skillfully carving through the water as it crashes.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.11, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T12:51:27.830280"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2670.692, "latencies_ms": [2670.692], "images_per_second": 0.374, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "surfboard: 1\nwetsuit: 1\nwater: 1\nwave: 1\ncable: 1\nperson: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12448.8, "ram_available_mb": 50392.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.347, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T12:51:32.525174"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2676.458, "latencies_ms": [2676.458], "images_per_second": 0.374, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The surfer is positioned near the center of the image, riding a wave. The wave is breaking towards the left side of the frame, creating a dynamic contrast with the surfer's position. The ocean extends into the background, providing a sense of scale and vastness.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12448.8, "ram_available_mb": 50392.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12449.7, "ram_available_mb": 50391.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.353, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.042}, "timestamp": "2026-01-19T12:51:37.218611"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2532.673, "latencies_ms": [2532.673], "images_per_second": 0.395, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A surfer in a wetsuit is skillfully riding a wave in the ocean. The wave is breaking, creating a dynamic scene with splashing water. The image is black and white, enhancing the dramatic effect.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12449.7, "ram_available_mb": 50391.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12449.9, "ram_available_mb": 50391.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.405, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.92}, "timestamp": "2026-01-19T12:51:41.775987"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3435.802, "latencies_ms": [3435.802], "images_per_second": 0.291, "prompt_tokens": 18, "response_tokens_est": 72, "n_tiles": 1, "output_text": "The black and white image captures a dynamic moment of action in the ocean. The lighting is dramatic, with strong contrasts between light and shadow, enhancing the visual impact of the surfer and the wave. The wave appears to be breaking, creating a powerful visual effect. The surfer is wearing a wetsuit, which suggests the presence of cold water conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.9, "ram_available_mb": 50391.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12449.9, "ram_available_mb": 50391.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.277, "power_cpu_cv_mean_watts": 1.809, "power_sys_5v0_mean_watts": 7.143}, "timestamp": "2026-01-19T12:51:47.250794"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2227.946, "latencies_ms": [2227.946], "images_per_second": 0.449, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A baseball player in a white uniform with orange and black accents is poised at home plate, ready to swing the bat, while a catcher in black and red gear crouches behind him.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12449.9, "ram_available_mb": 50391.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12449.3, "ram_available_mb": 50391.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.439, "power_cpu_cv_mean_watts": 1.625, "power_sys_5v0_mean_watts": 6.63}, "timestamp": "2026-01-19T12:51:51.520146"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2858.49, "latencies_ms": [2858.49], "images_per_second": 0.35, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball glove: 1\nbaseball mitt: 1\nbaseball: 1\ncatcher: 2\numpire: 1\nbaseball field: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.3, "ram_available_mb": 50391.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.653, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 6.771}, "timestamp": "2026-01-19T12:51:56.425873"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2967.927, "latencies_ms": [2967.927], "images_per_second": 0.337, "prompt_tokens": 25, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The main objects are positioned in a spatial arrangement that suggests a baseball game is taking place. The batter is in the foreground, preparing to swing, while the catcher and umpire are in the background, observing the play. The spectators are seated in a distant area, providing context to the game's atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.651, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T12:52:01.440012"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3707.798, "latencies_ms": [3707.798], "images_per_second": 0.27, "prompt_tokens": 19, "response_tokens_est": 73, "n_tiles": 1, "output_text": "A baseball game is in progress on a sunny day. A batter in a white uniform with orange accents is swinging at a pitch, while a catcher in a black uniform with red accents is crouched behind home plate. An umpire in a blue uniform is positioned behind the catcher, observing the play. Spectators are seated in the stands, watching the game unfold.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.762, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 6.881}, "timestamp": "2026-01-19T12:52:07.191201"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2085.307, "latencies_ms": [2085.307], "images_per_second": 0.48, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The batter is wearing white pants and an orange jersey. The catcher is wearing black and grey uniform. The lighting appears to be natural daylight, and the field is well-maintained.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.491, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 6.564}, "timestamp": "2026-01-19T12:52:11.303692"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1776.957, "latencies_ms": [1776.957], "images_per_second": 0.563, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The black and white image showcases a collection of fruits, including apples, oranges, grapes, and peanuts, arranged in a visually appealing manner.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12449.4, "ram_available_mb": 50391.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.941, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.667}, "timestamp": "2026-01-19T12:52:15.110553"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2080.556, "latencies_ms": [2080.556], "images_per_second": 0.481, "prompt_tokens": 21, "response_tokens_est": 22, "n_tiles": 1, "output_text": "apple: 2\norange: 1\ngrapes: 4\npeanuts: 10\nfruit: 5", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12449.4, "ram_available_mb": 50391.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.776, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.93}, "timestamp": "2026-01-19T12:52:19.230886"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2076.304, "latencies_ms": [2076.304], "images_per_second": 0.482, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The left side of the image features the fruits and nuts, while the right side shows the apple. The fruits and nuts are positioned in the foreground, while the apple is situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.94, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.77}, "timestamp": "2026-01-19T12:52:23.322373"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2309.819, "latencies_ms": [2309.819], "images_per_second": 0.433, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene depicts a still life arrangement featuring various fruits, including apples, grapes, and a citrus fruit, scattered across a surface. The setting appears to be indoors, possibly a kitchen or dining area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12450.0, "ram_available_mb": 50390.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.718, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 6.912}, "timestamp": "2026-01-19T12:52:27.667240"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2975.32, "latencies_ms": [2975.32], "images_per_second": 0.336, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The fruits are depicted in shades of white and gray, creating a monochromatic effect. The lighting in the image is soft and diffused, enhancing the textures and details of the fruits and nuts. The fruits appear to be whole and whole, showcasing their natural shapes and colors.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12450.0, "ram_available_mb": 50390.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.024, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 7.085}, "timestamp": "2026-01-19T12:52:32.658122"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1600.266, "latencies_ms": [1600.266], "images_per_second": 0.625, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A city street scene features modern buildings, a bike path, parked cars, and a bus traveling down the road.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12449.6, "ram_available_mb": 50391.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.181, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 6.148}, "timestamp": "2026-01-19T12:52:36.302960"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2844.679, "latencies_ms": [2844.679], "images_per_second": 0.352, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "building: 5\ncar: 2\nbus: 1\nstreet light: 2\npedestrian path: 1\nbus stop: 1\ntrees: 2\npower lines: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12449.6, "ram_available_mb": 50391.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.51, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T12:52:41.161575"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2583.279, "latencies_ms": [2583.279], "images_per_second": 0.387, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The foreground features a paved road with a bike path running alongside it.  The background includes buildings of varying heights and designs, creating a diverse urban landscape. The bike path appears relatively empty, contrasting with the more populated street scene.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12448.8, "ram_available_mb": 50392.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12448.7, "ram_available_mb": 50392.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.368, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 6.604}, "timestamp": "2026-01-19T12:52:45.807617"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2471.345, "latencies_ms": [2471.345], "images_per_second": 0.405, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a modern urban street with modern buildings lining both sides. A bike path runs alongside the road, providing a green space for cyclists. The street is relatively quiet, with only a few cars and a bus visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12448.7, "ram_available_mb": 50392.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12448.7, "ram_available_mb": 50392.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.616, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 6.706}, "timestamp": "2026-01-19T12:52:50.296359"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2418.342, "latencies_ms": [2418.342], "images_per_second": 0.414, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The buildings exhibit a mix of colors, including white, red, and brown. The lighting is bright, likely from streetlights and building windows. The materials appear to be primarily concrete and metal. The weather appears to be partly cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12448.7, "ram_available_mb": 50392.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12449.0, "ram_available_mb": 50391.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.235, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.53}, "timestamp": "2026-01-19T12:52:54.746478"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1497.464, "latencies_ms": [1497.464], "images_per_second": 0.668, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A man and a woman are seated at a wooden table in a cozy pub, smiling and embracing each other.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12449.0, "ram_available_mb": 50391.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.105, "power_cpu_cv_mean_watts": 1.019, "power_sys_5v0_mean_watts": 5.993}, "timestamp": "2026-01-19T12:52:58.267495"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2575.38, "latencies_ms": [2575.38], "images_per_second": 0.388, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "man: 2\nwoman: 2\ntie: 1\ntable: 1\nphone: 1\nscreen: 1\nchair: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.598, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 6.734}, "timestamp": "2026-01-19T12:53:02.871675"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1988.716, "latencies_ms": [1988.716], "images_per_second": 0.503, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with a man and woman seated at a table in the background. The man is on the left side of the image, and the woman is on the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.216, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 6.33}, "timestamp": "2026-01-19T12:53:06.875176"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2518.628, "latencies_ms": [2518.628], "images_per_second": 0.397, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "A man and a woman are seated at a table in a dimly lit bar or pub. The man is wearing a blue striped shirt and glasses, while the woman is wearing a white tank top. They are both smiling and appear to be enjoying each other's company.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12448.8, "ram_available_mb": 50392.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.557, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 6.628}, "timestamp": "2026-01-19T12:53:11.440798"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2470.624, "latencies_ms": [2470.624], "images_per_second": 0.405, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The man is wearing a purple striped shirt and a patterned tie. The lighting in the pub is warm and dim, creating a cozy atmosphere. The walls are painted a muted green, and the TV is displaying a sports broadcast.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12448.8, "ram_available_mb": 50392.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12449.0, "ram_available_mb": 50391.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.416, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.567}, "timestamp": "2026-01-19T12:53:15.930748"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1643.343, "latencies_ms": [1643.343], "images_per_second": 0.609, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A woman dressed in a costume and wearing a golden helmet is talking on her cell phone amidst a crowd of people.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.0, "ram_available_mb": 50391.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.302, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.73}, "timestamp": "2026-01-19T12:53:19.616794"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2723.809, "latencies_ms": [2723.809], "images_per_second": 0.367, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "woman: 1\nhelmet: 1\nman: 1\nman: 1\nman: 1\nman: 1\nman: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12449.0, "ram_available_mb": 50391.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.861, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T12:53:24.366661"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2053.702, "latencies_ms": [2053.702], "images_per_second": 0.487, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The man on the left is partially visible in the foreground, while the woman is centrally positioned and slightly to the right. The background features other individuals, creating a sense of depth and context.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.0, "ram_available_mb": 50391.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12449.9, "ram_available_mb": 50391.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.301, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T12:53:28.445264"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1897.525, "latencies_ms": [1897.525], "images_per_second": 0.527, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The scene takes place outdoors, possibly during a festival or event. A woman dressed in costume is talking on her cell phone amidst a crowd of people.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12449.9, "ram_available_mb": 50391.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.681, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.827}, "timestamp": "2026-01-19T12:53:32.375408"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2392.849, "latencies_ms": [2392.849], "images_per_second": 0.418, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The woman is wearing a gold and black costume with a helmet-like headpiece. Her hair is dark and appears to be styled in loose waves. The lighting suggests an outdoor setting, possibly in bright sunlight.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.489, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:53:36.793792"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1690.446, "latencies_ms": [1690.446], "images_per_second": 0.592, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The bathroom features a white toilet situated in the corner, surrounded by white tiles and pipes, with a shower and buckets nearby.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12450.2, "ram_available_mb": 50390.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12450.1, "ram_available_mb": 50390.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.49, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T12:53:40.527103"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3462.003, "latencies_ms": [3462.003], "images_per_second": 0.289, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "Shower head: 1\nPipe: 2\nToilet: 1\nToilet paper holder: 1\nBucket: 2\nFloor tiles: 8\nShelf: 1\nCleaning supplies: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12450.1, "ram_available_mb": 50390.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12450.1, "ram_available_mb": 50390.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.352, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.066}, "timestamp": "2026-01-19T12:53:46.027452"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1795.58, "latencies_ms": [1795.58], "images_per_second": 0.557, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The toilet is located in the foreground, close to the shower and bucket. The shower and bucket are situated in the background, further away from the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12450.1, "ram_available_mb": 50390.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.712, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.688}, "timestamp": "2026-01-19T12:53:49.849947"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1996.666, "latencies_ms": [1996.666], "images_per_second": 0.501, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The bathroom features a toilet, a shower stall, and several buckets. The scene suggests a functional and possibly temporary space for personal hygiene and cleaning.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12449.5, "ram_available_mb": 50391.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12449.6, "ram_available_mb": 50391.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.425, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.81}, "timestamp": "2026-01-19T12:53:53.875512"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2290.784, "latencies_ms": [2290.784], "images_per_second": 0.437, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bathroom is predominantly white, with gray tiled flooring. The lighting appears to be artificial, coming from overhead fixtures. The materials include white tiles, plastic pipes, and metal fixtures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.6, "ram_available_mb": 50391.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12449.4, "ram_available_mb": 50391.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.488, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.833}, "timestamp": "2026-01-19T12:53:58.214267"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1555.775, "latencies_ms": [1555.775], "images_per_second": 0.643, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A man wearing glasses and a green shirt stands next to an elephant with its trunk touching his face.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12449.4, "ram_available_mb": 50391.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12450.1, "ram_available_mb": 50390.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.629, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.627}, "timestamp": "2026-01-19T12:54:01.796500"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2711.59, "latencies_ms": [2711.59], "images_per_second": 0.369, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "elephant: 2\nman: 1\nglasses: 1\nt-shirt: 1\ntrunk: 1\nhills: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12450.1, "ram_available_mb": 50390.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12449.7, "ram_available_mb": 50391.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.116, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T12:54:06.526276"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2294.962, "latencies_ms": [2294.962], "images_per_second": 0.436, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The elephant is positioned close to the man, creating a close and intimate interaction. The elephant's trunk is partially visible, extending towards the man's face, suggesting an affectionate or playful connection.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12449.7, "ram_available_mb": 50391.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.552, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.779}, "timestamp": "2026-01-19T12:54:10.853526"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2353.922, "latencies_ms": [2353.922], "images_per_second": 0.425, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A man is standing next to an elephant, appearing to be interacting or playing with the elephant's trunk. The setting suggests a natural environment, possibly a jungle or forest, with trees and hills visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12449.2, "ram_available_mb": 50391.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12448.8, "ram_available_mb": 50392.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.866, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.869}, "timestamp": "2026-01-19T12:54:15.235390"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2476.24, "latencies_ms": [2476.24], "images_per_second": 0.404, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The elephant's skin is a dark brown color. The lighting appears to be natural, possibly sunlight, giving the image a warm tone. The elephant's trunk is dark brown and textured. The weather appears to be sunny and clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12448.8, "ram_available_mb": 50392.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12449.1, "ram_available_mb": 50391.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.383, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 6.965}, "timestamp": "2026-01-19T12:54:19.759019"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1553.612, "latencies_ms": [1553.612], "images_per_second": 0.644, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Five young children sit on the grass, each holding a white frisbee with a black design.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 12449.1, "ram_available_mb": 50391.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12448.4, "ram_available_mb": 50392.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.223, "power_cpu_cv_mean_watts": 0.934, "power_sys_5v0_mean_watts": 6.551}, "timestamp": "2026-01-19T12:54:23.350958"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3126.06, "latencies_ms": [3126.06], "images_per_second": 0.32, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Frisbee: 2\nUltimate: 1\nBoy: 3\nBoy: 2\nBoy: 1\nBoy: 1\nBoy: 1\nBoy: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12448.4, "ram_available_mb": 50392.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12448.0, "ram_available_mb": 50392.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.621, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.019}, "timestamp": "2026-01-19T12:54:28.498355"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2048.243, "latencies_ms": [2048.243], "images_per_second": 0.488, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The children's feet are positioned in the foreground, close to the frisbees. The frisbees are situated near the children, creating a sense of proximity and playfulness.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12448.0, "ram_available_mb": 50392.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12447.9, "ram_available_mb": 50393.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.397, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.822}, "timestamp": "2026-01-19T12:54:32.577968"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2197.249, "latencies_ms": [2197.249], "images_per_second": 0.455, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A group of young children is sitting on grass in a natural setting, possibly a park or outdoor area. They are holding frisbees, suggesting they might be playing or enjoying a game.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12447.9, "ram_available_mb": 50393.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12447.6, "ram_available_mb": 50393.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.0, "power_cpu_cv_mean_watts": 1.446, "power_sys_5v0_mean_watts": 6.91}, "timestamp": "2026-01-19T12:54:36.807881"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2351.948, "latencies_ms": [2351.948], "images_per_second": 0.425, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The children are wearing light brown and tan clothing. The lighting appears to be natural and diffused, suggesting an overcast day. The grass they are sitting on is short and green, typical of outdoor settings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.6, "ram_available_mb": 50393.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12447.4, "ram_available_mb": 50393.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.93, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 7.013}, "timestamp": "2026-01-19T12:54:41.207240"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1698.418, "latencies_ms": [1698.418], "images_per_second": 0.589, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A young girl in a red coat and blue jeans holds a blue and pink umbrella while standing on a wet sidewalk.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 12447.4, "ram_available_mb": 50393.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12447.6, "ram_available_mb": 50393.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.273, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T12:54:44.963517"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3080.01, "latencies_ms": [3080.01], "images_per_second": 0.325, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Umbrella: 1\nGirl: 1\nHedge: 1\nTruck: 1\nHouse: 2\nTrees: 3\nSky: 1\nPavement: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12447.6, "ram_available_mb": 50393.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12448.5, "ram_available_mb": 50392.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.716, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T12:54:50.063351"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2111.26, "latencies_ms": [2111.26], "images_per_second": 0.474, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The girl is positioned in the foreground of the image, standing on a wet sidewalk near a bush and a parked truck. The background includes houses and trees, indicating a residential setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12448.5, "ram_available_mb": 50392.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12449.6, "ram_available_mb": 50391.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.744, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 6.913}, "timestamp": "2026-01-19T12:54:54.238654"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2138.394, "latencies_ms": [2138.394], "images_per_second": 0.468, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A young girl in a red coat is standing on a wet sidewalk, holding a blue and pink umbrella. The scene takes place on a rainy day, with houses and trees visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12449.6, "ram_available_mb": 50391.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12451.3, "ram_available_mb": 50389.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.873, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T12:54:58.388156"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1856.8, "latencies_ms": [1856.8], "images_per_second": 0.539, "prompt_tokens": 18, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The girl is wearing a bright red coat. The umbrella is black with white and pink designs. The scene appears to be wet from rain.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12451.3, "ram_available_mb": 50389.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12453.5, "ram_available_mb": 50387.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.74, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T12:55:02.269236"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1900.437, "latencies_ms": [1900.437], "images_per_second": 0.526, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A group of elephants, including two calves, stand together near a body of water, their dusty bodies and expressive faces creating a captivating scene.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12453.5, "ram_available_mb": 50387.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12453.3, "ram_available_mb": 50387.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.199, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 6.706}, "timestamp": "2026-01-19T12:55:06.219824"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2277.166, "latencies_ms": [2277.166], "images_per_second": 0.439, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "elephant: 3\nwater: 1\ndirt: 2\ntrees: 1\nsky: 1\nground: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12453.3, "ram_available_mb": 50387.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12452.9, "ram_available_mb": 50388.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.954, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.876}, "timestamp": "2026-01-19T12:55:10.530537"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2153.335, "latencies_ms": [2153.335], "images_per_second": 0.464, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the elephant closest to the camera appearing larger and closer to the viewer. The background includes other elephants and a body of water, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12452.9, "ram_available_mb": 50388.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12452.1, "ram_available_mb": 50388.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.845, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T12:55:14.708853"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2439.897, "latencies_ms": [2439.897], "images_per_second": 0.41, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A group of elephants, including two young ones, is seen near a body of water. The elephants are dusty, indicating recent activity or movement. The setting appears to be a natural environment, possibly a savanna or wildlife reserve.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12452.1, "ram_available_mb": 50388.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12452.0, "ram_available_mb": 50388.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.224, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:55:19.199036"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2445.056, "latencies_ms": [2445.056], "images_per_second": 0.409, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The elephants are primarily brown in color. The lighting appears to be natural, possibly sunlight, giving a warm tone to the scene. The elephants are standing on a reddish-brown dirt surface, which contrasts with their skin color.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12452.0, "ram_available_mb": 50388.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12452.5, "ram_available_mb": 50388.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.381, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T12:55:23.673677"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2002.354, "latencies_ms": [2002.354], "images_per_second": 0.499, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A surfer in a red and green wetsuit is skillfully riding a wave on a white surfboard, performing an impressive aerial maneuver.", "error": null, "sys_before": {"cpu_percent": 6.1, "ram_used_mb": 12452.5, "ram_available_mb": 50388.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12452.8, "ram_available_mb": 50388.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.521, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.797}, "timestamp": "2026-01-19T12:55:27.715452"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2603.404, "latencies_ms": [2603.404], "images_per_second": 0.384, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "surfboard: 1\nsurfer: 1\nwaves: 1\nwater: 1\nsky: 1\nclouds: 1\nshore: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12452.8, "ram_available_mb": 50388.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12451.9, "ram_available_mb": 50389.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.403, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.993}, "timestamp": "2026-01-19T12:55:32.345166"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1984.173, "latencies_ms": [1984.173], "images_per_second": 0.504, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave. The wave extends towards the right side of the image, creating a dynamic and energetic scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12451.9, "ram_available_mb": 50389.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12452.0, "ram_available_mb": 50388.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.123, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.784}, "timestamp": "2026-01-19T12:55:36.375310"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2623.908, "latencies_ms": [2623.908], "images_per_second": 0.381, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A surfer in a red and green wetsuit is performing an aerial maneuver on a large green wave, skillfully riding the crest and executing a complex trick. The setting appears to be a coastal area with ocean waves.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12452.0, "ram_available_mb": 50388.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12451.8, "ram_available_mb": 50389.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.249, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 6.979}, "timestamp": "2026-01-19T12:55:41.034746"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1927.205, "latencies_ms": [1927.205], "images_per_second": 0.519, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The surfer is wearing a red and green wetsuit. The wave is green and white, and the lighting suggests an overcast sky.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12451.8, "ram_available_mb": 50389.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12451.5, "ram_available_mb": 50389.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.357, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.793}, "timestamp": "2026-01-19T12:55:44.997016"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1746.96, "latencies_ms": [1746.96], "images_per_second": 0.572, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Two men in traditional white clothing are riding horses along a sandy beach, waving to onlookers as they gallop.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12451.5, "ram_available_mb": 50389.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12450.7, "ram_available_mb": 50390.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.071, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 6.285}, "timestamp": "2026-01-19T12:55:48.792066"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2795.739, "latencies_ms": [2795.739], "images_per_second": 0.358, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Horse: 2\nPerson: 2\nSword: 1\nHat: 2\nSand: 2\nOcean: 1\nSky: 1\nClouds: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12450.7, "ram_available_mb": 50390.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12451.3, "ram_available_mb": 50389.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.633, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 6.712}, "timestamp": "2026-01-19T12:55:53.602302"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1740.084, "latencies_ms": [1740.084], "images_per_second": 0.575, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the beach and ocean in the background. The horses are moving towards the ocean, further back from the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12450.7, "ram_available_mb": 50390.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12451.5, "ram_available_mb": 50389.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.87, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.242}, "timestamp": "2026-01-19T12:55:57.398409"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2069.285, "latencies_ms": [2069.285], "images_per_second": 0.483, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Two men are riding horses on a sandy beach near the ocean, appearing to be engaged in a game or activity. The beach is crowded with people enjoying the sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12451.5, "ram_available_mb": 50389.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12451.1, "ram_available_mb": 50389.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.314, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 6.419}, "timestamp": "2026-01-19T12:56:01.501032"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2177.118, "latencies_ms": [2177.118], "images_per_second": 0.459, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The sky is bright blue with scattered white clouds. The beach is sandy and appears relatively empty except for a few people. The horses are light-colored and appear to be running on the sand.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12451.1, "ram_available_mb": 50389.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12451.1, "ram_available_mb": 50389.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.213, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.439}, "timestamp": "2026-01-19T12:56:05.696745"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1869.247, "latencies_ms": [1869.247], "images_per_second": 0.535, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A custom-built trike with a silver engine and distinctive front suspension is parked in a driveway, accompanied by a small dog.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12451.1, "ram_available_mb": 50389.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12451.0, "ram_available_mb": 50389.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.703, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.712}, "timestamp": "2026-01-19T12:56:09.611821"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2776.713, "latencies_ms": [2776.713], "images_per_second": 0.36, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "tire: 2\nchopper: 3\nbike: 1\nbicycle: 2\ndog: 1\ngarage: 1\ntruck: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12451.0, "ram_available_mb": 50389.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12451.5, "ram_available_mb": 50389.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.042, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.978}, "timestamp": "2026-01-19T12:56:14.420554"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1903.333, "latencies_ms": [1903.333], "images_per_second": 0.525, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The trike is positioned in the foreground, slightly to the right of the garage. The garage is situated in the background, partially obscured by trees and bushes.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12451.5, "ram_available_mb": 50389.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12453.8, "ram_available_mb": 50387.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.492, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T12:56:18.372397"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3202.644, "latencies_ms": [3202.644], "images_per_second": 0.312, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The scene depicts a custom trike with a silver engine and exposed frame, parked in a driveway in front of a garage. A small dog is sitting near the trike's frame.  In the background, a pickup truck with a blue tarp is parked, and several bicycles are visible inside the garage.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12453.8, "ram_available_mb": 50387.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12454.3, "ram_available_mb": 50386.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.577, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T12:56:23.595626"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2834.957, "latencies_ms": [2834.957], "images_per_second": 0.353, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The motorcycle is primarily silver and chrome, showcasing a metallic finish. The lighting in the image is bright, likely from natural daylight, creating a clear view. The materials appear to be sturdy metal and possibly some plastic components. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12454.3, "ram_available_mb": 50386.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12454.1, "ram_available_mb": 50386.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.987, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T12:56:28.471487"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1890.47, "latencies_ms": [1890.47], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man is flying a blue and white kite high above a sandy beach, surrounded by other beachgoers and enjoying the sunny day.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12454.1, "ram_available_mb": 50386.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12454.5, "ram_available_mb": 50386.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.573, "power_cpu_cv_mean_watts": 1.149, "power_sys_5v0_mean_watts": 6.686}, "timestamp": "2026-01-19T12:56:32.413387"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2839.534, "latencies_ms": [2839.534], "images_per_second": 0.352, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "kite: 1\nperson: 1\nsand: 8\nwater: 1\ntrees: 4\nbuildings: 2\nsky: 1\nclouds: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12454.5, "ram_available_mb": 50386.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12455.5, "ram_available_mb": 50385.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.833, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.972}, "timestamp": "2026-01-19T12:56:37.266312"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2155.488, "latencies_ms": [2155.488], "images_per_second": 0.464, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The man is standing on the sandy beach, facing the water.  In the background, other people can be seen near the water's edge. The man is positioned in the foreground, closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12455.5, "ram_available_mb": 50385.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12455.7, "ram_available_mb": 50385.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.389, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T12:56:41.457493"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2364.935, "latencies_ms": [2364.935], "images_per_second": 0.423, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene takes place on a sandy beach near a body of water, where people are enjoying various activities. A man is flying a kite high in the sky, while others are walking along the shoreline or playing in the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12455.7, "ram_available_mb": 50385.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12455.7, "ram_available_mb": 50385.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.526, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 6.939}, "timestamp": "2026-01-19T12:56:45.859048"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1755.222, "latencies_ms": [1755.222], "images_per_second": 0.57, "prompt_tokens": 18, "response_tokens_est": 23, "n_tiles": 1, "output_text": "The kite is light blue and white. The beach is sandy and appears sunny. The sky is partly cloudy.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12455.7, "ram_available_mb": 50385.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12455.9, "ram_available_mb": 50385.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.851, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T12:56:49.666351"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2229.505, "latencies_ms": [2229.505], "images_per_second": 0.449, "prompt_tokens": 8, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The kitchen counter is cluttered with various items, including cleaning supplies, a green bottle, a red bow, a notebook, a wine glass, a bowl, a microwave, a sink, and a refrigerator.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12455.9, "ram_available_mb": 50385.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12455.7, "ram_available_mb": 50385.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.115, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.865}, "timestamp": "2026-01-19T12:56:53.922884"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4801.569, "latencies_ms": [4801.569], "images_per_second": 0.208, "prompt_tokens": 21, "response_tokens_est": 72, "n_tiles": 1, "output_text": "kitchen sink: 2\nstainless steel refrigerator: 1\nwooden cabinets: 6\nmicrowave: 1\noven: 1\ncountertop: 2\nfaucet: 1\ngreen dishwashing detergent bottle: 1\nred bow: 1\nplastic cups: 2\nglass bottles: 2\nwooden cutting board: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12455.7, "ram_available_mb": 50385.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12454.4, "ram_available_mb": 50386.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.371, "power_cpu_cv_mean_watts": 1.983, "power_sys_5v0_mean_watts": 7.132}, "timestamp": "2026-01-19T12:57:00.758329"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2140.252, "latencies_ms": [2140.252], "images_per_second": 0.467, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The stainless steel refrigerator is positioned to the left of the kitchen counter. The sink is located in the foreground, closer to the viewer. The kitchen counter extends into the background, occupying a significant portion of the image.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12454.4, "ram_available_mb": 50386.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12453.9, "ram_available_mb": 50387.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.363, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 6.878}, "timestamp": "2026-01-19T12:57:04.940465"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2327.66, "latencies_ms": [2327.66], "images_per_second": 0.43, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The kitchen is clean and organized, with light wood cabinets, a stainless steel refrigerator, and a black countertop. A sink, dishwasher, and various kitchen items are visible on the counter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12453.9, "ram_available_mb": 50387.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12454.1, "ram_available_mb": 50386.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.589, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:57:09.294772"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2483.519, "latencies_ms": [2483.519], "images_per_second": 0.403, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The kitchen features light brown wooden cabinets and a black countertop. The lighting is bright, likely from overhead fixtures, creating a well-lit space. The materials include wood, stainless steel, and black countertop elements.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12454.1, "ram_available_mb": 50386.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12454.4, "ram_available_mb": 50386.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.642, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T12:57:13.808062"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1599.475, "latencies_ms": [1599.475], "images_per_second": 0.625, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A large orange and white kite soars high in the clear blue sky, tethered to the ground by multiple lines.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12454.4, "ram_available_mb": 50386.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12454.0, "ram_available_mb": 50386.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.059, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.156}, "timestamp": "2026-01-19T12:57:17.459250"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2890.952, "latencies_ms": [2890.952], "images_per_second": 0.346, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "kite: 1\nkite lines: 2\nkite fabric: 1\nkite shape: 1\nkite design: 1\nkite colors: 2\nkite material: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12454.0, "ram_available_mb": 50386.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12453.4, "ram_available_mb": 50387.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.615, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 6.766}, "timestamp": "2026-01-19T12:57:22.373817"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2215.852, "latencies_ms": [2215.852], "images_per_second": 0.451, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main object is a kite flying high in the sky, positioned near the foreground. The kite is primarily white with red and black accents. The background is a clear, bright blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12453.4, "ram_available_mb": 50387.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12453.4, "ram_available_mb": 50387.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.325, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.512}, "timestamp": "2026-01-19T12:57:26.604044"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2013.486, "latencies_ms": [2013.486], "images_per_second": 0.497, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A large kite soars high in the clear blue sky, controlled by a person holding the lines. The kite's vibrant colors contrast against the azure backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12452.8, "ram_available_mb": 50388.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12453.6, "ram_available_mb": 50387.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.464, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 6.52}, "timestamp": "2026-01-19T12:57:30.648311"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1588.655, "latencies_ms": [1588.655], "images_per_second": 0.629, "prompt_tokens": 18, "response_tokens_est": 20, "n_tiles": 1, "output_text": "The kite is predominantly white with red accents. The lighting suggests a sunny day with clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12453.6, "ram_available_mb": 50387.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12453.8, "ram_available_mb": 50387.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.046, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.081}, "timestamp": "2026-01-19T12:57:34.263615"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1872.21, "latencies_ms": [1872.21], "images_per_second": 0.534, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The room features two twin beds with white linens and gray throw blankets, accented with black and gray throw pillows.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12453.8, "ram_available_mb": 50387.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12453.4, "ram_available_mb": 50387.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.515, "power_cpu_cv_mean_watts": 1.148, "power_sys_5v0_mean_watts": 6.699}, "timestamp": "2026-01-19T12:57:38.183298"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2929.352, "latencies_ms": [2929.352], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "bed: 2\npillows: 4\ntowels: 2\nnightstands: 1\nlamps: 2\nartwork: 1\nwindow: 2\ndoor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12453.4, "ram_available_mb": 50387.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12452.4, "ram_available_mb": 50388.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.838, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T12:57:43.131777"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2360.41, "latencies_ms": [2360.41], "images_per_second": 0.424, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The beds are in the foreground, while the artwork and window are in the background. The door is situated near the window, offering a view outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12452.4, "ram_available_mb": 50388.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12452.3, "ram_available_mb": 50388.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.589, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:57:47.537786"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3223.988, "latencies_ms": [3223.988], "images_per_second": 0.31, "prompt_tokens": 19, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The scene depicts a hotel room with two twin beds, each adorned with neatly made white linens and dark gray throw blankets. The room features modern decor, including artwork on the walls and warm lighting from lamps and table lamps. A window offers a view of the outside, and a door is visible on the right side of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12452.3, "ram_available_mb": 50388.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12453.1, "ram_available_mb": 50387.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.651, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.052}, "timestamp": "2026-01-19T12:57:52.788828"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2127.326, "latencies_ms": [2127.326], "images_per_second": 0.47, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The room features warm lighting from lamps and a window with natural light filtering through. The walls are painted in a light green color, and the flooring is dark wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12453.1, "ram_available_mb": 50387.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12453.7, "ram_available_mb": 50387.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.061, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T12:57:56.931813"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2042.951, "latencies_ms": [2042.951], "images_per_second": 0.489, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man in a white helmet and leather jacket is riding a white motorcycle with green stripes down a curving road, passing spectators standing behind a wooden fence.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12453.7, "ram_available_mb": 50387.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12453.7, "ram_available_mb": 50387.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.597, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T12:58:01.024066"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3125.791, "latencies_ms": [3125.791], "images_per_second": 0.32, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Motorcycle: 1\nHelmet: 1\nRider: 1\nFence: 2\nGrass: 2\nRoad: 1\nSpectators: 2\nBright sunlight: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12453.7, "ram_available_mb": 50387.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12453.9, "ram_available_mb": 50387.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.792, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.044}, "timestamp": "2026-01-19T12:58:06.214833"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1816.359, "latencies_ms": [1816.359], "images_per_second": 0.551, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The motorcycle is positioned in the foreground, moving towards the left side of the image. The spectators are in the background, observing the motorcycle's performance.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12453.9, "ram_available_mb": 50387.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12457.2, "ram_available_mb": 50383.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.599, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T12:58:10.063794"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2069.215, "latencies_ms": [2069.215], "images_per_second": 0.483, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A man is riding a white motorcycle on a paved road, leaning into a turn. Spectators are gathered behind a fence, watching the motorcycle performance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12457.2, "ram_available_mb": 50383.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12457.2, "ram_available_mb": 50383.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.25, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.797}, "timestamp": "2026-01-19T12:58:14.148622"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2203.948, "latencies_ms": [2203.948], "images_per_second": 0.454, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The motorcycle is predominantly white with green accents. The lighting suggests it might be an overcast day. The motorcycle appears to be made of metal and has a sleek, aerodynamic design.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12457.2, "ram_available_mb": 50383.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12457.4, "ram_available_mb": 50383.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.913, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T12:58:18.375769"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1895.738, "latencies_ms": [1895.738], "images_per_second": 0.527, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The table is set for a romantic dinner, featuring white plates, silverware, wine glasses, and a centerpiece of white flowers in a vase.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12457.4, "ram_available_mb": 50383.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12457.1, "ram_available_mb": 50383.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.649, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.814}, "timestamp": "2026-01-19T12:58:22.310793"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2463.614, "latencies_ms": [2463.614], "images_per_second": 0.406, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "vase: 1\nflowers: 1\nglasses: 3\ntablecloth: 1\nplace settings: 2\ncutlery: 2", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12457.1, "ram_available_mb": 50383.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12456.0, "ram_available_mb": 50384.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.6, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T12:58:26.798193"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1899.163, "latencies_ms": [1899.163], "images_per_second": 0.527, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the table and chairs arranged in the background. The flowers are placed centrally on the table, creating a focal point.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12456.0, "ram_available_mb": 50384.9, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12457.2, "ram_available_mb": 50383.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.488, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.726}, "timestamp": "2026-01-19T12:58:30.721552"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3564.896, "latencies_ms": [3564.896], "images_per_second": 0.281, "prompt_tokens": 19, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The scene depicts a sophisticated dining setting with a table set for a meal, featuring white tablecloths, neatly folded napkins, wine glasses, and silverware. A centerpiece of white flowers in a glass vase adds a touch of elegance and freshness to the table. The background suggests a restaurant or upscale dining establishment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12457.2, "ram_available_mb": 50383.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12457.7, "ram_available_mb": 50383.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.126, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.052}, "timestamp": "2026-01-19T12:58:36.316924"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2801.079, "latencies_ms": [2801.079], "images_per_second": 0.357, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The table is covered with a pristine white tablecloth. The centerpiece is a vase filled with delicate white flowers, illuminated by a soft, warm light source. The table setting includes several wine glasses and silverware, ready for a meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12457.1, "ram_available_mb": 50383.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12457.3, "ram_available_mb": 50383.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.951, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.994}, "timestamp": "2026-01-19T12:58:41.156405"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1580.102, "latencies_ms": [1580.102], "images_per_second": 0.633, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A tall, ornate clock tower with two clock faces stands prominently against a hazy sky.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12457.3, "ram_available_mb": 50383.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12456.9, "ram_available_mb": 50384.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.893, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.72}, "timestamp": "2026-01-19T12:58:44.770328"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3296.202, "latencies_ms": [3296.202], "images_per_second": 0.303, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "clock: 2\npole: 1\nclock face: 2\nclock hands: 2\nclock numbers: 10, 11, 12, 13, 14, 15, 16, 17\nfog: 1\nfield: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12456.9, "ram_available_mb": 50384.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12456.6, "ram_available_mb": 50384.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.035, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.123}, "timestamp": "2026-01-19T12:58:50.112993"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2418.772, "latencies_ms": [2418.772], "images_per_second": 0.413, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The clock is positioned in the foreground, slightly to the right of the viewer. The field in the background is distant and appears blurred, creating a sense of depth. The clock is situated on a pole, further emphasizing its prominence in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12456.6, "ram_available_mb": 50384.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12458.2, "ram_available_mb": 50382.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.202, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T12:58:54.570798"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2462.49, "latencies_ms": [2462.49], "images_per_second": 0.406, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene features a square clock mounted on a pole, displaying the time. The background is blurred, suggesting an outdoor setting, possibly a park or a field. The image is in black and white, giving it a timeless and classic feel.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12458.2, "ram_available_mb": 50382.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12458.3, "ram_available_mb": 50382.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.182, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 7.091}, "timestamp": "2026-01-19T12:58:59.073171"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3416.872, "latencies_ms": [3416.872], "images_per_second": 0.293, "prompt_tokens": 18, "response_tokens_est": 69, "n_tiles": 1, "output_text": "The clock is primarily dark, possibly black or dark gray. The lighting appears to be soft and diffused, possibly from overcast skies or diffused sunlight. The clock's materials appear to be metal, giving it a sturdy and durable appearance. The weather appears to be overcast, contributing to the muted tones and overall mood of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12458.3, "ram_available_mb": 50382.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12460.0, "ram_available_mb": 50380.9, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.734, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 7.073}, "timestamp": "2026-01-19T12:59:04.522144"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2079.439, "latencies_ms": [2079.439], "images_per_second": 0.481, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A young man in a black t-shirt and baseball cap skillfully maneuvers his skateboard on a concrete surface, performing a trick while surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12459.8, "ram_available_mb": 50381.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12459.8, "ram_available_mb": 50381.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.154, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T12:59:08.637051"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3336.713, "latencies_ms": [3336.713], "images_per_second": 0.3, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "skateboard: 1\nbaseball cap: 1\nt-shirt: 1\npants: 1\nshoes: 1\nskateboard: 1\nground: 1\ntrees: 1\ngraffiti: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12459.8, "ram_available_mb": 50381.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12464.7, "ram_available_mb": 50376.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.036, "power_cpu_cv_mean_watts": 2.062, "power_sys_5v0_mean_watts": 7.179}, "timestamp": "2026-01-19T12:59:13.998063"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2086.843, "latencies_ms": [2086.843], "images_per_second": 0.479, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, moving towards the left side of the image. The skate park is situated in the background, extending beyond the immediate foreground.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12464.7, "ram_available_mb": 50376.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12465.5, "ram_available_mb": 50375.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.128, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T12:59:18.137294"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2538.766, "latencies_ms": [2538.766], "images_per_second": 0.394, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A young man is skateboarding at a skate park, performing a trick on a paved surface. He wears a black t-shirt and jeans. Trees and buildings are visible in the background, indicating an urban setting.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12465.5, "ram_available_mb": 50375.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12466.8, "ram_available_mb": 50374.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.461, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 7.01}, "timestamp": "2026-01-19T12:59:22.704033"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2474.28, "latencies_ms": [2474.28], "images_per_second": 0.404, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The skateboarder is wearing a black t-shirt and gray pants. The skateboard is black and appears to be made of wood. The lighting suggests an overcast day, and the scene takes place outdoors on a paved surface.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12466.8, "ram_available_mb": 50374.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12465.8, "ram_available_mb": 50375.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.441, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T12:59:27.218738"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1806.011, "latencies_ms": [1806.011], "images_per_second": 0.554, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A white plate is filled with freshly peeled and cut carrots, accompanied by a blue vegetable peeler and a small pile of beets.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12465.8, "ram_available_mb": 50375.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12465.5, "ram_available_mb": 50375.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.013, "power_cpu_cv_mean_watts": 1.344, "power_sys_5v0_mean_watts": 6.372}, "timestamp": "2026-01-19T12:59:31.057980"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2782.529, "latencies_ms": [2782.529], "images_per_second": 0.359, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "carrots: 20\nbeets: 3\ngreen beans: 6\ncarrot peeler: 1\nsink: 1\ncutting board: 1\nkitchen sink: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12465.5, "ram_available_mb": 50375.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12466.5, "ram_available_mb": 50374.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.614, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 6.736}, "timestamp": "2026-01-19T12:59:35.881682"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1969.74, "latencies_ms": [1969.74], "images_per_second": 0.508, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the carrots and beets placed near the plate. The sink and dish rack are in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12466.5, "ram_available_mb": 50374.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12466.5, "ram_available_mb": 50374.4, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.295, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.431}, "timestamp": "2026-01-19T12:59:39.877851"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2262.381, "latencies_ms": [2262.381], "images_per_second": 0.442, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a kitchen counter with a plate of freshly peeled and cut carrots, along with some beets and a blue vegetable peeler. A white dish rack and a knife are also visible in the background.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12466.5, "ram_available_mb": 50374.4, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12468.2, "ram_available_mb": 50372.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.503, "power_cpu_cv_mean_watts": 1.624, "power_sys_5v0_mean_watts": 6.619}, "timestamp": "2026-01-19T12:59:44.198959"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2109.719, "latencies_ms": [2109.719], "images_per_second": 0.474, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The carrots are bright orange and appear to be freshly peeled. The plate is white and round. The vegetables are placed on a countertop. The lighting is soft and diffused.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12468.2, "ram_available_mb": 50372.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12468.3, "ram_available_mb": 50372.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.496, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.522}, "timestamp": "2026-01-19T12:59:48.337642"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1856.303, "latencies_ms": [1856.303], "images_per_second": 0.539, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man is giving a presentation or lecture on a large screen, gesturing with his hands as he speaks to attentive audience members.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12467.6, "ram_available_mb": 50373.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12468.3, "ram_available_mb": 50372.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.808, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T12:59:52.262505"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2446.402, "latencies_ms": [2446.402], "images_per_second": 0.409, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "screen: 1\nman: 1\ntie: 1\ntable: 1\nwater bottles: 2\nlights: 2\npeople: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12468.3, "ram_available_mb": 50372.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12467.2, "ram_available_mb": 50373.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.661, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T12:59:56.732288"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2620.201, "latencies_ms": [2620.201], "images_per_second": 0.382, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main object, a man in a suit, is positioned in the foreground, facing the audience. The audience members are situated in the background, facing the screen. The screen is situated on a stage or platform, suggesting an audience-presented event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12467.2, "ram_available_mb": 50373.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12467.3, "ram_available_mb": 50373.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.383, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.979}, "timestamp": "2026-01-19T13:00:01.369654"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2394.26, "latencies_ms": [2394.26], "images_per_second": 0.418, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a presentation taking place on a large screen, possibly in a conference room or auditorium. Two people are visible, seemingly attending the presentation, with one person gesturing while the other is seated.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12466.7, "ram_available_mb": 50374.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12470.1, "ram_available_mb": 50370.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.823, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T13:00:05.792535"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2734.792, "latencies_ms": [2734.792], "images_per_second": 0.366, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The screen displays a vibrant teal background with geometric shapes in orange and purple. The lighting is bright and focused, illuminating the screen and the audience's faces. The screen appears to be made of a flexible material, potentially fabric or plastic.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12470.1, "ram_available_mb": 50370.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12469.8, "ram_available_mb": 50371.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.496, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T13:00:10.544635"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1804.936, "latencies_ms": [1804.936], "images_per_second": 0.554, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Two workers in blue uniforms are sitting on a chair outside a building, conversing while one holds a broom.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12469.8, "ram_available_mb": 50371.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12469.1, "ram_available_mb": 50371.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.909, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.789}, "timestamp": "2026-01-19T13:00:14.397451"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2766.794, "latencies_ms": [2766.794], "images_per_second": 0.361, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "scooter: 2\nchair: 1\nman: 2\nwoman: 1\nbroom: 1\nsign: 2\nstreet: 1\nbuilding: 2", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12469.1, "ram_available_mb": 50371.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12469.1, "ram_available_mb": 50371.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.059, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T13:00:19.203627"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1781.572, "latencies_ms": [1781.572], "images_per_second": 0.561, "prompt_tokens": 25, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The scooters are parked near the building, positioned on the sidewalk. The workers are standing further back, near the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12469.1, "ram_available_mb": 50371.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12468.6, "ram_available_mb": 50372.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.053, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.825}, "timestamp": "2026-01-19T13:00:23.035350"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2208.61, "latencies_ms": [2208.61], "images_per_second": 0.453, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two men in blue uniforms are sitting and standing on a city street near parked motorbikes and scooters. A sign with Chinese characters is visible in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12468.6, "ram_available_mb": 50372.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12469.3, "ram_available_mb": 50371.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.022, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.916}, "timestamp": "2026-01-19T13:00:27.293377"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3189.95, "latencies_ms": [3189.95], "images_per_second": 0.313, "prompt_tokens": 18, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The street scene is dominated by blue and white colors, creating a vibrant and somewhat industrial atmosphere. The lighting appears to be natural daylight, suggesting an overcast day or possibly late afternoon. The street is paved with asphalt, typical of urban settings, and there are two motor scooters parked nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12469.3, "ram_available_mb": 50371.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12469.6, "ram_available_mb": 50371.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.465, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T13:00:32.500071"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1759.108, "latencies_ms": [1759.108], "images_per_second": 0.568, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A white plate holds a serving of shredded chicken and a bowl of broccoli, arranged on a beige carpeted floor.", "error": null, "sys_before": {"cpu_percent": 3.2, "ram_used_mb": 12469.6, "ram_available_mb": 50371.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12470.1, "ram_available_mb": 50370.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.109, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.739}, "timestamp": "2026-01-19T13:00:36.314611"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2521.637, "latencies_ms": [2521.637], "images_per_second": 0.397, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "chicken: 2\nbroccoli: 2\ncasserole: 1\nfork: 1\nplastic plate: 1\ncarpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12470.1, "ram_available_mb": 50370.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12470.1, "ram_available_mb": 50370.8, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.707, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T13:00:40.865929"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1488.029, "latencies_ms": [1488.029], "images_per_second": 0.672, "prompt_tokens": 25, "response_tokens_est": 20, "n_tiles": 1, "output_text": "The chicken and broccoli are positioned in the foreground, with the fork resting on the plate behind them.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12470.1, "ram_available_mb": 50370.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12471.2, "ram_available_mb": 50369.7, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.189, "power_cpu_cv_mean_watts": 0.91, "power_sys_5v0_mean_watts": 6.698}, "timestamp": "2026-01-19T13:00:44.389742"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2082.781, "latencies_ms": [2082.781], "images_per_second": 0.48, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A white plate holds a serving of shredded chicken and broccoli. A fork rests on the plate. The setting appears to be a casual dining environment, possibly at home or a restaurant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12471.2, "ram_available_mb": 50369.7, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12471.3, "ram_available_mb": 50369.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.459, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.8}, "timestamp": "2026-01-19T13:00:48.521563"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2707.229, "latencies_ms": [2707.229], "images_per_second": 0.369, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The food is primarily yellow and green in color. The lighting appears to be soft and diffused, suggesting an indoor setting. The food appears to be made of plastic and possibly microwavable. The plate is white and appears to be made of plastic or ceramic.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12471.1, "ram_available_mb": 50369.8, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12471.3, "ram_available_mb": 50369.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.548, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.047}, "timestamp": "2026-01-19T13:00:53.257197"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1773.876, "latencies_ms": [1773.876], "images_per_second": 0.564, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man wearing a blue shirt, red tie, plaid cap, and round sunglasses stands in front of a building, smiling warmly.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12471.3, "ram_available_mb": 50369.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12472.6, "ram_available_mb": 50368.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.765, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T13:00:57.082244"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2444.906, "latencies_ms": [2444.906], "images_per_second": 0.409, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "hat: 1\nglasses: 2\nshirt: 1\ntie: 1\npool: 1\nwall: 1\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12472.6, "ram_available_mb": 50368.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12472.3, "ram_available_mb": 50368.6, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.58, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T13:01:01.567909"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2213.693, "latencies_ms": [2213.693], "images_per_second": 0.452, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The man is positioned in the foreground, with the background elements blurred, suggesting they are further away or out of focus. The man is wearing sunglasses, which adds a slightly distant perspective to his face.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12472.3, "ram_available_mb": 50368.6, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12470.9, "ram_available_mb": 50370.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.776, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.826}, "timestamp": "2026-01-19T13:01:05.825480"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2222.333, "latencies_ms": [2222.333], "images_per_second": 0.45, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A man wearing a blue shirt, red tie, and plaid cap is standing outdoors, possibly near a building or pool area. The background is out of focus, suggesting a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12470.9, "ram_available_mb": 50370.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12471.9, "ram_available_mb": 50369.0, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.821, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.882}, "timestamp": "2026-01-19T13:01:10.080917"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2114.017, "latencies_ms": [2114.017], "images_per_second": 0.473, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The man is wearing a blue shirt and a red tie. His hat is black and plaid. The lighting appears to be natural, possibly sunlight, and the background suggests an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12471.9, "ram_available_mb": 50369.0, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12473.4, "ram_available_mb": 50367.5, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.966, "power_cpu_cv_mean_watts": 1.414, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T13:01:14.233708"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1702.89, "latencies_ms": [1702.89], "images_per_second": 0.587, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The image features six different slices of pizza arranged on white plates, showcasing a variety of toppings and sauces.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12473.4, "ram_available_mb": 50367.5, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12472.8, "ram_available_mb": 50368.1, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.578, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.784}, "timestamp": "2026-01-19T13:01:17.982581"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4715.14, "latencies_ms": [4715.14], "images_per_second": 0.212, "prompt_tokens": 21, "response_tokens_est": 75, "n_tiles": 1, "output_text": "slice of pizza: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1\nslice of pizza with cheese and sauce: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12472.8, "ram_available_mb": 50368.1, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12473.7, "ram_available_mb": 50367.2, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.964, "power_cpu_cv_mean_watts": 1.951, "power_sys_5v0_mean_watts": 7.263}, "timestamp": "2026-01-19T13:01:24.736609"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2561.618, "latencies_ms": [2561.618], "images_per_second": 0.39, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main object, pizza slice, occupies the foreground of the image. The background consists of additional pizza slices on plates, suggesting the photo was likely taken in a casual setting like a pizzeria or home kitchen.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12473.7, "ram_available_mb": 50367.2, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12473.6, "ram_available_mb": 50367.3, "ram_percent": 19.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.803, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 7.027}, "timestamp": "2026-01-19T13:01:29.336662"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2829.692, "latencies_ms": [2829.692], "images_per_second": 0.353, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a casual dining setting, likely in a restaurant or pizzeria, where various slices of pizza are presented on white plates. The pizza slices vary in toppings and sauces, showcasing a diverse range of flavors and styles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12473.6, "ram_available_mb": 50367.3, "ram_percent": 19.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12474.4, "ram_available_mb": 50366.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.385, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.078}, "timestamp": "2026-01-19T13:01:34.192169"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2804.3, "latencies_ms": [2804.3], "images_per_second": 0.357, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The pizza slices exhibit a range of colors, including yellows, greens, and browns. The lighting in the image appears to be soft and warm, creating a pleasant ambiance. The pizza appears to be made with traditional ingredients, suggesting it might be a classic or homemade dish.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12474.4, "ram_available_mb": 50366.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12476.1, "ram_available_mb": 50364.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.456, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.091}, "timestamp": "2026-01-19T13:01:39.023708"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1648.545, "latencies_ms": [1648.545], "images_per_second": 0.607, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Two young girls in colorful dresses are petting a black goat while standing behind a metal fence.", "error": null, "sys_before": {"cpu_percent": 3.4, "ram_used_mb": 12476.1, "ram_available_mb": 50364.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12476.4, "ram_available_mb": 50364.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.515, "power_cpu_cv_mean_watts": 1.14, "power_sys_5v0_mean_watts": 6.831}, "timestamp": "2026-01-19T13:01:42.711904"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2338.89, "latencies_ms": [2338.89], "images_per_second": 0.428, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "goat: 2\ngirl: 2\nfence: 2\ngrass: 2\nman: 1\ngoat: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12476.4, "ram_available_mb": 50364.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12476.0, "ram_available_mb": 50364.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.779, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T13:01:47.111824"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2871.031, "latencies_ms": [2871.031], "images_per_second": 0.348, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the goat being the most prominent object. The children's interaction with the goat suggests a close relationship, potentially a petting or feeding experience. The background features additional elements like a fence and a person walking by, further emphasizing the setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12476.0, "ram_available_mb": 50364.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12476.6, "ram_available_mb": 50364.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T13:01:52.024223"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2787.409, "latencies_ms": [2787.409], "images_per_second": 0.359, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "Two young girls are petting a black goat at a petting zoo or farm. The goat is standing near a fence, while another goat is partially visible behind it. The scene takes place outdoors on a sunny day, with trees and a building visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12476.6, "ram_available_mb": 50364.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12477.4, "ram_available_mb": 50363.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.525, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.082}, "timestamp": "2026-01-19T13:01:56.835990"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1606.416, "latencies_ms": [1606.416], "images_per_second": 0.623, "prompt_tokens": 18, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The girls are wearing colorful dresses. The goat is black and white. The scene appears to be outdoors in bright sunlight.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12477.4, "ram_available_mb": 50363.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12477.4, "ram_available_mb": 50363.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.515, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.761}, "timestamp": "2026-01-19T13:02:00.473420"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1909.703, "latencies_ms": [1909.703], "images_per_second": 0.524, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The scene captures a busy intersection at dusk, with multiple traffic lights glowing green, cars waiting at the lights, and street signs visible.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12477.4, "ram_available_mb": 50363.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12477.4, "ram_available_mb": 50363.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.945, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.78}, "timestamp": "2026-01-19T13:02:04.420482"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2740.617, "latencies_ms": [2740.617], "images_per_second": 0.365, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "traffic light: 2\nstreet sign: 1\npower lines: 6\nbuildings: 2\nmountains: 1\ncars: 2\nstreetlights: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12477.4, "ram_available_mb": 50363.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12479.9, "ram_available_mb": 50361.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.258, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T13:02:09.186814"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2786.335, "latencies_ms": [2786.335], "images_per_second": 0.359, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The traffic light is positioned on the left side of the image, extending into the background. The streetlight is situated on the right side of the image, positioned near the traffic light. The scene is captured from a distance, showing the traffic light and the streetlight as prominent features.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12479.9, "ram_available_mb": 50361.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12479.9, "ram_available_mb": 50361.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.073, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.986}, "timestamp": "2026-01-19T13:02:13.994477"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2374.727, "latencies_ms": [2374.727], "images_per_second": 0.421, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene depicts a city intersection at dusk, with traffic lights glowing green and streetlights illuminating the darkened streets. Buildings line the horizon, and cars are visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12479.9, "ram_available_mb": 50361.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12484.1, "ram_available_mb": 50356.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.738, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T13:02:18.388827"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2531.522, "latencies_ms": [2531.522], "images_per_second": 0.395, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The sky is a deep blue, indicating it's likely dusk or early evening. The traffic lights are illuminated green, signaling that vehicles can proceed. The street is dark and appears empty, with some faint lights in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12484.1, "ram_available_mb": 50356.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12484.1, "ram_available_mb": 50356.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.723, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T13:02:22.958673"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1599.051, "latencies_ms": [1599.051], "images_per_second": 0.625, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A woman in a colorful dress stands behind a table displaying several bunches of ripe, yellow bananas.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12484.1, "ram_available_mb": 50356.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12485.4, "ram_available_mb": 50355.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.357, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 6.678}, "timestamp": "2026-01-19T13:02:26.612562"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1993.073, "latencies_ms": [1993.073], "images_per_second": 0.502, "prompt_tokens": 21, "response_tokens_est": 20, "n_tiles": 1, "output_text": "bananas: 5\nwoman: 1\ntable: 1\nbuilding: 2\npeople: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12485.4, "ram_available_mb": 50355.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12484.9, "ram_available_mb": 50356.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.223, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T13:02:30.643328"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1990.722, "latencies_ms": [1990.722], "images_per_second": 0.502, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bananas are in the foreground, slightly blurred, while the woman stands in the background, slightly out of focus. The bananas are positioned closer to the viewer, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12484.9, "ram_available_mb": 50356.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12485.0, "ram_available_mb": 50355.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.297, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.81}, "timestamp": "2026-01-19T13:02:34.686581"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1991.073, "latencies_ms": [1991.073], "images_per_second": 0.502, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A woman stands behind a table displaying several bunches of ripe, yellow bananas. The setting appears to be an outdoor market or marketplace, with a building visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12485.0, "ram_available_mb": 50355.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12486.9, "ram_available_mb": 50354.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.247, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.816}, "timestamp": "2026-01-19T13:02:38.699891"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2390.389, "latencies_ms": [2390.389], "images_per_second": 0.418, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The bananas are yellow and appear to be ripe. The lighting is bright, likely from natural sunlight, giving the bananas a vibrant appearance. The bananas are displayed on a wooden surface, suggesting they are for sale or display.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12486.9, "ram_available_mb": 50354.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12486.9, "ram_available_mb": 50354.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.866, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 6.976}, "timestamp": "2026-01-19T13:02:43.141277"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2200.662, "latencies_ms": [2200.662], "images_per_second": 0.454, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A green door with graffiti and a fire escape is situated between two metal roll-up doors on a city sidewalk, accompanied by a red brick building, a fire hydrant, and a bicycle.", "error": null, "sys_before": {"cpu_percent": 8.8, "ram_used_mb": 12486.9, "ram_available_mb": 50354.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12487.2, "ram_available_mb": 50353.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.488, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.039}, "timestamp": "2026-01-19T13:02:47.405678"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2956.841, "latencies_ms": [2956.841], "images_per_second": 0.338, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "building: 4\nfire escape: 1\ngarage doors: 2\nfire hydrant: 1\nbicycle: 1\ntree: 1\nsidewalk: 1\nstreet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12487.2, "ram_available_mb": 50353.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12487.4, "ram_available_mb": 50353.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.256, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.106}, "timestamp": "2026-01-19T13:02:52.387756"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1982.837, "latencies_ms": [1982.837], "images_per_second": 0.504, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The building is positioned in the foreground, with the fire escape and windows located on its right side. The bicycle is situated to the left of the building, near the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12487.4, "ram_available_mb": 50353.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12487.7, "ram_available_mb": 50353.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.074, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T13:02:56.421736"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2487.358, "latencies_ms": [2487.358], "images_per_second": 0.402, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a red brick building with green metal shutters and graffiti on its facade. A green door is visible, flanked by a fire escape. A bicycle is parked on the sidewalk in front of the building.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12487.7, "ram_available_mb": 50353.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12487.9, "ram_available_mb": 50353.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.881, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.98}, "timestamp": "2026-01-19T13:03:00.948365"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2471.711, "latencies_ms": [2471.711], "images_per_second": 0.405, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The building is primarily red brick with green metal accents, including railings and shutters. The windows are dark and appear to be multi-paned. The lighting is relatively even, suggesting an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12487.9, "ram_available_mb": 50353.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12488.1, "ram_available_mb": 50352.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.84, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:03:05.455889"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1934.266, "latencies_ms": [1934.266], "images_per_second": 0.517, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man wearing a black shirt and a blue and white striped hat is preparing to throw a yellow frisbee, capturing the moment with a focused expression.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12488.1, "ram_available_mb": 50352.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12487.5, "ram_available_mb": 50353.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.969, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.861}, "timestamp": "2026-01-19T13:03:09.430534"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3028.072, "latencies_ms": [3028.072], "images_per_second": 0.33, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Frisbee: 1\nPerson: 1\nHeadband: 1\nT-shirt: 1\nGround: 1\nCeiling: 1\nAudience: 1\nCamera: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12487.2, "ram_available_mb": 50353.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12486.7, "ram_available_mb": 50354.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.86, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T13:03:14.505662"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2797.583, "latencies_ms": [2797.583], "images_per_second": 0.357, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The man is positioned in the foreground, throwing the frisbee towards the right side of the image. The frisbee is relatively close to the man's hand, suggesting an active throwing motion. The background is slightly blurred, indicating a focus on the man and the frisbee.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12486.7, "ram_available_mb": 50354.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12488.6, "ram_available_mb": 50352.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.023, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T13:03:19.347274"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2477.668, "latencies_ms": [2477.668], "images_per_second": 0.404, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A man is captured mid-throw of a yellow frisbee, seemingly in a dimly lit indoor space, possibly a park or event venue.  A crowd of people is visible in the background, observing the action.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12488.6, "ram_available_mb": 50352.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12489.5, "ram_available_mb": 50351.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.685, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 7.01}, "timestamp": "2026-01-19T13:03:23.874941"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2608.527, "latencies_ms": [2608.527], "images_per_second": 0.383, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The man is wearing a black shirt and a blue and white patterned headband. His hair is dark and appears to be curly or wavy. The background is dimly lit, suggesting an indoor setting. The man is holding a bright yellow frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12489.5, "ram_available_mb": 50351.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12490.6, "ram_available_mb": 50350.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.499, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T13:03:28.520365"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1478.317, "latencies_ms": [1478.317], "images_per_second": 0.676, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A group of people are sitting around a table, working on their laptops in a dimly lit restaurant.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12490.6, "ram_available_mb": 50350.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12491.0, "ram_available_mb": 50349.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.427, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.478}, "timestamp": "2026-01-19T13:03:32.023251"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2776.553, "latencies_ms": [2776.553], "images_per_second": 0.36, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "laptop: 4\nkeyboard: 2\nmouse: 1\nglass: 2\nwater: 1\nhat: 1\nman: 2\nwoman: 4", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12491.0, "ram_available_mb": 50349.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12490.3, "ram_available_mb": 50350.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.107, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T13:03:36.858911"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2632.76, "latencies_ms": [2632.76], "images_per_second": 0.38, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The foreground features the laptops and people, while the background includes other individuals and tables. The laptops are placed in the foreground, closer to the viewer, while the people are situated in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12490.3, "ram_available_mb": 50350.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12490.2, "ram_available_mb": 50350.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.148, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.913}, "timestamp": "2026-01-19T13:03:41.510195"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2101.934, "latencies_ms": [2101.934], "images_per_second": 0.476, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A group of people are gathered around a table in a dimly lit restaurant or bar, working on laptops and possibly discussing work or sharing information. The atmosphere appears casual and collaborative.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12490.2, "ram_available_mb": 50350.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12490.7, "ram_available_mb": 50350.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.457, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.842}, "timestamp": "2026-01-19T13:03:45.639691"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2509.345, "latencies_ms": [2509.345], "images_per_second": 0.399, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The room is dimly lit with warm lighting, creating a cozy atmosphere. The walls have a checkered pattern, adding a unique touch to the space. The laptops are open and active, suggesting active use or collaborative work.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12490.7, "ram_available_mb": 50350.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12492.3, "ram_available_mb": 50348.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.503, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.985}, "timestamp": "2026-01-19T13:03:50.177892"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1624.465, "latencies_ms": [1624.465], "images_per_second": 0.616, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A young girl in a pink jacket and scarf holds a blue umbrella, gazing at the camera with a serious expression.", "error": null, "sys_before": {"cpu_percent": 6.1, "ram_used_mb": 12492.0, "ram_available_mb": 50348.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12491.3, "ram_available_mb": 50349.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.442, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.947}, "timestamp": "2026-01-19T13:03:53.887667"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2555.736, "latencies_ms": [2555.736], "images_per_second": 0.391, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Umbrella: 1\nGirl: 1\nJacket: 1\nScarf: 1\nJeans: 1\nGround: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12491.3, "ram_available_mb": 50349.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12493.2, "ram_available_mb": 50347.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.712, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:03:58.460467"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2163.697, "latencies_ms": [2163.697], "images_per_second": 0.462, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The girl is positioned in the foreground, holding a blue umbrella that extends towards the right side of the image. The umbrella is partially obscuring the background, drawing attention to the girl and her actions.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12493.2, "ram_available_mb": 50347.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12492.5, "ram_available_mb": 50348.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.533, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T13:04:02.653630"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1919.513, "latencies_ms": [1919.513], "images_per_second": 0.521, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A young girl is standing under a blue umbrella on a gravel surface. She is wearing a pink jacket and jeans, and appears to be looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12492.5, "ram_available_mb": 50348.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12492.2, "ram_available_mb": 50348.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.133, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T13:04:06.587842"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2060.527, "latencies_ms": [2060.527], "images_per_second": 0.485, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The girl is wearing a bright pink jacket and a colorful scarf. The umbrella is blue and appears to be made of sturdy material. The lighting suggests an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12491.5, "ram_available_mb": 50349.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12492.2, "ram_available_mb": 50348.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.532, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T13:04:10.660080"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1619.1, "latencies_ms": [1619.1], "images_per_second": 0.618, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man in a suit stands in front of a large window in a room, operating a control panel with various screens and buttons.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12491.9, "ram_available_mb": 50349.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12491.0, "ram_available_mb": 50349.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.364, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T13:04:14.323222"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2728.039, "latencies_ms": [2728.039], "images_per_second": 0.367, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "man: 1\ntable: 2\nkeyboard: 1\ncomputer: 1\nmonitor: 1\ncables: 2\nwindow: 1\nchair: 2", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12491.0, "ram_available_mb": 50349.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12493.4, "ram_available_mb": 50347.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.372, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.003}, "timestamp": "2026-01-19T13:04:19.081445"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2250.846, "latencies_ms": [2250.846], "images_per_second": 0.444, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The man is standing to the left of the image, near the foreground. The computer and monitor are positioned in the foreground, near the man. The window and chairs are in the background, further away from the man.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12493.4, "ram_available_mb": 50347.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12493.1, "ram_available_mb": 50347.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.069, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T13:04:23.365600"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2476.39, "latencies_ms": [2476.39], "images_per_second": 0.404, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A man is standing in a room with a desk and computer setup, possibly in a training or educational environment. The setup includes a monitor, keyboard, mouse, and a control box, suggesting the man is demonstrating or teaching something.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12493.1, "ram_available_mb": 50347.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12493.0, "ram_available_mb": 50347.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.763, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.924}, "timestamp": "2026-01-19T13:04:27.867270"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2268.536, "latencies_ms": [2268.536], "images_per_second": 0.441, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The room is lit by natural light coming through a window. The walls are white, and the overall atmosphere appears bright and airy. The materials used appear to be standard office furniture and equipment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12493.0, "ram_available_mb": 50347.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12495.4, "ram_available_mb": 50345.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.822, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.928}, "timestamp": "2026-01-19T13:04:32.179811"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1648.02, "latencies_ms": [1648.02], "images_per_second": 0.607, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A group of five young men are gathered around a wooden table, enjoying a meal and engaging in conversation.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12495.4, "ram_available_mb": 50345.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12494.7, "ram_available_mb": 50346.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.211, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.769}, "timestamp": "2026-01-19T13:04:35.859078"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3820.878, "latencies_ms": [3820.878], "images_per_second": 0.262, "prompt_tokens": 21, "response_tokens_est": 52, "n_tiles": 1, "output_text": "cup: 2\nsaucer: 1\nplate: 1\nbowl: 2\nsauce bottle: 1\nglass: 1\ntable: 1\nchopsticks: 0\nclock: 1\nwindow: 1\ncurtains: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12494.7, "ram_available_mb": 50346.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12494.6, "ram_available_mb": 50346.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.221, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.122}, "timestamp": "2026-01-19T13:04:41.703913"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2944.193, "latencies_ms": [2944.193], "images_per_second": 0.34, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The foreground is dominated by the table and chairs, while the background features the window and wooden elements. The table occupies the central portion of the image, drawing the viewer's eye towards the people seated around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12494.6, "ram_available_mb": 50346.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12494.0, "ram_available_mb": 50346.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.006, "power_cpu_cv_mean_watts": 1.586, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T13:04:46.672116"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3142.433, "latencies_ms": [3142.433], "images_per_second": 0.318, "prompt_tokens": 19, "response_tokens_est": 64, "n_tiles": 1, "output_text": "A group of young men is gathered around a wooden table in a cozy room, enjoying a meal together. They are seated in a traditional Japanese setting with wooden floors, curtains, and a clock on the wall. Various dishes, cups, and cutlery are spread across the table, hinting at a shared meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12494.0, "ram_available_mb": 50346.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12495.9, "ram_available_mb": 50345.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.927, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.144}, "timestamp": "2026-01-19T13:04:51.849389"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2438.082, "latencies_ms": [2438.082], "images_per_second": 0.41, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The room is lit by natural light coming through a large window with curtains. The table is dark brown and appears to be made of wood. The men are dressed casually and appear to be enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12495.9, "ram_available_mb": 50345.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12496.3, "ram_available_mb": 50344.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.603, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.965}, "timestamp": "2026-01-19T13:04:56.311570"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2040.348, "latencies_ms": [2040.348], "images_per_second": 0.49, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A person in winter clothing is standing next to a red pickup truck equipped with a snowplow, parked on a snow-covered street in a residential neighborhood.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 12496.3, "ram_available_mb": 50344.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.322, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T13:05:00.417490"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2993.579, "latencies_ms": [2993.579], "images_per_second": 0.334, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Truck: 1\nPlow: 1\nPerson: 1\nSnow: 2\nTrees: 2\nHouses: 4\nStreet: 1\nSnow: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12497.7, "ram_available_mb": 50343.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.572, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.059}, "timestamp": "2026-01-19T13:05:05.428566"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2064.711, "latencies_ms": [2064.711], "images_per_second": 0.484, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The red snowplow truck is positioned in the foreground, facing the viewer. The snowy street and houses in the background extend into the distance, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12497.7, "ram_available_mb": 50343.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12497.8, "ram_available_mb": 50343.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.551, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.895}, "timestamp": "2026-01-19T13:05:09.505906"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2704.859, "latencies_ms": [2704.859], "images_per_second": 0.37, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A red pickup truck with a snowplow is parked on a snow-covered residential street. A person in winter clothing is standing near the truck, possibly preparing to clear the snow. The scene depicts a typical winter day in a residential neighborhood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12497.8, "ram_available_mb": 50343.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12497.8, "ram_available_mb": 50343.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.148, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.014}, "timestamp": "2026-01-19T13:05:14.239635"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2146.904, "latencies_ms": [2146.904], "images_per_second": 0.466, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The red truck is covered in snow. The scene is lit by natural light, suggesting an overcast day. The snow is undisturbed on the truck and the surrounding area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12497.8, "ram_available_mb": 50343.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12498.0, "ram_available_mb": 50342.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.246, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 6.937}, "timestamp": "2026-01-19T13:05:18.415299"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1618.038, "latencies_ms": [1618.038], "images_per_second": 0.618, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A man is taking a selfie in a luxurious bathroom with a large mirror, marble countertop, and two sinks.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 12498.0, "ram_available_mb": 50342.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12499.8, "ram_available_mb": 50341.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.058, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 6.72}, "timestamp": "2026-01-19T13:05:22.088425"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4179.645, "latencies_ms": [4179.645], "images_per_second": 0.239, "prompt_tokens": 21, "response_tokens_est": 58, "n_tiles": 1, "output_text": "Bathroom: 4\nDouble vanity: 2\nSink: 2\nMirror: 2\nTowels: 2\nLighting fixtures: 2\nTelevision: 1\nBathtub: 1\nFloor: 2\nWalls: 2\nDoor: 2", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12499.8, "ram_available_mb": 50341.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12499.4, "ram_available_mb": 50341.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.048, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.217}, "timestamp": "2026-01-19T13:05:28.297442"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2514.296, "latencies_ms": [2514.296], "images_per_second": 0.398, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The large mirror spans the width of the bathroom, reflecting the vanity and surrounding space. The double sink is located in the foreground, positioned between the mirror and the bathtub. The bathtub is situated to the left of the sink.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12499.4, "ram_available_mb": 50341.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12501.4, "ram_available_mb": 50339.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.961, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 7.041}, "timestamp": "2026-01-19T13:05:32.831885"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2476.385, "latencies_ms": [2476.385], "images_per_second": 0.404, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a luxurious bathroom with a double vanity, marble countertop, and large mirror. The bathroom features beige and gold accents, marble flooring, and a large flat-screen TV mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.4, "ram_available_mb": 50339.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.8, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 7.0}, "timestamp": "2026-01-19T13:05:37.331835"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2861.099, "latencies_ms": [2861.099], "images_per_second": 0.35, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The bathroom features a dark green marble countertop and beige walls with gold accents. The lighting is warm and inviting, creating a relaxing atmosphere. The marble countertop is complemented by gold fixtures and accents, enhancing the overall luxurious feel of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.212, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T13:05:42.229095"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1525.259, "latencies_ms": [1525.259], "images_per_second": 0.656, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "Two men are loading luggage into a white car parked in a busy airport parking lot.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.356, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 6.686}, "timestamp": "2026-01-19T13:05:45.822536"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2672.318, "latencies_ms": [2672.318], "images_per_second": 0.374, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "car: 2\nluggage: 4\nsuitcases: 2\ntrolley: 1\nperson: 2\nwindow: 1\nsign: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.929, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T13:05:50.528250"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1993.057, "latencies_ms": [1993.057], "images_per_second": 0.502, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The luggage cart is positioned to the left of the main objects in the image. The car is parked in the background, slightly further away than the luggage cart.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.8, "ram_available_mb": 50338.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12503.0, "ram_available_mb": 50337.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.547, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T13:05:54.590703"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3182.483, "latencies_ms": [3182.483], "images_per_second": 0.314, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The scene depicts a busy airport parking lot where two men are loading luggage into a car parked nearby. The car is white and appears to be a station wagon or hatchback. The men are surrounded by various suitcases and bags, indicating they are either preparing for a trip or have just arrived.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.0, "ram_available_mb": 50337.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.743, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.091}, "timestamp": "2026-01-19T13:05:59.808318"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2493.211, "latencies_ms": [2493.211], "images_per_second": 0.401, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The car is white, and the lighting is bright, illuminating the scene. The luggage is primarily black and brown, contrasting with the white car. The overall atmosphere suggests a typical airport parking lot.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T13:06:04.323797"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2326.395, "latencies_ms": [2326.395], "images_per_second": 0.43, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The plate contains a grilled chicken sandwich with sesame seed buns, accompanied by golden brown french fries and two small bowls of ketchup and mayonnaise.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.177, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.972}, "timestamp": "2026-01-19T13:06:08.685937"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3168.538, "latencies_ms": [3168.538], "images_per_second": 0.316, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "bun: 2\nfries: 8\nchicken: 2\nketchup: 1\nlettuce: 1\ntomato: 1\nmayonnaise: 1\nsauce: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.759, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 7.091}, "timestamp": "2026-01-19T13:06:13.871888"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2444.023, "latencies_ms": [2444.023], "images_per_second": 0.409, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The sandwich is in the foreground, while the fries and sauce are in the background. The plate is situated on a surface, providing a neutral backdrop for the food.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.541, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T13:06:18.380163"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2910.372, "latencies_ms": [2910.372], "images_per_second": 0.344, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a casual dining setting with a plate containing a grilled chicken sandwich, french fries, and two small bowls of condiments. The sandwich is served on a white plate, accompanied by a knife. The overall setting suggests a relaxed and informal dining environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.212, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.038}, "timestamp": "2026-01-19T13:06:23.320355"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2816.648, "latencies_ms": [2816.648], "images_per_second": 0.355, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The plate features a mix of golden-brown fries, vibrant red ketchup, and fresh green lettuce. The lighting is bright, enhancing the colors and textures of the food. The plate appears to be made of ceramic or porcelain, suitable for outdoor dining.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.793, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.942}, "timestamp": "2026-01-19T13:06:28.161384"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1874.559, "latencies_ms": [1874.559], "images_per_second": 0.533, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The room features a bed with a mosquito net draped over it, situated beneath a thatched roof and surrounded by large windows.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.729, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.787}, "timestamp": "2026-01-19T13:06:32.104153"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2863.502, "latencies_ms": [2863.502], "images_per_second": 0.349, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "bed: 2\ncurtains: 3\nnightstands: 2\ncandle: 1\ntable: 1\nchair: 1\nwindow: 3\nwall: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.756, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.001}, "timestamp": "2026-01-19T13:06:37.002669"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2281.096, "latencies_ms": [2281.096], "images_per_second": 0.438, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned slightly to the right of the image. The window is situated in the background, further away from the bed. The table and chair are placed in the background, near the window.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.802, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:06:41.311450"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2537.817, "latencies_ms": [2537.817], "images_per_second": 0.394, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a serene and cozy bedroom with a thatched roof, bathed in natural light. The room features a bed with a mosquito net, a small table with a lit candle, and several framed pictures on the walls.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.721, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.965}, "timestamp": "2026-01-19T13:06:45.875156"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2676.122, "latencies_ms": [2676.122], "images_per_second": 0.374, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The room features a warm, inviting ambiance with warm yellow walls and a thatched roof. The lighting is soft and warm, creating a cozy atmosphere. The bed is covered in a green mosquito net, adding a unique touch to the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.269, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T13:06:50.582861"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1597.287, "latencies_ms": [1597.287], "images_per_second": 0.626, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A tabby cat with striking blue eyes is standing on the hood of a sleek black car in a garage.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.998, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.148}, "timestamp": "2026-01-19T13:06:54.233785"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2807.897, "latencies_ms": [2807.897], "images_per_second": 0.356, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "lamp: 2\nbox: 2\ncar: 1\ncat: 1\nglove: 1\nbicycle: 1\nshelf: 1\ntools: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.432, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 6.707}, "timestamp": "2026-01-19T13:06:59.061030"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1694.449, "latencies_ms": [1694.449], "images_per_second": 0.59, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The black car is positioned in the foreground, slightly to the right of the cat. The garage is situated in the background, extending from left to right.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.214, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.257}, "timestamp": "2026-01-19T13:07:02.775703"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1920.786, "latencies_ms": [1920.786], "images_per_second": 0.521, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A tabby cat is standing on the hood of a black car in a garage. The garage contains various items like tools, boxes, and bicycles.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.107, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.31}, "timestamp": "2026-01-19T13:07:06.708011"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1984.692, "latencies_ms": [1984.692], "images_per_second": 0.504, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The car is black. The lighting is dim, casting shadows on the car's surface. The materials appear to be metal and plastic. The weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.241, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.39}, "timestamp": "2026-01-19T13:07:10.715770"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1930.258, "latencies_ms": [1930.258], "images_per_second": 0.518, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The dish features a meat patty topped with gravy, onions, tomatoes, and herbs, served on a bun and accompanied by a knife.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.267, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.881}, "timestamp": "2026-01-19T13:07:14.683919"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3137.916, "latencies_ms": [3137.916], "images_per_second": 0.319, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "bun: 1\ntomato: 1\nonion: 1\ngravy: 1\nmeat: 1\nsauce: 1\ncrumbs: 1\nknife: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.198, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T13:07:19.841656"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2574.795, "latencies_ms": [2574.795], "images_per_second": 0.388, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The main object, consisting of a sandwich with gravy, onions, and tomato, sits in the foreground of the image. The sandwich is positioned slightly to the right of the viewer. The background features a metal table with a partially visible plate of food and a glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.86, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.094}, "timestamp": "2026-01-19T13:07:24.453015"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2679.652, "latencies_ms": [2679.652], "images_per_second": 0.373, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene is set outdoors on a metal table, showcasing a plate with a generous serving of gravy, meat, and vegetables topped with tomato slices and herbs. A knife rests on the plate, suggesting the meal is ready to be enjoyed.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.688, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T13:07:29.150483"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2782.157, "latencies_ms": [2782.157], "images_per_second": 0.359, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The dish features a rich brown gravy drizzled over it, which adds a vibrant color. The plate is white, providing a clean backdrop for the colorful food. The lighting is soft and warm, enhancing the visual appeal of the dish.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 7.065}, "timestamp": "2026-01-19T13:07:33.952131"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1648.299, "latencies_ms": [1648.299], "images_per_second": 0.607, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Three men are gathered in a cozy living room, playing a video game together while enjoying snacks and drinks.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.238, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 6.722}, "timestamp": "2026-01-19T13:07:37.639437"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3579.275, "latencies_ms": [3579.275], "images_per_second": 0.279, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "laptop: 1\ncans: 2\nbottles: 2\ncork: 1\ncan opener: 1\ntable: 1\nred couch: 1\npillow: 1\nwindow blinds: 2\nfloor lamp: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.482, "power_cpu_cv_mean_watts": 1.878, "power_sys_5v0_mean_watts": 7.205}, "timestamp": "2026-01-19T13:07:43.247819"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2209.836, "latencies_ms": [2209.836], "images_per_second": 0.453, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a couch on the left and a red couch on the right. The foreground is dominated by the red couch, while the background features a window and a lamp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.688, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.826}, "timestamp": "2026-01-19T13:07:47.496838"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3425.982, "latencies_ms": [3425.982], "images_per_second": 0.292, "prompt_tokens": 19, "response_tokens_est": 67, "n_tiles": 1, "output_text": "Three young men are gathered in a cozy living room, playing a video game on a Nintendo Wii console. They are surrounded by various items, including a laptop, a red couch, a coffee table with drinks and snacks, and a window with blinds. The scene suggests a casual, relaxed atmosphere where friends are enjoying leisure time together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.42, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.117}, "timestamp": "2026-01-19T13:07:52.948412"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2706.201, "latencies_ms": [2706.201], "images_per_second": 0.37, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The room is lit by warm yellow lighting, creating a cozy atmosphere. The walls are painted a light beige color, and the furniture includes a red couch, a beige sofa, and a red coffee table. The scene suggests a casual gathering or party.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.002, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.927}, "timestamp": "2026-01-19T13:07:57.694017"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1659.228, "latencies_ms": [1659.228], "images_per_second": 0.603, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A baseball catcher crouches behind home plate, preparing to catch a pitch during a game.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.114, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.691}, "timestamp": "2026-01-19T13:08:01.428807"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2795.646, "latencies_ms": [2795.646], "images_per_second": 0.358, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "catcher: 2\nglove: 1\nhelmet: 1\njersey: 1\npants: 1\nshoes: 1\nbaseball field: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.055, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.078}, "timestamp": "2026-01-19T13:08:06.266881"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2319.864, "latencies_ms": [2319.864], "images_per_second": 0.431, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The catcher is positioned in the foreground, crouched down on the baseball field. The pitcher is further in the background, near the outfield wall. The field extends into the distance, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.822, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.87}, "timestamp": "2026-01-19T13:08:10.636374"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2370.235, "latencies_ms": [2370.235], "images_per_second": 0.422, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A baseball catcher is crouched behind home plate, preparing to catch a ball during a game. The field is well-maintained, and the overall atmosphere suggests a professional or competitive setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.759, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T13:08:15.054579"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1774.674, "latencies_ms": [1774.674], "images_per_second": 0.563, "prompt_tokens": 18, "response_tokens_est": 23, "n_tiles": 1, "output_text": "The catcher is wearing a white uniform with black accents. The field is well-lit, suggesting sunny weather conditions.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.679, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T13:08:18.879237"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1854.927, "latencies_ms": [1854.927], "images_per_second": 0.539, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The bathroom features a white bathtub, a toilet, a sink with a wooden cabinet, and a shower curtain, all set against pink and light blue walls.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.157, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.436}, "timestamp": "2026-01-19T13:08:22.753897"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4002.796, "latencies_ms": [4002.796], "images_per_second": 0.25, "prompt_tokens": 21, "response_tokens_est": 58, "n_tiles": 1, "output_text": "Bathtub: 1\nToilet: 1\nShower curtain: 1\nBathtub surround: 1\nWindow: 1\nVanity: 1\nSink: 1\nCabinet: 1\nFloor: 1\nWalls: 2\nDoor: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.967, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T13:08:28.802855"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2340.843, "latencies_ms": [2340.843], "images_per_second": 0.427, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The toilet is positioned near the bathtub and sink, occupying the foreground. The bathtub and sink are located in the background, separated by a small window. The toilet is situated further back in the room.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.488, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.621}, "timestamp": "2026-01-19T13:08:33.203312"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1934.289, "latencies_ms": [1934.289], "images_per_second": 0.517, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bathroom features a pink and white color scheme, with a white bathtub, toilet, and sink. A green bathmat is placed on the floor, and a window provides natural light.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.534, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.471}, "timestamp": "2026-01-19T13:08:37.172130"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2854.115, "latencies_ms": [2854.115], "images_per_second": 0.35, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The bathroom features a pink and white color scheme. The lighting appears to be natural or soft, contributing to a calm atmosphere. The materials include tiled walls, wood cabinets, and a white bathtub and toilet. The weather is sunny, enhancing the brightness and cleanliness of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.684, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 6.758}, "timestamp": "2026-01-19T13:08:42.055909"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2014.622, "latencies_ms": [2014.622], "images_per_second": 0.496, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A bed with a yellow and white plaid comforter is positioned next to a window with sheer white curtains, allowing soft natural light into the room.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12506.6, "ram_available_mb": 50334.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.171, "power_cpu_cv_mean_watts": 1.226, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T13:08:46.124176"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2806.774, "latencies_ms": [2806.774], "images_per_second": 0.356, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bed: 2\ncurtains: 2\nwindow: 1\nnightstand: 1\nlamp: 1\nheadboard: 1\nplaid bedspread: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12506.6, "ram_available_mb": 50334.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.846, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 6.941}, "timestamp": "2026-01-19T13:08:50.967481"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1888.309, "latencies_ms": [1888.309], "images_per_second": 0.53, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned to the right of the window. The window is situated near the left side of the image, offering a view of the outside.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.809, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.908}, "timestamp": "2026-01-19T13:08:54.883596"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2553.142, "latencies_ms": [2553.142], "images_per_second": 0.392, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a dimly lit bedroom with a plaid-covered bed, a window with sheer curtains, and a dark-colored headboard with decorative squares. A small nightstand with a lamp is positioned next to the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T13:08:59.478218"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2755.41, "latencies_ms": [2755.41], "images_per_second": 0.363, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The bed has a plaid comforter in shades of yellow and white. The walls are a muted yellow or tan color. The lighting in the room is soft and diffused, coming from the window and likely a lamp on the nightstand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.184, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.991}, "timestamp": "2026-01-19T13:09:04.267034"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1655.93, "latencies_ms": [1655.93], "images_per_second": 0.604, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A young woman in a black dress is helping a young man put on a boutonniere on his lapel.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.79, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.778}, "timestamp": "2026-01-19T13:09:07.957083"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2545.871, "latencies_ms": [2545.871], "images_per_second": 0.393, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "man: 1\nwoman: 2\nflower: 1\ntie: 1\ndress: 1\nnecklace: 1\nbelt: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.708, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T13:09:12.555021"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1898.266, "latencies_ms": [1898.266], "images_per_second": 0.527, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The man is positioned to the left of the woman, who is positioned to the right. The woman is standing closer to the man than the man is standing to the woman.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.942, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T13:09:16.490064"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2611.894, "latencies_ms": [2611.894], "images_per_second": 0.383, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A young man and woman are dressed in formal attire, likely attending a prom or wedding. The woman is helping the man with his boutonniere. The setting appears to be indoors, possibly in a hallway or reception area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.725, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 7.027}, "timestamp": "2026-01-19T13:09:21.157540"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2468.946, "latencies_ms": [2468.946], "images_per_second": 0.405, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The man is wearing a black suit with a gold tie. The woman is wearing a black dress with a sparkly or sequined bodice. The lighting is soft and warm, enhancing the colors and details of the attire.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.841, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 7.01}, "timestamp": "2026-01-19T13:09:25.659920"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1846.398, "latencies_ms": [1846.398], "images_per_second": 0.542, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A stop sign is mounted on a metal post behind a chain-link fence, with trash and debris scattered around the base.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.679, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.724}, "timestamp": "2026-01-19T13:09:29.565926"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2748.55, "latencies_ms": [2748.55], "images_per_second": 0.364, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "stop sign: 1\nchain link fence: 1\npalm trees: 4\ngrass: 2\ntrash: 2\nbuilding: 1\nshrubs: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.95, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 6.985}, "timestamp": "2026-01-19T13:09:34.330819"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2856.045, "latencies_ms": [2856.045], "images_per_second": 0.35, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The stop sign is positioned in the foreground, slightly to the right of the chain-link fence. The background features palm trees and a building, indicating a tropical or suburban setting. The stop sign is situated between the fence and the palm trees, further emphasizing the proximity of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.986, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.022}, "timestamp": "2026-01-19T13:09:39.216897"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2603.191, "latencies_ms": [2603.191], "images_per_second": 0.384, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a stop sign situated behind a chain-link fence in a grassy area with palm trees in the background. The fence appears somewhat overgrown with weeds and debris, suggesting the location might be a park or a public space.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.537, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.108}, "timestamp": "2026-01-19T13:09:43.834638"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2199.647, "latencies_ms": [2199.647], "images_per_second": 0.455, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The stop sign is red and white. The scene is lit by sunlight, giving a bright and sunny appearance. The stop sign is positioned in a grassy area with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.199, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T13:09:48.076161"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1581.623, "latencies_ms": [1581.623], "images_per_second": 0.632, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A man is riding a motorcycle past two parked bicycles, one yellow and one black, with a person standing nearby.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.08, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.157}, "timestamp": "2026-01-19T13:09:51.698667"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3135.694, "latencies_ms": [3135.694], "images_per_second": 0.319, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "bike: 2\nmotorcycle: 1\nbicycle: 2\nbag: 1\ntowel: 1\nperson: 1\nshorts: 1\nsocks: 1\nshoe: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.815, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 6.87}, "timestamp": "2026-01-19T13:09:56.854785"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2028.598, "latencies_ms": [2028.598], "images_per_second": 0.493, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The motorcycle is positioned in the foreground, slightly to the left of the image. The bicycles are positioned in the background, slightly to the right. The motorcycle is closer to the viewer than the bicycles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.188, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.432}, "timestamp": "2026-01-19T13:10:00.922905"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2312.578, "latencies_ms": [2312.578], "images_per_second": 0.432, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Two bicycles, one yellow and one black, are parked on a paved path near a fence and trees. A person on a motorcycle is passing by, and another person is standing nearby, observing the scene.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.298, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.557}, "timestamp": "2026-01-19T13:10:05.252876"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1592.503, "latencies_ms": [1592.503], "images_per_second": 0.628, "prompt_tokens": 18, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The yellow bicycle is partially obscured by the motorcycle. The motorcycle has a bright headlight. The scene appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.213, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.266}, "timestamp": "2026-01-19T13:10:08.910146"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1570.515, "latencies_ms": [1570.515], "images_per_second": 0.637, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "Two pedestrians are standing on the sidewalk near a street corner, waiting to cross the road.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.206, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.683}, "timestamp": "2026-01-19T13:10:12.532113"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3277.999, "latencies_ms": [3277.999], "images_per_second": 0.305, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Sign: 2\nTraffic light: 3\nStreet light: 1\nCar: 1\nBicycle: 1\nPerson: 2\nTrash can: 1\nCrosswalk: 2\nBuilding: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.434, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 7.088}, "timestamp": "2026-01-19T13:10:17.853068"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2338.799, "latencies_ms": [2338.799], "images_per_second": 0.428, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The foreground features a brick sidewalk and a black trash can. The background includes traffic lights, street signs, cars, and pedestrians. The central focus is the street corner where the pedestrians and cars are present.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.653, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T13:10:22.216749"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2781.194, "latencies_ms": [2781.194], "images_per_second": 0.36, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The scene depicts a busy city intersection with pedestrians, vehicles, and street signs. A man is standing near a signpost, while another person walks nearby. The setting includes buildings, traffic lights, and streetlights, typical of an urban environment.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.055, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 7.078}, "timestamp": "2026-01-19T13:10:27.035082"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2622.658, "latencies_ms": [2622.658], "images_per_second": 0.381, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene is lit by streetlights, giving it a slightly dim atmosphere. The buildings in the background are primarily brick and concrete, contributing to the urban feel. The street is paved with brick and asphalt, typical of city streets.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.612, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.017}, "timestamp": "2026-01-19T13:10:31.693056"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1680.097, "latencies_ms": [1680.097], "images_per_second": 0.595, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "Two bronze statues depict women sitting on a bench outdoors, one appearing to be reading, while the other holds a purse.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.868, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 6.613}, "timestamp": "2026-01-19T13:10:35.421663"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2974.896, "latencies_ms": [2974.896], "images_per_second": 0.336, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Bench: 2\nStatue: 2\nBag: 1\nHandbag: 1\nWoman: 2\nMan: 1\nPerson: 2\nBricks: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.671, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.971}, "timestamp": "2026-01-19T13:10:40.424660"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2290.702, "latencies_ms": [2290.702], "images_per_second": 0.437, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The statue is positioned in the foreground, slightly to the left of the viewer. The background features people standing and walking, further away from the statue. The statue is situated on a bench, situated near the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.632, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.87}, "timestamp": "2026-01-19T13:10:44.754151"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2491.365, "latencies_ms": [2491.365], "images_per_second": 0.401, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a public outdoor space with a bronze statue of two women sitting on a bench, seemingly engaged in conversation. The setting appears to be a sidewalk or pedestrian area, with people casually walking by and passing by the statue.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.661, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.884}, "timestamp": "2026-01-19T13:10:49.266511"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2452.218, "latencies_ms": [2452.218], "images_per_second": 0.408, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The statue is bronze and appears weathered, suggesting it is made of metal. The lighting in the image creates a dramatic contrast, highlighting the statue's details and casting shadows on the ground. The setting appears to be outdoors on a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.881, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.97}, "timestamp": "2026-01-19T13:10:53.766678"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1563.99, "latencies_ms": [1563.99], "images_per_second": 0.639, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A tall pole displays multiple directional signs in German, guiding travelers to various destinations.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.557, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 6.594}, "timestamp": "2026-01-19T13:10:57.369557"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2790.238, "latencies_ms": [2790.238], "images_per_second": 0.358, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Sign: 4\nAirplane: 1\nHighway: 1\nTruck: 1\nParking sign: 1\nNo parking sign: 1\nTrees: 2", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.194, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 7.012}, "timestamp": "2026-01-19T13:11:02.201436"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1654.187, "latencies_ms": [1654.187], "images_per_second": 0.605, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The signs are positioned in the foreground, slightly to the right of the image. The background consists of trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.546, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T13:11:05.881177"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2873.402, "latencies_ms": [2873.402], "images_per_second": 0.348, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a street sign post with multiple directional signs in German, guiding travelers to various locations such as an airport, bus stop, and parking area. The signs are mounted on a brown pole amidst trees, indicating a public or semi-public space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.177, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 7.064}, "timestamp": "2026-01-19T13:11:10.775578"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2075.478, "latencies_ms": [2075.478], "images_per_second": 0.482, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The signs are primarily blue and white. The lighting appears to be overcast, creating a slightly muted effect. The signs appear to be made of metal and have a slightly weathered appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.151, "power_cpu_cv_mean_watts": 1.225, "power_sys_5v0_mean_watts": 6.788}, "timestamp": "2026-01-19T13:11:14.905604"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2098.757, "latencies_ms": [2098.757], "images_per_second": 0.476, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Two women, one in a red shirt and the other in a blue shirt, are standing next to a large black suitcase at a train station, smiling and posing for the camera.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.08, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.836}, "timestamp": "2026-01-19T13:11:19.054622"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2619.002, "latencies_ms": [2619.002], "images_per_second": 0.382, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "suitcase: 1\nbackpack: 2\nhandbag: 2\nwatch: 1\njeans: 1\nshirt: 2\nsmile: 2", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.744, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T13:11:23.687944"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2431.147, "latencies_ms": [2431.147], "images_per_second": 0.411, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The two women are standing close to the large black suitcase, positioned in the foreground of the image. The suitcase is situated near a yellow line on the platform, suggesting they are at a train station or similar location.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.032, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 6.976}, "timestamp": "2026-01-19T13:11:28.148892"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2017.925, "latencies_ms": [2017.925], "images_per_second": 0.496, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Two women are standing at a train station, preparing for a journey. They are both smiling and posing for a photo, with one woman holding a suitcase and the other wearing a backpack.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.023, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.942}, "timestamp": "2026-01-19T13:11:32.197054"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2106.332, "latencies_ms": [2106.332], "images_per_second": 0.475, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The women are wearing bright colors. The lighting is bright, likely from overhead fluorescent lights. The suitcase appears to be made of durable material. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.48, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T13:11:36.335067"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1677.052, "latencies_ms": [1677.052], "images_per_second": 0.596, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Three zebras stand in a row, facing the camera, with a backdrop of purple flowers and trees.", "error": null, "sys_before": {"cpu_percent": 16.1, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.115, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 6.769}, "timestamp": "2026-01-19T13:11:40.077322"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2547.172, "latencies_ms": [2547.172], "images_per_second": 0.393, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "zebra: 3\ntree: 2\nflowers: 2\nground: 2\ndirt: 1\nbranches: 2\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.344, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 6.969}, "timestamp": "2026-01-19T13:11:44.647918"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2111.881, "latencies_ms": [2111.881], "images_per_second": 0.474, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The zebras are positioned in the foreground, with the purple flowers in the background. The zebras are relatively close to the viewer, while the flowers are further away, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.198, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T13:11:48.823691"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1956.056, "latencies_ms": [1956.056], "images_per_second": 0.511, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Three zebras stand in a natural setting with trees and purple flowers in the background. The zebras appear to be in a zoo or wildlife park environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.42, "power_cpu_cv_mean_watts": 1.577, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T13:11:52.801012"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3462.566, "latencies_ms": [3462.566], "images_per_second": 0.289, "prompt_tokens": 18, "response_tokens_est": 75, "n_tiles": 1, "output_text": "The zebras exhibit a striking combination of black and white stripes, creating a visually striking pattern. The lighting in the image appears to be natural daylight, enhancing the visibility of the zebras' stripes and features. The zebras are standing on a dirt path, which contrasts with their striped coats. The background includes trees and purple flowers, suggesting a natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.647, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.118}, "timestamp": "2026-01-19T13:11:58.309428"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1665.585, "latencies_ms": [1665.585], "images_per_second": 0.6, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A black tripod with a camera mounted on it is set up in a room with a table, chair, and vending machine in the background.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.337, "power_cpu_cv_mean_watts": 1.17, "power_sys_5v0_mean_watts": 6.187}, "timestamp": "2026-01-19T13:12:02.016068"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2946.643, "latencies_ms": [2946.643], "images_per_second": 0.339, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "camera: 1\nlaptop: 1\ntripod: 1\nchair: 1\nvending machine: 1\ntable: 1\ncontainers: 2\nfloor: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.748, "power_cpu_cv_mean_watts": 1.819, "power_sys_5v0_mean_watts": 6.846}, "timestamp": "2026-01-19T13:12:06.996240"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2294.682, "latencies_ms": [2294.682], "images_per_second": 0.436, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The camera is positioned in the foreground, slightly to the right of the tripod. The laptop is placed on the chair in the foreground, angled towards the camera. The vending machine is further in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.303, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.54}, "timestamp": "2026-01-19T13:12:11.318709"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2376.055, "latencies_ms": [2376.055], "images_per_second": 0.421, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene depicts a workspace with a camera mounted on a tripod, positioned near a laptop and a chair. The background includes a vending machine, suggesting an indoor setting possibly in a public or commercial space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.404, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T13:12:15.730436"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2656.94, "latencies_ms": [2656.94], "images_per_second": 0.376, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The camera is black and has a green light. The lighting appears to be artificial, possibly from spotlights. The camera is mounted on a tripod, suggesting it is set up for photography or videography. The setting appears to be indoors, possibly a storage or event area.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.614, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 6.73}, "timestamp": "2026-01-19T13:12:20.440224"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1464.255, "latencies_ms": [1464.255], "images_per_second": 0.683, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A white sheep stands among piles of freshly sheared wool in a fenced area.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.334, "power_cpu_cv_mean_watts": 1.019, "power_sys_5v0_mean_watts": 6.781}, "timestamp": "2026-01-19T13:12:23.981625"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3156.286, "latencies_ms": [3156.286], "images_per_second": 0.317, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Sheep: 2\nFelt: 2\nWool: 2\nFence: 1\nGround: 1\nBall: 1\nSheep's head: 1\nSheep's body: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.851, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.094}, "timestamp": "2026-01-19T13:12:29.165094"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2072.403, "latencies_ms": [2072.403], "images_per_second": 0.483, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main sheep is positioned in the foreground, partially obscured by the pile of wool. The pile of wool is situated in the background, extending beyond the immediate foreground of the sheep.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.27, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T13:12:33.253898"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2344.526, "latencies_ms": [2344.526], "images_per_second": 0.427, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A white sheep is standing behind a pile of freshly sheared wool in a fenced area. The wool is piled up around its legs and body, indicating a recent shearing process.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.8, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.971}, "timestamp": "2026-01-19T13:12:37.621964"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1886.943, "latencies_ms": [1886.943], "images_per_second": 0.53, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The sheep is primarily white with patches of gray wool. The lighting appears to be natural, possibly outdoors, and the scene suggests a cold environment.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.702, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T13:12:41.534485"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1782.318, "latencies_ms": [1782.318], "images_per_second": 0.561, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Two female tennis players are engaged in a match on a blue court, with one player preparing to hit the ball and the other positioned near the net.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.052, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.861}, "timestamp": "2026-01-19T13:12:45.386017"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3028.035, "latencies_ms": [3028.035], "images_per_second": 0.33, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "net: 1\nball: 1\nracket: 1\ncourt: 2\nplayers: 2\nreferee: 1\nspectators: 2\nadvertising boards: 3", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.937, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.035}, "timestamp": "2026-01-19T13:12:50.436358"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2410.114, "latencies_ms": [2410.114], "images_per_second": 0.415, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The foreground features a tennis court with a net, players, and spectators. The background includes spectators seated in bleachers and additional advertising boards. The players are positioned on the court, engaging in the match.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.758, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 6.912}, "timestamp": "2026-01-19T13:12:54.870838"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2276.817, "latencies_ms": [2276.817], "images_per_second": 0.439, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A tennis match is taking place on a blue court, with players in red and pink outfits competing against each other. The match is taking place in a stadium with spectators seated in the stands.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.89, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.91}, "timestamp": "2026-01-19T13:12:59.185191"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1816.059, "latencies_ms": [1816.059], "images_per_second": 0.551, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The tennis court is predominantly blue. The lighting appears to be bright and evenly distributed, enhancing the visibility of both players and spectators.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.108, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T13:13:03.027882"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1661.37, "latencies_ms": [1661.37], "images_per_second": 0.602, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A man dressed in black is walking through a modern airport terminal, pulling a suitcase behind him.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.993, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.59}, "timestamp": "2026-01-19T13:13:06.729071"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2485.056, "latencies_ms": [2485.056], "images_per_second": 0.402, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "person: 1\nsuitcase: 1\nscreen: 1\nstairs: 2\npillars: 2\nfloor: 6\nsigns: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.581, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T13:13:11.272465"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2684.788, "latencies_ms": [2684.788], "images_per_second": 0.372, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The man is walking through the airport terminal, moving from left to right. The foreground is dominated by the airport terminal entrance, partially obscured by the glass door. The background features escalators, further emphasizing the airport's spaciousness.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.313, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 6.941}, "timestamp": "2026-01-19T13:13:16.003356"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2083.042, "latencies_ms": [2083.042], "images_per_second": 0.48, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man in dark clothing is walking through a modern airport terminal, pulling a rolling suitcase behind him. Large pillars and escalators are visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.294, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.895}, "timestamp": "2026-01-19T13:13:20.112467"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2728.345, "latencies_ms": [2728.345], "images_per_second": 0.367, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The airport terminal features a predominantly gray color scheme, with blue and white directional signs. The lighting is bright, likely from overhead fluorescent fixtures, creating a well-lit environment. The materials appear to be modern glass and metal, contributing to the sleek and clean aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.312, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T13:13:24.863024"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1933.001, "latencies_ms": [1933.001], "images_per_second": 0.517, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "An elderly woman is seated at a table with two pizzas, glasses of beverages, and utensils, enjoying a meal in a cozy setting.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.648, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T13:13:28.838685"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2823.31, "latencies_ms": [2823.31], "images_per_second": 0.354, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "pizza: 2\nglass: 2\nchicken: 0\nfork: 1\nknife: 1\ntablecloth: 1\nchair: 1\nwoman: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.02, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T13:13:33.679262"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2109.066, "latencies_ms": [2109.066], "images_per_second": 0.474, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the pizza boxes and glasses placed nearby. The woman in the background is situated further back, suggesting the setting is relatively open and spacious.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.104, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.789}, "timestamp": "2026-01-19T13:13:37.806047"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2627.899, "latencies_ms": [2627.899], "images_per_second": 0.381, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a casual dining setting with two pizzas on white boxes placed on a table, accompanied by glasses, cutlery, and a vase of flowers. An elderly woman is seated in the background, seemingly enjoying the meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.401, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.93}, "timestamp": "2026-01-19T13:13:42.451621"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2731.987, "latencies_ms": [2731.987], "images_per_second": 0.366, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The pizza boxes are white with red lettering. The table is covered with a multicolored plaid tablecloth. The pizza appears to have a golden-brown crust and toppings. The lighting in the image is soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.364, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 6.977}, "timestamp": "2026-01-19T13:13:47.200833"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2406.727, "latencies_ms": [2406.727], "images_per_second": 0.416, "prompt_tokens": 8, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A youth baseball game is in progress, with a batter in a white shirt and gray pants preparing to swing at a pitch, while a catcher in a red shirt and gray pants crouches behind him.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.8, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 7.018}, "timestamp": "2026-01-19T13:13:51.656285"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3547.582, "latencies_ms": [3547.582], "images_per_second": 0.282, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball glove: 1\nbaseball helmet: 1\nbaseball: 1\nbaseball field: 1\nbaseball diamond: 1\nbaseball player: 2\nspectators: 4\ntree: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.495, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.191}, "timestamp": "2026-01-19T13:13:57.232325"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1968.685, "latencies_ms": [1968.685], "images_per_second": 0.508, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, while the catcher is further back, preparing to catch the ball. The spectators are situated in the background, watching the game unfold.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.747, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.778}, "timestamp": "2026-01-19T13:14:01.250616"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2377.068, "latencies_ms": [2377.068], "images_per_second": 0.421, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A youth baseball game is taking place in a park. A young boy is swinging a bat, while a catcher crouches behind him. Spectators are watching the game from the sidelines.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.762, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.929}, "timestamp": "2026-01-19T13:14:05.667563"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2301.625, "latencies_ms": [2301.625], "images_per_second": 0.434, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene is bathed in bright sunlight, creating a vibrant atmosphere. The green grass and trees provide a natural backdrop, while the dirt field and bleachers suggest an outdoor setting for sports.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.778, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.87}, "timestamp": "2026-01-19T13:14:09.993616"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1831.27, "latencies_ms": [1831.27], "images_per_second": 0.546, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A black telephone with a banana attached to its earpiece sits on a white desk, accompanied by a stapler and a piece of paper with handwritten text.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.908, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T13:14:13.877446"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2586.136, "latencies_ms": [2586.136], "images_per_second": 0.387, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "phone: 8\nbanana: 1\nstaple: 1\nprinter: 1\nnotepad: 1\ntable: 1\ncord: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.783, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.07}, "timestamp": "2026-01-19T13:14:18.527088"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1738.07, "latencies_ms": [1738.07], "images_per_second": 0.575, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The banana is positioned in the foreground, slightly to the right of the phone. The phone is placed in the background, slightly to the left of the banana.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.764, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T13:14:22.294317"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2190.798, "latencies_ms": [2190.798], "images_per_second": 0.456, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene depicts a desk with a black telephone with a banana attached to its handset. A stapler is visible in the background, and a piece of paper with handwritten notes is on the desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.34, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:14:26.498418"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2243.543, "latencies_ms": [2243.543], "images_per_second": 0.446, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The phone is black and has a yellow banana attached to its handset. The phone appears to be made of plastic and has a digital display. The desk is white and appears to be clean and organized.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.266, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.916}, "timestamp": "2026-01-19T13:14:30.764718"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1468.61, "latencies_ms": [1468.61], "images_per_second": 0.681, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A large crowd of people is gathered in a public area, engaged in various activities and conversations.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.75, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.588}, "timestamp": "2026-01-19T13:14:34.296710"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4021.441, "latencies_ms": [4021.441], "images_per_second": 0.249, "prompt_tokens": 21, "response_tokens_est": 53, "n_tiles": 1, "output_text": "Teddy bear: 1\nBag: 1\nHandbag: 1\nBackpack: 2\nScarf: 2\nShirt: 3\nSweater: 3\nGlasses: 1\nHair: 6\nGirl: 6\nPerson: 6", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12508.0, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.936, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 7.121}, "timestamp": "2026-01-19T13:14:40.357805"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1855.603, "latencies_ms": [1855.603], "images_per_second": 0.539, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The teddy bear is positioned in the foreground, slightly to the right of the center. The crowd extends into the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.0, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.908, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T13:14:44.245107"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2382.793, "latencies_ms": [2382.793], "images_per_second": 0.42, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene depicts a crowded public space, possibly a busy street or plaza, with many people standing and interacting. A large teddy bear is visible among the crowd, adding a playful element to the atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.99, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 7.066}, "timestamp": "2026-01-19T13:14:48.651656"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2833.401, "latencies_ms": [2833.401], "images_per_second": 0.353, "prompt_tokens": 18, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The crowd is densely packed, showcasing a variety of colors, including red, green, and white. The lighting appears to be natural daylight, creating a bright and lively atmosphere. The materials include clothing, bags, and personal items like teddy bears. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.247, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.099}, "timestamp": "2026-01-19T13:14:53.507262"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1476.785, "latencies_ms": [1476.785], "images_per_second": 0.677, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A man tenderly pets a brown horse's nose while holding a toddler on his hip.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.823, "power_cpu_cv_mean_watts": 0.983, "power_sys_5v0_mean_watts": 6.707}, "timestamp": "2026-01-19T13:14:57.017245"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2854.832, "latencies_ms": [2854.832], "images_per_second": 0.35, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "horse: 1\nman: 2\nchild: 1\nred shirt: 1\njeans: 1\nstone building: 1\nporch: 1\nroof: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.246, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.104}, "timestamp": "2026-01-19T13:15:01.888043"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2140.218, "latencies_ms": [2140.218], "images_per_second": 0.467, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The horse is positioned to the left of the man and baby, creating a spatial relationship that suggests proximity. The man and baby are standing close to the horse, implying a close interaction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.317, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T13:15:06.082343"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1933.034, "latencies_ms": [1933.034], "images_per_second": 0.517, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A man is holding a toddler while petting a brown horse. The setting appears to be a stable or farm, with a wooden porch and stone building visible in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.647, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T13:15:10.039340"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1562.816, "latencies_ms": [1562.816], "images_per_second": 0.64, "prompt_tokens": 18, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The horse is brown. The man is wearing a red shirt. The setting appears to be sunny and outdoors.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12506.6, "ram_available_mb": 50334.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.023, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.72}, "timestamp": "2026-01-19T13:15:13.631582"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1638.439, "latencies_ms": [1638.439], "images_per_second": 0.61, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A ripe banana with a small cup of peanut butter sits on a simple white plate with a brown rim, set against a wooden table.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12506.6, "ram_available_mb": 50334.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.46, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 6.358}, "timestamp": "2026-01-19T13:15:17.317272"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1708.399, "latencies_ms": [1708.399], "images_per_second": 0.585, "prompt_tokens": 21, "response_tokens_est": 18, "n_tiles": 1, "output_text": "banana: 1\npeanut butter: 1\nplate: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.121, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.218}, "timestamp": "2026-01-19T13:15:21.037807"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1677.899, "latencies_ms": [1677.899], "images_per_second": 0.596, "prompt_tokens": 25, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The banana is positioned in the foreground, partially covering the peanut butter. The plate is situated in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.09, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.249}, "timestamp": "2026-01-19T13:15:24.755115"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1815.73, "latencies_ms": [1815.73], "images_per_second": 0.551, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A ripe banana rests on a small plate, accompanied by a dollop of peanut butter. The plate is placed on a wooden table, creating a simple, casual setting.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.156, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.3}, "timestamp": "2026-01-19T13:15:28.595757"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2369.662, "latencies_ms": [2369.662], "images_per_second": 0.422, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The banana is white and appears ripe. The peanut butter is light brown and has a smooth, glossy texture. The plate is off-white with a thin orange-brown rim. The table appears to be wooden.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12504.9, "ram_available_mb": 50336.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.172, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.504}, "timestamp": "2026-01-19T13:15:32.990271"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1365.832, "latencies_ms": [1365.832], "images_per_second": 0.732, "prompt_tokens": 8, "response_tokens_est": 15, "n_tiles": 1, "output_text": "A man in green and blue is repairing a motorcycle wheel on the sidewalk.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12504.9, "ram_available_mb": 50336.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.909, "power_cpu_cv_mean_watts": 0.841, "power_sys_5v0_mean_watts": 6.713}, "timestamp": "2026-01-19T13:15:36.430662"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3025.377, "latencies_ms": [3025.377], "images_per_second": 0.331, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Motorcycle: 2\nBike wheel: 1\nMan: 1\nGlasses: 1\nFloor: 1\nBicycle: 1\nPole: 1\nShoe: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.845, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T13:15:41.479382"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2063.411, "latencies_ms": [2063.411], "images_per_second": 0.485, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The motorcycle is positioned to the left of the man, who is crouched down working on the wheel. The background includes other motorcycles and bicycles, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.365, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T13:15:45.570352"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1704.288, "latencies_ms": [1704.288], "images_per_second": 0.587, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man is repairing a motorcycle wheel on a city street. He appears to be working on a spare tire next to a parked motorcycle.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.269, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.73}, "timestamp": "2026-01-19T13:15:49.301570"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2265.308, "latencies_ms": [2265.308], "images_per_second": 0.441, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The motorcycle is primarily blue and silver. The lighting appears to be natural, possibly from street lamps or overcast conditions. The motorcycle appears to be made of metal and plastic. The weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.134, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.938}, "timestamp": "2026-01-19T13:15:53.592879"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2005.927, "latencies_ms": [2005.927], "images_per_second": 0.499, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A young man with dreadlocks is skillfully performing a trick on his skateboard, airborne over a concrete ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12504.9, "ram_available_mb": 50336.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.548, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T13:15:57.643126"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2974.673, "latencies_ms": [2974.673], "images_per_second": 0.336, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "skateboard: 1\nman: 1\nfence: 1\ntrees: 1\ngrass: 1\nskate ramp: 1\ncamera: 1\nwatermark: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12504.9, "ram_available_mb": 50336.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.2, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.823, "power_cpu_cv_mean_watts": 1.903, "power_sys_5v0_mean_watts": 7.022}, "timestamp": "2026-01-19T13:16:02.630876"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2938.826, "latencies_ms": [2938.826], "images_per_second": 0.34, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick on a ramp. The skateboard is situated near the center of the image, slightly angled towards the left. The background features a grassy area and a fence, providing a contrast to the skateboarder's action.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.021, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 7.114}, "timestamp": "2026-01-19T13:16:07.614142"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2423.219, "latencies_ms": [2423.219], "images_per_second": 0.413, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A young man with dreadlocks is performing a skateboard trick on a concrete ramp in a skate park. He wears a black t-shirt and dark pants. The background includes a grassy area and a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.438, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 7.098}, "timestamp": "2026-01-19T13:16:12.071612"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2532.644, "latencies_ms": [2532.644], "images_per_second": 0.395, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The skateboarder is wearing black clothing and a brown baseball cap. The scene appears to be outdoors in natural daylight, with some shadows cast by the trees. The skateboard is light brown and appears to be made of wood.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.537, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.017}, "timestamp": "2026-01-19T13:16:16.620098"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1566.687, "latencies_ms": [1566.687], "images_per_second": 0.638, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A group of four people, dressed casually, are posing for a photo on a grassy field, each holding a frisbee.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.115, "power_cpu_cv_mean_watts": 1.102, "power_sys_5v0_mean_watts": 6.182}, "timestamp": "2026-01-19T13:16:20.224916"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3272.227, "latencies_ms": [3272.227], "images_per_second": 0.306, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Frisbee: 3\nFrisbee: 2\nFrisbee: 1\nFrisbee: 1\nFrisbee: 1\nFrisbee: 1\nFrisbee: 1\nFrisbee: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.944, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 6.843}, "timestamp": "2026-01-19T13:16:25.513688"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1764.063, "latencies_ms": [1764.063], "images_per_second": 0.567, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The frisbees are positioned in the foreground, with the players standing behind them. The grassy field extends in the background, separating the main subjects from the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.214, "power_cpu_cv_mean_watts": 1.259, "power_sys_5v0_mean_watts": 6.292}, "timestamp": "2026-01-19T13:16:29.328715"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2180.829, "latencies_ms": [2180.829], "images_per_second": 0.459, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A group of four people are enjoying a game of frisbee in a grassy field at sunset. They are posing with frisbees and smiling, showcasing their fun and friendly atmosphere.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.978, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.445}, "timestamp": "2026-01-19T13:16:33.529262"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2738.791, "latencies_ms": [2738.791], "images_per_second": 0.365, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The people are wearing casual clothing in shades of blue, white, and red. The lighting suggests it might be either early morning or late evening. The frisbees appear to be made of plastic or similar materials. The setting appears to be a grassy field, possibly a park or recreational area.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.542, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 6.721}, "timestamp": "2026-01-19T13:16:38.286131"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1930.974, "latencies_ms": [1930.974], "images_per_second": 0.518, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A large commercial passenger airplane, painted white with a red tail and displaying the JAL logo, is parked at an airport gate with jet bridges attached.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12505.2, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.678, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T13:16:42.282076"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2704.129, "latencies_ms": [2704.129], "images_per_second": 0.37, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "airplane: 1\ntarmac: 1\njet bridge: 1\nservice vehicles: 2\nground crew: 1\nservice carts: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.569, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.033}, "timestamp": "2026-01-19T13:16:47.029599"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2305.444, "latencies_ms": [2305.444], "images_per_second": 0.434, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main object is a large passenger airplane parked on the tarmac, positioned in the foreground. The airplane is facing towards the right side of the image.  In the background, other aircraft and airport infrastructure are visible.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12504.3, "ram_available_mb": 50336.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.161, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T13:16:51.369731"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2918.553, "latencies_ms": [2918.553], "images_per_second": 0.343, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A large Japan Airlines Boeing 777-300ER is parked at an airport gate, ready for boarding or disembarking passengers. The plane is surrounded by ground support equipment, including baggage carts and service vehicles, indicating a busy airport environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.3, "ram_available_mb": 50336.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.72, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 6.967}, "timestamp": "2026-01-19T13:16:56.312003"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1852.859, "latencies_ms": [1852.859], "images_per_second": 0.54, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The airplane is predominantly white with red accents on the tail and around the engines. The sky is bright blue with scattered white clouds.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.731, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T13:17:00.200916"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2041.533, "latencies_ms": [2041.533], "images_per_second": 0.49, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A young man in a yellow shirt and black pants is skillfully riding a skateboard on a concrete ramp in a skate park, surrounded by graffiti and trees.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.677, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.873}, "timestamp": "2026-01-19T13:17:04.282145"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2862.408, "latencies_ms": [2862.408], "images_per_second": 0.349, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "trash can: 1\nbench: 2\npark bench: 2\nskateboard: 1\nskateboard ramp: 1\ngraffiti: 2\ncar: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.268, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.082}, "timestamp": "2026-01-19T13:17:09.174359"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2652.491, "latencies_ms": [2652.491], "images_per_second": 0.377, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick on a concrete ramp. The park setting with benches, trees, and a bus stop in the background creates a spatial relationship between the skateboarder and the park elements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.31, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T13:17:13.870551"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2294.923, "latencies_ms": [2294.923], "images_per_second": 0.436, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A young man is performing a skateboard trick on a concrete ramp in a park-like setting. The park features benches, a bus stop, and trees, creating a casual and recreational atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.025, "power_cpu_cv_mean_watts": 1.446, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T13:17:18.195542"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2394.916, "latencies_ms": [2394.916], "images_per_second": 0.418, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The skateboarder is wearing a yellow shirt and brown pants. The scene is brightly lit, suggesting sunlight. The skateboard is light brown and appears to be made of wood. The ground is concrete.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.825, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T13:17:22.633284"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2131.304, "latencies_ms": [2131.304], "images_per_second": 0.469, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A slice of decadent chocolate cake, drizzled with chocolate sauce and adorned with white chocolate drizzle, sits on a decorative white plate.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.107, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:17:26.827402"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3022.007, "latencies_ms": [3022.007], "images_per_second": 0.331, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "slice of chocolate cake: 1\nchocolate frosting: 1\ncaramel sauce: 1\nchocolate drizzle: 1\nfloral pattern: 1\nplate: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.892, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.011}, "timestamp": "2026-01-19T13:17:31.869441"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2365.724, "latencies_ms": [2365.724], "images_per_second": 0.423, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The chocolate cake is positioned in the foreground of the image, resting on a white plate with a gold floral pattern. The plate is situated on a surface, possibly a table, which further emphasizes the foreground placement of the cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12502.5, "ram_available_mb": 50338.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.887, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.976}, "timestamp": "2026-01-19T13:17:36.296613"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2151.392, "latencies_ms": [2151.392], "images_per_second": 0.465, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A slice of chocolate cake with a drizzle of white chocolate sits on a decorative plate. The plate is placed on a wooden table, enhancing the warm and inviting ambiance of the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12502.5, "ram_available_mb": 50338.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.201, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T13:17:40.471787"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2170.635, "latencies_ms": [2170.635], "images_per_second": 0.461, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The chocolate cake is topped with white drizzle and sits on a white plate with a gold floral pattern. The cake appears moist and rich in color, reflecting the ambient lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12501.9, "ram_available_mb": 50339.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.65, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.931}, "timestamp": "2026-01-19T13:17:44.684811"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1549.345, "latencies_ms": [1549.345], "images_per_second": 0.645, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man is working on a laptop at a cluttered desk, surrounded by various electronic devices and equipment.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12501.9, "ram_available_mb": 50339.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12502.0, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.426, "power_cpu_cv_mean_watts": 0.935, "power_sys_5v0_mean_watts": 6.577}, "timestamp": "2026-01-19T13:17:48.280004"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3547.154, "latencies_ms": [3547.154], "images_per_second": 0.282, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "laptop: 2\nkeyboard: 1\nmouse: 1\nlaptop: 2\ncord: 1\nwater bottle: 1\ncardboard box: 2\nchair: 4\ntable: 2\nperson: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.0, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12502.0, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.456, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 7.104}, "timestamp": "2026-01-19T13:17:53.854125"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3052.538, "latencies_ms": [3052.538], "images_per_second": 0.328, "prompt_tokens": 25, "response_tokens_est": 68, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The foreground features the laptop and the person working on it, while the background includes other desks, chairs, and equipment. The person working on the laptop is situated towards the left side of the image, while the person in the background is near the center.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.0, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.831, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.048}, "timestamp": "2026-01-19T13:17:58.930698"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2023.456, "latencies_ms": [2023.456], "images_per_second": 0.494, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The scene depicts a busy workspace with multiple people working on laptops and collaborating on projects. The room features desks, chairs, and various electronic equipment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.401, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T13:18:02.968057"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2738.994, "latencies_ms": [2738.994], "images_per_second": 0.365, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The room is lit by fluorescent lighting, giving it a bright and airy atmosphere. The walls are covered with various materials, including cardboard boxes, papers, and possibly some electronic components. The floor appears to be painted in a light yellow or tan color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12500.6, "ram_available_mb": 50340.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.145, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 6.928}, "timestamp": "2026-01-19T13:18:07.749183"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1653.042, "latencies_ms": [1653.042], "images_per_second": 0.605, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of friends is playing a video game in a cozy living room, enjoying each other's company and having a good time.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12500.6, "ram_available_mb": 50340.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12500.2, "ram_available_mb": 50340.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.46, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.707}, "timestamp": "2026-01-19T13:18:11.430524"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2642.192, "latencies_ms": [2642.192], "images_per_second": 0.378, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "woman: 2\nman: 2\nman: 2\nman: 2\nman: 2\nman: 2\nman: 2\nman: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12499.6, "ram_available_mb": 50341.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12499.5, "ram_available_mb": 50341.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.403, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T13:18:16.091666"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2387.162, "latencies_ms": [2387.162], "images_per_second": 0.419, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a couch in the background and a table and chair in the foreground. The couch is situated further back than the foreground elements, while the table and chair are closer in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12499.5, "ram_available_mb": 50341.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12499.2, "ram_available_mb": 50341.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.526, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 6.88}, "timestamp": "2026-01-19T13:18:20.499546"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2714.804, "latencies_ms": [2714.804], "images_per_second": 0.368, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "A group of friends is playing a video game in a cozy living room. They are standing barefoot and holding Wii remotes, enjoying a casual and fun activity together. The room features a couch, a coffee table, and various personal items, creating a comfortable and relaxed atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12499.2, "ram_available_mb": 50341.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12498.8, "ram_available_mb": 50342.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.953, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.065}, "timestamp": "2026-01-19T13:18:25.252761"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1885.237, "latencies_ms": [1885.237], "images_per_second": 0.53, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The room is lit by soft, warm lighting, creating a cozy atmosphere. The walls are painted white, and the carpet is a neutral beige color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.8, "ram_available_mb": 50342.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.997, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.814}, "timestamp": "2026-01-19T13:18:29.167242"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1753.674, "latencies_ms": [1753.674], "images_per_second": 0.57, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A person is silhouetted against the setting sun, standing on a frozen surface with footprints nearby, gazing towards a vibrant sky.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12498.5, "ram_available_mb": 50342.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.45, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.732}, "timestamp": "2026-01-19T13:18:32.994625"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2519.885, "latencies_ms": [2519.885], "images_per_second": 0.397, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "sun: 1\nperson: 1\nfrisbee: 1\nice: 2\nwater: 2\nsky: 1\nhorizon: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12498.5, "ram_available_mb": 50342.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.458, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T13:18:37.554566"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3184.144, "latencies_ms": [3184.144], "images_per_second": 0.314, "prompt_tokens": 25, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The person stands in the middle of the image, facing the setting sun. The sun is positioned behind them, casting a warm glow and creating a contrast between the person and the bright sky. The person's silhouette is visible against the orange and yellow hues of the sunset, making them appear as dark silhouettes against the vibrant backdrop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.679, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 7.101}, "timestamp": "2026-01-19T13:18:42.766499"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2566.142, "latencies_ms": [2566.142], "images_per_second": 0.39, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A person is standing on a frozen surface, possibly a beach or ice floe, during sunset. The sun is setting in the background, creating a warm glow and casting long shadows. The scene evokes a sense of solitude and tranquility.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.478, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T13:18:47.347654"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2311.845, "latencies_ms": [2311.845], "images_per_second": 0.433, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The sky is a vibrant mix of orange and blue, indicating a sunset. The ground is partially covered with ice and snow, reflecting the warm light of the setting sun. The scene is peaceful and serene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.821, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T13:18:51.693749"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2084.231, "latencies_ms": [2084.231], "images_per_second": 0.48, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The living room features a white sofa, a coffee table, a television, a dining table with four chairs, and various decorative elements such as vases, books, and wall art.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12498.7, "ram_available_mb": 50342.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.575, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 6.961}, "timestamp": "2026-01-19T13:18:55.806290"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2932.076, "latencies_ms": [2932.076], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "sofa: 2\nchairs: 3\nrug: 1\ntable: 1\ntelevision: 1\nlamp: 1\nflowers: 1\nwall decor: 4", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12498.7, "ram_available_mb": 50342.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12498.7, "ram_available_mb": 50342.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.038, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.078}, "timestamp": "2026-01-19T13:19:00.758178"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2835.856, "latencies_ms": [2835.856], "images_per_second": 0.353, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The white sofa and wooden coffee table are positioned in the foreground, facing the window. The dining table and chairs are situated in the background, facing the window and television. The living room area is further back, separated from the dining area by a folding screen.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12498.7, "ram_available_mb": 50342.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.125, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.047}, "timestamp": "2026-01-19T13:19:05.637537"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3116.164, "latencies_ms": [3116.164], "images_per_second": 0.321, "prompt_tokens": 19, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The living room features a modern and stylish design with natural light from a large window, complemented by colorful accents and decorative elements. The room is furnished with a white sofa, a coffee table, a television, and a dining table with chairs, offering a comfortable and inviting space for relaxation and socializing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.764, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.015}, "timestamp": "2026-01-19T13:19:10.773690"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2786.773, "latencies_ms": [2786.773], "images_per_second": 0.359, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The room features a warm color palette, primarily with cream, beige, and light brown tones. The lighting is soft and warm, creating a cozy atmosphere. The furniture includes white, wood, and red elements, adding contrast and visual interest to the space.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.366, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.019}, "timestamp": "2026-01-19T13:19:15.576162"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1656.581, "latencies_ms": [1656.581], "images_per_second": 0.604, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A curious tabby cat with a blue collar sits atop a blue refrigerator in a kitchen, gazing upwards.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.238, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.784}, "timestamp": "2026-01-19T13:19:19.266627"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3051.432, "latencies_ms": [3051.432], "images_per_second": 0.328, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Refrigerator: 2\nCabinet: 1\nLight fixture: 1\nCat: 1\nWall: 1\nFloor: 1\nMirror: 1\nMagnet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.94, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T13:19:24.351953"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2030.246, "latencies_ms": [2030.246], "images_per_second": 0.493, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The cat is positioned near the refrigerator, seemingly looking up at it.  The refrigerator is situated in the background, partially obscured by the cat's position.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.375, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T13:19:28.431201"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1985.305, "latencies_ms": [1985.305], "images_per_second": 0.504, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A tabby cat with a blue collar is perched atop a blue refrigerator in a kitchen. The kitchen features white cabinets and a light-colored ceiling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.222, "power_cpu_cv_mean_watts": 1.176, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T13:19:32.446914"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2129.969, "latencies_ms": [2129.969], "images_per_second": 0.469, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The cat is brown and gray, wearing a blue collar. The kitchen has light-colored cabinets and a blue refrigerator. The lighting is bright, likely from overhead fluorescent fixtures.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.197, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.865}, "timestamp": "2026-01-19T13:19:36.607246"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1795.341, "latencies_ms": [1795.341], "images_per_second": 0.557, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The living room is decorated with colorful balloons, including a large yellow smiley face balloon, and scattered white paper confetti on the floor.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12499.7, "ram_available_mb": 50341.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.024, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.724}, "timestamp": "2026-01-19T13:19:40.433709"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3410.096, "latencies_ms": [3410.096], "images_per_second": 0.293, "prompt_tokens": 21, "response_tokens_est": 48, "n_tiles": 1, "output_text": "smiley face balloon: 1\nrefrigerator: 2\nwooden shelving unit: 2\nbed: 1\nrug: 1\ntable: 1\nbookshelf: 2\nplant: 1\nchandelier: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12499.7, "ram_available_mb": 50341.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12498.8, "ram_available_mb": 50342.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.62, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.142}, "timestamp": "2026-01-19T13:19:45.861825"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2262.705, "latencies_ms": [2262.705], "images_per_second": 0.442, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The refrigerator is positioned on the left side of the image, near the foreground. The bedroom is situated in the background, near the center of the image. The living area is further back, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.8, "ram_available_mb": 50342.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.021, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:19:50.176744"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2374.611, "latencies_ms": [2374.611], "images_per_second": 0.421, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a cozy, cluttered apartment with a living room, kitchen, and bedroom. The living room is decorated with balloons and has a small wooden cart. The kitchen area features a refrigerator and various items.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12499.2, "ram_available_mb": 50341.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.884, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T13:19:54.567725"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2030.709, "latencies_ms": [2030.709], "images_per_second": 0.492, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The room is decorated with yellow and blue balloons, creating a cheerful atmosphere. The wooden floor and light-colored walls contribute to the overall warm and cozy feel of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12499.2, "ram_available_mb": 50341.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12499.1, "ram_available_mb": 50341.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.498, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.904}, "timestamp": "2026-01-19T13:19:58.620250"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1825.258, "latencies_ms": [1825.258], "images_per_second": 0.548, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man with red hair, wearing a green jacket, is sitting in a train seat, focused on his laptop computer while listening to headphones.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12499.1, "ram_available_mb": 50341.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12498.6, "ram_available_mb": 50342.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.108, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.861}, "timestamp": "2026-01-19T13:20:02.485957"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2608.78, "latencies_ms": [2608.78], "images_per_second": 0.383, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "laptop: 1\ntable: 1\nchair: 2\nwindow: 1\nman: 1\nheadphones: 1\njacket: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.6, "ram_available_mb": 50342.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12499.7, "ram_available_mb": 50341.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.306, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 6.984}, "timestamp": "2026-01-19T13:20:07.110808"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2764.485, "latencies_ms": [2764.485], "images_per_second": 0.362, "prompt_tokens": 25, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The main object is a person seated at a table, using a laptop. The laptop is positioned in the foreground, close to the person's face. The table and chair are placed in the background, further away from the person. The train window is positioned in the background, further away from the person.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12499.7, "ram_available_mb": 50341.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.003, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T13:20:11.920425"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1733.239, "latencies_ms": [1733.239], "images_per_second": 0.577, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man is sitting in a train seat, using a laptop computer. He appears to be focused on his work or browsing the internet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12501.4, "ram_available_mb": 50339.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.935, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.717}, "timestamp": "2026-01-19T13:20:15.670780"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1611.332, "latencies_ms": [1611.332], "images_per_second": 0.621, "prompt_tokens": 18, "response_tokens_est": 21, "n_tiles": 1, "output_text": "The man is wearing a green jacket. The laptop is silver. The train appears to have natural lighting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12500.7, "ram_available_mb": 50340.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.423, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.602}, "timestamp": "2026-01-19T13:20:19.299054"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1842.427, "latencies_ms": [1842.427], "images_per_second": 0.543, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A silver train is traveling on a track beneath a white metal bridge, passing through a suburban area with buildings and trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.854, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T13:20:23.185005"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2459.479, "latencies_ms": [2459.479], "images_per_second": 0.407, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bridge: 2\ntrain: 2\nroad: 1\nsky: 1\nclouds: 2\nbuildings: 2\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.723, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T13:20:27.661219"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2286.935, "latencies_ms": [2286.935], "images_per_second": 0.437, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The train is positioned in the foreground, moving away from the viewer. The road and bridge are located in the background, extending into the distance. The bridge spans across the road and appears to connect two points.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.044, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:20:31.992479"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2506.966, "latencies_ms": [2506.966], "images_per_second": 0.399, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a modern, elevated train station with multiple train tracks. A silver train is traveling on the tracks, passing under a distinctive white bridge. The surrounding area features residential buildings and a hilly landscape in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.553, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.003}, "timestamp": "2026-01-19T13:20:36.546429"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2023.73, "latencies_ms": [2023.73], "images_per_second": 0.494, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The bridge is primarily white, contrasting with the blue sky and white clouds above. The lighting suggests a sunny day with bright sunlight illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.148, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.715}, "timestamp": "2026-01-19T13:20:40.595583"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1568.208, "latencies_ms": [1568.208], "images_per_second": 0.638, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of people are flying a large, colorful kite with orange, yellow, and blue hues in a vibrant park.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12500.2, "ram_available_mb": 50340.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.623, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.787}, "timestamp": "2026-01-19T13:20:44.222798"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2997.282, "latencies_ms": [2997.282], "images_per_second": 0.334, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "kite: 1\nperson: 2\ngrass: 8\nfence: 1\nsoccer ball: 1\nsports ball: 1\nchairs: 1\nbags: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.2, "ram_available_mb": 50340.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12499.8, "ram_available_mb": 50341.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.703, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.043}, "timestamp": "2026-01-19T13:20:49.271988"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2279.131, "latencies_ms": [2279.131], "images_per_second": 0.439, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The kite is positioned in the foreground, close to the people. The field extends in the background, further away from the kite. The people are scattered across the field, some closer to the kite and others further away.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12499.8, "ram_available_mb": 50341.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12499.8, "ram_available_mb": 50341.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.777, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.764}, "timestamp": "2026-01-19T13:20:53.567209"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2612.965, "latencies_ms": [2612.965], "images_per_second": 0.383, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene takes place in a park on a sunny day. A group of people, including children, gathers on a grassy field to fly a large, colorful kite. The kite has a dragon-like design and is tethered to the ground by strings.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12499.2, "ram_available_mb": 50341.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12499.2, "ram_available_mb": 50341.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.344, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.017}, "timestamp": "2026-01-19T13:20:58.218754"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2109.5, "latencies_ms": [2109.5], "images_per_second": 0.474, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The kite is predominantly blue with vibrant orange and yellow accents. The lighting suggests a sunny day, and the materials appear to be lightweight and flexible, suitable for outdoor activities.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12498.1, "ram_available_mb": 50342.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.346, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 6.917}, "timestamp": "2026-01-19T13:21:02.344241"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1949.532, "latencies_ms": [1949.532], "images_per_second": 0.513, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A group of miniature workers in orange uniforms are standing next to a red and black Virgin train, appearing to inspect or prepare the train for a journey.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12498.1, "ram_available_mb": 50342.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12498.6, "ram_available_mb": 50342.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.758, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T13:21:06.321616"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3368.593, "latencies_ms": [3368.593], "images_per_second": 0.297, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Train: 6\nTrain car: 2\nTrain tracks: 4\nTrain wires: 4\nTrain workers: 6\nTrain engine: 1\nTrain body: 1\nTrain wheels: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.6, "ram_available_mb": 50342.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12498.6, "ram_available_mb": 50342.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.412, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 7.119}, "timestamp": "2026-01-19T13:21:11.727208"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2078.26, "latencies_ms": [2078.26], "images_per_second": 0.481, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The red and black train is positioned in the foreground, moving towards the left side of the image. The miniature model train track extends into the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.6, "ram_available_mb": 50342.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12499.1, "ram_available_mb": 50341.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.547, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:21:15.847609"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2188.727, "latencies_ms": [2188.727], "images_per_second": 0.457, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A model train is traveling on tracks in a miniature model landscape. Workers in orange uniforms are seen working near the train, likely performing maintenance or preparing the tracks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12499.1, "ram_available_mb": 50341.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.033, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.878}, "timestamp": "2026-01-19T13:21:20.055570"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2672.811, "latencies_ms": [2672.811], "images_per_second": 0.374, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The train is primarily red and black. The lighting in the image creates a dramatic effect, highlighting the colors of the train and the workers. The materials appear to be standard model train construction, typical for miniature models. The weather is not visible in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12497.4, "ram_available_mb": 50343.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.329, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T13:21:24.774046"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1700.974, "latencies_ms": [1700.974], "images_per_second": 0.588, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A brown and white cat's fur is visible, appearing soft and slightly ruffled against the textured background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12497.4, "ram_available_mb": 50343.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12496.9, "ram_available_mb": 50344.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.707, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.666}, "timestamp": "2026-01-19T13:21:28.523780"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2223.851, "latencies_ms": [2223.851], "images_per_second": 0.45, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "cat: 2\nblanket: 2\nfur: 2\nhair: 2\nskin: 2\nbody: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12496.9, "ram_available_mb": 50344.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12497.3, "ram_available_mb": 50343.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.01, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 6.895}, "timestamp": "2026-01-19T13:21:32.788783"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1815.434, "latencies_ms": [1815.434], "images_per_second": 0.551, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the beige textured surface. The cat's fur is partially visible, blending with the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12497.3, "ram_available_mb": 50343.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12498.0, "ram_available_mb": 50342.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.879, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T13:21:36.640782"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1750.599, "latencies_ms": [1750.599], "images_per_second": 0.571, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A cat with brown and white fur is resting on a textured, beige blanket. The blanket has a subtle pattern of triangles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.0, "ram_available_mb": 50342.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12498.0, "ram_available_mb": 50342.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.88, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.732}, "timestamp": "2026-01-19T13:21:40.443469"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2503.628, "latencies_ms": [2503.628], "images_per_second": 0.399, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The cat's fur is predominantly light brown with white patches. The lighting appears to be soft and diffused, possibly coming from a window or soft overhead light. The material appears to be a textured fabric, possibly a blanket or sheet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.0, "ram_available_mb": 50342.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.441, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:21:44.985148"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1880.932, "latencies_ms": [1880.932], "images_per_second": 0.532, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A cow is standing in a milking parlor, receiving milk from a machine with four red tubes connected to a black machine.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12497.9, "ram_available_mb": 50343.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.382, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.686}, "timestamp": "2026-01-19T13:21:48.899328"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3341.971, "latencies_ms": [3341.971], "images_per_second": 0.299, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Cow: 4\nMilking machine: 3\nMilk tub: 2\nPumps: 2\nPipes: 2\nMetal: 1\nWood: 1\nPlastic: 1\nStick: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12497.9, "ram_available_mb": 50343.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12498.0, "ram_available_mb": 50342.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.52, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.113}, "timestamp": "2026-01-19T13:21:54.270447"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2126.726, "latencies_ms": [2126.726], "images_per_second": 0.47, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The cow's legs are positioned in the foreground, partially obscuring the background. The milking machine is situated near the cow's legs, partially hidden by them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.0, "ram_available_mb": 50342.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.198, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.794}, "timestamp": "2026-01-19T13:21:58.440100"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2378.924, "latencies_ms": [2378.924], "images_per_second": 0.42, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A cow is milking a cow in a barn or milking parlor. The milking apparatus consists of red and white tubes connected to a machine. The surrounding area is clean and organized.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12498.8, "ram_available_mb": 50342.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.715, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T13:22:02.879882"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2215.218, "latencies_ms": [2215.218], "images_per_second": 0.451, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The cow's legs are partially visible, adorned with red and white tubes. The cow's coat is predominantly black and white. The lighting in the image is soft and diffused.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.8, "ram_available_mb": 50342.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12498.5, "ram_available_mb": 50342.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.977, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.927}, "timestamp": "2026-01-19T13:22:07.131572"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1713.361, "latencies_ms": [1713.361], "images_per_second": 0.584, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A half-eaten sandwich with red filling and scattered seeds sits on a patterned plate, accompanied by a knife.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12498.5, "ram_available_mb": 50342.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12498.8, "ram_available_mb": 50342.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.176, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T13:22:10.897681"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2684.783, "latencies_ms": [2684.783], "images_per_second": 0.372, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "sandwich: 3\nbread: 2\njelly: 1\nbutter: 1\nplate: 1\nknife: 1\ngreen napkin: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.8, "ram_available_mb": 50342.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12500.0, "ram_available_mb": 50340.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.274, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 7.028}, "timestamp": "2026-01-19T13:22:15.624668"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1797.375, "latencies_ms": [1797.375], "images_per_second": 0.556, "prompt_tokens": 25, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The sandwich is positioned in the foreground, partially obscuring the background. The knife is placed near the sandwich, resting on the plate.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12500.0, "ram_available_mb": 50340.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12500.0, "ram_available_mb": 50340.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.879, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T13:22:19.458651"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2235.821, "latencies_ms": [2235.821], "images_per_second": 0.447, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A partially eaten sandwich with visible jelly or fruit filling sits on a patterned plate, accompanied by a knife. The setting appears to be a casual dining environment, possibly a home or informal gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.0, "ram_available_mb": 50340.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12500.7, "ram_available_mb": 50340.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.911, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T13:22:23.736925"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2641.692, "latencies_ms": [2641.692], "images_per_second": 0.379, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The sandwich is primarily light brown in color. The bread appears soft and slightly moist. The sandwich is cut in half, revealing a dark red filling. The plate has a decorative pattern and rests on a green napkin.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.7, "ram_available_mb": 50340.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12500.7, "ram_available_mb": 50340.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.63, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T13:22:28.403996"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1906.579, "latencies_ms": [1906.579], "images_per_second": 0.524, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The meal includes a variety of colorful and healthy food items, including pasta, vegetables, fruits, and meat, arranged in four distinct containers.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12500.7, "ram_available_mb": 50340.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12501.0, "ram_available_mb": 50339.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.594, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.874}, "timestamp": "2026-01-19T13:22:32.342984"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3077.059, "latencies_ms": [3077.059], "images_per_second": 0.325, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Pasta: 2\nGrapes: 6\nCarrots: 2\nQuinoa: 1\nTomato: 1\nBeans: 1\nMeat: 1\nCheese: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12501.0, "ram_available_mb": 50339.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12501.0, "ram_available_mb": 50339.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.828, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.084}, "timestamp": "2026-01-19T13:22:37.447937"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2322.335, "latencies_ms": [2322.335], "images_per_second": 0.431, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main objects are arranged in a visually appealing manner, with the main dish (left) positioned in the foreground and the side dishes (right) in the background. The vegetables are placed near the right side of the main dish.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12501.0, "ram_available_mb": 50339.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12500.6, "ram_available_mb": 50340.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.526, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:22:41.831406"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2367.072, "latencies_ms": [2367.072], "images_per_second": 0.422, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a colorful bento box meal on a dark surface. The meal includes a variety of food items such as pasta, vegetables, meat, and cheese, arranged in four separate containers.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12500.6, "ram_available_mb": 50340.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.99, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T13:22:46.213516"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2353.414, "latencies_ms": [2353.414], "images_per_second": 0.425, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The meal is presented in a vibrant purple lunchbox. The food items are arranged in colorful containers, highlighting the variety of textures and colors. The lighting appears to be soft and warm, creating a pleasant atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.011, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T13:22:50.582062"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1714.401, "latencies_ms": [1714.401], "images_per_second": 0.583, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A traffic light with red lights illuminated is mounted on a pole above a tree covered in blooming cherry blossoms.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.822, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T13:22:54.349540"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1864.332, "latencies_ms": [1864.332], "images_per_second": 0.536, "prompt_tokens": 21, "response_tokens_est": 21, "n_tiles": 1, "output_text": "traffic light: 3\ncherry blossoms: 10\ntrees: 10\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.854, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T13:22:58.230186"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1933.889, "latencies_ms": [1933.889], "images_per_second": 0.517, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The cherry blossoms are in the foreground, partially obscuring the traffic light. The traffic light is positioned slightly above and to the right of the blossoms.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.651, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T13:23:02.178569"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2728.962, "latencies_ms": [2728.962], "images_per_second": 0.366, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a cherry blossom tree in full bloom, adorned with pink and white flowers. A traffic light hangs above the tree, displaying a red light. The setting suggests a city street or roadway where these beautiful blossoms are present.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 7.033}, "timestamp": "2026-01-19T13:23:06.952110"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2634.607, "latencies_ms": [2634.607], "images_per_second": 0.38, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The traffic light is red, indicating a stop. The cherry blossoms are pink and white, creating a beautiful contrast against the sky. The lighting suggests it's likely daytime, and the material of the traffic light and cherry blossoms appears to be metal and plastic, respectively.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.147, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T13:23:11.618494"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2044.606, "latencies_ms": [2044.606], "images_per_second": 0.489, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A white plate holds a generous serving of saut\u00e9ed broccoli, alongside a piece of grilled salmon, arranged neatly on a white tablecloth.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.397, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:23:15.719314"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3157.788, "latencies_ms": [3157.788], "images_per_second": 0.317, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "broccoli: 8\nsalmon: 1\ngarlic: 1\nred pepper flakes: 1\nonions: 1\nbutter: 1\ngarlic powder: 1\nsesame seeds: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.2, "ram_available_mb": 50339.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12500.8, "ram_available_mb": 50340.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.758, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 7.133}, "timestamp": "2026-01-19T13:23:20.898607"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1601.359, "latencies_ms": [1601.359], "images_per_second": 0.624, "prompt_tokens": 25, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The broccoli is positioned in the foreground, slightly to the left of the salmon. The salmon is placed in the background, behind the broccoli.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.8, "ram_available_mb": 50340.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.453, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T13:23:24.552763"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2917.803, "latencies_ms": [2917.803], "images_per_second": 0.343, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a meal consisting of a piece of cooked salmon and steamed broccoli on a white plate. The broccoli appears seasoned and cooked, complementing the salmon's rich flavor. The setting suggests a home-cooked meal, possibly a family dinner or a casual gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.037, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.014}, "timestamp": "2026-01-19T13:23:29.496379"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2805.634, "latencies_ms": [2805.634], "images_per_second": 0.356, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The broccoli appears vibrant green, contrasting with the golden-brown of the salmon. The lighting is soft and warm, enhancing the colors and textures of the food. The broccoli and salmon appear to be cooked together, showcasing a well-balanced and appetizing dish.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.352, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T13:23:34.330841"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1546.886, "latencies_ms": [1546.886], "images_per_second": 0.646, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A young boy is eating something while sitting at a table with two adults in a dimly lit restaurant.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.825, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.694}, "timestamp": "2026-01-19T13:23:37.947330"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2718.845, "latencies_ms": [2718.845], "images_per_second": 0.368, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "woman: 2\nboy: 1\nman: 2\ntable: 2\nnapkins: 2\nfood: 1\nglass: 1\nchair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.311, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.936}, "timestamp": "2026-01-19T13:23:42.696614"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2030.645, "latencies_ms": [2030.645], "images_per_second": 0.492, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The man and woman are seated at a table in the foreground, while the boy is seated further back. The background is slightly blurred, indicating a focus on the people in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12501.6, "ram_available_mb": 50339.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.4, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.803}, "timestamp": "2026-01-19T13:23:46.758864"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2624.513, "latencies_ms": [2624.513], "images_per_second": 0.381, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene takes place in a restaurant or dining area, where a family is seated at a table. A young boy is eating something, possibly a snack, while a woman looks on. The atmosphere is casual and relaxed, with other people visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.6, "ram_available_mb": 50339.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12501.6, "ram_available_mb": 50339.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.456, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.991}, "timestamp": "2026-01-19T13:23:51.413708"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2570.918, "latencies_ms": [2570.918], "images_per_second": 0.389, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The lighting in the image is dim, creating a warm ambiance. The colors are primarily dark, with some hints of red and brown. The materials appear to be wood and metal, contributing to the overall ambiance. The weather appears to be nighttime.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12501.6, "ram_available_mb": 50339.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12501.3, "ram_available_mb": 50339.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.576, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T13:23:56.002588"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1596.241, "latencies_ms": [1596.241], "images_per_second": 0.626, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A yellow bus is driving down a city street, passing by a tall building and several trees.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12501.3, "ram_available_mb": 50339.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12502.3, "ram_available_mb": 50338.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.691, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.77}, "timestamp": "2026-01-19T13:23:59.663285"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2796.277, "latencies_ms": [2796.277], "images_per_second": 0.358, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "building: 10\nbus: 2\ncar: 1\ntrees: 4\nstreetlights: 2\nsidewalk: 2\nbike rack: 1\nfence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.3, "ram_available_mb": 50338.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.492, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T13:24:04.496310"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2259.345, "latencies_ms": [2259.345], "images_per_second": 0.443, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The foreground features a yellow bus parked near a sidewalk, positioned between the foreground and the background. The background showcases a modern building with multiple windows, situated behind the bus and further in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.8, "ram_available_mb": 50339.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12502.7, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.246, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T13:24:08.795862"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2304.499, "latencies_ms": [2304.499], "images_per_second": 0.434, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a city street with a yellow bus, a white bus, and a van parked near a modern building. The setting appears to be urban, with trees lining the street and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12502.7, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.826, "power_cpu_cv_mean_watts": 1.78, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:24:13.131632"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2013.797, "latencies_ms": [2013.797], "images_per_second": 0.497, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The building is primarily gray and light-colored. The street is paved with asphalt and features streetlights. The scene is well-lit, suggesting sunny weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.128, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.936}, "timestamp": "2026-01-19T13:24:17.163877"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1568.538, "latencies_ms": [1568.538], "images_per_second": 0.638, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A stop sign is mounted on a metal pole at the corner of a street, with a bus visible in the background.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.792, "power_cpu_cv_mean_watts": 1.034, "power_sys_5v0_mean_watts": 6.728}, "timestamp": "2026-01-19T13:24:20.758623"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2738.325, "latencies_ms": [2738.325], "images_per_second": 0.365, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "stop sign: 1\npole: 1\nbus: 1\nbuildings: 2\nvehicles: 2\nrailings: 1\nvegetation: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.917, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T13:24:25.516343"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2717.747, "latencies_ms": [2717.747], "images_per_second": 0.368, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The stop sign is positioned in the foreground, slightly to the left of the image. The background features a street scene with a bus and buildings, suggesting an urban setting. The stop sign is situated near the center of the image, drawing the viewer's attention to its presence.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.37, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.065}, "timestamp": "2026-01-19T13:24:30.290489"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2219.049, "latencies_ms": [2219.049], "images_per_second": 0.451, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene is set in an urban area, with a stop sign prominently displayed on a pole. The sun is shining brightly, casting a warm glow on the street and buildings, creating a pleasant atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12503.9, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.889, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T13:24:34.554891"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2085.431, "latencies_ms": [2085.431], "images_per_second": 0.48, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The stop sign is red and white. The lighting suggests it might be late afternoon or early evening. The stop sign appears to be made of metal and has a weathered appearance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12503.9, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.273, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.835}, "timestamp": "2026-01-19T13:24:38.663503"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1847.654, "latencies_ms": [1847.654], "images_per_second": 0.541, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white and brown cat with green eyes is lying on a black surface, gazing at the camera with its paws stretched out.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.737, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T13:24:42.563032"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2532.58, "latencies_ms": [2532.58], "images_per_second": 0.395, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "cat: 2\nmouse: 1\ncord: 1\ncouch: 1\npaws: 2\nfur: 2\neyes: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.611, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T13:24:47.126909"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2170.207, "latencies_ms": [2170.207], "images_per_second": 0.461, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, slightly to the right of the mouse. The mouse is situated near the cat, closer to the viewer's perspective. The background is dark and out of focus.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.152, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T13:24:51.323672"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2047.586, "latencies_ms": [2047.586], "images_per_second": 0.488, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A brown and white cat with bright green eyes is lying on a dark surface, seemingly playing with a computer mouse. The scene takes place in a dimly lit room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.497, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T13:24:55.412186"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2320.027, "latencies_ms": [2320.027], "images_per_second": 0.431, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The cat has striking green eyes and a coat of brown and white fur. The lighting is dim, creating a moody atmosphere. The cat is lying on a dark surface, possibly a couch or chair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.884, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 6.992}, "timestamp": "2026-01-19T13:24:59.781480"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1545.802, "latencies_ms": [1545.802], "images_per_second": 0.647, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A bustling city bus station is filled with various colored buses and people waiting for their ride.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.89, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.711}, "timestamp": "2026-01-19T13:25:03.357527"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2593.097, "latencies_ms": [2593.097], "images_per_second": 0.386, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "bus: 5\nbuses: 5\ntraffic light: 1\nbuildings: 8\ntrees: 2\nroad: 4\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.174, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 6.902}, "timestamp": "2026-01-19T13:25:07.977936"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2983.087, "latencies_ms": [2983.087], "images_per_second": 0.335, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects in the image are positioned in a spatial arrangement that suggests a perspective from above. The foreground features the buses and roadway, while the background showcases a cityscape with buildings of varying heights and structures. The buses are situated near the foreground, moving towards the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.685, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 6.983}, "timestamp": "2026-01-19T13:25:12.993301"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2226.333, "latencies_ms": [2226.333], "images_per_second": 0.449, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The scene depicts a busy city bus station with multiple buses parked and moving around. The setting includes tall buildings, power lines, and a clear blue sky, indicating a bustling urban environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.458, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.973}, "timestamp": "2026-01-19T13:25:17.239252"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2733.246, "latencies_ms": [2733.246], "images_per_second": 0.366, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The sky is partly cloudy with blue and white clouds. The lighting appears to be natural daylight, creating a bright and airy atmosphere. The buildings in the background are primarily white and gray, contributing to the urban setting. The overall scene suggests a bustling city environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.389, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.065}, "timestamp": "2026-01-19T13:25:22.006736"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1877.491, "latencies_ms": [1877.491], "images_per_second": 0.533, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A shirtless man in cowboy attire skillfully maneuvers a skateboard on a ramp in a desert-like environment.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.756, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.74}, "timestamp": "2026-01-19T13:25:25.930103"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3085.417, "latencies_ms": [3085.417], "images_per_second": 0.324, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Skateboard: 1\nHat: 1\nShorts: 1\nSkateboard: 1\nRamp: 1\nGround: 1\nBalloons: 2\nTable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12501.6, "ram_available_mb": 50339.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.908, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.072}, "timestamp": "2026-01-19T13:25:31.034965"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2642.46, "latencies_ms": [2642.46], "images_per_second": 0.378, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick on a ramp. The background features tents, suggesting an outdoor or temporary setting. The skateboarder is relatively close to the foreground, while the tents are further in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12501.6, "ram_available_mb": 50339.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.384, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.969}, "timestamp": "2026-01-19T13:25:35.722708"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2338.168, "latencies_ms": [2338.168], "images_per_second": 0.428, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The scene depicts a skateboarder performing a trick on a ramp in a desert-like environment. The backdrop features large tents, suggesting an outdoor recreational area or possibly a temporary camp.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.8, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T13:25:40.100238"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2734.21, "latencies_ms": [2734.21], "images_per_second": 0.366, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The skateboarder is wearing light-colored shorts and a straw hat. The scene appears to be outdoors in bright sunlight. The skateboard is red and white. The background includes large green fabric structures, suggesting an outdoor event or festival.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.366, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.028}, "timestamp": "2026-01-19T13:25:44.875490"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1506.614, "latencies_ms": [1506.614], "images_per_second": 0.664, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man is windsurfing in the ocean, surrounded by several colorful kites flying in the sky.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.813, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.115}, "timestamp": "2026-01-19T13:25:48.436319"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2997.937, "latencies_ms": [2997.937], "images_per_second": 0.334, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "kite: 5\nwindsurfboard: 1\nkite: 2\nkite: 1\nkite: 1\nkite: 1\nkite: 1\nkite: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.765, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T13:25:53.461742"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1815.564, "latencies_ms": [1815.564], "images_per_second": 0.551, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The windsurfer is positioned in the foreground, close to the water's edge. The kites are located in the background, further out from the shore.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.157, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.278}, "timestamp": "2026-01-19T13:25:57.312184"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2082.525, "latencies_ms": [2082.525], "images_per_second": 0.48, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts a windsurfer preparing to enter the ocean, alongside several other kite surfers. The setting is a sunny beach with waves crashing against the shore.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.364, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.482}, "timestamp": "2026-01-19T13:26:01.410644"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2623.111, "latencies_ms": [2623.111], "images_per_second": 0.381, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The windsurfing equipment is primarily white and blue. The sky is bright blue with a few scattered clouds. The ocean appears dark blue with whitecaps. The scene suggests a sunny day with suitable wind conditions for windsurfing.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12501.5, "ram_available_mb": 50339.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12501.9, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.863, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 6.797}, "timestamp": "2026-01-19T13:26:06.061884"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1614.514, "latencies_ms": [1614.514], "images_per_second": 0.619, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "An old, rusted fire hydrant stands in a lush green lawn, contrasting with the vibrant surroundings.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12501.9, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12501.9, "ram_available_mb": 50339.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.326, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.661}, "timestamp": "2026-01-19T13:26:09.715424"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2286.301, "latencies_ms": [2286.301], "images_per_second": 0.437, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "fire hydrant: 1\nhouse: 1\ntrees: 1\nflowers: 2\ngrass: 4\ndandelions: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.9, "ram_available_mb": 50339.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12502.2, "ram_available_mb": 50338.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.138, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 7.039}, "timestamp": "2026-01-19T13:26:14.039881"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1938.784, "latencies_ms": [1938.784], "images_per_second": 0.516, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The fire hydrant is positioned in the foreground, slightly to the right of the viewer. The house and trees are in the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.2, "ram_available_mb": 50338.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12502.7, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.386, "power_cpu_cv_mean_watts": 1.149, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T13:26:17.992809"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2189.923, "latencies_ms": [2189.923], "images_per_second": 0.457, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene is set in a residential area with a vibrant red fire hydrant in the foreground, situated on a grassy lawn. In the background, a white house with purple flowers is partially visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.7, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12502.7, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.09, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.865}, "timestamp": "2026-01-19T13:26:22.203161"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1897.244, "latencies_ms": [1897.244], "images_per_second": 0.527, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The fire hydrant is predominantly red with black accents. The lighting suggests a sunny day, and the materials appear to be metal and painted paint.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.7, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.838, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.894}, "timestamp": "2026-01-19T13:26:26.121910"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1982.761, "latencies_ms": [1982.761], "images_per_second": 0.504, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A small bird with black and brown feathers is captured in mid-flight, approaching a wooden structure where several other birds are perched.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.473, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.791}, "timestamp": "2026-01-19T13:26:30.133992"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2533.879, "latencies_ms": [2533.879], "images_per_second": 0.395, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "bird: 3\nroof: 2\nwood: 2\nblue: 2\nroof: 2\ntwigs: 1\nleaves: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.42, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 6.887}, "timestamp": "2026-01-19T13:26:34.730574"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2324.852, "latencies_ms": [2324.852], "images_per_second": 0.43, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main object, a bird, is positioned in the foreground, close to the viewer. The background features the blue wooden surface, which extends into the distance. The bird is relatively close to the viewer, suggesting it is close to the viewer as well.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.932, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T13:26:39.070401"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2686.781, "latencies_ms": [2686.781], "images_per_second": 0.372, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "A bird is captured in mid-flight, seemingly preparing to land on a weathered wooden surface. Several other birds are perched nearby, possibly observing the incoming creature. The scene is set outdoors, with a blue wooden wall or roof providing the backdrop.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.314, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.996}, "timestamp": "2026-01-19T13:26:43.782168"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2048.153, "latencies_ms": [2048.153], "images_per_second": 0.488, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The building's exterior is painted in a faded teal color. The lighting suggests an overcast day, giving the image a soft, diffused quality.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.401, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T13:26:47.853413"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1770.331, "latencies_ms": [1770.331], "images_per_second": 0.565, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A woman in blue jeans is leading a brown horse with a saddle in a rustic barn, guiding it with its front legs extended.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.454, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.825}, "timestamp": "2026-01-19T13:26:51.668962"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2781.537, "latencies_ms": [2781.537], "images_per_second": 0.36, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "door: 1\nladder: 1\nhorse: 1\nwoman: 1\ntable: 1\nbucket: 1\nchair: 1\nwheelbarrow: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.125, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T13:26:56.487148"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1855.246, "latencies_ms": [1855.246], "images_per_second": 0.539, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The horse is positioned in the foreground, moving towards the left side of the image. The woman is standing near the horse, seemingly observing or guiding it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12504.4, "ram_available_mb": 50336.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.784, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T13:27:00.370714"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2462.404, "latencies_ms": [2462.404], "images_per_second": 0.406, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A woman is leading a brown horse in a rustic barn. The horse is wearing a saddle and appears to be in motion, moving towards the woman. The barn has a wooden interior, with various items and equipment scattered around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.4, "ram_available_mb": 50336.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.542, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.935}, "timestamp": "2026-01-19T13:27:04.853669"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2282.284, "latencies_ms": [2282.284], "images_per_second": 0.438, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The horse is brown and white. The lighting is bright, likely from natural light coming in through the open door. The barn's interior is constructed of wood, giving it a rustic appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.867, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.938}, "timestamp": "2026-01-19T13:27:09.195591"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1732.382, "latencies_ms": [1732.382], "images_per_second": 0.577, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A group of zebras and rhinoceroses are grazing peacefully in a lush, green field enclosed by a wooden fence.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.765, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.674}, "timestamp": "2026-01-19T13:27:12.998109"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2677.917, "latencies_ms": [2677.917], "images_per_second": 0.373, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "rhino: 2\nzebra: 2\nhorse: 1\nwildebeest: 2\ntree: 1\nrocks: 2\nwater: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.202, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T13:27:17.728594"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2084.097, "latencies_ms": [2084.097], "images_per_second": 0.48, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The animals are positioned in a grassy field with a backdrop of trees. The foreground is dominated by the tree branches, while the background features more trees and a glimpse of a body of water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.34, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.842}, "timestamp": "2026-01-19T13:27:21.869995"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2926.392, "latencies_ms": [2926.392], "images_per_second": 0.342, "prompt_tokens": 19, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The scene depicts a grassy field with various animals, including zebras, grazing and roaming. A tall, bare tree stands in the foreground, and a small body of water is visible in the background. The setting appears to be a zoo or wildlife park, given the presence of animals and the natural landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.887, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.035}, "timestamp": "2026-01-19T13:27:26.821932"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2836.861, "latencies_ms": [2836.861], "images_per_second": 0.353, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The grass is a vibrant green, illuminated by sunlight, creating a bright and lively atmosphere. The sky is partly cloudy, casting a soft, diffused light over the scene. The overall setting suggests a naturalistic enclosure, possibly within a zoo or wildlife park.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.247, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 7.021}, "timestamp": "2026-01-19T13:27:31.677042"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2200.637, "latencies_ms": [2200.637], "images_per_second": 0.454, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A horse-drawn trolley car, labeled \"Disneyland,\" travels down a street lined with trees and people, while a white horse pulls the carriage.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.316, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.931}, "timestamp": "2026-01-19T13:27:35.910498"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2849.172, "latencies_ms": [2849.172], "images_per_second": 0.351, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "horse: 1\ncarriage: 1\nperson: 2\nbench: 1\ntree: 1\nstreet: 1\numbrella: 1\npeople: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.092, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.034}, "timestamp": "2026-01-19T13:27:40.799931"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3321.265, "latencies_ms": [3321.265], "images_per_second": 0.301, "prompt_tokens": 25, "response_tokens_est": 73, "n_tiles": 1, "output_text": "The main object is a trolley car moving down the street, positioned in the foreground and slightly to the left of the horse and carriage. The trolley car is closer to the viewer, while the horse and carriage are further away in the background. The trolley car appears to be traveling on a paved road, while the horse and carriage are on a sidewalk.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.723, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 7.123}, "timestamp": "2026-01-19T13:27:46.145911"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2262.22, "latencies_ms": [2262.22], "images_per_second": 0.442, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The scene depicts a horse-drawn carriage traveling down a street, possibly at a theme park or fair. The carriage is decorated and carries passengers, blending traditional transportation with modern attractions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12502.4, "ram_available_mb": 50338.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.401, "power_cpu_cv_mean_watts": 1.446, "power_sys_5v0_mean_watts": 7.0}, "timestamp": "2026-01-19T13:27:50.446405"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2940.546, "latencies_ms": [2940.546], "images_per_second": 0.34, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The trolley is painted in vibrant colors, including red, green, and gold. The lighting is bright, likely from sunlight, creating a pleasant atmosphere. The trolley appears to be made of sturdy wood and metal, suitable for outdoor use. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.4, "ram_available_mb": 50338.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12502.3, "ram_available_mb": 50338.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.838, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.009}, "timestamp": "2026-01-19T13:27:55.408186"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1730.175, "latencies_ms": [1730.175], "images_per_second": 0.578, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A man wearing glasses is sitting on a green bench reading a newspaper, while other individuals are seated on similar benches nearby.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12502.0, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12502.0, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.213, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.278}, "timestamp": "2026-01-19T13:27:59.171226"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3452.679, "latencies_ms": [3452.679], "images_per_second": 0.29, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "Bench: 4\nTrash can: 3\nNewspaper: 1\nMan: 2\nMan in red shirt: 1\nMan in blue shirt: 1\nMan in brown shirt: 1\nBuilding: 1\nStairs: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12502.0, "ram_available_mb": 50338.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12502.3, "ram_available_mb": 50338.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.9, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T13:28:04.637235"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2618.66, "latencies_ms": [2618.66], "images_per_second": 0.382, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The main objects are positioned in a line or row, creating a sense of proximity and order. The foreground features the man reading, while other individuals are situated further back on the sidewalk. The background includes a building and a sign, further emphasizing the urban setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12500.7, "ram_available_mb": 50340.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.557, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 6.672}, "timestamp": "2026-01-19T13:28:09.299242"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2156.085, "latencies_ms": [2156.085], "images_per_second": 0.464, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene takes place on a sidewalk in front of a building with several people sitting on benches and trash cans. Some individuals are reading newspapers, while others appear to be engaged in conversation or observing their surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12500.7, "ram_available_mb": 50340.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12501.9, "ram_available_mb": 50339.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.404, "power_cpu_cv_mean_watts": 1.579, "power_sys_5v0_mean_watts": 6.581}, "timestamp": "2026-01-19T13:28:13.504561"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2007.121, "latencies_ms": [2007.121], "images_per_second": 0.498, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The chairs are dark green, and the man reading is wearing glasses. The lighting is bright, suggesting it's daytime. The chairs appear to be made of metal and have a decorative design.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12501.9, "ram_available_mb": 50339.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.189, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 6.464}, "timestamp": "2026-01-19T13:28:17.554836"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1811.553, "latencies_ms": [1811.553], "images_per_second": 0.552, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A wooden desk with a laptop, phone, lamp, and glass of orange juice is situated against a white wall, accompanied by a painting.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.166, "power_cpu_cv_mean_watts": 1.631, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T13:28:21.411844"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3193.518, "latencies_ms": [3193.518], "images_per_second": 0.313, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "laptop: 1\ntelephone: 1\ndesk: 1\nlamp: 1\nglass: 1\npicture frame: 1\npapers: 1\ncup: 1\nchair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.5, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.882, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 7.11}, "timestamp": "2026-01-19T13:28:26.641628"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2210.807, "latencies_ms": [2210.807], "images_per_second": 0.452, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The laptop is positioned in the foreground, slightly to the left of the image. The desk is situated in the background, extending from the left edge to the right edge of the image. The picture hangs on the wall behind the desk.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.888, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T13:28:30.893529"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2633.124, "latencies_ms": [2633.124], "images_per_second": 0.38, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a home office setup with a wooden desk, a laptop, a telephone, a lamp, a glass of orange juice, and a picture on the wall. The desk is illuminated by the lamp, casting a warm glow on the surrounding area.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12507.9, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.631, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 7.065}, "timestamp": "2026-01-19T13:28:35.550179"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2698.205, "latencies_ms": [2698.205], "images_per_second": 0.371, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The room is lit by warm yellow light from a lamp with a black shade. The desk is made of dark wood and has a laptop, glass, and papers on it. The walls are painted a light color, and the overall atmosphere is cozy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.9, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.13, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 6.936}, "timestamp": "2026-01-19T13:28:40.267727"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1565.884, "latencies_ms": [1565.884], "images_per_second": 0.639, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Two surfboards and a beach towel are laid out on the sandy beach, ready for use.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.223, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.77}, "timestamp": "2026-01-19T13:28:43.864773"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3125.809, "latencies_ms": [3125.809], "images_per_second": 0.32, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "beach towel: 2\nsurfboard: 2\numbrella: 1\nchair: 2\ncooler: 1\nbags: 2\nsandals: 1\nfrisbee: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.151, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.1}, "timestamp": "2026-01-19T13:28:49.017884"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2437.561, "latencies_ms": [2437.561], "images_per_second": 0.41, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The foreground features the beach setup with towels, surfboards, and a cooler, positioned near the water's edge. The background showcases the ocean with waves and a clear sky, extending to the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.117, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 7.05}, "timestamp": "2026-01-19T13:28:53.488862"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2512.163, "latencies_ms": [2512.163], "images_per_second": 0.398, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene is set on a sandy beach under a clear blue sky, with surfboards, towels, and a beach umbrella set up for relaxation and sunbathing. A person is visible in the distance, enjoying the ocean waves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.821, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T13:28:58.014253"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2738.045, "latencies_ms": [2738.045], "images_per_second": 0.365, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The beach scene features a bright blue sky and light blue ocean waves, creating a serene atmosphere. The sand is light-colored and appears smooth. Various beach items are scattered on the sand, including two surfboards, a beach towel, and beach chairs.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.948, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.12}, "timestamp": "2026-01-19T13:29:02.780082"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1702.532, "latencies_ms": [1702.532], "images_per_second": 0.587, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A white sheep with black markings on its face and legs stands confidently atop a large, rugged rock formation, gazing towards the horizon.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.128, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.328}, "timestamp": "2026-01-19T13:29:06.530293"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2480.523, "latencies_ms": [2480.523], "images_per_second": 0.403, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "rock: 10\nsheep: 1\nsky: 10\nclouds: 10\ngrass: 10\nhills: 1\nrocks: 10", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.475, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.658}, "timestamp": "2026-01-19T13:29:11.034442"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1898.744, "latencies_ms": [1898.744], "images_per_second": 0.527, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The sheep is positioned prominently in the foreground, contrasting with the rocky terrain in the background. The sheep appears to be standing relatively close to the viewer, emphasizing its prominence in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.535, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 6.437}, "timestamp": "2026-01-19T13:29:14.962505"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2018.986, "latencies_ms": [2018.986], "images_per_second": 0.495, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A white sheep stands on a rocky outcrop, gazing towards the horizon under a bright blue sky dotted with fluffy white clouds. The scene suggests a rural or mountainous landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.288, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.457}, "timestamp": "2026-01-19T13:29:19.034044"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1763.899, "latencies_ms": [1763.899], "images_per_second": 0.567, "prompt_tokens": 18, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The sky is a bright blue with scattered white clouds. The rocky terrain is dark gray and appears to be made of large, rugged stones.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.87, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.17}, "timestamp": "2026-01-19T13:29:22.822959"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1789.883, "latencies_ms": [1789.883], "images_per_second": 0.559, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A woman with vibrant blue hair and a blue collared shirt takes a selfie while holding a colorful phone in her right hand.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.909, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.674}, "timestamp": "2026-01-19T13:29:26.649754"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2706.394, "latencies_ms": [2706.394], "images_per_second": 0.369, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "phone: 1\ntie: 1\nshirt: 2\nhair: 1\nring: 1\nmirror: 1\nwall: 1\nhand: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.403, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.033}, "timestamp": "2026-01-19T13:29:31.373058"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2269.777, "latencies_ms": [2269.777], "images_per_second": 0.441, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The woman is taking a selfie with her phone held close to her face, capturing the blue hair and clothing. The phone is positioned in the foreground, while the woman's reflection is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.044, "power_cpu_cv_mean_watts": 1.446, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T13:29:35.673525"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2218.208, "latencies_ms": [2218.208], "images_per_second": 0.451, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A woman with vibrant blue hair is taking a selfie in a bathroom mirror, wearing a blue shirt and tie. The mirror reflects her image, showcasing her colorful hair and outfit.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.2, "power_cpu_cv_mean_watts": 1.291, "power_sys_5v0_mean_watts": 6.876}, "timestamp": "2026-01-19T13:29:39.920989"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3279.857, "latencies_ms": [3279.857], "images_per_second": 0.305, "prompt_tokens": 18, "response_tokens_est": 70, "n_tiles": 1, "output_text": "The woman's hair is a vibrant shade of blue. The lighting appears to be natural, possibly from a window, casting a soft glow on her face and hair. The shirt appears to be made of a durable, textured material, possibly cotton or a blend. The weather seems pleasant, as there is no visible indication of rain or strong sunlight.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.442, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.071}, "timestamp": "2026-01-19T13:29:45.216237"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2146.096, "latencies_ms": [2146.096], "images_per_second": 0.466, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The room features a fireplace with a black mantelpiece, a wooden cabinet with two doors, a wooden table with a book, and two chairs, one of which is a rolling office chair.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.128, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.83}, "timestamp": "2026-01-19T13:29:49.393273"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2968.315, "latencies_ms": [2968.315], "images_per_second": 0.337, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "fireplace: 2\nvases: 2\noil lamp: 1\npicture frame: 1\nwooden cabinet: 1\ndesk: 1\nchair: 2\ntable: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.07, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.018}, "timestamp": "2026-01-19T13:29:54.391677"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2315.31, "latencies_ms": [2315.31], "images_per_second": 0.432, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The fireplace is positioned to the left of the wooden table and chairs, creating a sense of spatial proximity. The table and chairs are situated in the foreground, closer to the viewer, while the fireplace occupies the left side of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.78, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T13:29:58.745905"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2379.988, "latencies_ms": [2379.988], "images_per_second": 0.42, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene depicts a cozy, antique-looking room with a fireplace, wooden furniture, and paintings on the walls. A small table with books is situated in the center of the room, alongside two chairs.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.758, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 6.881}, "timestamp": "2026-01-19T13:30:03.166262"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2578.725, "latencies_ms": [2578.725], "images_per_second": 0.388, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The room features a warm color palette, primarily due to the fireplace and wooden furniture. The lighting is soft and warm, enhancing the cozy atmosphere. The materials include dark wood, metal, and fabric, adding to the antique ambiance.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.554, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T13:30:07.779939"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1842.607, "latencies_ms": [1842.607], "images_per_second": 0.543, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A brown dog jumps to catch a red frisbee in a green yard with a tree, bushes, and a parked car in the background.", "error": null, "sys_before": {"cpu_percent": 8.6, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.156, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 6.793}, "timestamp": "2026-01-19T13:30:11.705137"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2577.382, "latencies_ms": [2577.382], "images_per_second": 0.388, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "tree: 1\nfrisbee: 1\ndog: 1\ngrass: 1\ncar: 1\nshrubs: 2\nmulch: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.862, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T13:30:16.317412"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2051.61, "latencies_ms": [2051.61], "images_per_second": 0.487, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The black car is positioned in the background, slightly further away than the dog. The dog is positioned in the foreground, jumping to catch a red frisbee.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12504.4, "ram_available_mb": 50336.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.507, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.842}, "timestamp": "2026-01-19T13:30:20.394099"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1785.558, "latencies_ms": [1785.558], "images_per_second": 0.56, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A brown dog is jumping to catch a red frisbee in a grassy yard. A black car is parked nearby.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12504.4, "ram_available_mb": 50336.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.684, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.912}, "timestamp": "2026-01-19T13:30:24.236358"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2440.27, "latencies_ms": [2440.27], "images_per_second": 0.41, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The dog is dark brown, appears to be mid-leap, and has a red frisbee in its mouth. The scene is brightly lit, suggesting sunny weather. The grassy area provides a natural setting for the playful interaction.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12504.4, "ram_available_mb": 50336.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.022, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T13:30:28.734418"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1622.589, "latencies_ms": [1622.589], "images_per_second": 0.616, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A giraffe with brown and white spots and large, expressive eyes gazes directly at the camera in a lush, green environment.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12504.4, "ram_available_mb": 50336.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.147, "power_cpu_cv_mean_watts": 1.268, "power_sys_5v0_mean_watts": 6.241}, "timestamp": "2026-01-19T13:30:32.386428"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3165.926, "latencies_ms": [3165.926], "images_per_second": 0.316, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "giraffe: 1\ntree: 1\nleaves: 1\ngiraffe's head: 1\ngiraffe's neck: 1\ngiraffe's ears: 2\ngiraffe's mouth: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.707, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 6.831}, "timestamp": "2026-01-19T13:30:37.592360"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1897.083, "latencies_ms": [1897.083], "images_per_second": 0.527, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The giraffe is positioned in the foreground, with its head and neck dominating the left side of the image. The background consists of blurred green foliage, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.401, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 6.424}, "timestamp": "2026-01-19T13:30:41.523100"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2776.479, "latencies_ms": [2776.479], "images_per_second": 0.36, "prompt_tokens": 19, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The scene is set in a lush, green environment, possibly a zoo or wildlife park. The focus is on a giraffe's head and neck, with its distinctive spotted pattern and large, expressive eyes. The giraffe appears to be looking directly at the camera, creating a sense of connection between the viewer and the subject.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.632, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 6.815}, "timestamp": "2026-01-19T13:30:46.371783"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1947.622, "latencies_ms": [1947.622], "images_per_second": 0.513, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The giraffe's coat is predominantly brown and white, contrasting with the lush green foliage. The lighting suggests a bright, sunny day, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.239, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.457}, "timestamp": "2026-01-19T13:30:50.364789"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1744.276, "latencies_ms": [1744.276], "images_per_second": 0.573, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "Two zebras stand side by side, facing away from the camera, showcasing their distinct black and white striped patterns.", "error": null, "sys_before": {"cpu_percent": 8.8, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.507, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.667}, "timestamp": "2026-01-19T13:30:54.158376"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2301.634, "latencies_ms": [2301.634], "images_per_second": 0.434, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "zebra: 2\nfence: 1\nground: 1\nleaves: 1\nrocks: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.889, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.916}, "timestamp": "2026-01-19T13:30:58.477256"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2281.134, "latencies_ms": [2281.134], "images_per_second": 0.438, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the zebra on the left appearing slightly further away. The background is relatively open and features trees and a fence, suggesting an enclosure or open area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.977, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T13:31:02.797818"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2174.323, "latencies_ms": [2174.323], "images_per_second": 0.46, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Two zebras stand side by side in a fenced enclosure, facing away from the camera. The ground is covered with grass and scattered leaves, indicating a natural habitat.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.977, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 6.798}, "timestamp": "2026-01-19T13:31:06.995816"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2728.721, "latencies_ms": [2728.721], "images_per_second": 0.366, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The zebras have distinct black and white stripes. The lighting in the image appears to be natural, possibly sunlight, giving the scene a warm tone. The zebras are standing on a patch of grass, which suggests a relatively dry and warm environment.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.442, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T13:31:11.765785"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2040.914, "latencies_ms": [2040.914], "images_per_second": 0.49, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A silver car is parked on the side of the road, while a group of horses, including brown, black, and white ones, stand nearby, seemingly curious about the vehicle.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12504.3, "ram_available_mb": 50336.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.121, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.741}, "timestamp": "2026-01-19T13:31:15.847177"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2729.26, "latencies_ms": [2729.26], "images_per_second": 0.366, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Horses: 4\nCar: 1\nFence: 1\nTrees: 4\nRoad: 1\nHorses' dung: 1\nGrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.3, "ram_available_mb": 50336.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12504.3, "ram_available_mb": 50336.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.293, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 7.074}, "timestamp": "2026-01-19T13:31:20.635604"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1718.943, "latencies_ms": [1718.943], "images_per_second": 0.582, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The car is positioned in the foreground, slightly to the right of the horses. The horses are situated in the background, closer to the car.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.3, "ram_available_mb": 50336.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.178, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.691}, "timestamp": "2026-01-19T13:31:24.382968"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1723.923, "latencies_ms": [1723.923], "images_per_second": 0.58, "prompt_tokens": 19, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A group of horses is gathered near a road in a rural setting. A car is parked nearby, observing the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.765, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.688}, "timestamp": "2026-01-19T13:31:28.164944"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2671.549, "latencies_ms": [2671.549], "images_per_second": 0.374, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene is bathed in bright sunlight, creating a warm and inviting atmosphere. The road is paved and appears to be well-maintained, suitable for driving. The horses are dark brown or black, contrasting with the lighter colors of the surrounding environment.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.592, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T13:31:32.856052"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1798.18, "latencies_ms": [1798.18], "images_per_second": 0.556, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A wooden desk with a stack of blue books, a red apple, and a bell sits in front of a chalkboard in a classroom setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.051, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T13:31:36.727202"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3005.156, "latencies_ms": [3005.156], "images_per_second": 0.333, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Chalkboard: 10\nBooks: 5\nWooden desk: 2\nWooden chair: 1\nBell: 1\nApple: 1\nWooden floor: 1\nWhite door: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.055, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 7.11}, "timestamp": "2026-01-19T13:31:41.776207"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2731.937, "latencies_ms": [2731.937], "images_per_second": 0.366, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a spatial arrangement that suggests a classroom setting. The books are placed on the desk in the foreground, while the bell and apple are situated near the back of the desk. The chalkboard is positioned in the background, further emphasizing the classroom setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.4, "ram_available_mb": 50337.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.184, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.023}, "timestamp": "2026-01-19T13:31:46.550280"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2545.13, "latencies_ms": [2545.13], "images_per_second": 0.393, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The scene depicts a vintage classroom setting. A wooden desk with a stack of blue books and a red apple sits in front of a chalkboard. A wooden chair is positioned behind the desk, and a bell is placed on the desk's surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.364, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T13:31:51.130774"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2501.337, "latencies_ms": [2501.337], "images_per_second": 0.4, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The room features a dark green chalkboard, illuminated by a soft, natural light source. The wooden desk and chair are crafted from warm-toned wood, complementing the overall ambiance of the classroom.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.401, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:31:55.650488"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1837.136, "latencies_ms": [1837.136], "images_per_second": 0.544, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A yellow bus with the number 475 and text in Hindi is driving down a busy city street, passing a silver SUV.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.943, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.827}, "timestamp": "2026-01-19T13:31:59.559687"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2486.683, "latencies_ms": [2486.683], "images_per_second": 0.402, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bus: 475\nvan: 2\ncar: 1\nmotorcycle: 1\nman: 1\nroad: 2\nbuildings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.861, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.879}, "timestamp": "2026-01-19T13:32:04.065222"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2004.418, "latencies_ms": [2004.418], "images_per_second": 0.499, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main object is a bus moving rightward on the road. The foreground includes other vehicles, such as a car and a motorcycle. The background features buildings and a clear sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.622, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.835}, "timestamp": "2026-01-19T13:32:08.112927"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2863.968, "latencies_ms": [2863.968], "images_per_second": 0.349, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a busy urban street with a yellow bus driving down the road, alongside a white van and a motorcycle. The bus displays the number 475 and text in multiple languages, indicating its origin or destination. The overall setting suggests a bustling city environment.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.142, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.113}, "timestamp": "2026-01-19T13:32:13.006427"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2008.891, "latencies_ms": [2008.891], "images_per_second": 0.498, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The bus is predominantly yellow with white and green accents. The lighting suggests it might be daytime. The bus appears to be made of metal and has a visible rear bumper.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.521, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 6.898}, "timestamp": "2026-01-19T13:32:17.075222"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1599.819, "latencies_ms": [1599.819], "images_per_second": 0.625, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A bathroom features a flat-screen TV mounted on the wall, displaying a sports game between two teams.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.823, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.694}, "timestamp": "2026-01-19T13:32:20.731598"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2831.926, "latencies_ms": [2831.926], "images_per_second": 0.353, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "sink: 2\ntoilet paper dispenser: 1\nhand dryer: 1\nmirror: 1\ntile: 6\ndoor: 1\nwall: 6", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.143, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.003}, "timestamp": "2026-01-19T13:32:25.582600"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1796.617, "latencies_ms": [1796.617], "images_per_second": 0.557, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The sink is located in the foreground, while the mirror reflects the sink and door in the background. The sink is situated closer to the viewer than the mirror.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.793, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T13:32:29.399182"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1964.767, "latencies_ms": [1964.767], "images_per_second": 0.509, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The scene depicts a public restroom with a television mounted on the wall, displaying a sports game. Two sinks are visible, one on each side of the counter.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.729, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T13:32:33.376301"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2608.759, "latencies_ms": [2608.759], "images_per_second": 0.383, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The bathroom features a beige tiled wall with a mosaic tile border. The lighting is bright, likely from overhead fixtures, creating a well-lit environment. The sink and countertop appear to be made of granite or a similar material, adding a luxurious touch to the space.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.573, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 7.084}, "timestamp": "2026-01-19T13:32:38.006346"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1781.454, "latencies_ms": [1781.454], "images_per_second": 0.561, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man sits on a park bench, gazing thoughtfully at the surrounding trees and buildings, including a tall church with a pointed steeple.", "error": null, "sys_before": {"cpu_percent": 17.9, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.08, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T13:32:41.856930"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2757.538, "latencies_ms": [2757.538], "images_per_second": 0.363, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Bench: 1\nPerson: 1\nTrees: 2\nBuildings: 2\nStreetlights: 2\nFlowers: 2\nSky: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.075, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.987}, "timestamp": "2026-01-19T13:32:46.639301"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2141.123, "latencies_ms": [2141.123], "images_per_second": 0.467, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The man is positioned in the foreground, facing the church tower and trees in the background. The church tower is situated near the man, creating a sense of proximity between the man and the church.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.198, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T13:32:50.812319"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2219.291, "latencies_ms": [2219.291], "images_per_second": 0.451, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A man sits on a park bench, appearing contemplative or relaxed. In the background, a church with a tall steeple stands amidst trees and bushes, creating a serene and peaceful atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.999, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:32:55.077638"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2922.919, "latencies_ms": [2922.919], "images_per_second": 0.342, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The photograph is in black and white, showcasing a calm and peaceful atmosphere. The lighting is soft and diffused, creating a serene ambiance. Visually, the image captures the contrast between the dark clothing of the seated man and the lighter tones of the surrounding foliage and the building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.869, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.026}, "timestamp": "2026-01-19T13:33:00.061830"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1750.546, "latencies_ms": [1750.546], "images_per_second": 0.571, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A bustling city street scene features various vehicles, including cars, buses, and vans, navigating through the traffic.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.907, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.775}, "timestamp": "2026-01-19T13:33:03.846401"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2701.974, "latencies_ms": [2701.974], "images_per_second": 0.37, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "bus: 2\ncar: 4\nvan: 2\ncar: 2\nminivan: 2\ncar: 2\nbuilding: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.239, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.019}, "timestamp": "2026-01-19T13:33:08.591365"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2794.41, "latencies_ms": [2794.41], "images_per_second": 0.358, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The foreground features a green bus parked on the left side of the street, partially obscuring the view of the background. The background includes various parked cars and a building, which appears to be situated further back from the bus. The bus is positioned near the center-left of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.898, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T13:33:13.433364"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2794.639, "latencies_ms": [2794.639], "images_per_second": 0.358, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a busy street intersection, likely in Jerusalem, with various vehicles, including cars, vans, and a bus, navigating the road. A person is seen walking on the sidewalk near the bus stop. The buildings in the background suggest a historical or religious context.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.124, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 6.972}, "timestamp": "2026-01-19T13:33:18.261462"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2430.945, "latencies_ms": [2430.945], "images_per_second": 0.411, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is bathed in bright sunlight, creating a vibrant atmosphere. The buildings in the background are constructed from light-colored stone, blending harmoniously with the clear sky. The overall lighting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12504.9, "ram_available_mb": 50336.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.821, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T13:33:22.716180"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2740.604, "latencies_ms": [2740.604], "images_per_second": 0.365, "prompt_tokens": 8, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A wooden table holds a breakfast spread consisting of a golden-brown omelette topped with banana slices, a plate of assorted fruits including watermelon, pineapple, and cantaloupe, and two white cups filled with tea.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12504.9, "ram_available_mb": 50336.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.166, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.991}, "timestamp": "2026-01-19T13:33:27.497738"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3692.134, "latencies_ms": [3692.134], "images_per_second": 0.271, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "Omelet: 1\nBanana slices: 2\nWatermelon: 1\nFruit: 2\nFruit salad: 1\nTea: 1\nSugar: 1\nSpoon: 1\nFork: 1\nTable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.233, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.098}, "timestamp": "2026-01-19T13:33:33.212343"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2170.29, "latencies_ms": [2170.29], "images_per_second": 0.461, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The breakfast is arranged on a table with a wooden surface, positioned near a window that casts shadows. The table occupies the foreground, while the window and table are in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.151, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T13:33:37.400932"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2367.542, "latencies_ms": [2367.542], "images_per_second": 0.422, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a breakfast setting on a tiled floor, featuring a plate with a partially eaten omelet, a fruit platter with bananas, watermelon, and pineapple, and two cups of tea.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12504.9, "ram_available_mb": 50336.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.526, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:33:41.792761"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2323.764, "latencies_ms": [2323.764], "images_per_second": 0.43, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The table is brown wood, contrasting with the white tiles. The food is colorful, featuring yellow bananas, sliced watermelon, and pineapple. The table is well-lit, suggesting sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.9, "ram_available_mb": 50336.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.8, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T13:33:46.152241"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2203.239, "latencies_ms": [2203.239], "images_per_second": 0.454, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "An elderly woman in a green and white striped shirt and pink apron is carefully placing dough into baking pans on a kitchen table, surrounded by various baked goods and kitchenware.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.481, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.913}, "timestamp": "2026-01-19T13:33:50.397878"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3586.987, "latencies_ms": [3586.987], "images_per_second": 0.279, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "bread: 8\ncookies: 8\nbuns: 2\npastry: 2\nglaze: 1\nbaking pan: 1\ntable: 1\nplacemats: 2\nglasses: 2\ntoy: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.565, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 7.118}, "timestamp": "2026-01-19T13:33:56.013923"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2457.315, "latencies_ms": [2457.315], "images_per_second": 0.407, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The woman is positioned on the left side of the image, preparing food on a table. The table occupies the foreground, displaying various baked goods and cooking utensils. The background features a partially visible living room with a couch and a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.042, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.954}, "timestamp": "2026-01-19T13:34:00.493088"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2643.12, "latencies_ms": [2643.12], "images_per_second": 0.378, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "A woman is preparing baked goods at a wooden table in a cozy living room. She is working with various breads and pastries, using a baking pan and tongs. She is surrounded by several cups and decorative items, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.611, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.041}, "timestamp": "2026-01-19T13:34:05.163488"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2548.222, "latencies_ms": [2548.222], "images_per_second": 0.392, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The table is covered with a patterned tablecloth in shades of red, pink, and cream. The woman is wearing glasses and a green and white striped shirt. The table is equipped with several baking trays and ingredients.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12502.3, "ram_available_mb": 50338.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.267, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.993}, "timestamp": "2026-01-19T13:34:09.751257"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1664.539, "latencies_ms": [1664.539], "images_per_second": 0.601, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A man in a white t-shirt and shorts stands next to a traffic light displaying a red light, surrounded by lush greenery and white flowers.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12502.3, "ram_available_mb": 50338.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12502.2, "ram_available_mb": 50338.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.302, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.675}, "timestamp": "2026-01-19T13:34:13.473239"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2844.015, "latencies_ms": [2844.015], "images_per_second": 0.352, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "traffic light: 3\nsign: 1\nman: 1\ntrees: 2\nflowers: 2\nground: 2\nrocks: 2\nred object: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12502.2, "ram_available_mb": 50338.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12502.5, "ram_available_mb": 50338.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.076, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.038}, "timestamp": "2026-01-19T13:34:18.367061"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2797.156, "latencies_ms": [2797.156], "images_per_second": 0.358, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The man is standing in the foreground of the image, positioned next to the traffic light. The traffic light is situated in the background, slightly further away than the man. The setting appears to be outdoors, with vegetation and a gravel or dirt area around the man and the traffic light.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12502.5, "ram_available_mb": 50338.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12502.6, "ram_available_mb": 50338.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.077, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T13:34:23.205111"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2702.704, "latencies_ms": [2702.704], "images_per_second": 0.37, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A young man stands next to a traffic light pole in a garden-like setting with lush foliage and flowering plants. A sign nearby reads \"AUSTRALIA\" and \"TRAFFIC LIGHT,\" indicating the location is in Australia.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.6, "ram_available_mb": 50338.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12501.6, "ram_available_mb": 50339.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.406, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.977}, "timestamp": "2026-01-19T13:34:27.944137"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2326.12, "latencies_ms": [2326.12], "images_per_second": 0.43, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The traffic light is red, indicating a stop. The man is wearing sandals. The setting appears to be outdoors, possibly in Australia, given the presence of the Australian sign. The lighting suggests it's daytime.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12501.6, "ram_available_mb": 50339.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.552, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.875}, "timestamp": "2026-01-19T13:34:32.309122"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2027.768, "latencies_ms": [2027.768], "images_per_second": 0.493, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A lively kite festival is taking place in a park, with numerous colorful kites soaring in the sky, including three clownfish-shaped kites.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12501.7, "ram_available_mb": 50339.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.3, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:34:36.411218"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2956.21, "latencies_ms": [2956.21], "images_per_second": 0.338, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "kite: 4\nflag: 4\nkite: 4\nkite: 4\nkite: 4\nkite: 4\nkite: 4\nkite: 4", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 12501.1, "ram_available_mb": 50339.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12501.0, "ram_available_mb": 50339.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.991, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.093}, "timestamp": "2026-01-19T13:34:41.413498"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1917.236, "latencies_ms": [1917.236], "images_per_second": 0.522, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the background extending towards the right. The foreground area appears to be a grassy field, while the background features trees and a building in the distance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12501.0, "ram_available_mb": 50339.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12501.4, "ram_available_mb": 50339.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.678, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T13:34:45.368479"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2801.875, "latencies_ms": [2801.875], "images_per_second": 0.357, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a lively kite festival in a park with several large, colorful fish-shaped kites soaring in the sky. The park is filled with people enjoying the event, with some standing near the kite strings and others scattered across the grassy field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.4, "ram_available_mb": 50339.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12501.0, "ram_available_mb": 50339.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.02, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T13:34:50.217030"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2092.869, "latencies_ms": [2092.869], "images_per_second": 0.478, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The kites are predominantly red, orange, and purple. The lighting suggests an overcast day. The kites appear to be made of a lightweight, flexible material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.0, "ram_available_mb": 50339.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12500.1, "ram_available_mb": 50340.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.547, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 6.967}, "timestamp": "2026-01-19T13:34:54.350153"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1587.465, "latencies_ms": [1587.465], "images_per_second": 0.63, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man is sharing a slice of pizza with a young boy, who appears excited and eager to eat.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12500.1, "ram_available_mb": 50340.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12500.5, "ram_available_mb": 50340.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.46, "power_cpu_cv_mean_watts": 1.102, "power_sys_5v0_mean_watts": 6.77}, "timestamp": "2026-01-19T13:34:57.999653"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3367.396, "latencies_ms": [3367.396], "images_per_second": 0.297, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "Pizza: 2\nPizza box: 1\nPizza slice: 1\nMan: 1\nChild: 1\nChild's shoes: 1\nWater bottle: 1\nCurtains: 1\nFloor: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12500.5, "ram_available_mb": 50340.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12499.8, "ram_available_mb": 50341.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.592, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.135}, "timestamp": "2026-01-19T13:35:03.414688"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2375.82, "latencies_ms": [2375.82], "images_per_second": 0.421, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The man is on the left side of the image, holding the pizza slice. The child is on the right side of the image, looking at the pizza slice. The pizza is positioned between the man and the child, suggesting a casual interaction.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12499.8, "ram_available_mb": 50341.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12499.1, "ram_available_mb": 50341.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.739, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T13:35:07.819906"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1981.708, "latencies_ms": [1981.708], "images_per_second": 0.505, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A man is sharing a slice of pizza with a young child in a cozy living room. The child is seated on the floor, watching the pizza with interest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12499.1, "ram_available_mb": 50341.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12499.7, "ram_available_mb": 50341.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.542, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T13:35:11.838220"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2646.875, "latencies_ms": [2646.875], "images_per_second": 0.378, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The room is lit by natural light coming in through a window. The walls are painted a warm orange color. The man is wearing a blue hoodie with a pattern. The child is wearing a blue shirt and brown pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12499.7, "ram_available_mb": 50341.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12499.7, "ram_available_mb": 50341.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.192, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T13:35:16.539457"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1704.156, "latencies_ms": [1704.156], "images_per_second": 0.587, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A woman is sitting in a camping chair outdoors, eating a sandwich and enjoying a plate of fried food.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12499.7, "ram_available_mb": 50341.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12499.3, "ram_available_mb": 50341.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.115, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T13:35:20.307476"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2788.684, "latencies_ms": [2788.684], "images_per_second": 0.359, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "woman: 2\nchair: 1\nplate: 1\nfood: 1\nsauce: 1\nbread: 1\nground: 1\nrocks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12499.3, "ram_available_mb": 50341.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12499.2, "ram_available_mb": 50341.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.04, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 6.941}, "timestamp": "2026-01-19T13:35:25.138774"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2424.434, "latencies_ms": [2424.434], "images_per_second": 0.412, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The woman is seated in a chair, eating a sandwich. The sandwich is positioned in the foreground, close to the woman. The chair is situated in the background, slightly out of focus. The scene appears to be outdoors, near a fire pit.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12499.2, "ram_available_mb": 50341.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12498.6, "ram_available_mb": 50342.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.784, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 7.036}, "timestamp": "2026-01-19T13:35:29.614302"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2021.734, "latencies_ms": [2021.734], "images_per_second": 0.495, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A woman is sitting outdoors, eating a sandwich and chips. She is surrounded by rocks and a dark area, suggesting an outdoor camping or picnic setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12498.6, "ram_available_mb": 50342.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12498.5, "ram_available_mb": 50342.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.248, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.835}, "timestamp": "2026-01-19T13:35:33.694922"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2461.533, "latencies_ms": [2461.533], "images_per_second": 0.406, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The woman is wearing a green and white striped shirt. The scene is dimly lit, suggesting nighttime. The food appears to be fried and possibly served on a paper plate. The ground is dark and appears to be dirt or soil.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12498.5, "ram_available_mb": 50342.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12498.4, "ram_available_mb": 50342.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.545, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.97}, "timestamp": "2026-01-19T13:35:38.219217"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1790.621, "latencies_ms": [1790.621], "images_per_second": 0.558, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A large family is gathered around a dining table, sharing a meal of diverse dishes and drinks in a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12498.4, "ram_available_mb": 50342.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12497.8, "ram_available_mb": 50343.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.911, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.775}, "timestamp": "2026-01-19T13:35:42.062822"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3203.314, "latencies_ms": [3203.314], "images_per_second": 0.312, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "table: 8\nplates: 8\nserving dishes: 8\nglasses: 4\nwine glasses: 2\ncutlery: 2\nchairs: 2\npeople: 10\nfamily: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12497.8, "ram_available_mb": 50343.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12498.2, "ram_available_mb": 50342.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.837, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 7.133}, "timestamp": "2026-01-19T13:35:47.303190"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2933.878, "latencies_ms": [2933.878], "images_per_second": 0.341, "prompt_tokens": 25, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The main objects are positioned in a diagonal line across the image, creating a sense of depth and perspective. The foreground is dominated by the table and plates, while the background features the living room and additional people. The table occupies the central portion of the image, drawing the viewer's eye towards the gathering.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12498.2, "ram_available_mb": 50342.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.037, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.03}, "timestamp": "2026-01-19T13:35:52.264883"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2553.083, "latencies_ms": [2553.083], "images_per_second": 0.392, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A large family is gathered around a dining table, enjoying a meal together. The setting appears to be a home, with various dishes, glasses, and utensils spread across the table. The atmosphere is warm and inviting, typical of a family gathering.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.535, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T13:35:56.836274"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3286.457, "latencies_ms": [3286.457], "images_per_second": 0.304, "prompt_tokens": 18, "response_tokens_est": 70, "n_tiles": 1, "output_text": "The table is covered with a purple tablecloth. The lighting is warm and inviting, creating a cozy atmosphere. The table is adorned with plates, bowls, cups, wine glasses, and utensils, showcasing a variety of colors and materials. The scene appears to be set during a festive gathering, with people seated around the table enjoying a meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.114, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.153}, "timestamp": "2026-01-19T13:36:02.142984"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1721.574, "latencies_ms": [1721.574], "images_per_second": 0.581, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A baseball player slides into home plate, attempting to reach a base while another player attempts to tag him out.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12498.3, "ram_available_mb": 50342.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12498.2, "ram_available_mb": 50342.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.732, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.869}, "timestamp": "2026-01-19T13:36:05.902002"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4391.971, "latencies_ms": [4391.971], "images_per_second": 0.228, "prompt_tokens": 21, "response_tokens_est": 62, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball glove: 1\nbaseball: 1\nbaseball diamond: 4\nbaseball field: 4\nbaseball player: 2\nbaseball umpire: 1\nbaseball umpire: 1\nbaseball umpire: 1\nbaseball umpire: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.2, "ram_available_mb": 50342.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.047, "power_cpu_cv_mean_watts": 1.938, "power_sys_5v0_mean_watts": 7.222}, "timestamp": "2026-01-19T13:36:12.345101"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2245.153, "latencies_ms": [2245.153], "images_per_second": 0.445, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, sliding into the base. The catcher is standing in the background, watching the play. The field extends beyond the immediate action, appearing distant and open.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.4, "ram_available_mb": 50342.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.068, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:36:16.624172"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2501.652, "latencies_ms": [2501.652], "images_per_second": 0.4, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A baseball game is in progress on a sunny day. A batter is sliding into a base, while a catcher and an umpire are closely observing the play. Spectators are seated in bleachers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.575, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T13:36:21.175720"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1695.258, "latencies_ms": [1695.258], "images_per_second": 0.59, "prompt_tokens": 18, "response_tokens_est": 21, "n_tiles": 1, "output_text": "The field is predominantly green with brown dirt. The lighting suggests it might be late afternoon or early evening.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.9, "ram_available_mb": 50342.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12498.7, "ram_available_mb": 50342.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.115, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.761}, "timestamp": "2026-01-19T13:36:24.909167"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2186.96, "latencies_ms": [2186.96], "images_per_second": 0.457, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A skateboarder in black attire and helmet is performing a trick on a concrete ramp, skillfully balancing on one foot while extending the other arm for balance.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12498.7, "ram_available_mb": 50342.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12498.7, "ram_available_mb": 50342.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.27, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T13:36:29.170186"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3099.87, "latencies_ms": [3099.87], "images_per_second": 0.323, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "helmet: 1\nknee pads: 2\nelbow pads: 1\nshin guards: 1\nskateboard: 1\nfence: 1\nground: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12498.7, "ram_available_mb": 50342.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12499.6, "ram_available_mb": 50341.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.102, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.14}, "timestamp": "2026-01-19T13:36:34.284463"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2748.74, "latencies_ms": [2748.74], "images_per_second": 0.364, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick on a concrete ramp. The skateboarder's shadow is cast onto the ramp's surface. The background features a grassy area and a fence, suggesting an outdoor skatepark setting.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12499.6, "ram_available_mb": 50341.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.56, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 7.073}, "timestamp": "2026-01-19T13:36:39.065605"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2174.25, "latencies_ms": [2174.25], "images_per_second": 0.46, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A skateboarder is performing a trick on a concrete ramp in a skate park. The skate park is surrounded by trees and grass, creating a natural and urban setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12500.9, "ram_available_mb": 50340.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 12501.9, "ram_available_mb": 50339.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.849, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.989}, "timestamp": "2026-01-19T13:36:43.299566"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2449.689, "latencies_ms": [2449.689], "images_per_second": 0.408, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The skateboarder is wearing a black helmet, black shirt, and black knee pads. The scene appears to be outdoors on a sunny day, with natural lighting illuminating the skateboarder's shadow on the concrete ramp.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12501.9, "ram_available_mb": 50339.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.016, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 7.066}, "timestamp": "2026-01-19T13:36:47.763631"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2233.012, "latencies_ms": [2233.012], "images_per_second": 0.448, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A neatly arranged meal on a white tablecloth includes a burger with fries, a salad with tomatoes, lettuce, pickle, and coleslaw, and condiments in bowls.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.092, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.898}, "timestamp": "2026-01-19T13:36:52.024424"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3511.422, "latencies_ms": [3511.422], "images_per_second": 0.285, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "fries: 10\nbun: 2\nham patty: 1\ntomato: 2\npickle: 1\ncoleslaw: 1\nmayo: 1\nlemon: 1\nsalt and pepper shakers: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.552, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 7.115}, "timestamp": "2026-01-19T13:36:57.564238"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2814.69, "latencies_ms": [2814.69], "images_per_second": 0.355, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of balance and visual flow. The foreground features the burger, fries, and pickle, while the background includes additional plates, condiments, and a drink. The arrangement suggests a well-planned and organized meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.024, "power_cpu_cv_mean_watts": 1.568, "power_sys_5v0_mean_watts": 7.016}, "timestamp": "2026-01-19T13:37:02.421727"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2466.673, "latencies_ms": [2466.673], "images_per_second": 0.405, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a hotel room meal featuring a burger, fries, tomato salad, pickle, coleslaw, lemon wedges, and condiments on a tray. A glass of beer is also present.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.684, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 7.015}, "timestamp": "2026-01-19T13:37:06.939594"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2772.483, "latencies_ms": [2772.483], "images_per_second": 0.361, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The food items display vibrant colors, including golden french fries, fresh tomatoes, and creamy coleslaw. The lighting is soft and warm, creating a pleasant ambiance. The food appears to be served on white plates, enhancing the overall presentation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.143, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.1}, "timestamp": "2026-01-19T13:37:11.744774"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1524.269, "latencies_ms": [1524.269], "images_per_second": 0.656, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A red motorcycle is parked on the side of a road near a sandy beach with palm trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12503.6, "ram_available_mb": 50337.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.06, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.787}, "timestamp": "2026-01-19T13:37:15.309195"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2621.742, "latencies_ms": [2621.742], "images_per_second": 0.381, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "motorcycle: 1\npalm trees: 3\nbeach: 2\nsand: 2\nfence: 1\nsky: 1\nroad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.5, "ram_available_mb": 50337.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.616, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T13:37:19.970748"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2685.773, "latencies_ms": [2685.773], "images_per_second": 0.372, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The motorcycle is positioned in the foreground, facing the left side of the image. The beach and palm trees are in the background, extending from the left to the right of the motorcycle. The motorcycle is relatively close to the viewer, implying a close proximity to the beach and palm trees.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12504.5, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12504.4, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.262, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 7.033}, "timestamp": "2026-01-19T13:37:24.704221"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2091.061, "latencies_ms": [2091.061], "images_per_second": 0.478, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A red Harley Davidson motorcycle is parked on a paved area near a beach with palm trees and a wooden fence in the background. The scene suggests a sunny, tropical beach setting.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12504.4, "ram_available_mb": 50336.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.648, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.972}, "timestamp": "2026-01-19T13:37:28.824783"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1946.08, "latencies_ms": [1946.08], "images_per_second": 0.514, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The motorcycle is red and appears to be made of chrome or stainless steel. The lighting suggests a sunny day, and the materials suggest a beach setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.723, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T13:37:32.809810"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1568.245, "latencies_ms": [1568.245], "images_per_second": 0.638, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man is elegantly dressed in a black suit with a white shirt and a patterned black tie.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.427, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.669}, "timestamp": "2026-01-19T13:37:36.435499"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2600.239, "latencies_ms": [2600.239], "images_per_second": 0.385, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "suit: 2\ntie: 1\nshirt: 1\njacket: 1\nvest: 1\npocket: 1\nlight switch: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.25, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.916}, "timestamp": "2026-01-19T13:37:41.053817"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1990.242, "latencies_ms": [1990.242], "images_per_second": 0.502, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The man is positioned in the foreground, with the suit and tie slightly behind him. The background is dark and out of focus, drawing attention to the man's attire.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.222, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.772}, "timestamp": "2026-01-19T13:37:45.096112"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2189.428, "latencies_ms": [2189.428], "images_per_second": 0.457, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A man is dressed in a formal black suit and tie, standing in a dimly lit room, possibly a hotel or event venue. The setting suggests a professional or formal occasion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.058, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T13:37:49.315527"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2609.74, "latencies_ms": [2609.74], "images_per_second": 0.383, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The suit is primarily dark gray or black. The lighting in the image is soft and subdued, creating a contrast with the dark suit. The material appears to be smooth, possibly silk or a similar fabric. The weather is not explicitly visible in the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.363, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T13:37:53.937026"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1671.384, "latencies_ms": [1671.384], "images_per_second": 0.598, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A gray and white cat is peacefully sleeping on a pair of sneakers, curled up with its eyes closed.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.176, "power_cpu_cv_mean_watts": 1.078, "power_sys_5v0_mean_watts": 6.683}, "timestamp": "2026-01-19T13:37:57.630930"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2837.914, "latencies_ms": [2837.914], "images_per_second": 0.352, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "shoe: 2\ncat: 1\nwall: 1\nsneaker: 1\nshoe laces: 1\nshoe sole: 1\nconverse: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.038, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T13:38:02.522592"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1931.112, "latencies_ms": [1931.112], "images_per_second": 0.518, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The cat is positioned close to the foreground shoe, partially covering it. The shoes are placed near the cat, creating a sense of proximity between the cat and the objects.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.624, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.706}, "timestamp": "2026-01-19T13:38:06.473642"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1860.086, "latencies_ms": [1860.086], "images_per_second": 0.538, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A cat is sleeping peacefully on a pair of sneakers placed against a textured wall. The scene takes place indoors, likely on a hardwood floor.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.199, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.811}, "timestamp": "2026-01-19T13:38:10.349476"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2355.86, "latencies_ms": [2355.86], "images_per_second": 0.424, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The cat is sleeping next to a pair of blue and white sneakers. The lighting in the image appears to be soft and diffused, suggesting natural light. The sneakers appear to be made of canvas or a similar material.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.616, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.896}, "timestamp": "2026-01-19T13:38:14.736717"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2003.312, "latencies_ms": [2003.312], "images_per_second": 0.499, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Two workers in green uniforms and safety vests are sitting atop a green Isuzu dump truck parked on the side of a city street.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.677, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T13:38:18.768365"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2904.427, "latencies_ms": [2904.427], "images_per_second": 0.344, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Truck: 2\nMan: 2\nWoman: 1\nHat: 1\nVest: 1\nBus: 1\nBuilding: 1\nTrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.121, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.089}, "timestamp": "2026-01-19T13:38:23.699729"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2396.092, "latencies_ms": [2396.092], "images_per_second": 0.417, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main object is a green Isuzu dump truck parked on the street. The truck is positioned in the foreground, with a person standing near its front. The background features buildings, trees, and a glimpse of a red bus.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.903, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.98}, "timestamp": "2026-01-19T13:38:28.136367"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2883.271, "latencies_ms": [2883.271], "images_per_second": 0.347, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a green Isuzu dump truck driving down a city street. Two workers in green uniforms are visible on the truck, one sitting on the back and the other standing near the front. The truck has various signs and markings, including one in Thai script.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.888, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.026}, "timestamp": "2026-01-19T13:38:33.041476"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2400.154, "latencies_ms": [2400.154], "images_per_second": 0.417, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The truck is predominantly green with red and white stripes on the front. The truck has blue headlights and orange reflective stripes on the sides. The truck is parked on a city street with buildings in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.076, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T13:38:37.463910"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1654.716, "latencies_ms": [1654.716], "images_per_second": 0.604, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A large bird, possibly a crane or heron, stands prominently in the shallow waters of a river, surrounded by rocks and vegetation.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.937, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.148}, "timestamp": "2026-01-19T13:38:41.159422"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2855.922, "latencies_ms": [2855.922], "images_per_second": 0.35, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "River: 10\nRocks: 20\nBird: 1\nBridge: 2\nTrees: 3\nVegetation: 4\nWater: 5\nSky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.632, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 6.797}, "timestamp": "2026-01-19T13:38:46.074847"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1847.418, "latencies_ms": [1847.418], "images_per_second": 0.541, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The large rock formation is positioned in the foreground, partially obscuring the view of the river. The river extends into the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.294, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.37}, "timestamp": "2026-01-19T13:38:49.983574"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2650.752, "latencies_ms": [2650.752], "images_per_second": 0.377, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a riverbank with scattered rocks and patches of green vegetation. A bird, possibly a heron, is standing on the rocks near the riverbank, seemingly observing its surroundings. The river flows gently through the landscape, with a bridge visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.724, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 6.781}, "timestamp": "2026-01-19T13:38:54.695032"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1598.485, "latencies_ms": [1598.485], "images_per_second": 0.626, "prompt_tokens": 18, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The river is clear and blue. The lighting suggests a sunny day. The riverbed is rocky and uneven.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.98, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.106}, "timestamp": "2026-01-19T13:38:58.324010"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1951.758, "latencies_ms": [1951.758], "images_per_second": 0.512, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A row of parked motor scooters in various colors lines the sidewalk in front of a red-awning bar and restaurant, with people walking by.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.622, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.8}, "timestamp": "2026-01-19T13:39:02.316677"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2506.571, "latencies_ms": [2506.571], "images_per_second": 0.399, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "building: 5\nscooters: 10\nbar: 1\nstreet: 2\nsigns: 3\npeople: 2\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.42, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T13:39:06.864148"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2124.743, "latencies_ms": [2124.743], "images_per_second": 0.471, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scooters are parked along the right side of the street, occupying the foreground. The background features buildings with storefronts and awnings, extending into the distance.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.175, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T13:39:11.049628"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2358.959, "latencies_ms": [2358.959], "images_per_second": 0.424, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene is set on a street in Paris, France, with a row of parked motor scooters lining the sidewalk in front of a bar and restaurant. The atmosphere is lively, with people walking and interacting near the shops.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12503.7, "ram_available_mb": 50337.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.718, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.859}, "timestamp": "2026-01-19T13:39:15.441772"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2729.534, "latencies_ms": [2729.534], "images_per_second": 0.366, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene is dominated by vibrant colors, particularly red and green from the storefront awnings and parked motorcycles. The lighting appears to be natural daylight, creating a pleasant atmosphere. The motorcycles are parked in a somewhat organized manner, suggesting an urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.7, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.402, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.019}, "timestamp": "2026-01-19T13:39:20.228591"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1523.417, "latencies_ms": [1523.417], "images_per_second": 0.656, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A person's hand is holding a piece of broccoli with a brown, dried insect perched on top.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.356, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 6.669}, "timestamp": "2026-01-19T13:39:23.805345"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2942.505, "latencies_ms": [2942.505], "images_per_second": 0.34, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Broccoli: 2\nCaterpillar: 1\nBroccoli florets: 6\nHuman finger: 2\nCountertop: 1\nWall: 1\nStove: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.842, "power_cpu_cv_mean_watts": 1.569, "power_sys_5v0_mean_watts": 7.014}, "timestamp": "2026-01-19T13:39:28.791134"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1702.727, "latencies_ms": [1702.727], "images_per_second": 0.587, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The broccoli is held in the foreground, while the person's hand is positioned in the background. The broccoli is closer to the viewer than the hand.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.211, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T13:39:32.507346"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1810.005, "latencies_ms": [1810.005], "images_per_second": 0.552, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A person is holding a piece of broccoli with a brown, dried insect on it. The setting appears to be a kitchen counter with a tiled backsplash.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.998, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.84}, "timestamp": "2026-01-19T13:39:36.368519"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2141.63, "latencies_ms": [2141.63], "images_per_second": 0.467, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The broccoli is predominantly green and has a slightly browned stem. The lighting appears to be natural, possibly from sunlight, and the material appears to be fresh and likely a leafy vegetable.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.775, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T13:39:40.540782"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1766.861, "latencies_ms": [1766.861], "images_per_second": 0.566, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two people are standing close together, one wearing a black hooded jacket and the other wearing a black jacket with a fur hood, both with their faces partially covered.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.224, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T13:39:44.342171"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2456.193, "latencies_ms": [2456.193], "images_per_second": 0.407, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "woman: 2\nman: 2\nhood: 2\njacket: 2\nhair: 2\nface: 2\nfood: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.761, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T13:39:48.832215"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1796.565, "latencies_ms": [1796.565], "images_per_second": 0.557, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, partially obscured by the man's hood. The man is situated in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.824, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.702}, "timestamp": "2026-01-19T13:39:52.661575"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2651.827, "latencies_ms": [2651.827], "images_per_second": 0.377, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "Two people are in a dimly lit setting, possibly a cafe or restaurant. One person is wearing a black hooded jacket and appears to be laughing or expressing excitement. The other person, partially obscured by the hood, is also smiling and seems to be enjoying the atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.289, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.969}, "timestamp": "2026-01-19T13:39:57.333338"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2436.974, "latencies_ms": [2436.974], "images_per_second": 0.41, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The woman is wearing a black hooded coat, and the lighting is bright, likely from artificial sources. The coat appears to be made of a thick, possibly waterproof material. The background is blurry, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.612, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.928}, "timestamp": "2026-01-19T13:40:01.800008"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1983.222, "latencies_ms": [1983.222], "images_per_second": 0.504, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A male tennis player, dressed in white and black, is poised to strike a yellow tennis ball with a racket on a blue tennis court.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.522, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T13:40:05.848359"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2915.868, "latencies_ms": [2915.868], "images_per_second": 0.343, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "man: 1\ntennis racket: 1\ntennis ball: 1\ntennis shoes: 2\ntennis court: 2\nchairs: 8\ngreen surface: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.957, "power_cpu_cv_mean_watts": 1.569, "power_sys_5v0_mean_watts": 6.992}, "timestamp": "2026-01-19T13:40:10.797374"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2327.756, "latencies_ms": [2327.756], "images_per_second": 0.43, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The man is positioned on the left side of the image, facing towards the right. The tennis ball is in the foreground, slightly in front of him. The tennis court is situated in the background, extending beyond the man's immediate view.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.866, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T13:40:15.150484"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2407.921, "latencies_ms": [2407.921], "images_per_second": 0.415, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A man is playing tennis on a blue court, poised to hit a yellow tennis ball. He is wearing a white shirt, black shorts, and white shoes. Empty white folding chairs are visible in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.847, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T13:40:19.595598"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2485.351, "latencies_ms": [2485.351], "images_per_second": 0.402, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The tennis court is painted in vibrant blue and green. The lighting appears to be bright and evenly distributed, illuminating the scene effectively. The materials appear to be standard tennis court components, including grass, netting, and court markings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.962, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.02}, "timestamp": "2026-01-19T13:40:24.118026"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1766.473, "latencies_ms": [1766.473], "images_per_second": 0.566, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A tall, ornate vase with an etched design of a woman is prominently displayed on a wooden shelf, accompanied by a lit candle and string lights.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.186, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 6.393}, "timestamp": "2026-01-19T13:40:27.914083"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2772.813, "latencies_ms": [2772.813], "images_per_second": 0.361, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Vase: 1\nCandle: 1\nString lights: 4\nMirror: 1\nWooden frame: 1\nGlass: 1\nFlower: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.69, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 6.744}, "timestamp": "2026-01-19T13:40:32.705458"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1731.253, "latencies_ms": [1731.253], "images_per_second": 0.578, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The vase is positioned in the foreground, slightly to the right of the candle. The candle is placed further back, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.69, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.226}, "timestamp": "2026-01-19T13:40:36.461177"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2111.888, "latencies_ms": [2111.888], "images_per_second": 0.474, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene is set on a wooden shelf with a decorative vase containing a painted figure, illuminated by string lights. A white candle is placed next to the vase, enhancing the cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.358, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 6.552}, "timestamp": "2026-01-19T13:40:40.606651"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2465.646, "latencies_ms": [2465.646], "images_per_second": 0.406, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The vase is primarily a reddish-orange color. The lighting in the scene is warm and inviting, illuminating the vase and the surrounding area. String lights are draped around the shelf, adding a cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.598, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 6.647}, "timestamp": "2026-01-19T13:40:45.127923"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1751.998, "latencies_ms": [1751.998], "images_per_second": 0.571, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man is standing in a room, smiling and leaning forward, while another man stands behind him, holding a camera and possibly filming.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.277, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 6.365}, "timestamp": "2026-01-19T13:40:48.916562"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2875.916, "latencies_ms": [2875.916], "images_per_second": 0.348, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "suitcase: 1\ncamera: 1\nlighting stand: 1\nman: 2\ncouch: 1\njacket: 1\nshirt: 1\njeans: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.6, "power_cpu_cv_mean_watts": 2.055, "power_sys_5v0_mean_watts": 6.815}, "timestamp": "2026-01-19T13:40:53.825886"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2375.435, "latencies_ms": [2375.435], "images_per_second": 0.421, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The suitcase is positioned in the foreground, slightly to the left of the man. The man is standing in the background, slightly to the right of the suitcase. The suitcase is situated near the man, and the background suggests a studio or living space.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 10.018, "power_cpu_cv_mean_watts": 2.045, "power_sys_5v0_mean_watts": 6.849}, "timestamp": "2026-01-19T13:40:58.220149"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2948.054, "latencies_ms": [2948.054], "images_per_second": 0.339, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "A man is standing in a room, appearing to be in a photoshoot or filming session. He is positioned near a tripod and a suitcase, suggesting he might be involved in a professional or artistic project. The room features a couch, a chair, and a laptop, indicating a casual yet professional environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.9, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.684, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 6.821}, "timestamp": "2026-01-19T13:41:03.200044"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2269.002, "latencies_ms": [2269.002], "images_per_second": 0.441, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The room is lit by natural light from a window, creating a warm ambiance. The walls are painted a light color, complementing the wooden floor. The man is wearing a gray sweater and jeans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.662, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 6.692}, "timestamp": "2026-01-19T13:41:07.501096"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1829.247, "latencies_ms": [1829.247], "images_per_second": 0.547, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman in a hat and striped tank top smokes a cigarette, smiling warmly as she looks off to the side.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.998, "power_cpu_cv_mean_watts": 1.059, "power_sys_5v0_mean_watts": 6.724}, "timestamp": "2026-01-19T13:41:11.355520"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2679.006, "latencies_ms": [2679.006], "images_per_second": 0.373, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "hat: 1\nwoman: 1\ncigarette: 1\ntie: 1\ntank top: 1\nbracelet: 1\nearrings: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.661, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 6.991}, "timestamp": "2026-01-19T13:41:16.059290"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1891.857, "latencies_ms": [1891.857], "images_per_second": 0.529, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, wearing a hat and tie. The background is blurred and out of focus, drawing attention to the woman and her actions.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.295, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T13:41:19.975280"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2217.281, "latencies_ms": [2217.281], "images_per_second": 0.451, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The black and white image shows a woman wearing a wide-brimmed hat and a striped tank top. She is smiling and holding a cigarette in her mouth, appearing relaxed and enjoying herself.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.427, "power_cpu_cv_mean_watts": 1.291, "power_sys_5v0_mean_watts": 6.91}, "timestamp": "2026-01-19T13:41:24.238015"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3171.87, "latencies_ms": [3171.87], "images_per_second": 0.315, "prompt_tokens": 18, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The woman is wearing a wide-brimmed hat in dark colors. The lighting appears to be soft and diffused, possibly from a natural light source. The hat appears to be made of a lightweight material like felt or linen. The woman is smiling and holding a cigarette, which suggests a relaxed and casual atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.995, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.04}, "timestamp": "2026-01-19T13:41:29.429206"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1556.88, "latencies_ms": [1556.88], "images_per_second": 0.642, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two zebras are grazing on green grass in a zoo enclosure, surrounded by trees and rocks.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.559, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.585}, "timestamp": "2026-01-19T13:41:33.027238"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2780.546, "latencies_ms": [2780.546], "images_per_second": 0.36, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "zebra: 2\ngrass: 2\nrocks: 2\ntree: 2\nbush: 1\npath: 1\nfence: 1\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.321, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.021}, "timestamp": "2026-01-19T13:41:37.820232"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2365.121, "latencies_ms": [2365.121], "images_per_second": 0.423, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The zebra on the left is positioned closer to the viewer, while the zebra on the right is further away, occupying the foreground. The zebras are situated in a grassy area, which appears relatively open and spacious.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.782, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 6.87}, "timestamp": "2026-01-19T13:41:42.213987"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2168.945, "latencies_ms": [2168.945], "images_per_second": 0.461, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Two zebras are grazing on green grass in a zoo enclosure. The enclosure features a rocky wall, trees, and a grassy area, providing a natural habitat for the animals.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.914, "power_cpu_cv_mean_watts": 1.291, "power_sys_5v0_mean_watts": 6.809}, "timestamp": "2026-01-19T13:41:46.427330"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2036.218, "latencies_ms": [2036.218], "images_per_second": 0.491, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The zebras are black and white. The lighting is bright, likely from sunlight filtering through the trees. The grass is green and appears to be well-maintained.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.524, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.785}, "timestamp": "2026-01-19T13:41:50.493566"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1738.983, "latencies_ms": [1738.983], "images_per_second": 0.575, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "An old, rusted fire hydrant with a chain attached stands alone on a sidewalk, partially obscured by fallen leaves.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.183, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 6.249}, "timestamp": "2026-01-19T13:41:54.264258"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3236.664, "latencies_ms": [3236.664], "images_per_second": 0.309, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "fire hydrant: 1\nchain: 1\nbolts: 4\ncap: 1\nbumper: 1\nhandle: 1\nground: 1\npavement: 1\nwall: 1\nplants: 2", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 10.004, "power_cpu_cv_mean_watts": 1.899, "power_sys_5v0_mean_watts": 6.884}, "timestamp": "2026-01-19T13:41:59.543164"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1984.511, "latencies_ms": [1984.511], "images_per_second": 0.504, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The fire hydrant is positioned in the foreground, slightly to the right of the image. The background features a stone wall with a painted design and a small flower bed with pink flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.368, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 6.482}, "timestamp": "2026-01-19T13:42:03.588143"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2288.46, "latencies_ms": [2288.46], "images_per_second": 0.437, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a weathered fire hydrant situated on a sidewalk next to a stone wall with a painted design. Pink flowers are visible in the background, adding a touch of color to the otherwise muted tones.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.576, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 6.631}, "timestamp": "2026-01-19T13:42:07.909165"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2514.693, "latencies_ms": [2514.693], "images_per_second": 0.398, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The fire hydrant is primarily a light brown color. The lighting in the image appears to be natural, possibly from sunlight filtering through the surrounding foliage. The hydrant appears to be made of metal and has a weathered, rusty appearance.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.116, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.562}, "timestamp": "2026-01-19T13:42:12.437054"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1404.25, "latencies_ms": [1404.25], "images_per_second": 0.712, "prompt_tokens": 8, "response_tokens_est": 15, "n_tiles": 1, "output_text": "Two brown bears are captured running along a dirt road in a wilderness setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.719, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.607}, "timestamp": "2026-01-19T13:42:15.877386"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2563.464, "latencies_ms": [2563.464], "images_per_second": 0.39, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Bear: 2\nGround: 6\nRocks: 4\nBushes: 2\nBear fur: 4\nBear's face: 2", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.463, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T13:42:20.469556"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2362.253, "latencies_ms": [2362.253], "images_per_second": 0.423, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and distance. The foreground bear is closer and larger, while the other bear is further away and smaller, emphasizing the vastness of the environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.826, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.971}, "timestamp": "2026-01-19T13:42:24.851265"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2100.335, "latencies_ms": [2100.335], "images_per_second": 0.476, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two brown bears are seen in a dry, rocky landscape. One bear is walking, while the other is standing, appearing alert and possibly observing its surroundings.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.133, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.872}, "timestamp": "2026-01-19T13:42:28.995565"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1977.389, "latencies_ms": [1977.389], "images_per_second": 0.506, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The bears are brown and appear to be running on a dirt road. The lighting suggests a sunny day, and the material is dirt, gravel, and rocks.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.376, "power_cpu_cv_mean_watts": 1.177, "power_sys_5v0_mean_watts": 6.734}, "timestamp": "2026-01-19T13:42:33.021357"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2026.485, "latencies_ms": [2026.485], "images_per_second": 0.493, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A young child, dressed in a white shirt and tie, crouches down next to a metal bowl filled with dirt, appearing to be playing or exploring.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.326, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.81}, "timestamp": "2026-01-19T13:42:37.099334"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3311.667, "latencies_ms": [3311.667], "images_per_second": 0.302, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Bucket: 1\nGround: 1\nBoy: 1\nTie: 1\nShirt: 1\nPants: 1\nShoes: 1\nGround: 1\nBush: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.595, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.07}, "timestamp": "2026-01-19T13:42:42.447081"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1976.665, "latencies_ms": [1976.665], "images_per_second": 0.506, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The child is positioned near the foreground, interacting with a metal bowl on the ground. The background is blurred, drawing focus to the child and the bowl.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.125, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.785}, "timestamp": "2026-01-19T13:42:46.442769"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2497.072, "latencies_ms": [2497.072], "images_per_second": 0.4, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A young child, dressed in a white shirt and tie, is crouched down near a metal bowl filled with dirt, appearing to be digging or playing in the ground. The setting is outdoors, with a dark background of foliage.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.405, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 7.025}, "timestamp": "2026-01-19T13:42:50.965827"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2159.032, "latencies_ms": [2159.032], "images_per_second": 0.463, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The child is wearing a white shirt and a colorful tie. The lighting appears to be natural, possibly outdoors in sunlight. The child is playing with a metal bowl, possibly filled with soil or dirt.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.93, "power_cpu_cv_mean_watts": 1.414, "power_sys_5v0_mean_watts": 6.973}, "timestamp": "2026-01-19T13:42:55.158698"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1782.056, "latencies_ms": [1782.056], "images_per_second": 0.561, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A teddy bear wearing clothes sits on a chair amidst a barren, dirt-covered landscape, accompanied by various items and flowers.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.387, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 6.393}, "timestamp": "2026-01-19T13:42:58.963211"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3195.934, "latencies_ms": [3195.934], "images_per_second": 0.313, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "teddy bear: 2\nblanket: 1\nchair: 1\nred cross: 1\nstuffed animal: 2\ntable: 1\nflowers: 1\nbottles: 2\nsoda cans: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.724, "power_cpu_cv_mean_watts": 1.803, "power_sys_5v0_mean_watts": 6.846}, "timestamp": "2026-01-19T13:43:04.184325"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2844.718, "latencies_ms": [2844.718], "images_per_second": 0.352, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The stuffed bear is positioned in the foreground, slightly to the right of the chair. The chair and teddy bear are situated in the middle ground, separated by a small table with bottles and flowers. The background is vast and barren, emphasizing the isolation and solitude of the scene.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.773, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T13:43:09.082998"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2760.864, "latencies_ms": [2760.864], "images_per_second": 0.362, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene is set in a barren, desert-like environment. A teddy bear is lying on a makeshift chair amidst various items, including clothes, flowers, and bottles. The chair appears to be repurposed as a makeshift bed or seating area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.599, "power_cpu_cv_mean_watts": 1.712, "power_sys_5v0_mean_watts": 6.744}, "timestamp": "2026-01-19T13:43:13.870820"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2764.325, "latencies_ms": [2764.325], "images_per_second": 0.362, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The scene is dominated by earthy tones of brown and reddish-brown. The lighting appears to be natural sunlight, creating a warm and inviting atmosphere. The materials include fabric, wood, and metal, contributing to the rustic aesthetic. The setting suggests a dry, arid environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.545, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 6.731}, "timestamp": "2026-01-19T13:43:18.660121"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1565.115, "latencies_ms": [1565.115], "images_per_second": 0.639, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "Two green fishing boats are docked at a wooden pier, ready for their next voyage.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.893, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.644}, "timestamp": "2026-01-19T13:43:22.266862"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3614.028, "latencies_ms": [3614.028], "images_per_second": 0.277, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "Boat: 3\nFishing boat: 2\nDock: 2\nPier: 1\nSailboats: 2\nBuoys: 2\nPaint cans: 1\nWooden planks: 1\nMetal railing: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.504, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.126}, "timestamp": "2026-01-19T13:43:27.926178"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1950.859, "latencies_ms": [1950.859], "images_per_second": 0.513, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the boats docked at a pier in the background. The boats are situated near the water's edge, extending into the distance.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.128, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 6.961}, "timestamp": "2026-01-19T13:43:31.922483"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2715.58, "latencies_ms": [2715.58], "images_per_second": 0.368, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene depicts a harbor with several fishing boats docked near a pier. The boats are equipped with various safety features, including life jackets and orange buoys. The setting is surrounded by hills and mountains, creating a picturesque backdrop for the harbor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12511.0, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.045, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.147}, "timestamp": "2026-01-19T13:43:36.676264"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2597.836, "latencies_ms": [2597.836], "images_per_second": 0.385, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The boats are primarily green and white. The lighting is soft and diffused, suggesting an overcast sky. The boats appear to be made of sturdy materials like metal and wood. The overall scene conveys a peaceful and tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.0, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.826, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.012}, "timestamp": "2026-01-19T13:43:41.310509"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1523.965, "latencies_ms": [1523.965], "images_per_second": 0.656, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman with short brown hair bites into a hot dog, wearing a dark jacket and scarf, with a blurred background.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.548, "power_cpu_cv_mean_watts": 1.235, "power_sys_5v0_mean_watts": 6.274}, "timestamp": "2026-01-19T13:43:44.875466"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2807.194, "latencies_ms": [2807.194], "images_per_second": 0.356, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "hot dog: 1\nwoman: 1\nfood: 1\nnapkin: 1\ntongue: 1\nhair: 1\nface: 1\neyes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.2, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.708, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 6.744}, "timestamp": "2026-01-19T13:43:49.702511"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2417.562, "latencies_ms": [2417.562], "images_per_second": 0.414, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, eating a hot dog. The background is blurred, suggesting an outdoor setting at night. The hot dog is held in her right hand, while the woman's face and upper body are visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.455, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.658}, "timestamp": "2026-01-19T13:43:54.152953"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2099.572, "latencies_ms": [2099.572], "images_per_second": 0.476, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A woman is eating a hot dog at night in a dimly lit setting, possibly outdoors or in a bar or restaurant. The background is blurred, drawing focus to the woman and her food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.315, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.52}, "timestamp": "2026-01-19T13:43:58.275715"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2014.473, "latencies_ms": [2014.473], "images_per_second": 0.496, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The woman is wearing a dark-colored jacket. The lighting is dim, suggesting an outdoor setting at night. The food item appears to be a hot dog, judging by its shape and color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.317, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.47}, "timestamp": "2026-01-19T13:44:02.353299"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1787.814, "latencies_ms": [1787.814], "images_per_second": 0.559, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man in a black suit and bow tie holds a martini glass while standing next to a woman in a long black dress.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.855, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.638}, "timestamp": "2026-01-19T13:44:06.176091"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3120.439, "latencies_ms": [3120.439], "images_per_second": 0.32, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "woman: 2\nman: 1\ndress: 1\ngloves: 1\nbow tie: 1\ncocktail glass: 1\nfloor: 1\ndoor: 1\ncurtains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.912, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T13:44:11.331246"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1950.48, "latencies_ms": [1950.48], "images_per_second": 0.513, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The woman is positioned to the left of the man, who is standing further back. Both are standing near a doorway, suggesting they are in a room or hallway.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.68, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T13:44:15.306380"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2436.968, "latencies_ms": [2436.968], "images_per_second": 0.41, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A man and a woman are standing in a doorway, holding a martini glass. The woman is wearing a long dark dress, while the man is dressed in a tuxedo. They are likely attending a formal event or gathering.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.466, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.894}, "timestamp": "2026-01-19T13:44:19.775641"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3070.26, "latencies_ms": [3070.26], "images_per_second": 0.326, "prompt_tokens": 18, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The woman is wearing a dark green dress, and the man is wearing a dark suit with a bow tie. The lighting is soft and diffused, suggesting an indoor setting. The materials appear to be standard dress fabrics. The weather is likely cool and possibly rainy, given the presence of a martini glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.752, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.108}, "timestamp": "2026-01-19T13:44:24.875314"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1969.509, "latencies_ms": [1969.509], "images_per_second": 0.508, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A blue wooden shelf holds various items, including several small metal cups, a silver teapot, a silver vase, a book, and orange price tags.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.19, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 6.451}, "timestamp": "2026-01-19T13:44:28.872709"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4411.835, "latencies_ms": [4411.835], "images_per_second": 0.227, "prompt_tokens": 21, "response_tokens_est": 68, "n_tiles": 1, "output_text": "vase: 1\nteapot: 1\nsmall metal container: 1\nsmall metal cup: 2\nsmall metal teapot: 1\nbook: 1\nsmall metal container: 1\nsmall metal teapot: 1\nsmall metal cup: 2\nsmall metal teapot: 1\nsmall metal container: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 10.082, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.02}, "timestamp": "2026-01-19T13:44:35.320696"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2611.809, "latencies_ms": [2611.809], "images_per_second": 0.383, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The silver teapot and cups are placed on the blue shelf in the foreground, while the silver vase and candlesticks are positioned on the wooden table in the background. The blue shelf is situated near the wooden table, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.827, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 6.724}, "timestamp": "2026-01-19T13:44:39.966985"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3184.182, "latencies_ms": [3184.182], "images_per_second": 0.314, "prompt_tokens": 19, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The scene depicts a cluttered outdoor setting, possibly a yard sale or flea market. A blue shelf holds various items, including vases, cups, and a book, with price tags attached. The surrounding area is filled with other discarded furniture and items, contributing to the overall sense of disorganization and sale atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12510.7, "ram_available_mb": 50330.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.893, "power_cpu_cv_mean_watts": 1.818, "power_sys_5v0_mean_watts": 6.85}, "timestamp": "2026-01-19T13:44:45.176007"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2372.758, "latencies_ms": [2372.758], "images_per_second": 0.421, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The blue shelf stands out against the surrounding furniture and objects. The lighting in the image is soft and diffused, creating a calm atmosphere. The shelf appears to be made of metal and has a slightly worn or weathered appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.7, "ram_available_mb": 50330.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.342, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.594}, "timestamp": "2026-01-19T13:44:49.568562"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1961.208, "latencies_ms": [1961.208], "images_per_second": 0.51, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A white plate holds four square crackers topped with a white substance, likely butter or cream cheese, accompanied by a black computer keyboard and a computer mouse in the background.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.129, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.898}, "timestamp": "2026-01-19T13:44:53.603515"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2015.181, "latencies_ms": [2015.181], "images_per_second": 0.496, "prompt_tokens": 21, "response_tokens_est": 22, "n_tiles": 1, "output_text": "keyboard: 2\nmouse: 1\nplate: 4\nbutter: 4\ncookies: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.552, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T13:44:57.641622"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2257.347, "latencies_ms": [2257.347], "images_per_second": 0.443, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the plate of crackers slightly behind them. The background includes a keyboard, a mouse, and a partially visible cup, suggesting an office or workspace setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.715, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.832}, "timestamp": "2026-01-19T13:45:01.931298"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2213.448, "latencies_ms": [2213.448], "images_per_second": 0.452, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A white plate with several square crackers topped with a white substance sits on a desk. A black computer keyboard and a computer mouse are visible in the background, along with a partially visible yellow object.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.937, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 6.831}, "timestamp": "2026-01-19T13:45:06.190154"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2474.927, "latencies_ms": [2474.927], "images_per_second": 0.404, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The plate is white and appears to be made of ceramic or porcelain. The butter on the crackers is a pale yellow color. The lighting in the image is soft and diffused, creating a gentle and warm ambiance.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.506, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.904}, "timestamp": "2026-01-19T13:45:10.687432"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1476.477, "latencies_ms": [1476.477], "images_per_second": 0.677, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A man in a black suit and tie adjusts his colorful tie against a dark gray background.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.894, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T13:45:14.210891"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2726.696, "latencies_ms": [2726.696], "images_per_second": 0.367, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "man: 2\nglasses: 1\nsuit: 1\ntie: 1\nring: 1\nbelt: 1\nshirt: 1\nbackground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.571, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.037}, "timestamp": "2026-01-19T13:45:18.956190"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1890.089, "latencies_ms": [1890.089], "images_per_second": 0.529, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The man is positioned in the foreground, with the illuminated tie extending towards his right. The tie is centrally placed in the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.84, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.814}, "timestamp": "2026-01-19T13:45:22.868736"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1593.38, "latencies_ms": [1593.38], "images_per_second": 0.628, "prompt_tokens": 19, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man in a suit is adjusting a glowing tie against a dark background. He appears to be in a professional or formal setting.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.766, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T13:45:26.489228"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2824.037, "latencies_ms": [2824.037], "images_per_second": 0.354, "prompt_tokens": 18, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The tie features a vibrant array of colors, including red, green, and yellow, creating a visually striking effect. The lighting highlights the colors and creates a dynamic effect. The tie appears to be made of a smooth, potentially synthetic material. The man is wearing a suit, suggesting formal attire.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.46, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.025}, "timestamp": "2026-01-19T13:45:31.334567"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2267.007, "latencies_ms": [2267.007], "images_per_second": 0.441, "prompt_tokens": 8, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A woman in a brown jacket and blue jeans is walking across a street corner, carrying a black bag and passing by a white building with a curved facade and a \"TADURIA\" sign.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.36, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:45:35.646746"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2798.093, "latencies_ms": [2798.093], "images_per_second": 0.357, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "building: 4\nstreetlight: 1\nperson: 1\ncar: 1\ntraffic light: 1\nshop: 1\nsign: 1\npeople: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.042, "power_cpu_cv_mean_watts": 1.568, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T13:45:40.472633"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2271.63, "latencies_ms": [2271.63], "images_per_second": 0.44, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The woman is standing in the foreground, facing the camera. The building is positioned in the background, slightly to the right of the woman. The street and traffic lights are located further back, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.762, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.928}, "timestamp": "2026-01-19T13:45:44.794267"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2967.094, "latencies_ms": [2967.094], "images_per_second": 0.337, "prompt_tokens": 19, "response_tokens_est": 61, "n_tiles": 1, "output_text": "A woman is walking across a street corner in front of a white building with a \"TADURIA\" sign. A traffic light is visible, signaling pedestrians to stop. Several other people are walking or standing near the building. The scene is illuminated by streetlights, creating a calm and nighttime atmosphere.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.954, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.022}, "timestamp": "2026-01-19T13:45:49.805338"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2214.747, "latencies_ms": [2214.747], "images_per_second": 0.452, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The building is primarily white with light-colored trim and features warm lighting from street lamps and building lights. The sky is a deep blue, suggesting it's either dusk or dawn.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.391, "power_cpu_cv_mean_watts": 1.414, "power_sys_5v0_mean_watts": 6.937}, "timestamp": "2026-01-19T13:45:54.038064"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1875.961, "latencies_ms": [1875.961], "images_per_second": 0.533, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A young girl in a purple bikini skillfully surfs a wave on a blue surfboard, surrounded by other surfers in the ocean.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.053, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T13:45:57.947713"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2629.729, "latencies_ms": [2629.729], "images_per_second": 0.38, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "surfboard: 2\nwoman: 1\nbikini: 1\nsurfer: 1\nwaves: 2\nwater: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.692, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T13:46:02.597522"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2892.588, "latencies_ms": [2892.588], "images_per_second": 0.346, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The main object, the young girl surfing, is positioned in the foreground of the image. The background features other surfers on surfboards, indicating a shared surfing environment. The girl is relatively close to the foreground, riding a wave, while the other surfers are further back in the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.389, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 7.047}, "timestamp": "2026-01-19T13:46:07.514746"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2675.992, "latencies_ms": [2675.992], "images_per_second": 0.374, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a sunny day at the beach with several people enjoying surfing. A young girl in a purple bikini is skillfully riding a wave on a blue surfboard, while two other surfers are paddling in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.498, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.079}, "timestamp": "2026-01-19T13:46:12.234182"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2219.232, "latencies_ms": [2219.232], "images_per_second": 0.451, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The water is a greenish-blue color. The lighting appears to be natural daylight. The surfboards appear to be made of fiberglass or similar lightweight materials. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.979, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:46:16.490088"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1618.589, "latencies_ms": [1618.589], "images_per_second": 0.618, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A man in a white shirt and khaki pants is feeding a gray elephant over a fence in a zoo enclosure.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12506.3, "ram_available_mb": 50334.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.365, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.676}, "timestamp": "2026-01-19T13:46:20.163618"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2448.031, "latencies_ms": [2448.031], "images_per_second": 0.408, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "elephant: 1\nman: 1\nfence: 2\ngrass: 2\ntree: 2\nman: 1\nhat: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.966, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T13:46:24.650663"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2105.45, "latencies_ms": [2105.45], "images_per_second": 0.475, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The elephant is positioned to the left of the man, who is positioned to the right of the elephant. The man is standing in the foreground, while the elephant is further back, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.322, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T13:46:28.788725"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2201.508, "latencies_ms": [2201.508], "images_per_second": 0.454, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "An elephant is standing in a fenced enclosure, reaching over a metal railing to interact with a man. The man is feeding the elephant, seemingly enjoying the interaction.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.107, "power_cpu_cv_mean_watts": 1.437, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T13:46:33.021291"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2953.29, "latencies_ms": [2953.29], "images_per_second": 0.339, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The elephant is gray and appears to have some grayish-brown patches on its skin. The lighting in the image suggests it might be daytime, with natural light illuminating the scene. The enclosure appears to be constructed of concrete and metal fencing, typical of zoo or wildlife park settings.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.311, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.084}, "timestamp": "2026-01-19T13:46:38.020513"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1649.014, "latencies_ms": [1649.014], "images_per_second": 0.606, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A brown dog sits on a bed surrounded by various items, including a brown bag, clothes, a box, and a pillow.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.489, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.745}, "timestamp": "2026-01-19T13:46:41.718812"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2589.895, "latencies_ms": [2589.895], "images_per_second": 0.386, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bed: 2\npillows: 2\nblankets: 2\nbags: 1\nbox: 1\nclothes: 2\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.33, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 6.916}, "timestamp": "2026-01-19T13:46:46.339092"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2178.064, "latencies_ms": [2178.064], "images_per_second": 0.459, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The dog is positioned to the left of the foreground, slightly behind and to the left of the pile of clothes. The pile of clothes occupies the foreground and extends towards the right side of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.848, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 6.927}, "timestamp": "2026-01-19T13:46:50.568643"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2126.44, "latencies_ms": [2126.44], "images_per_second": 0.47, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A brown dog sits on a bed surrounded by various items, including clothes, a backpack, and a box. The bed appears to be cluttered, possibly indicating a recent move or reorganization.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.344, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T13:46:54.731236"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1963.375, "latencies_ms": [1963.375], "images_per_second": 0.509, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The dog is brown and white. The bed is covered in white sheets and blankets. The lighting appears to be soft and diffused, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.154, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T13:46:58.712126"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1863.989, "latencies_ms": [1863.989], "images_per_second": 0.536, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A man, dressed professionally in a blue shirt and tie, sits at a desk with a laptop, pen in hand, appearing deep in thought.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.161, "power_cpu_cv_mean_watts": 1.308, "power_sys_5v0_mean_watts": 6.39}, "timestamp": "2026-01-19T13:47:02.641742"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2853.254, "latencies_ms": [2853.254], "images_per_second": 0.35, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "laptop: 1\nglasses: 1\nnotebook: 1\npen: 1\ntie: 1\nman: 1\ntable: 1\nclipboard: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.601, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 6.8}, "timestamp": "2026-01-19T13:47:07.538627"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2036.724, "latencies_ms": [2036.724], "images_per_second": 0.491, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The man is seated at a desk with a laptop and papers, indicating a workspace. The background is blurred, suggesting the setting is likely an office or professional environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.341, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.526}, "timestamp": "2026-01-19T13:47:11.623371"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1946.868, "latencies_ms": [1946.868], "images_per_second": 0.514, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A man is sitting at a desk in an office, appearing thoughtful as he looks up from his laptop. He is surrounded by office supplies, including a pen and papers, suggesting a professional environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.217, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.478}, "timestamp": "2026-01-19T13:47:15.613462"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2074.715, "latencies_ms": [2074.715], "images_per_second": 0.482, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The man is wearing a light blue shirt and a blue tie. His glasses are silver and appear to be made of metal. The background is blurred, suggesting an office setting with natural lighting.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.475, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.498}, "timestamp": "2026-01-19T13:47:19.743037"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1709.2, "latencies_ms": [1709.2], "images_per_second": 0.585, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A large commercial airplane with red accents is captured in mid-flight, passing a full moon in the sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.15, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T13:47:23.489217"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1811.856, "latencies_ms": [1811.856], "images_per_second": 0.552, "prompt_tokens": 21, "response_tokens_est": 17, "n_tiles": 1, "output_text": "airplane: 1\nmoon: 1\nsky: 1\nclouds: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12510.9, "ram_available_mb": 50330.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.456, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T13:47:27.337629"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1794.984, "latencies_ms": [1794.984], "images_per_second": 0.557, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The airplane is flying towards the right side of the image, while the moon is positioned in the lower left corner, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12510.9, "ram_available_mb": 50330.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.771, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.709}, "timestamp": "2026-01-19T13:47:31.151669"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2090.231, "latencies_ms": [2090.231], "images_per_second": 0.478, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A large commercial airplane is captured in mid-flight against a clear, light blue sky. A large, full moon is visible in the lower left corner of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.177, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T13:47:35.280962"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2488.287, "latencies_ms": [2488.287], "images_per_second": 0.402, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The moon is a pale orange-yellow color, illuminated by the sun's light. The airplane is primarily gray with red accents and appears to be in flight. The sky is a light blue, suggesting fair weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.746, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.975}, "timestamp": "2026-01-19T13:47:39.825566"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2162.871, "latencies_ms": [2162.871], "images_per_second": 0.462, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A young man in a purple tie-dye shirt and black pants is skillfully performing a trick on his skateboard, airborne over a concrete ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.428, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.0}, "timestamp": "2026-01-19T13:47:44.054069"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3875.402, "latencies_ms": [3875.402], "images_per_second": 0.258, "prompt_tokens": 21, "response_tokens_est": 57, "n_tiles": 1, "output_text": "skateboard: 2\ntie-dye shirt: 1\nskateboard wheels: 4\nskateboard deck: 1\nskateboard: 1\nskateboarder: 1\nskatepark: 1\npalm trees: 2\nplayground: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.588, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 7.213}, "timestamp": "2026-01-19T13:47:49.958255"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2221.973, "latencies_ms": [2221.973], "images_per_second": 0.45, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, mid-air, performing a trick. The skate park is situated in the background, partially obscured by palm trees and other structures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.093, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.87}, "timestamp": "2026-01-19T13:47:54.216985"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2697.902, "latencies_ms": [2697.902], "images_per_second": 0.371, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A young man is performing a skateboard trick in a skate park. He is mid-air, executing a trick while wearing a tie-dye shirt and jeans. The park is surrounded by palm trees and other greenery, with buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.549, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 7.0}, "timestamp": "2026-01-19T13:47:58.942494"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3160.059, "latencies_ms": [3160.059], "images_per_second": 0.316, "prompt_tokens": 18, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The skateboarder is wearing a tie-dye shirt in shades of purple and blue. The lighting appears to be natural daylight, creating a bright and clear atmosphere. The skateboard itself appears to be made of wood and metal, typical materials for skateboarding. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.117, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.067}, "timestamp": "2026-01-19T13:48:04.122844"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1655.112, "latencies_ms": [1655.112], "images_per_second": 0.604, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A curious sheep gazes through the wire fence, its fluffy white coat contrasting with the rusty metal.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.274, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.784}, "timestamp": "2026-01-19T13:48:07.817602"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2281.386, "latencies_ms": [2281.386], "images_per_second": 0.438, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "sheep: 2\nwire fence: 1\ngrass: 1\ntrees: 4\nbush: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.932, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T13:48:12.157858"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1828.961, "latencies_ms": [1828.961], "images_per_second": 0.547, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The main sheep is positioned in the foreground, partially obscured by the wire fence. The background features trees and a grassy area, creating a natural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.799, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T13:48:16.007963"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2282.395, "latencies_ms": [2282.395], "images_per_second": 0.438, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A sheep is standing behind a wire fence in a grassy field with trees in the background. The scene suggests a farm or rural setting where the sheep are likely being cared for or grazing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.952, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.912}, "timestamp": "2026-01-19T13:48:20.345020"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2490.375, "latencies_ms": [2490.375], "images_per_second": 0.402, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The sheep's wool is a light beige color. The lighting in the image appears to be natural, possibly from the sun, creating a soft, warm glow. The scene is set in a grassy area with trees in the background, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.863, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T13:48:24.858029"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1556.374, "latencies_ms": [1556.374], "images_per_second": 0.643, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A close-up shot reveals the illuminated buttons and screen of a silver Sony Walkman phone.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.426, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.694}, "timestamp": "2026-01-19T13:48:28.478776"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3060.339, "latencies_ms": [3060.339], "images_per_second": 0.327, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "button: 2\nscreen: 1\nvolume knob: 1\nplay button: 1\nwalkman button: 1\nback button: 1\nflash button: 1\nbrowser button: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.136, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 7.048}, "timestamp": "2026-01-19T13:48:33.554984"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1913.816, "latencies_ms": [1913.816], "images_per_second": 0.523, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The left object is positioned in the foreground, while the right object is further away in the background. The device is angled towards the viewer, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.973, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T13:48:37.494593"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2391.857, "latencies_ms": [2391.857], "images_per_second": 0.418, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Close-up view of a silver Sony Walkman phone, showcasing its illuminated buttons and screen. The phone rests on a dark surface, emphasizing its metallic finish and the orange lights that illuminate the buttons.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.885, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T13:48:41.909959"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2128.121, "latencies_ms": [2128.121], "images_per_second": 0.47, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The phone is silver and appears to be made of metal. The lighting is warm and highlights the metallic texture of the device. The phone's surface appears smooth and reflective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.892, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T13:48:46.103107"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1611.505, "latencies_ms": [1611.505], "images_per_second": 0.621, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman in a sparkly black dress stands in front of a stainless steel refrigerator, holding a glass of orange juice.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.806, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.59}, "timestamp": "2026-01-19T13:48:49.747389"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3074.714, "latencies_ms": [3074.714], "images_per_second": 0.325, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "woman: 1\ndress: 1\nglasses: 1\nwine bottle: 1\nfoil roll: 1\nrefrigerator: 1\ncounter: 1\ncabinets: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.751, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.027}, "timestamp": "2026-01-19T13:48:54.876079"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1886.854, "latencies_ms": [1886.854], "images_per_second": 0.53, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The woman is standing near the refrigerator, positioned in the foreground of the image. The kitchen counter and cabinets are in the background, extending into the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.733, "power_cpu_cv_mean_watts": 1.148, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T13:48:58.789514"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2555.229, "latencies_ms": [2555.229], "images_per_second": 0.391, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "A woman in a sparkly black dress is standing in a kitchen, holding a glass of orange juice. She is smiling and appears to be enjoying herself. The kitchen features wooden cabinets, a stainless steel refrigerator, and a tiled backsplash.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.349, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T13:49:03.389879"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2637.994, "latencies_ms": [2637.994], "images_per_second": 0.379, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The kitchen features warm brown wooden cabinets and light-colored tile flooring. The stainless steel refrigerator stands out, adding a modern touch to the space. The woman is wearing black dress and glasses, completing the stylish ensemble.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.312, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 6.946}, "timestamp": "2026-01-19T13:49:08.069523"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1718.992, "latencies_ms": [1718.992], "images_per_second": 0.582, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A yellow school bus is reflected in the side mirror of a truck, capturing a glimpse of the road ahead.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.056, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.676}, "timestamp": "2026-01-19T13:49:11.847086"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2589.952, "latencies_ms": [2589.952], "images_per_second": 0.386, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "school bus: 1\nroad: 2\ncar: 1\ntraffic light: 1\nbuildings: 2\nsign: 1\npole: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.52, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T13:49:16.481397"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2069.448, "latencies_ms": [2069.448], "images_per_second": 0.483, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The school bus is positioned in the foreground, partially obscuring the background. The mirror reflects the school bus and the surrounding environment, indicating a relatively close proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.251, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.816}, "timestamp": "2026-01-19T13:49:20.585067"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2236.017, "latencies_ms": [2236.017], "images_per_second": 0.447, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A yellow school bus is reflected in the side mirror of a vehicle. The reflection shows a road with cars and traffic lights. The setting appears to be a street or parking lot near a building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.091, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.871}, "timestamp": "2026-01-19T13:49:24.860168"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2263.146, "latencies_ms": [2263.146], "images_per_second": 0.442, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The yellow school bus is reflected in the round side mirror. The lighting conditions suggest an overcast sky. The bus appears to be made of metal, and the reflection shows a roadway with vehicles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.98, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.837}, "timestamp": "2026-01-19T13:49:29.163155"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1756.353, "latencies_ms": [1756.353], "images_per_second": 0.569, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A gray cat is sitting on a wooden table near two potted plants, while a brown dog stands nearby, seemingly observing the cat.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.157, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 6.372}, "timestamp": "2026-01-19T13:49:32.949390"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2324.775, "latencies_ms": [2324.775], "images_per_second": 0.43, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "cat: 1\ndog: 1\nplant: 2\npot: 2\ntable: 1\nwindow: 1\nfence: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.488, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.568}, "timestamp": "2026-01-19T13:49:37.321860"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1558.117, "latencies_ms": [1558.117], "images_per_second": 0.642, "prompt_tokens": 25, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the potted plants. The dog is further in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.281, "power_cpu_cv_mean_watts": 1.235, "power_sys_5v0_mean_watts": 6.266}, "timestamp": "2026-01-19T13:49:40.898979"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2129.513, "latencies_ms": [2129.513], "images_per_second": 0.47, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A cat and a dog are seen together on a wooden surface, possibly a table or deck. The cat is sitting and looking down, while the dog stands nearby, seemingly observing the cat.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.427, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.593}, "timestamp": "2026-01-19T13:49:45.059705"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1953.741, "latencies_ms": [1953.741], "images_per_second": 0.512, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The cat is gray, and the dog is brown. The lighting appears to be natural daylight. The cat and dog are sitting near a wooden table and planters.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.054, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.37}, "timestamp": "2026-01-19T13:49:49.040067"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1813.626, "latencies_ms": [1813.626], "images_per_second": 0.551, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A female soccer player in a blue jersey is skillfully dribbling the ball while another player in a yellow jersey watches.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.913, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T13:49:52.917404"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2737.181, "latencies_ms": [2737.181], "images_per_second": 0.365, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "woman: 1\nball: 1\njersey: 1\nshorts: 1\nheadband: 1\nhair: 1\nface: 1\nbackground: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.348, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.046}, "timestamp": "2026-01-19T13:49:57.695569"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1839.62, "latencies_ms": [1839.62], "images_per_second": 0.544, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The ball is positioned in the foreground, slightly to the left of the main subject. The background is blurred, suggesting the focus is on the player in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.227, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T13:50:01.572596"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1862.447, "latencies_ms": [1862.447], "images_per_second": 0.537, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A female soccer player in a blue jersey is dribbling the ball on a field. Another player in a yellow jersey is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.974, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T13:50:05.478950"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2003.787, "latencies_ms": [2003.787], "images_per_second": 0.499, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The player is wearing a blue jersey with red and white accents. The ball is white with blue and red markings. The setting appears to be outdoors in natural light.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.451, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.873}, "timestamp": "2026-01-19T13:50:09.501213"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1576.421, "latencies_ms": [1576.421], "images_per_second": 0.634, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two giraffes stand in a grassy enclosure, one leaning over a wooden fence while the other faces away from the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.281, "power_cpu_cv_mean_watts": 1.235, "power_sys_5v0_mean_watts": 6.216}, "timestamp": "2026-01-19T13:50:13.111000"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2181.804, "latencies_ms": [2181.804], "images_per_second": 0.458, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "giraffe: 2\nfence: 1\ntrees: 6\ngrass: 6\ndirt: 1\npath: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.815, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.608}, "timestamp": "2026-01-19T13:50:17.337678"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2539.192, "latencies_ms": [2539.192], "images_per_second": 0.394, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The giraffes are positioned near the fence and trees in the background, suggesting they are in a relatively enclosed area. The giraffes are situated in a grassy area, which further reinforces the impression of a zoo or wildlife park setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.521, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 6.672}, "timestamp": "2026-01-19T13:50:21.914090"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2744.553, "latencies_ms": [2744.553], "images_per_second": 0.364, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "Two giraffes are in a zoo enclosure. One giraffe is bending over a wooden fence, seemingly reaching for something, while the other giraffe stands nearby, observing its surroundings. The enclosure is surrounded by lush green trees and grass, creating a natural habitat for the animals.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.634, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T13:50:26.694982"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2158.993, "latencies_ms": [2158.993], "images_per_second": 0.463, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The giraffes exhibit a mix of brown and tan patterns, illuminated by natural daylight. The enclosure is constructed from light-colored wood, blending seamlessly with the surrounding greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.481, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.585}, "timestamp": "2026-01-19T13:50:30.882633"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1880.135, "latencies_ms": [1880.135], "images_per_second": 0.532, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Three pieces of luggage, including a suitcase, a duffel bag, and a smaller bag, are neatly arranged on the floor near a curtain.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.294, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T13:50:34.796894"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2371.958, "latencies_ms": [2371.958], "images_per_second": 0.422, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "suitcase: 1\nbag: 1\ncarpet: 1\ncurtains: 1\nbooks: 2\nplastic bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.0, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.079, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T13:50:39.191079"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2479.366, "latencies_ms": [2479.366], "images_per_second": 0.403, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close and central arrangement. The suitcase is positioned slightly further back than the other items, placed in the foreground. The bags are placed further back, partially obscured by the suitcase.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.0, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.132, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.046}, "timestamp": "2026-01-19T13:50:43.711374"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2436.027, "latencies_ms": [2436.027], "images_per_second": 0.411, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a room with several pieces of luggage, including a suitcase, a tote bag, and a smaller bag, arranged on the floor near a curtain. The setting suggests preparation for a trip or travel.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.125, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.975}, "timestamp": "2026-01-19T13:50:48.194492"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2839.858, "latencies_ms": [2839.858], "images_per_second": 0.352, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The suitcase appears to be gray or dark gray in color. The lighting in the image is soft and diffused, suggesting natural light coming from a window or overhead light. The suitcase appears to be made of a sturdy material, possibly fabric or hard-shell.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.321, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.073}, "timestamp": "2026-01-19T13:50:53.068354"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1551.692, "latencies_ms": [1551.692], "images_per_second": 0.644, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Two men are riding donkeys down a rocky trail in a forest, surrounded by tall trees and rocks.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.895, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.728}, "timestamp": "2026-01-19T13:50:56.664933"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2837.743, "latencies_ms": [2837.743], "images_per_second": 0.352, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "person: 2\nhorse: 2\nbackpack: 1\nbandana: 1\nhat: 1\ngloves: 1\nground: 4\nrocks: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.903, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 6.924}, "timestamp": "2026-01-19T13:51:01.518023"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2256.898, "latencies_ms": [2256.898], "images_per_second": 0.443, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The man and horse are positioned in the foreground of the image, moving along a narrow path. The man and horse are relatively close to the viewer, while the path extends into the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.003, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.826}, "timestamp": "2026-01-19T13:51:05.791890"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1888.672, "latencies_ms": [1888.672], "images_per_second": 0.529, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two people are riding donkeys along a rocky trail in a forest. The trail is surrounded by tall trees and rocks, creating a natural and rugged environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.627, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.8}, "timestamp": "2026-01-19T13:51:09.703360"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3297.106, "latencies_ms": [3297.106], "images_per_second": 0.303, "prompt_tokens": 18, "response_tokens_est": 72, "n_tiles": 1, "output_text": "The scene is bathed in sunlight, creating a warm and inviting atmosphere. The colors are vibrant, with the green of the trees contrasting with the blue of the man's shirt and the brown of the horses' coats. The lighting is natural, illuminating the path and the surrounding forest. The materials appear to be natural, sturdy, and suitable for outdoor activities.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.639, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 7.123}, "timestamp": "2026-01-19T13:51:15.045227"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1677.101, "latencies_ms": [1677.101], "images_per_second": 0.596, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A man in a sweatshirt and jeans rides a horse, holding the reins and guiding it along a track.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.243, "power_cpu_cv_mean_watts": 1.264, "power_sys_5v0_mean_watts": 6.769}, "timestamp": "2026-01-19T13:51:18.761971"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2957.832, "latencies_ms": [2957.832], "images_per_second": 0.338, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "horse: 1\nman: 1\nsaddle: 1\njockey: 1\nhelmet: 1\nshoe: 1\nbelt: 1\nfence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.973, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T13:51:23.753359"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2128.084, "latencies_ms": [2128.084], "images_per_second": 0.47, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The man is positioned near the foreground of the image, riding a horse. The background features blurred structures, possibly buildings or tents, which create a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.872, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.783}, "timestamp": "2026-01-19T13:51:27.920280"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2086.293, "latencies_ms": [2086.293], "images_per_second": 0.479, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A man is riding a horse in a black and white image, possibly at a racetrack or similar venue. The horse and rider appear to be in motion, creating a dynamic scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.452, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T13:51:32.031132"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1852.29, "latencies_ms": [1852.29], "images_per_second": 0.54, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The horse and rider appear to be wearing dark-colored clothing. The background is blurred, suggesting motion, and appears to be outdoors in natural light.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.713, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.739}, "timestamp": "2026-01-19T13:51:35.903263"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1604.86, "latencies_ms": [1604.86], "images_per_second": 0.623, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Three ducks are swimming leisurely in a calm, reflective body of water, surrounded by lush greenery and tall grasses.", "error": null, "sys_before": {"cpu_percent": 5.7, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.212, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.614}, "timestamp": "2026-01-19T13:51:39.560701"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2321.741, "latencies_ms": [2321.741], "images_per_second": 0.431, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "goose: 4\nwater: 4\nshore: 4\ngrass: 4\ntrees: 4\nbushes: 4", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.53, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 6.838}, "timestamp": "2026-01-19T13:51:43.938298"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1909.727, "latencies_ms": [1909.727], "images_per_second": 0.524, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground of the image, with the water providing a background. The geese are situated near the water's edge, closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.625, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.834}, "timestamp": "2026-01-19T13:51:47.886336"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1564.929, "latencies_ms": [1564.929], "images_per_second": 0.639, "prompt_tokens": 19, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of geese is swimming in a calm body of water near a grassy bank with trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.523, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.636}, "timestamp": "2026-01-19T13:51:51.494616"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1888.646, "latencies_ms": [1888.646], "images_per_second": 0.529, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The water is a calm, reflective blue-green. The lighting suggests a sunny day, with soft shadows cast by the surrounding trees and bushes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.733, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T13:51:55.411714"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1715.006, "latencies_ms": [1715.006], "images_per_second": 0.583, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "An orange and white cat is comfortably resting on the hood of a black Mercedes-Benz car parked in a residential area.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.185, "power_cpu_cv_mean_watts": 1.259, "power_sys_5v0_mean_watts": 6.278}, "timestamp": "2026-01-19T13:51:59.153827"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2732.464, "latencies_ms": [2732.464], "images_per_second": 0.366, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "cat: 1\ncar: 1\nmercedes: 1\ngrill: 1\nbush: 1\nfence: 1\nwindow: 2\nbuilding: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.79, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 6.766}, "timestamp": "2026-01-19T13:52:03.927645"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1903.811, "latencies_ms": [1903.811], "images_per_second": 0.525, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The cat is positioned on the car's hood, near the front grill. The car is parked in front of a house with a fence and plants visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.429, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 6.471}, "timestamp": "2026-01-19T13:52:07.846936"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2121.837, "latencies_ms": [2121.837], "images_per_second": 0.471, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A calico cat is resting on the hood of a black Mercedes-Benz parked near a house. The car is parked in front of a green bush with yellow flowers.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.145, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.397}, "timestamp": "2026-01-19T13:52:11.986956"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1785.036, "latencies_ms": [1785.036], "images_per_second": 0.56, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The car is black and appears to be made of metal. The lighting suggests it might be daytime. The cat is orange and white and appears to be relaxed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.987, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.228}, "timestamp": "2026-01-19T13:52:15.812036"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1964.781, "latencies_ms": [1964.781], "images_per_second": 0.509, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A snowboarder in a brown jacket and yellow pants is captured mid-air, performing a trick against a clear blue sky and snow-covered slope.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.466, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.84}, "timestamp": "2026-01-19T13:52:19.804338"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2930.755, "latencies_ms": [2930.755], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "snowboard: 1\nsnow: 1\nsky: 1\nclouds: 0\nperson: 1\ngloves: 1\nhelmet: 1\npants: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.056, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.026}, "timestamp": "2026-01-19T13:52:24.748554"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2549.156, "latencies_ms": [2549.156], "images_per_second": 0.392, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The snowboarder is positioned in the foreground, mid-air, against a clear blue sky. The snowboard is situated in the background, slightly elevated above the snow. The snowboarder is angled towards the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.406, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T13:52:29.333287"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2193.214, "latencies_ms": [2193.214], "images_per_second": 0.456, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A snowboarder is captured mid-air, performing a trick against a clear blue sky. The scene takes place on a snow-covered slope, emphasizing the winter sports aspect.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.062, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:52:33.544819"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2192.3, "latencies_ms": [2192.3], "images_per_second": 0.456, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The snowboarder is wearing a brown jacket and yellow pants. The sky is clear and blue, indicating sunny weather. The snowboard is white and appears to be made of foam or plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.78, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T13:52:37.790164"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1903.934, "latencies_ms": [1903.934], "images_per_second": 0.525, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The bathroom features a vintage-style toilet with a wooden seat and a white tank, situated beneath a white pipe system against a white wall.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.546, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T13:52:41.748387"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3030.53, "latencies_ms": [3030.53], "images_per_second": 0.33, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Toilet: 1\nBathtub: 1\nPipes: 6\nChain: 1\nPaper: 1\nFloor: 1\nWalls: 2\nDoor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.945, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.08}, "timestamp": "2026-01-19T13:52:46.801132"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1825.578, "latencies_ms": [1825.578], "images_per_second": 0.548, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, slightly to the left of the bathtub. The bathtub is situated in the background, further away from the toilet.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.941, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T13:52:50.656915"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2892.206, "latencies_ms": [2892.206], "images_per_second": 0.346, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The bathroom features a vintage-style toilet with a wooden seat and a chain hanging from the tank. A white bathtub is situated next to the toilet, partially obscured by pipes. The space appears to be in a basement or attic area, with exposed pipes and aged fixtures.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.04, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.038}, "timestamp": "2026-01-19T13:52:55.591074"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3077.006, "latencies_ms": [3077.006], "images_per_second": 0.325, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The bathroom features a predominantly white color scheme, accented by rust-colored tiles on the floor. The lighting is minimal, relying on natural light from the small window above the toilet. The materials appear to be old and possibly made of wood or plaster, giving the space a somewhat rustic feel.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.798, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.027}, "timestamp": "2026-01-19T13:53:00.694091"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1970.948, "latencies_ms": [1970.948], "images_per_second": 0.507, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The statue depicts two children, one standing and one kneeling, holding a colorful kite that soars high above them, symbolizing freedom and joy.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.424, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.835}, "timestamp": "2026-01-19T13:53:04.707734"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2338.568, "latencies_ms": [2338.568], "images_per_second": 0.428, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "kite: 1\nstatue: 2\nbuilding: 1\nsky: 1\nclouds: 1\nreflection: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.846, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 7.013}, "timestamp": "2026-01-19T13:53:09.091350"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1955.907, "latencies_ms": [1955.907], "images_per_second": 0.511, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The statue is positioned in the foreground, slightly to the right of the kite. The kite is situated in the background, slightly above and to the right of the statue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.785, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.84}, "timestamp": "2026-01-19T13:53:13.066091"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2132.498, "latencies_ms": [2132.498], "images_per_second": 0.469, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two children in costumes are flying a colorful kite on a pedestal in front of a modern glass and steel building. The scene suggests a playful and joyful atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.201, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T13:53:17.230036"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3022.896, "latencies_ms": [3022.896], "images_per_second": 0.331, "prompt_tokens": 18, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The kite is multicolored with stripes of yellow, blue, and red. The lighting in the image is soft and diffused, suggesting an overcast sky. The statue appears to be made of a light-colored material, possibly stone or concrete. The overall atmosphere is serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.881, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 7.12}, "timestamp": "2026-01-19T13:53:22.305016"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2420.011, "latencies_ms": [2420.011], "images_per_second": 0.413, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A wooden table displays a vibrant array of fresh produce, including red radishes, green asparagus, purple cabbage, carrots, potatoes, cucumbers, broccoli, strawberries, and green beans.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.972, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 7.024}, "timestamp": "2026-01-19T13:53:26.789001"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3108.825, "latencies_ms": [3108.825], "images_per_second": 0.322, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "strawberries: 10\nbroccoli: 2\ncucumbers: 2\nasparagus: 1\nradishes: 8\npeas: 1\ncarrots: 4\npotatoes: 4", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.882, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.071}, "timestamp": "2026-01-19T13:53:31.913612"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1845.29, "latencies_ms": [1845.29], "images_per_second": 0.542, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The strawberries are positioned to the left of the vegetables, closer to the viewer. The vegetables are spread out across the foreground and background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.706, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.773}, "timestamp": "2026-01-19T13:53:35.800097"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2845.512, "latencies_ms": [2845.512], "images_per_second": 0.351, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene depicts a vibrant display of fresh produce, including strawberries, broccoli, carrots, radishes, asparagus, and potatoes. The produce is arranged on a wooden surface, possibly a table or countertop, showcasing a colorful and healthy assortment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.956, "power_cpu_cv_mean_watts": 1.586, "power_sys_5v0_mean_watts": 7.026}, "timestamp": "2026-01-19T13:53:40.686216"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2475.128, "latencies_ms": [2475.128], "images_per_second": 0.404, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The produce displays vibrant colors, including reds, greens, and oranges. The lighting appears to be natural, possibly from overhead, suggesting an outdoor setting. The vegetables appear to be fresh and crisp, indicating good quality and care in preparation.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.506, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T13:53:45.201099"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1701.686, "latencies_ms": [1701.686], "images_per_second": 0.588, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Three people are sitting on a bed in a dimly lit room, laughing and playing a video game using Wii remotes.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.796, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.823}, "timestamp": "2026-01-19T13:53:48.940561"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2569.01, "latencies_ms": [2569.01], "images_per_second": 0.389, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "projector: 1\nscreen: 1\nwii controllers: 2\ncouch: 2\nman: 3\nman: 2\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.538, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.017}, "timestamp": "2026-01-19T13:53:53.552973"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2040.614, "latencies_ms": [2040.614], "images_per_second": 0.49, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the projection screen and remote control placed further back. The couch and bed are situated in the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.508, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T13:53:57.619888"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2023.426, "latencies_ms": [2023.426], "images_per_second": 0.494, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Three people are gathered in a dimly lit room, watching a video game on a projector. They are comfortably seated on a couch and bed, each holding a game controller.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.374, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T13:54:01.702055"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2768.556, "latencies_ms": [2768.556], "images_per_second": 0.361, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The room is dimly lit, creating a moody atmosphere. The walls appear to be a light color, possibly white or off-white. The couch is covered in a multicolored, patterned fabric. The overall ambiance suggests a casual, relaxed setting.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.277, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.037}, "timestamp": "2026-01-19T13:54:06.490345"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1613.314, "latencies_ms": [1613.314], "images_per_second": 0.62, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A group of cows, including white, brown, and black ones, are resting and grazing peacefully in a lush green field.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.56, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 6.711}, "timestamp": "2026-01-19T13:54:10.133651"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2917.823, "latencies_ms": [2917.823], "images_per_second": 0.343, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "tree: 1\ncow: 5\nsheep: 1\ngrass: 8\ncow: 5\ncow: 1\ncow: 1\ncow: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.373, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.025}, "timestamp": "2026-01-19T13:54:15.065499"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2357.246, "latencies_ms": [2357.246], "images_per_second": 0.424, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The foreground features a young lamb resting under the shade of a tree, positioned between the foreground and the background. The background includes several cows lying down in the grassy field, extending from the foreground to the middle ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.868, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 7.024}, "timestamp": "2026-01-19T13:54:19.452590"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1793.537, "latencies_ms": [1793.537], "images_per_second": 0.558, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A group of cows, including some calves, are resting in a lush green field. A large tree trunk is visible near the animals, providing shade.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.883, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T13:54:23.277882"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2304.632, "latencies_ms": [2304.632], "images_per_second": 0.434, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The field is predominantly green with patches of sunlight filtering through the trees, creating a bright and peaceful atmosphere. The grass appears lush and well-maintained, contributing to the overall tranquility of the scene.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.865, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.912}, "timestamp": "2026-01-19T13:54:27.612920"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1855.02, "latencies_ms": [1855.02], "images_per_second": 0.539, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A large group of boys in uniform, sitting and standing together in front of a brick building, poses for a school photograph in April 1929.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.881, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T13:54:31.528347"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2946.909, "latencies_ms": [2946.909], "images_per_second": 0.339, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "group: 20\nboys: 20\nschool building: 10\nsitting: 10\nsocks: 10\nshoes: 10\njackets: 10\nsuits: 10", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.757, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T13:54:36.496900"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2302.126, "latencies_ms": [2302.126], "images_per_second": 0.434, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close and centered arrangement, with the boys sitting in the foreground and the brick building in the background. The photograph captures the students from the waist up, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.805, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.87}, "timestamp": "2026-01-19T13:54:40.827127"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2373.031, "latencies_ms": [2373.031], "images_per_second": 0.421, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A large group of boys, likely from the Goodmayes Boys' School, poses for a group photograph in April 1929. The photo captures the school building in the background and the boys sitting on the ground in front.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12511.0, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.594, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T13:54:45.238529"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2817.497, "latencies_ms": [2817.497], "images_per_second": 0.355, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The photograph is in black and white and appears to be taken outdoors in natural light. The students are wearing formal attire, including suits and ties. The building in the background suggests a school setting. The overall composition and style of the photograph indicate it was taken during an earlier era.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12511.0, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.198, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.047}, "timestamp": "2026-01-19T13:54:50.096258"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1384.315, "latencies_ms": [1384.315], "images_per_second": 0.722, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A rainbow-colored kite soars high in the sky above a lush green park.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.287, "power_cpu_cv_mean_watts": 1.019, "power_sys_5v0_mean_watts": 6.066}, "timestamp": "2026-01-19T13:54:53.532415"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1940.721, "latencies_ms": [1940.721], "images_per_second": 0.515, "prompt_tokens": 21, "response_tokens_est": 22, "n_tiles": 1, "output_text": "kite: 1\nperson: 1\ntrees: 4\nbuildings: 3\nsky: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.161, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.411}, "timestamp": "2026-01-19T13:54:57.526895"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2218.57, "latencies_ms": [2218.57], "images_per_second": 0.451, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The kite is positioned to the right of the image, flying above a grassy field. The background features trees and residential buildings, suggesting the kite is flying in a park or open space.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.371, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 6.54}, "timestamp": "2026-01-19T13:55:01.785030"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1868.3, "latencies_ms": [1868.3], "images_per_second": 0.535, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene is set in a park-like area with trees and houses in the background. A colorful kite is flying high in the sky, caught in the wind.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.454, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.316}, "timestamp": "2026-01-19T13:55:05.674879"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1603.63, "latencies_ms": [1603.63], "images_per_second": 0.624, "prompt_tokens": 18, "response_tokens_est": 22, "n_tiles": 1, "output_text": "The kite is brightly colored with a rainbow pattern. The lighting suggests a sunny day with potentially warm temperatures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.122, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.218}, "timestamp": "2026-01-19T13:55:09.311528"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1604.381, "latencies_ms": [1604.381], "images_per_second": 0.623, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A large cheese pizza with red sauce and melted cheese sits in a cardboard box on a black surface.", "error": null, "sys_before": {"cpu_percent": 6.1, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.992, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.577}, "timestamp": "2026-01-19T13:55:12.963173"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3464.761, "latencies_ms": [3464.761], "images_per_second": 0.289, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Pizza: 8\nCheese: 8\nTomato sauce: 8\nPepperoni: 8\nTomato sauce: 8\nCheese: 8\nSauce: 8\nBaking: 8\nBox: 8", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.421, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.07}, "timestamp": "2026-01-19T13:55:18.465838"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1696.774, "latencies_ms": [1696.774], "images_per_second": 0.589, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The main object, the pizza, is positioned in the foreground of the image. The pizza box is situated in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.361, "power_cpu_cv_mean_watts": 1.386, "power_sys_5v0_mean_watts": 6.846}, "timestamp": "2026-01-19T13:55:22.195060"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2068.223, "latencies_ms": [2068.223], "images_per_second": 0.484, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A large cheese pizza sits in a cardboard box on a dark surface. The pizza is cut into eight slices and appears freshly baked, with melted cheese covering the crust.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.674, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 6.942}, "timestamp": "2026-01-19T13:55:26.284030"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2457.026, "latencies_ms": [2457.026], "images_per_second": 0.407, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The pizza is topped with melted cheese and has a golden-brown crust. The cheese appears slightly browned, indicating it has been cooked. The lighting in the image is bright, highlighting the colors and textures of the pizza.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.906, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 7.04}, "timestamp": "2026-01-19T13:55:30.759811"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1756.797, "latencies_ms": [1756.797], "images_per_second": 0.569, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Two women are sitting inside an open white refrigerator on a city sidewalk, one smoking a cigarette and the other holding a drink.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.625, "power_cpu_cv_mean_watts": 1.059, "power_sys_5v0_mean_watts": 6.637}, "timestamp": "2026-01-19T13:55:34.570556"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2788.937, "latencies_ms": [2788.937], "images_per_second": 0.359, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "woman: 2\nrefrigerator: 1\ncup: 2\ncigarette: 1\nwindow: 1\nstreet: 2\nsidewalk: 1\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.373, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.016}, "timestamp": "2026-01-19T13:55:39.415745"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2512.562, "latencies_ms": [2512.562], "images_per_second": 0.398, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The woman on the left is positioned in the foreground, leaning against the wall and holding a cigarette. The open refrigerator is situated in the background, slightly to the right of the woman. The street and buildings are visible in the background, suggesting an urban setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.504, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T13:55:43.963884"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2002.843, "latencies_ms": [2002.843], "images_per_second": 0.499, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Two women are sitting on a sidewalk outside a building, engaged in conversation. One woman is smoking a cigarette, while the other is sitting inside an open refrigerator.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.225, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.778}, "timestamp": "2026-01-19T13:55:47.987670"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2313.459, "latencies_ms": [2313.459], "images_per_second": 0.432, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The woman is wearing a brown jacket and dark blue jeans. The scene is lit by natural daylight, creating a warm ambiance. The presence of a beverage suggests a casual, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.508, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.859}, "timestamp": "2026-01-19T13:55:52.332174"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1479.3, "latencies_ms": [1479.3], "images_per_second": 0.676, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A man wearing a straw hat is preparing a meal of hot dogs on a silver tray.", "error": null, "sys_before": {"cpu_percent": 8.8, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.119, "power_cpu_cv_mean_watts": 0.947, "power_sys_5v0_mean_watts": 6.698}, "timestamp": "2026-01-19T13:55:55.863633"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2919.833, "latencies_ms": [2919.833], "images_per_second": 0.342, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "hot dog: 8\nbun: 8\ntray: 1\nman: 1\nhat: 1\ngrass: 1\nchair: 1\nsweatshirt: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.874, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.043}, "timestamp": "2026-01-19T13:56:00.803866"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1960.55, "latencies_ms": [1960.55], "images_per_second": 0.51, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main object is a person holding a tray of hot dogs. The tray is placed in the foreground, slightly to the right of the person. The background consists of grass and a white fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.676, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T13:56:04.800133"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2238.167, "latencies_ms": [2238.167], "images_per_second": 0.447, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A man is preparing hot dogs on a tray outdoors, likely at a picnic or outdoor gathering. He appears to be in a casual setting, possibly a backyard or park, with some grass visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.291, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.938}, "timestamp": "2026-01-19T13:56:09.091650"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2438.469, "latencies_ms": [2438.469], "images_per_second": 0.41, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The hot dogs are red and appear to be cooked on a tray. The lighting is bright, likely from sunlight, creating a warm and inviting atmosphere. The tray is made of aluminum foil, suggesting it is designed for easy handling and cleanup.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.741, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:56:13.551990"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1988.82, "latencies_ms": [1988.82], "images_per_second": 0.503, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The living room features a desk with a laptop, a chair, a couch, a bookshelf, a radiator, and a star decoration, creating a cozy and functional space.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.298, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.766}, "timestamp": "2026-01-19T13:56:17.613934"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2887.232, "latencies_ms": [2887.232], "images_per_second": 0.346, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "desk: 1\nlaptop: 1\nchair: 1\nbookshelf: 2\nbooks: 2\nheater: 1\ncouch: 1\nbags: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.037, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.009}, "timestamp": "2026-01-19T13:56:22.515909"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1797.868, "latencies_ms": [1797.868], "images_per_second": 0.556, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The desk and chair are positioned to the left of the couch, near the foreground. The bookshelf is located in the background, near the couch.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.083, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.782}, "timestamp": "2026-01-19T13:56:26.368277"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3000.47, "latencies_ms": [3000.47], "images_per_second": 0.333, "prompt_tokens": 19, "response_tokens_est": 68, "n_tiles": 1, "output_text": "The room appears to be a home office or study area. A desk with a laptop is positioned on the left side, while a bookshelf filled with books occupies the center. A couch with personal items, including a backpack and pillows, is situated on the right side. The room is dimly lit, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.825, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.022}, "timestamp": "2026-01-19T13:56:31.382233"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2285.687, "latencies_ms": [2285.687], "images_per_second": 0.438, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The room has neutral-colored walls and carpeting. The lighting appears to be soft and warm, creating a calm atmosphere. The furniture includes a desk with a laptop and a couch with blankets and bags.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.67, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.809}, "timestamp": "2026-01-19T13:56:35.691421"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1501.639, "latencies_ms": [1501.639], "images_per_second": 0.666, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Two majestic elephants stand in a grassy field, their trunks intertwined in a gentle interaction.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.792, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.588}, "timestamp": "2026-01-19T13:56:39.221547"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2692.727, "latencies_ms": [2692.727], "images_per_second": 0.371, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "elephant: 2\ntrunk: 2\ntusks: 2\ngrass: 2\nleaves: 2\nbushes: 2\nhills: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.298, "power_cpu_cv_mean_watts": 1.512, "power_sys_5v0_mean_watts": 6.927}, "timestamp": "2026-01-19T13:56:43.951134"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2473.147, "latencies_ms": [2473.147], "images_per_second": 0.404, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main objects are positioned relatively close to the viewer, creating a sense of proximity and interaction. The foreground is dominated by the elephants, while the background features more vegetation and a hazy sky, suggesting the scene is situated in a relatively open area.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.906, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.03}, "timestamp": "2026-01-19T13:56:48.463197"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2026.161, "latencies_ms": [2026.161], "images_per_second": 0.494, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Two elephants are seen interacting in a grassy field with scattered trees and shrubs. The scene appears to be in a natural habitat, possibly a savanna or grassland.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.351, "power_cpu_cv_mean_watts": 1.177, "power_sys_5v0_mean_watts": 6.74}, "timestamp": "2026-01-19T13:56:52.521395"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2222.387, "latencies_ms": [2222.387], "images_per_second": 0.45, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The elephants are dark brown, contrasting with the light green vegetation. The lighting is soft and diffused, suggesting an overcast sky. The scene appears natural and peaceful.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.959, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.803}, "timestamp": "2026-01-19T13:56:56.770243"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2027.557, "latencies_ms": [2027.557], "images_per_second": 0.493, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A man is holding a white frisbee and a green bottle, possibly preparing to throw the frisbee during a game or practice session in a park.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12514.2, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.327, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.822}, "timestamp": "2026-01-19T13:57:00.859853"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3145.714, "latencies_ms": [3145.714], "images_per_second": 0.318, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "man: 1\nfrisbee: 1\nbottle: 1\nsunglasses: 1\nbelt: 1\nshorts: 1\ngrass: 1\ntrees: 2\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.314, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.108}, "timestamp": "2026-01-19T13:57:06.022291"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2249.209, "latencies_ms": [2249.209], "images_per_second": 0.445, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The man is positioned in the foreground, holding a frisbee and bottle, while another person can be seen in the background walking away. The frisbee and bottle are located close to the man, creating a sense of proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.382, "power_cpu_cv_mean_watts": 1.514, "power_sys_5v0_mean_watts": 7.028}, "timestamp": "2026-01-19T13:57:10.310699"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2466.042, "latencies_ms": [2466.042], "images_per_second": 0.406, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A man is playing frisbee in a park. He is shirtless and wearing khaki shorts, carrying a frisbee and a green bottle. Another person is visible in the background, walking across the grassy field.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.585, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T13:57:14.809366"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2550.689, "latencies_ms": [2550.689], "images_per_second": 0.392, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The man is shirtless and wearing khaki shorts. He holds a white frisbee and a green bottle in his hands. The scene takes place on a sunny day with a clear blue sky. The grass appears to be well-maintained.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.54, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T13:57:19.405111"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1888.087, "latencies_ms": [1888.087], "images_per_second": 0.53, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A young boy in a blue soccer jersey is cutting into a large chocolate cake designed to look like a skateboard, complete with wheels and flames.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.297, "power_cpu_cv_mean_watts": 1.389, "power_sys_5v0_mean_watts": 6.397}, "timestamp": "2026-01-19T13:57:23.323496"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2474.432, "latencies_ms": [2474.432], "images_per_second": 0.404, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "cake: 1\nknife: 1\nplates: 2\ntoys: 4\ntable: 2\nfoil: 1\ntablecloth: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.677, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 6.733}, "timestamp": "2026-01-19T13:57:27.824158"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2329.254, "latencies_ms": [2329.254], "images_per_second": 0.429, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The boy is positioned in the foreground, cutting the chocolate cake with a knife. The cake is placed on a table in the background, partially obscured by the boy. The table is situated near a wall, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.467, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.61}, "timestamp": "2026-01-19T13:57:32.217849"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2528.839, "latencies_ms": [2528.839], "images_per_second": 0.395, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A young boy in a blue soccer jersey is cutting a chocolate cake shaped like a skateboard on a table covered with a colorful tablecloth. The cake is decorated with chocolate wheels and flames, and small toy figures are scattered around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.717, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 6.779}, "timestamp": "2026-01-19T13:57:36.773410"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2314.238, "latencies_ms": [2314.238], "images_per_second": 0.432, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The cake is primarily dark brown with red and yellow accents. The lighting in the image is warm and soft, creating a pleasant atmosphere. The materials appear to be chocolate and fondant, and the weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.681, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.61}, "timestamp": "2026-01-19T13:57:41.120646"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1388.766, "latencies_ms": [1388.766], "images_per_second": 0.72, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Two zebras are standing close together, one in the foreground and the other partially visible in the background.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12516.0, "ram_available_mb": 50324.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.105, "power_cpu_cv_mean_watts": 1.02, "power_sys_5v0_mean_watts": 6.066}, "timestamp": "2026-01-19T13:57:44.555354"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2592.359, "latencies_ms": [2592.359], "images_per_second": 0.386, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "zebra: 2\nface: 2\neye: 2\nmouth: 1\nnose: 1\nhead: 1\nears: 1\nbody: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.655, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 6.681}, "timestamp": "2026-01-19T13:57:49.191765"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2347.577, "latencies_ms": [2347.577], "images_per_second": 0.426, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The zebra's head is positioned in the foreground, partially obscuring the background. The zebra is situated close to the viewer, suggesting proximity. The zebra's head is angled towards the viewer, further emphasizing its presence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.722, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 6.642}, "timestamp": "2026-01-19T13:57:53.594722"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1851.368, "latencies_ms": [1851.368], "images_per_second": 0.54, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two zebras are seen in a zoo enclosure, one in the foreground and the other partially visible in the background. The setting appears to be outdoors, with some greenery visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.269, "power_cpu_cv_mean_watts": 1.309, "power_sys_5v0_mean_watts": 6.377}, "timestamp": "2026-01-19T13:57:57.498209"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1936.24, "latencies_ms": [1936.24], "images_per_second": 0.516, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The zebra's coat is predominantly black and white. The lighting suggests a sunny day, and the materials appear to be natural, potentially dirt or grass. The weather appears to be pleasant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.456, "power_cpu_cv_mean_watts": 1.495, "power_sys_5v0_mean_watts": 6.484}, "timestamp": "2026-01-19T13:58:01.476667"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1672.52, "latencies_ms": [1672.52], "images_per_second": 0.598, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two trains are stationed at the La Spezia Centrale train station, Italy, as indicated by the sign above the platform.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.705, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.769}, "timestamp": "2026-01-19T13:58:05.197604"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2591.521, "latencies_ms": [2591.521], "images_per_second": 0.386, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "train: 2\nplatform: 2\nsign: 1\nbuildings: 2\npeople: 1\nmountains: 1\ntracks: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.426, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T13:58:09.815535"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2903.678, "latencies_ms": [2903.678], "images_per_second": 0.344, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The main objects are positioned in a spatial arrangement that suggests a central location or focus. The foreground is dominated by the platform and tracks, while the background features the station building and mountains in the distance. The train is situated further back, emphasizing the distance between the station and the train.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.09, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 7.11}, "timestamp": "2026-01-19T13:58:14.762211"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2642.952, "latencies_ms": [2642.952], "images_per_second": 0.378, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a train station in La Spezia, Centrale, Italy. A train is stationed on the tracks, waiting for passengers. The station features a covered platform and multiple train tracks, creating a functional and bustling environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.445, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:58:19.436802"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2569.737, "latencies_ms": [2569.737], "images_per_second": 0.389, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The train station is illuminated by overhead lights, creating a bright and welcoming atmosphere. The platform is made of brick, contrasting with the modern train cars. The black and white photograph captures the architectural details of the station and the train tracks.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.293, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T13:58:24.036027"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1843.036, "latencies_ms": [1843.036], "images_per_second": 0.543, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A woman in a black wetsuit sits on a red surfboard in the ocean, gazing out towards the horizon as the sun sets.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.884, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T13:58:27.928391"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2666.014, "latencies_ms": [2666.014], "images_per_second": 0.375, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "woman: 1\nsurfboard: 1\nwater: 1\nsky: 1\nclouds: 1\nsunset: 1\nmountains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.007, "power_cpu_cv_mean_watts": 1.512, "power_sys_5v0_mean_watts": 6.922}, "timestamp": "2026-01-19T13:58:32.628417"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2438.916, "latencies_ms": [2438.916], "images_per_second": 0.41, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The woman is positioned in the foreground of the image, close to the red surfboard. The ocean stretches behind her, occupying the majority of the background. The setting sun casts a warm glow over the scene, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.953, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T13:58:37.083527"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1922.311, "latencies_ms": [1922.311], "images_per_second": 0.52, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A woman is sitting on a red surfboard in the ocean at sunset. The sky is filled with clouds, and the water reflects the warm hues of the setting sun.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.627, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.84}, "timestamp": "2026-01-19T13:58:41.027443"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2955.517, "latencies_ms": [2955.517], "images_per_second": 0.338, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The sky is a mix of muted orange and gray, indicating a sunset or sunrise. The water appears dark and somewhat choppy, reflecting the colors of the sky. The woman is wearing a dark wetsuit, which contrasts with the warm hues of the sky and ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.092, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.068}, "timestamp": "2026-01-19T13:58:46.029847"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1980.429, "latencies_ms": [1980.429], "images_per_second": 0.505, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man and a woman are enjoying a meal of sushi and pastries while seated on a train, smiling and sharing a pleasant experience.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.326, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.709}, "timestamp": "2026-01-19T13:58:50.061800"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3040.739, "latencies_ms": [3040.739], "images_per_second": 0.329, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "man: 2\nwoman: 2\nchopsticks: 2\nfood: 3\ntable: 2\nsushi: 1\nplate: 1\nwindow: 1\ntrain: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.924, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T13:58:55.119510"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1948.907, "latencies_ms": [1948.907], "images_per_second": 0.513, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the man on the left and the woman on the right. The background is slightly blurred, suggesting they are situated further away.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.412, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.72}, "timestamp": "2026-01-19T13:58:59.108276"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2346.81, "latencies_ms": [2346.81], "images_per_second": 0.426, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A man and a woman are enjoying a meal together on a train. The meal consists of sushi rolls, meat, and vegetables. They are seated at a table with chopsticks, eating with plates in front of them.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.952, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.917}, "timestamp": "2026-01-19T13:59:03.475772"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3116.331, "latencies_ms": [3116.331], "images_per_second": 0.321, "prompt_tokens": 18, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The train's interior is primarily light-colored, possibly off-white or beige. The lighting appears to be soft and diffused, creating a calm atmosphere. The train's seats and surfaces appear to be made of a durable, light-colored material. The overall ambiance suggests a comfortable and pleasant travel experience.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.579, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 7.032}, "timestamp": "2026-01-19T13:59:08.626683"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1934.247, "latencies_ms": [1934.247], "images_per_second": 0.517, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two men in business attire, one in a white shirt and black tie and the other in a pink shirt and striped tie, walk down a city street at night.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.575, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.827}, "timestamp": "2026-01-19T13:59:12.609697"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2705.318, "latencies_ms": [2705.318], "images_per_second": 0.37, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "building: 2\nstreet: 2\ncrosswalk: 2\nman: 2\ncar: 1\nman: 1\ntie: 2\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.407, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.941}, "timestamp": "2026-01-19T13:59:17.353428"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1462.542, "latencies_ms": [1462.542], "images_per_second": 0.684, "prompt_tokens": 25, "response_tokens_est": 20, "n_tiles": 1, "output_text": "The two men are positioned in the foreground of the image, with the building and street behind them.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.938, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.616}, "timestamp": "2026-01-19T13:59:20.859760"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2714.669, "latencies_ms": [2714.669], "images_per_second": 0.368, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Two men in business attire are walking down a city street at night, passing a building with signage that says \"Hierro Y Alberto.\"  The scene is illuminated by streetlights, creating a nighttime ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.389, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T13:59:25.593976"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2177.772, "latencies_ms": [2177.772], "images_per_second": 0.459, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The men are wearing dark suits and ties. The scene is lit by streetlights, creating a nighttime ambiance. The buildings in the background are illuminated, contributing to the overall atmosphere.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.51, "power_cpu_cv_mean_watts": 1.579, "power_sys_5v0_mean_watts": 6.961}, "timestamp": "2026-01-19T13:59:29.786060"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1743.893, "latencies_ms": [1743.893], "images_per_second": 0.573, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A man in a gray shirt and glasses is standing behind a bar, holding a wine bottle and wiping it with a cloth.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.942, "power_cpu_cv_mean_watts": 1.345, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T13:59:33.586181"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3685.377, "latencies_ms": [3685.377], "images_per_second": 0.271, "prompt_tokens": 21, "response_tokens_est": 53, "n_tiles": 1, "output_text": "Wine bottle: 1\nWine glass: 1\nWine bottle: 1\nWine glass: 1\nWine bottle: 1\nWine glass: 1\nWine bottle: 1\nWine glass: 1\nWine bottle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.4, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.237, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 7.173}, "timestamp": "2026-01-19T13:59:39.312174"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2723.509, "latencies_ms": [2723.509], "images_per_second": 0.367, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The main object is a person standing at the bar, cleaning a wine bottle with a cloth. The wine bottle is positioned in the foreground, slightly to the right of the person. The bar counter and wine bottles are in the background, extending from the left to the right side of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.234, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.977}, "timestamp": "2026-01-19T13:59:44.076712"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2407.608, "latencies_ms": [2407.608], "images_per_second": 0.415, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A man is standing behind a bar, cleaning a wine bottle with a cloth. He appears to be in a wine tasting setting, with wine bottles and glasses visible on the bar. The atmosphere seems relaxed and casual.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12515.8, "ram_available_mb": 50325.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.911, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T13:59:48.515558"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2459.239, "latencies_ms": [2459.239], "images_per_second": 0.407, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The wine bottles are predominantly dark colors, possibly red or brown. The lighting in the scene is warm and inviting, creating a cozy atmosphere. The wooden bar counter and shelving unit contribute to the overall aesthetic of the setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12515.8, "ram_available_mb": 50325.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.586, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T13:59:53.022094"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2143.051, "latencies_ms": [2143.051], "images_per_second": 0.467, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A tennis player, dressed in white, is captured mid-swing with a blue and white racket, poised to strike a yellow tennis ball in the air.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.129, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T13:59:57.236245"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3153.211, "latencies_ms": [3153.211], "images_per_second": 0.317, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 4\nTennis player: 1\nTennis shirt: 1\nTennis shorts: 1\nTennis wristbands: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.728, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.04}, "timestamp": "2026-01-19T14:00:02.432550"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1982.497, "latencies_ms": [1982.497], "images_per_second": 0.504, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground, preparing to hit the tennis ball. The tennis court extends into the background, creating a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.2, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.829}, "timestamp": "2026-01-19T14:00:06.467251"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2347.829, "latencies_ms": [2347.829], "images_per_second": 0.426, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A tennis player is executing a forehand shot on a grass court, showcasing their skill and athleticism. The green grass court with white boundary lines provides a vibrant backdrop for the action.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.634, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.859}, "timestamp": "2026-01-19T14:00:10.859178"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2156.579, "latencies_ms": [2156.579], "images_per_second": 0.464, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The tennis player is wearing a white shirt and shorts. The grass court is well-maintained and appears to be sunny. The player is holding a blue and white tennis racket.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.979, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.803}, "timestamp": "2026-01-19T14:00:15.072554"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1886.738, "latencies_ms": [1886.738], "images_per_second": 0.53, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white and orange cat is perched atop a wooden TV stand, attentively watching a television screen displaying a man's face.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.571, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T14:00:18.998214"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2738.821, "latencies_ms": [2738.821], "images_per_second": 0.365, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "cat: 1\ntelevision: 1\ndvd player: 1\ncable box: 1\ncup: 1\ntable: 1\nshelf: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.261, "power_cpu_cv_mean_watts": 1.493, "power_sys_5v0_mean_watts": 6.927}, "timestamp": "2026-01-19T14:00:23.760849"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1929.482, "latencies_ms": [1929.482], "images_per_second": 0.518, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the television and DVD player. The television and DVD player are situated in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.814, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:00:27.739822"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2513.186, "latencies_ms": [2513.186], "images_per_second": 0.398, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A white and orange cat is perched atop a wooden TV stand, watching a television screen displaying a man's face. The TV stand is situated in a room with a yellow wall and a partially visible blue curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.506, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.935}, "timestamp": "2026-01-19T14:00:32.268618"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2523.98, "latencies_ms": [2523.98], "images_per_second": 0.396, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The cat is primarily white with orange markings. The lighting in the room appears to be soft and warm, creating a cozy atmosphere. The TV and entertainment center are made of wood and metal, contributing to the overall aesthetic of the space.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.666, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 7.015}, "timestamp": "2026-01-19T14:00:36.826499"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1709.609, "latencies_ms": [1709.609], "images_per_second": 0.585, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A blue circular sign with a white silhouette of a person walking with a child on a bicycle is mounted on a metal pole.", "error": null, "sys_before": {"cpu_percent": 8.8, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12516.0, "ram_available_mb": 50324.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.059, "power_cpu_cv_mean_watts": 1.017, "power_sys_5v0_mean_watts": 6.707}, "timestamp": "2026-01-19T14:00:40.591134"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2662.381, "latencies_ms": [2662.381], "images_per_second": 0.376, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "sign: 2\nbicycle: 1\npedestrian: 1\ntree: 1\nstreet light: 1\nmetal post: 1\nclear sky: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.151, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.996}, "timestamp": "2026-01-19T14:00:45.311921"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2594.391, "latencies_ms": [2594.391], "images_per_second": 0.385, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The sign is positioned in the foreground, partially obscured by the tree branches. The sign is situated near the top of a pole, further back from the tree. The sign is positioned further back from the pole, further away from the tree branches.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.52, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T14:00:49.926411"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2593.719, "latencies_ms": [2593.719], "images_per_second": 0.386, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene is set outdoors on a sunny day, with a blue circular sign featuring a bicycle symbol and a pedestrian symbol above a street sign with Chinese characters. The sign is mounted on a metal pole, partially obscured by tree branches.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.405, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:00:54.546998"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1820.156, "latencies_ms": [1820.156], "images_per_second": 0.549, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The sign is blue and white. The lighting is bright, likely from sunlight. The sign appears to be made of metal and has a weathered appearance.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.97, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.811}, "timestamp": "2026-01-19T14:00:58.410085"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1799.716, "latencies_ms": [1799.716], "images_per_second": 0.556, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young girl with black hair and yellow earrings is sitting at a wooden table in a restaurant, enjoying a slice of pizza.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12514.9, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.596, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.786}, "timestamp": "2026-01-19T14:01:02.266067"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3007.186, "latencies_ms": [3007.186], "images_per_second": 0.333, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Pizza: 2\nPizza pan: 1\nGlass of water: 1\nPaper napkin: 1\nBook: 1\nGirl: 1\nChair: 4\nTable: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.9, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.944, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.096}, "timestamp": "2026-01-19T14:01:07.290181"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2791.342, "latencies_ms": [2791.342], "images_per_second": 0.358, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The girl is positioned in the foreground of the image, sitting at a table with a partially eaten pizza and a glass of water. The table is situated near a window, which provides natural light to the scene. The background features additional tables and chairs, indicating a restaurant setting.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.644, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.12}, "timestamp": "2026-01-19T14:01:12.098730"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2557.841, "latencies_ms": [2557.841], "images_per_second": 0.391, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A young girl with braided hair is seated at a wooden table in a restaurant, enjoying a slice of pizza and a glass of water. The restaurant has a casual atmosphere with wooden chairs and tables, and several other people can be seen in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.464, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T14:01:16.691681"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2201.827, "latencies_ms": [2201.827], "images_per_second": 0.454, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The restaurant has a warm ambiance with wooden furniture and dim lighting. Visible colors include browns, yellows, and greens from the food. The atmosphere appears cozy and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.894, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T14:01:20.933769"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2028.097, "latencies_ms": [2028.097], "images_per_second": 0.493, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A table is set with plates of food, bowls of vegetables, bread rolls, a glass of water, and a spoon, indicating a meal preparation or serving scene.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.402, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T14:01:25.005914"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3402.643, "latencies_ms": [3402.643], "images_per_second": 0.294, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "broccoli: 2\ncauliflower: 2\ncarrots: 1\ncorn: 1\ncasserole: 1\nbread rolls: 2\nwater: 1\naluminum foil: 1\nplate: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.453, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 7.084}, "timestamp": "2026-01-19T14:01:30.436170"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2696.276, "latencies_ms": [2696.276], "images_per_second": 0.371, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The broccoli, cauliflower, and bread are placed in the foreground, while the plates of food and the utensils are situated in the background. The arrangement suggests a casual, home-cooked meal.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.39, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.037}, "timestamp": "2026-01-19T14:01:35.177075"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3520.697, "latencies_ms": [3520.697], "images_per_second": 0.284, "prompt_tokens": 19, "response_tokens_est": 79, "n_tiles": 1, "output_text": "The scene depicts a kitchen counter with various food items and utensils. A large bowl of broccoli and cauliflower is prominently displayed, along with a plate of rice and broccoli. A glass of water and a spoon are also visible on the counter, along with a bowl of what appears to be bread rolls and a container of salad. The overall setting suggests a casual, home-cooked meal.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.375, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 7.157}, "timestamp": "2026-01-19T14:01:40.728605"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3098.715, "latencies_ms": [3098.715], "images_per_second": 0.323, "prompt_tokens": 18, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The food is brightly colored, predominantly orange and green. The lighting is soft and diffused, creating a warm and inviting atmosphere. The dishes appear to be made of metal and glass, reflecting the ambient light. The setting suggests a casual, home-cooked meal, possibly in a kitchen or dining area.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.821, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.071}, "timestamp": "2026-01-19T14:01:45.855742"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2016.616, "latencies_ms": [2016.616], "images_per_second": 0.496, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A green and white bus is stopped at a traffic light on a busy city street, with several cars waiting behind it and a person walking on the sidewalk nearby.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.424, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T14:01:49.923167"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2984.588, "latencies_ms": [2984.588], "images_per_second": 0.335, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "street sign: 1\nbus: 1\ncar: 2\ntruck: 1\nvan: 1\ntree: 2\nbuildings: 5\ncars: 5\nperson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.92, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.144}, "timestamp": "2026-01-19T14:01:54.946445"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2515.232, "latencies_ms": [2515.232], "images_per_second": 0.398, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The foreground features a street intersection with several vehicles, including a red car, a bus, and a truck. The background showcases tall buildings and a street sign. The left side of the image shows an urban setting with trees and a sidewalk.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.381, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.924}, "timestamp": "2026-01-19T14:01:59.488655"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2638.699, "latencies_ms": [2638.699], "images_per_second": 0.379, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a busy city street with several vehicles, including a bus, cars, and a truck, navigating through traffic. Pedestrians are walking on the sidewalk, and trees line the street, adding greenery to the urban environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.23, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T14:02:04.151213"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2643.433, "latencies_ms": [2643.433], "images_per_second": 0.378, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene is dominated by various colors, including red, green, and white. The lighting appears to be natural daylight, creating a pleasant atmosphere. The buildings in the background are primarily brick and feature large windows. The overall setting suggests a bustling urban environment.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.441, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 7.022}, "timestamp": "2026-01-19T14:02:08.836741"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1654.703, "latencies_ms": [1654.703], "images_per_second": 0.604, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A black Toshiba laptop is open on a white table, accompanied by a smartphone, a small microphone, and a red shirt in the background.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.336, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 6.241}, "timestamp": "2026-01-19T14:02:12.551350"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2494.622, "latencies_ms": [2494.622], "images_per_second": 0.401, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "laptop: 1\nphone: 1\ntripod: 1\nmicrophone: 1\ntable: 1\nperson: 1\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.414, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.602}, "timestamp": "2026-01-19T14:02:17.087566"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2241.425, "latencies_ms": [2241.425], "images_per_second": 0.446, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The laptop is positioned in the foreground, slightly to the right of the camera. The person's red shirt is partially visible in the background, near the laptop. The cell phone is situated near the laptop, slightly further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.259, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 6.518}, "timestamp": "2026-01-19T14:02:21.343109"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2517.414, "latencies_ms": [2517.414], "images_per_second": 0.397, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a workspace with a Toshiba laptop open on a table, accompanied by a smartphone, a small device, and a tripod. The laptop screen displays a Windows desktop, indicating a typical work or study environment.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.695, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 6.723}, "timestamp": "2026-01-19T14:02:25.915490"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1475.363, "latencies_ms": [1475.363], "images_per_second": 0.678, "prompt_tokens": 18, "response_tokens_est": 20, "n_tiles": 1, "output_text": "The laptop is black. The table is white. The phone is black. The background is dark.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.6, "ram_available_mb": 50325.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.068, "power_cpu_cv_mean_watts": 1.165, "power_sys_5v0_mean_watts": 6.167}, "timestamp": "2026-01-19T14:02:29.439495"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1945.828, "latencies_ms": [1945.828], "images_per_second": 0.514, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A desk with a computer setup, keyboard, mouse, books, papers, and a water bottle is situated near a window in an office.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.096, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T14:02:33.433006"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2901.07, "latencies_ms": [2901.07], "images_per_second": 0.345, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "computer monitor: 1\nkeyboard: 1\nlaptop: 1\nmouse: 1\nbooks: 5\nwater bottle: 1\ndesk: 2\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.937, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T14:02:38.360949"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2556.451, "latencies_ms": [2556.451], "images_per_second": 0.391, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main objects are positioned in a diagonal arrangement, with the computer monitor and keyboard located in the foreground. The books and laptop are placed in the background, near the window. The desk is situated near the window, offering a view of the building outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.503, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T14:02:42.939557"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3266.583, "latencies_ms": [3266.583], "images_per_second": 0.306, "prompt_tokens": 19, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The scene depicts a well-organized workspace with a desk featuring a computer setup, including a monitor, keyboard, mouse, and laptop. The desk is positioned near a window, offering natural light and possibly a view of an external building. Various books and office supplies are present on the desk, indicating a studious environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.79, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.11}, "timestamp": "2026-01-19T14:02:48.220680"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2428.711, "latencies_ms": [2428.711], "images_per_second": 0.412, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The desk is light beige or tan. The lighting appears to be natural daylight coming in through a window with blinds. The desk is equipped with a computer setup, including a monitor, keyboard, mouse, and laptop.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.741, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T14:02:52.684072"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2322.161, "latencies_ms": [2322.161], "images_per_second": 0.431, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A skateboarder wearing a black shirt and helmet is performing an impressive trick mid-air, flipping their skateboard while airborne above a crowd of onlookers.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.824, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 6.939}, "timestamp": "2026-01-19T14:02:57.063024"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2810.704, "latencies_ms": [2810.704], "images_per_second": 0.356, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "skateboard: 1\nhelmet: 1\ncamera: 1\nskateboarder: 1\nspectators: 6\nbarrier: 1\nbanners: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.216, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.086}, "timestamp": "2026-01-19T14:03:01.894715"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2593.612, "latencies_ms": [2593.612], "images_per_second": 0.386, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, performing a trick above a crowd of spectators. The skateboarder is relatively close to the spectators, suggesting they are close by. The background is filled with spectators watching the performance.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.804, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.032}, "timestamp": "2026-01-19T14:03:06.517471"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2301.282, "latencies_ms": [2301.282], "images_per_second": 0.435, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A skateboarder is performing a trick mid-air, capturing the attention of spectators watching from behind a railing. The setting appears to be an indoor arena or stadium.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.078, "power_cpu_cv_mean_watts": 1.371, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:03:10.867379"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2881.867, "latencies_ms": [2881.867], "images_per_second": 0.347, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The skateboarder is wearing black clothing and a red and white helmet. The lighting is focused on the skateboarder, creating a dramatic effect. The skateboard appears to be made of wood and metal. The setting appears to be indoors, possibly in a large arena or stadium.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.207, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T14:03:15.769681"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2036.901, "latencies_ms": [2036.901], "images_per_second": 0.491, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "An orange fire hydrant, adorned with a smiley face and a bowtie, stands on a sidewalk next to a tree, with cars parked on the street in the background.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.06, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.859}, "timestamp": "2026-01-19T14:03:19.869193"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2764.773, "latencies_ms": [2764.773], "images_per_second": 0.362, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "hydrant: 1\nstreet: 2\ncar: 2\ntree: 1\nbuildings: 2\ntrees: 2\nstreet: 2\nsidewalk: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.038, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.981}, "timestamp": "2026-01-19T14:03:24.679710"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1904.489, "latencies_ms": [1904.489], "images_per_second": 0.525, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The fire hydrant is positioned in the foreground, slightly to the right of the viewer. The street and sidewalk are in the background, with the cars parked further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.466, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.773}, "timestamp": "2026-01-19T14:03:28.609418"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2492.514, "latencies_ms": [2492.514], "images_per_second": 0.401, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "An orange fire hydrant with a smiley face and bowtie is situated on a sidewalk next to a tree and street. Parked cars are visible in the background, indicating a typical urban street setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.586, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 6.97}, "timestamp": "2026-01-19T14:03:33.117977"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1969.736, "latencies_ms": [1969.736], "images_per_second": 0.508, "prompt_tokens": 18, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The fire hydrant is bright orange, contrasting with the surrounding grey asphalt and concrete. The image is well-lit, suggesting sunny weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.274, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.785}, "timestamp": "2026-01-19T14:03:37.119175"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1676.191, "latencies_ms": [1676.191], "images_per_second": 0.597, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A green cart loaded with old suitcases in various sizes and colors is positioned in front of a green building.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.996, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.676}, "timestamp": "2026-01-19T14:03:40.858201"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2565.152, "latencies_ms": [2565.152], "images_per_second": 0.39, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "suitcase: 8\ncart: 8\nbicycle: 1\nposter: 1\ndoor: 1\nfloor: 1\nwall: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.206, "power_cpu_cv_mean_watts": 1.823, "power_sys_5v0_mean_watts": 6.965}, "timestamp": "2026-01-19T14:03:45.448973"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2894.799, "latencies_ms": [2894.799], "images_per_second": 0.345, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The suitcases are stacked in a somewhat haphazard manner, occupying the foreground of the image. The green cart is positioned in the background, partially obscured by the suitcases. The suitcases are positioned in front of a green door, suggesting they are being transported or moved.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.06, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T14:03:50.371312"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3065.282, "latencies_ms": [3065.282], "images_per_second": 0.326, "prompt_tokens": 19, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The scene depicts a vintage luggage cart loaded with several suitcases and trunks, positioned in front of a green building. A young girl is visible in the background, possibly observing the luggage. The setting suggests a travel or transportation hub, possibly a train station or a vintage luggage shop.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.153, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.108}, "timestamp": "2026-01-19T14:03:55.460323"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2518.271, "latencies_ms": [2518.271], "images_per_second": 0.397, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The luggage is primarily a mix of brown, blue, and green colors. The lighting appears to be natural, possibly from daylight, creating a warm and inviting atmosphere. The luggage appears to be made of sturdy materials, suggesting vintage or antique construction.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.603, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.965}, "timestamp": "2026-01-19T14:04:00.017326"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1651.902, "latencies_ms": [1651.902], "images_per_second": 0.605, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A young girl in a pink dress is sitting on a brown couch, holding a white Wii remote and appearing focused.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.089, "power_cpu_cv_mean_watts": 1.079, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T14:04:03.703124"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2614.663, "latencies_ms": [2614.663], "images_per_second": 0.382, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "girl: 1\ndress: 1\ncouch: 1\nwindow blinds: 2\ncontroller: 1\nwii: 1\ncamera: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.388, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T14:04:08.338872"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2220.099, "latencies_ms": [2220.099], "images_per_second": 0.45, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The girl is positioned near the foreground of the image, standing on a couch. She is holding a Wii remote in her right hand. The couch is situated in the background, extending from left to right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.248, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T14:04:12.599485"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2174.173, "latencies_ms": [2174.173], "images_per_second": 0.46, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A young girl is sitting on a brown couch, holding a white Wii remote and appearing to play a video game. She is wearing a pink dress and is positioned in front of a window with closed blinds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.18, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T14:04:16.793966"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2784.024, "latencies_ms": [2784.024], "images_per_second": 0.359, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The girl is wearing a pink dress with brown floral patterns. The lighting in the room is soft and diffused, suggesting natural light from a window. The couch appears to be upholstered in a neutral fabric. The overall atmosphere is calm and relaxed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.2, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.095, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T14:04:21.620914"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2225.577, "latencies_ms": [2225.577], "images_per_second": 0.449, "prompt_tokens": 8, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A sleek glass and metal desk is set up in a room with a window, holding an open laptop, a keyboard, a mouse, a jar, a pair of headphones, and a computer tower.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12512.2, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.96, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T14:04:25.898276"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4035.111, "latencies_ms": [4035.111], "images_per_second": 0.248, "prompt_tokens": 21, "response_tokens_est": 56, "n_tiles": 1, "output_text": "laptop: 1\nkeyboard: 2\nmouse: 1\nheadphones: 1\nglass jar: 1\ntrash can: 1\ncomputer tower: 1\ndesk: 2\nchair: 1\nfloor: 1\nwindow: 1\nheater: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.117, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.13}, "timestamp": "2026-01-19T14:04:31.953827"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2696.695, "latencies_ms": [2696.695], "images_per_second": 0.371, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close-knit arrangement, with the desk and chair in the foreground and the computer tower and keyboard in the background. The desk and chair are situated close to the window, which suggests a bright and airy workspace.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.112, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T14:04:36.673399"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2537.408, "latencies_ms": [2537.408], "images_per_second": 0.394, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene depicts a home office setup with a desk, laptop, keyboard, mouse, headphones, and a computer tower. A trash can and computer peripherals are also present. The room is illuminated by natural light from a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.027, "power_cpu_cv_mean_watts": 1.563, "power_sys_5v0_mean_watts": 7.121}, "timestamp": "2026-01-19T14:04:41.249132"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2488.79, "latencies_ms": [2488.79], "images_per_second": 0.402, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The desk is primarily made of clear glass and silver metal. The lighting in the room appears to be natural light from a window, creating a bright and airy atmosphere. The desk is situated in a room with wooden flooring.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.726, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.924}, "timestamp": "2026-01-19T14:04:45.757581"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2122.324, "latencies_ms": [2122.324], "images_per_second": 0.471, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A person is enjoying a freshly made pizza topped with pepperoni, mushrooms, green peppers, and onions, served on a white plate with a red and white checkered tablecloth.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.178, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.789}, "timestamp": "2026-01-19T14:04:49.918325"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3169.955, "latencies_ms": [3169.955], "images_per_second": 0.315, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Pizza: 8\nPepperoni: 2\nMushrooms: 4\nGreen peppers: 4\nTomato: 1\nCheese: 1\nSausage: 1\nFork: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.732, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.098}, "timestamp": "2026-01-19T14:04:55.101158"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2156.629, "latencies_ms": [2156.629], "images_per_second": 0.464, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The pizza is positioned in the foreground of the image, with the person's hand and fork visible in the background. The table and checkered tablecloth are placed in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.026, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 6.882}, "timestamp": "2026-01-19T14:04:59.301836"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2306.34, "latencies_ms": [2306.34], "images_per_second": 0.434, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A person is enjoying a freshly made pizza topped with pepperoni, mushrooms, green peppers, and bell peppers. The pizza is served on a white plate on a red and white checkered tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.4, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.678, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:05:03.650409"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2958.036, "latencies_ms": [2958.036], "images_per_second": 0.338, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The pizza is topped with vibrant red sauce, melted cheese, and several green bell peppers. The lighting is warm and inviting, enhancing the colors and textures of the toppings. The pizza appears to be made of traditional ingredients like tomato sauce, cheese, mushrooms, and bell peppers.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.4, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.992, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.03}, "timestamp": "2026-01-19T14:05:08.651638"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1877.557, "latencies_ms": [1877.557], "images_per_second": 0.533, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white and red Metropolitan Transit System bus is parked on the side of the road, carrying passengers and displaying a destination sign.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.788, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.861}, "timestamp": "2026-01-19T14:05:12.592320"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2624.905, "latencies_ms": [2624.905], "images_per_second": 0.381, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "bus: 5\ntree: 1\nbuilding: 2\nwindow: 4\nsign: 1\nbaby: 1\nman: 1\nwoman: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12511.9, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.153, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T14:05:17.263355"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1833.125, "latencies_ms": [1833.125], "images_per_second": 0.546, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, slightly to the right of the image. The building in the background is further back, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12511.9, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.974, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T14:05:21.158462"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2230.325, "latencies_ms": [2230.325], "images_per_second": 0.448, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A white and red Metropolitan Transit System bus is parked near a tall building, with people visible inside and outside the bus. The scene suggests a typical urban environment with a transit system.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.604, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:05:25.414859"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2229.184, "latencies_ms": [2229.184], "images_per_second": 0.449, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The bus is primarily white with red accents. The lighting appears to be natural daylight, creating a bright and pleasant atmosphere. The bus appears to be modern in design, constructed from metal and glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.651, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.078}, "timestamp": "2026-01-19T14:05:29.659631"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1286.616, "latencies_ms": [1286.616], "images_per_second": 0.777, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A baseball glove and cap rest on the ground, positioned next to each other.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.133, "power_cpu_cv_mean_watts": 0.921, "power_sys_5v0_mean_watts": 5.947}, "timestamp": "2026-01-19T14:05:32.987172"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2453.091, "latencies_ms": [2453.091], "images_per_second": 0.408, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "baseball cap: 1\nbaseball glove: 1\nbaseball: 1\nfence post: 1\nground: 1\nsand: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.457, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 6.597}, "timestamp": "2026-01-19T14:05:37.454370"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1942.062, "latencies_ms": [1942.062], "images_per_second": 0.515, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The baseball glove and cap are positioned close to the ground, close to the right edge of the image. The glove is partially obscured by the cap, lying in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.3, "ram_available_mb": 50329.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.456, "power_cpu_cv_mean_watts": 1.495, "power_sys_5v0_mean_watts": 6.531}, "timestamp": "2026-01-19T14:05:41.427924"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2024.438, "latencies_ms": [2024.438], "images_per_second": 0.494, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A baseball glove and cap rest on the ground near a metal pole, likely at a baseball field. The scene suggests a moment of anticipation or preparation for a game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.114, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.426}, "timestamp": "2026-01-19T14:05:45.482417"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1858.31, "latencies_ms": [1858.31], "images_per_second": 0.538, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The baseball cap is navy blue, and the glove is tan and leather-like. The lighting suggests it might be sunny, and the ground appears to be dirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.267, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.404}, "timestamp": "2026-01-19T14:05:49.383951"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1890.544, "latencies_ms": [1890.544], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A surfer in a red shirt skillfully rides a wave on a white surfboard with green stripes, showcasing their expertise in surfing.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.028, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.827}, "timestamp": "2026-01-19T14:05:53.334070"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2326.421, "latencies_ms": [2326.421], "images_per_second": 0.43, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "surfboard: 1\nperson: 1\nwaves: 2\nwater: 1\nsky: 1\nsurfboard: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.889, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T14:05:57.702777"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2606.759, "latencies_ms": [2606.759], "images_per_second": 0.384, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave. The wave is further in the background, creating a sense of distance between the surfer and the wave. The surfer is relatively close to the wave, suggesting they are actively surfing it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.48, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.931}, "timestamp": "2026-01-19T14:06:02.348360"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2150.525, "latencies_ms": [2150.525], "images_per_second": 0.465, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A surfer in a red rash guard skillfully rides a wave on a yellow and white surfboard. The ocean is a vibrant turquoise color, creating a dynamic and energetic atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.177, "power_cpu_cv_mean_watts": 1.273, "power_sys_5v0_mean_watts": 6.788}, "timestamp": "2026-01-19T14:06:06.524154"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2177.846, "latencies_ms": [2177.846], "images_per_second": 0.459, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The water is a vibrant turquoise color, creating a striking contrast with the white and green surfboard. The lighting suggests a sunny day with bright, natural light illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.965, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.872}, "timestamp": "2026-01-19T14:06:10.722932"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1603.705, "latencies_ms": [1603.705], "images_per_second": 0.624, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A pristine white toilet is positioned next to a granite countertop sink in a clean, minimalist bathroom.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.014, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 6.174}, "timestamp": "2026-01-19T14:06:14.382132"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3242.684, "latencies_ms": [3242.684], "images_per_second": 0.308, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "toilet: 1\nsink: 1\nmirror: 1\nleaf: 1\nfaucet: 1\nsoap dispenser: 1\ntoilet brush: 1\ntoilet paper: 3", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.661, "power_cpu_cv_mean_watts": 1.825, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T14:06:19.642093"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1830.519, "latencies_ms": [1830.519], "images_per_second": 0.546, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The toilet is positioned to the left of the sink, which is situated in the background. The toilet and sink are located close together, creating a functional and compact bathroom layout.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.5, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 6.393}, "timestamp": "2026-01-19T14:06:23.512989"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2118.191, "latencies_ms": [2118.191], "images_per_second": 0.472, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The black and white image shows a bathroom setting with a toilet, sink, and tiled walls. A leaf-shaped object rests on the countertop, and a roll of toilet paper is visible on the floor.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.239, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.47}, "timestamp": "2026-01-19T14:06:27.645234"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2093.14, "latencies_ms": [2093.14], "images_per_second": 0.478, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The bathroom features a black and white color scheme, illuminated by natural light coming in from the window. The walls are tiled with stone-like tiles, and the floor is dark and shiny.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.403, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.522}, "timestamp": "2026-01-19T14:06:31.757902"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1998.905, "latencies_ms": [1998.905], "images_per_second": 0.5, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A white clock tower with a green dome and clock face is situated atop a red-tiled roof, partially obscured by a decorative white structure.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.425, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T14:06:35.819342"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2461.131, "latencies_ms": [2461.131], "images_per_second": 0.406, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "gazebo: 2\nbell tower: 1\nclock: 1\nroof tiles: 8\ntrees: 2\nclear sky: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.646, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.975}, "timestamp": "2026-01-19T14:06:40.324199"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2831.513, "latencies_ms": [2831.513], "images_per_second": 0.353, "prompt_tokens": 25, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The white clock tower is positioned in the foreground, slightly to the right of the gazebo. The gazebo is situated in the background, extending across the entire width of the image. The clock tower and gazebo are separated by a distance, emphasizing the spatial relationship between the two structures.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.236, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.099}, "timestamp": "2026-01-19T14:06:45.195177"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2273.441, "latencies_ms": [2273.441], "images_per_second": 0.44, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene is set in a historic area, featuring a white clock tower with a green dome and ornate metalwork on a rooftop. The clock tower is surrounded by lush green trees under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.338, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:06:49.484128"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3215.086, "latencies_ms": [3215.086], "images_per_second": 0.311, "prompt_tokens": 18, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The building features a distinctive blue dome roof and clock tower, contrasting with the clear, bright blue sky. The roof is made of terracotta tiles, adding a warm and rustic touch to the structure. The clock tower is white and appears to be made of solid white material, complementing the overall aesthetic.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.594, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.067}, "timestamp": "2026-01-19T14:06:54.759465"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1497.177, "latencies_ms": [1497.177], "images_per_second": 0.668, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A group of elephants, including one in the foreground, is seen walking along a dirt path surrounded by trees and bushes.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.56, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.619}, "timestamp": "2026-01-19T14:06:58.289627"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2562.462, "latencies_ms": [2562.462], "images_per_second": 0.39, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "elephant: 5\ntusk: 2\ntrunk: 1\nears: 4\nbody: 6\nhair: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.139, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.883}, "timestamp": "2026-01-19T14:07:02.881287"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2318.997, "latencies_ms": [2318.997], "images_per_second": 0.431, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The elephant in the foreground is positioned to the left of the image, drawing the viewer's attention to its presence. The elephants in the background are slightly out of focus, creating a sense of depth and distance between the foreground and the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.036, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T14:07:07.231676"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1945.934, "latencies_ms": [1945.934], "images_per_second": 0.514, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A group of elephants is gathered in a natural setting, possibly a savanna or forest. The elephants are standing close together, partially obscured by vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.452, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.829}, "timestamp": "2026-01-19T14:07:11.203936"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2014.868, "latencies_ms": [2014.868], "images_per_second": 0.496, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The elephants are primarily gray in color. The lighting suggests an overcast day. The scene appears to be set in a natural environment with trees and vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.224, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T14:07:15.281972"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1669.286, "latencies_ms": [1669.286], "images_per_second": 0.599, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "The open refrigerator door reveals an empty interior with four crisper drawers and a carton of eggs.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.578, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.761}, "timestamp": "2026-01-19T14:07:19.004288"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3471.571, "latencies_ms": [3471.571], "images_per_second": 0.288, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "Egg carton: 2\nOrange juice bottle: 1\nIce maker: 1\nFridge door: 3\nPlastic drawer: 2\nGlass crisper: 1\nRefrigerator shelves: 4\nFloor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.776, "power_cpu_cv_mean_watts": 1.824, "power_sys_5v0_mean_watts": 7.167}, "timestamp": "2026-01-19T14:07:24.506659"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2466.66, "latencies_ms": [2466.66], "images_per_second": 0.405, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main object, the refrigerator, is positioned in the foreground of the image. The eggs are located on the top shelf of the refrigerator, near the light. The open refrigerator door reveals the empty shelves and crisper drawers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.505, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.904}, "timestamp": "2026-01-19T14:07:29.012904"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2476.716, "latencies_ms": [2476.716], "images_per_second": 0.404, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts an empty refrigerator in a kitchen, illuminated by a light source inside. The refrigerator is stocked with various items, including a carton of eggs, a bottle of liquid, and a few other unidentified items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.867, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T14:07:33.546366"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2132.787, "latencies_ms": [2132.787], "images_per_second": 0.469, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The refrigerator is white and appears clean and empty. The lighting inside the refrigerator is bright, illuminating the contents. The refrigerator's shelves and compartments are made of clear plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.344, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T14:07:37.709331"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1442.891, "latencies_ms": [1442.891], "images_per_second": 0.693, "prompt_tokens": 8, "response_tokens_est": 15, "n_tiles": 1, "output_text": "A bunch of ripe yellow bananas with small stickers rests on a blue surface.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.629, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.698}, "timestamp": "2026-01-19T14:07:41.185895"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1906.349, "latencies_ms": [1906.349], "images_per_second": 0.525, "prompt_tokens": 21, "response_tokens_est": 20, "n_tiles": 1, "output_text": "bananas: 8\nstickers: 2\nmetal tray: 1\npurple surface: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.026, "power_cpu_cv_mean_watts": 1.149, "power_sys_5v0_mean_watts": 6.78}, "timestamp": "2026-01-19T14:07:45.111894"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1809.254, "latencies_ms": [1809.254], "images_per_second": 0.553, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, creating a sense of proximity and depth. The background is blurred, drawing attention to the bananas in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.429, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 6.926}, "timestamp": "2026-01-19T14:07:48.967815"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2425.016, "latencies_ms": [2425.016], "images_per_second": 0.412, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a close-up view of a bunch of ripe bananas resting on a metallic surface, possibly a tray or stand. The bananas are yellow and appear fresh. The setting suggests a market or grocery store environment.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.909, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 7.046}, "timestamp": "2026-01-19T14:07:53.435064"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2396.56, "latencies_ms": [2396.56], "images_per_second": 0.417, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The bananas are predominantly yellow, indicating they are ripe. The lighting appears to be soft and diffused, possibly from a diffused light source. The bananas appear to be resting on a metallic surface, possibly a tray or container.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.927, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T14:07:57.866055"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1985.859, "latencies_ms": [1985.859], "images_per_second": 0.504, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A row of tall, shiny orange fire hydrants with gold knobs is lined up on a city sidewalk, contrasting with the surrounding urban landscape.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.002, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.885}, "timestamp": "2026-01-19T14:08:01.909922"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2346.177, "latencies_ms": [2346.177], "images_per_second": 0.426, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "fire hydrant: 4\npipes: 4\nbuilding: 5\ntrees: 2\ncity street: 2\npeople: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.2, "ram_available_mb": 50332.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.142, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 7.013}, "timestamp": "2026-01-19T14:08:06.285366"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2092.211, "latencies_ms": [2092.211], "images_per_second": 0.478, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The fire hydrants are positioned in the foreground, slightly to the right of the center. The cityscape, including skyscrapers and buildings, stretches out in the background, further away from the hydrants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.674, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T14:08:10.423516"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2560.962, "latencies_ms": [2560.962], "images_per_second": 0.39, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene depicts a city street with tall buildings in the background and a row of copper-colored fire hydrants lined up in the foreground. The fire hydrants are positioned in a somewhat orderly manner, contrasting with the more casual urban environment.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.967, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 7.086}, "timestamp": "2026-01-19T14:08:15.003862"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2180.614, "latencies_ms": [2180.614], "images_per_second": 0.459, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The fire hydrants are copper-colored and stand out against the light gray stone pavement. The lighting suggests an overcast day, giving the scene a subdued atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.719, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T14:08:19.208272"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2079.849, "latencies_ms": [2079.849], "images_per_second": 0.481, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A jockey wearing a white helmet and riding a brown pony harnessed to a red carriage, competes in a race on a dirt track.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.627, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T14:08:23.327453"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2871.043, "latencies_ms": [2871.043], "images_per_second": 0.348, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "horse: 1\nperson: 1\ncart: 1\nnumber: 1\nnumber: 1\nnumber: 1\nnumber: 1\nnumber: 1\nnumber: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.339, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 7.078}, "timestamp": "2026-01-19T14:08:28.246494"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2175.782, "latencies_ms": [2175.782], "images_per_second": 0.46, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The horse and driver are positioned in the foreground of the image, with the horse and cart moving towards the background. The track is situated near the background, extending beyond the immediate focus of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.297, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 6.967}, "timestamp": "2026-01-19T14:08:32.463695"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2565.766, "latencies_ms": [2565.766], "images_per_second": 0.39, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A jockey and horse are racing on a dirt track. The jockey is wearing a helmet and riding a red carriage with a number \"8\" displayed. The horse is brown and pulling the carriage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.559, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.979}, "timestamp": "2026-01-19T14:08:37.077054"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2202.481, "latencies_ms": [2202.481], "images_per_second": 0.454, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The horse and driver are brown. The scene is well-lit, likely under bright sunlight. The horse and driver appear to be wearing protective gear. The track appears to be dry and dusty.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.205, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T14:08:41.322591"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1546.913, "latencies_ms": [1546.913], "images_per_second": 0.646, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A brown dog with white markings stands alertly on a gray deck in a backyard, gazing at the camera.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.047, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.048}, "timestamp": "2026-01-19T14:08:44.895112"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2488.604, "latencies_ms": [2488.604], "images_per_second": 0.402, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "dog: 1\nfence: 1\ntree: 1\nlemon: 2\ngrass: 1\nwooden bench: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.416, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 6.607}, "timestamp": "2026-01-19T14:08:49.433271"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2568.056, "latencies_ms": [2568.056], "images_per_second": 0.389, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The dog is positioned in the foreground, slightly to the right of the image. The fence and tree are in the background, extending from left to right. The dog is situated on a raised surface, which appears to be a patio or deck, placed between the dog and the tree.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.517, "power_cpu_cv_mean_watts": 1.703, "power_sys_5v0_mean_watts": 6.723}, "timestamp": "2026-01-19T14:08:54.016486"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2158.762, "latencies_ms": [2158.762], "images_per_second": 0.463, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A brown dog, possibly a Labrador Retriever mix, stands on a gray deck in a backyard.  The dog is positioned in front of a tree with several ripe oranges hanging from its branches.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.6, "ram_available_mb": 50332.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.311, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 6.457}, "timestamp": "2026-01-19T14:08:58.195773"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2338.448, "latencies_ms": [2338.448], "images_per_second": 0.428, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The dog is light brown with darker brown markings. The lighting is bright, likely from sunlight, and the dog is standing on a gray surface, possibly a deck or patio. The dog appears to be in a backyard setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.638, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.605}, "timestamp": "2026-01-19T14:09:02.562036"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2286.025, "latencies_ms": [2286.025], "images_per_second": 0.437, "prompt_tokens": 8, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A person wearing red pants and blue and yellow shoes stands on a wooden bench with a handwritten sign that reads \"WEINER, YOU'VE GOT TO BE SITTING ME!!\".", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.847, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.838}, "timestamp": "2026-01-19T14:09:06.881706"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2635.289, "latencies_ms": [2635.289], "images_per_second": 0.379, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Bench: 2\nSign: 1\nPerson's legs: 2\nShoes: 2\nBricks: 6\nWood: 6\nGround: 6", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.57, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.001}, "timestamp": "2026-01-19T14:09:11.554849"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2828.604, "latencies_ms": [2828.604], "images_per_second": 0.354, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The wooden bench is positioned in the foreground, slightly to the right of the person's feet. The person's feet are placed on the bench, occupying the central and foreground areas. The bench is situated against a light-colored wall or fence, further emphasizing its placement in the foreground.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.111, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T14:09:16.398334"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2457.197, "latencies_ms": [2457.197], "images_per_second": 0.407, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "A person is standing on a wooden bench with a sign that reads \"WEINER. You've got to be sittin' me!!!\" The setting appears to be a brick-paved area, possibly a sidewalk or courtyard.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.785, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T14:09:20.880864"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2075.853, "latencies_ms": [2075.853], "images_per_second": 0.482, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The bench is made of wood and has a light brown color. The lighting in the image suggests it was taken during daylight hours. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.179, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.794}, "timestamp": "2026-01-19T14:09:25.012603"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2374.676, "latencies_ms": [2374.676], "images_per_second": 0.421, "prompt_tokens": 8, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The living room features a red sofa, a wooden coffee table with a tea set, a flat-screen TV, and a wooden dresser, all set against a yellow wall and accented by brown curtains.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.548, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.912}, "timestamp": "2026-01-19T14:09:29.439153"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3338.881, "latencies_ms": [3338.881], "images_per_second": 0.3, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "sofa: 2\ntable: 1\nchairs: 2\nlamp: 2\ntea set: 1\ntelevision: 1\ndresser: 1\npicture frame: 1\ncarpet: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.517, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 7.067}, "timestamp": "2026-01-19T14:09:34.816897"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2504.853, "latencies_ms": [2504.853], "images_per_second": 0.399, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The orange couch is positioned to the left of the dining table and chairs. The dining table and chairs are situated in the background, slightly further away than the couch. The television is positioned in the background, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.5, "ram_available_mb": 50333.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.348, "power_cpu_cv_mean_watts": 1.45, "power_sys_5v0_mean_watts": 6.897}, "timestamp": "2026-01-19T14:09:39.358639"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3762.653, "latencies_ms": [3762.653], "images_per_second": 0.266, "prompt_tokens": 19, "response_tokens_est": 81, "n_tiles": 1, "output_text": "The scene depicts a cozy hotel room with a comfortable living area and a dining area. The living area features a red sofa, a wooden coffee table, and a small side table with a lamp and flowers. The dining area has a round table set for tea or coffee, surrounded by chairs. The room is well-lit by natural light coming through a window with curtains, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.129, "power_cpu_cv_mean_watts": 1.809, "power_sys_5v0_mean_watts": 7.117}, "timestamp": "2026-01-19T14:09:45.162804"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3029.264, "latencies_ms": [3029.264], "images_per_second": 0.33, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The room features a warm color scheme with orange walls and brown curtains. The lighting is soft and warm, creating a cozy atmosphere. The furniture includes a red sofa, a round table with chairs, and a wooden dresser. A large window provides natural light, enhancing the overall ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.973, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.092}, "timestamp": "2026-01-19T14:09:50.225081"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2106.617, "latencies_ms": [2106.617], "images_per_second": 0.475, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A black frying pan is filled with a vibrant stir fry of broccoli, carrots, bell peppers, and sliced sausage, all coated in a light brown sauce.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.128, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T14:09:54.392064"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3029.782, "latencies_ms": [3029.782], "images_per_second": 0.33, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "broccoli: 8\ncarrots: 8\npeppers: 8\nham: 8\nzucchini: 2\npotatoes: 2\nsalt: 1\nspoon: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.911, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.052}, "timestamp": "2026-01-19T14:09:59.439160"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1619.73, "latencies_ms": [1619.73], "images_per_second": 0.617, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The broccoli, carrots, and meat are positioned in the foreground of the image, with the pan and spoon placed in the background.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.022, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.73}, "timestamp": "2026-01-19T14:10:03.102677"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2404.382, "latencies_ms": [2404.382], "images_per_second": 0.416, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A skillet filled with a colorful mix of vegetables, including broccoli, carrots, and meat, is being prepared on a stovetop. A serving spoon rests in the pan, indicating the cooking process is underway.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.632, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T14:10:07.547925"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2567.841, "latencies_ms": [2567.841], "images_per_second": 0.389, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The vegetables in the pan display vibrant colors, including green broccoli, orange carrots, and red bell peppers. The lighting is bright, enhancing the vividness of the colors. The pan appears to be made of metal, and the vegetables seem to be cooked together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.764, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.022}, "timestamp": "2026-01-19T14:10:12.151003"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1674.243, "latencies_ms": [1674.243], "images_per_second": 0.597, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Three hot dogs, each topped with yellow mustard, are arranged on a dark plate on a countertop, accompanied by a magazine.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.519, "power_cpu_cv_mean_watts": 1.14, "power_sys_5v0_mean_watts": 6.815}, "timestamp": "2026-01-19T14:10:15.872762"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2335.374, "latencies_ms": [2335.374], "images_per_second": 0.428, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "hot dog: 3\nbun: 2\nmustard: 2\nplate: 1\ntable: 1\nmagazine: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.908, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.992}, "timestamp": "2026-01-19T14:10:20.242828"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2107.075, "latencies_ms": [2107.075], "images_per_second": 0.475, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are positioned close together, with the hot dogs placed in the foreground and the magazine in the background. The hot dogs are situated on the plate, which occupies the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.504, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 6.913}, "timestamp": "2026-01-19T14:10:24.390783"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1716.7, "latencies_ms": [1716.7], "images_per_second": 0.583, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Three hot dogs topped with mustard are arranged on a dark plate on a countertop. A magazine is visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.853, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.696}, "timestamp": "2026-01-19T14:10:28.167992"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2217.573, "latencies_ms": [2217.573], "images_per_second": 0.451, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The hot dogs are topped with yellow mustard. The plate appears to be dark brown or black. The lighting is bright, likely from overhead lighting. The hot dogs appear to be made of beef.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.9, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.821, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.843}, "timestamp": "2026-01-19T14:10:32.440974"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1602.037, "latencies_ms": [1602.037], "images_per_second": 0.624, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A group of people are enjoying a sunny day at the beach, swimming and playing in the water under a green umbrella.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12506.9, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.056, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.605}, "timestamp": "2026-01-19T14:10:36.078338"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2362.529, "latencies_ms": [2362.529], "images_per_second": 0.423, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Umbrella: 1\nBeach chairs: 2\nSand: 1\nWater: 4\nPeople: 4\nWaves: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.9, "ram_available_mb": 50334.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.909, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T14:10:40.479234"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1896.821, "latencies_ms": [1896.821], "images_per_second": 0.527, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the beach chair and umbrella situated near the middle ground. The water extends to the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.865, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.793}, "timestamp": "2026-01-19T14:10:44.399768"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2461.489, "latencies_ms": [2461.489], "images_per_second": 0.406, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A group of people are enjoying a sunny day at the beach, swimming and playing in the ocean. Two beach chairs with colorful umbrellas are set up on the sandy shore, providing shade and seating for the beachgoers.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.645, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T14:10:48.909809"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2169.759, "latencies_ms": [2169.759], "images_per_second": 0.461, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The beach is sandy and appears wet, likely due to recent waves. The beach umbrella is green and provides shade for the beach chairs. The lighting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.271, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T14:10:53.109419"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2529.247, "latencies_ms": [2529.247], "images_per_second": 0.395, "prompt_tokens": 8, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The vintage kitchen features green and white patterned wallpaper, a wooden table with a white bowl and teapot, a white sink, a white refrigerator, a wooden cabinet, a stove, a wooden chair, and a wooden bucket.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.703, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T14:10:57.692476"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4009.604, "latencies_ms": [4009.604], "images_per_second": 0.249, "prompt_tokens": 21, "response_tokens_est": 56, "n_tiles": 1, "output_text": "kitchen: 6\ntable: 1\ncabinets: 4\nrefrigerator: 1\nsink: 1\nfaucet: 1\npan: 1\nwooden chair: 1\nwooden bucket: 1\nfan: 1\nwallpaper: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.197, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 7.166}, "timestamp": "2026-01-19T14:11:03.757107"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2258.466, "latencies_ms": [2258.466], "images_per_second": 0.443, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The kitchen is positioned in the foreground, with the dining table, chairs, and appliances extending towards the right side of the image. The kitchen area is further back, creating a sense of depth and perspective in the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.155, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T14:11:08.068732"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2078.78, "latencies_ms": [2078.78], "images_per_second": 0.481, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The scene depicts a vintage kitchen exhibit, featuring antique appliances and furniture. The kitchen is decorated with green and white wallpaper and showcases a retro aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.081, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.824}, "timestamp": "2026-01-19T14:11:12.176851"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2644.584, "latencies_ms": [2644.584], "images_per_second": 0.378, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The kitchen features green and white color schemes, creating a vintage aesthetic. The lighting is soft and diffused, enhancing the overall ambiance. The materials include wood, metal, and fabric, contributing to the rustic feel of the space.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.112, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T14:11:16.850092"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1603.076, "latencies_ms": [1603.076], "images_per_second": 0.624, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A black and white dog is playing with a frisbee in a wooded area, surrounded by fallen leaves and tall trees.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.694, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 6.762}, "timestamp": "2026-01-19T14:11:20.487312"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2333.105, "latencies_ms": [2333.105], "images_per_second": 0.429, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "tree: 1\nfrisbee: 1\nground: 1\nleaves: 4\ndog: 1\nshadow: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.782, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T14:11:24.847019"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2302.987, "latencies_ms": [2302.987], "images_per_second": 0.434, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The dog is positioned to the left of the image, close to the foreground. The tree trunk occupies the background, extending from the left edge towards the center. The dog appears to be interacting with the ground near the tree.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.914, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:11:29.168249"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2060.5, "latencies_ms": [2060.5], "images_per_second": 0.485, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A black and tan dog is playing with a frisbee in a park with fallen leaves on the ground. A large tree trunk with moss is visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.2, "ram_available_mb": 50334.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.998, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T14:11:33.267206"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2474.029, "latencies_ms": [2474.029], "images_per_second": 0.404, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The dog is black and white and appears to be playing with a brown frisbee. The ground is covered with fallen leaves, suggesting it's autumn. The lighting is soft and diffused, likely due to the sun filtering through the trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.444, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.909}, "timestamp": "2026-01-19T14:11:37.754840"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1686.078, "latencies_ms": [1686.078], "images_per_second": 0.593, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A person wearing skis and carrying a backpack is skiing down a snowy slope, leaving a trail behind them.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.903, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.637}, "timestamp": "2026-01-19T14:11:41.478062"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3158.781, "latencies_ms": [3158.781], "images_per_second": 0.317, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Ski: 2\nSki poles: 2\nSki boots: 2\nBackpack: 1\nSnow: 6\nSki tracks: 4\nTrees: 4\nSky: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.897, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.087}, "timestamp": "2026-01-19T14:11:46.653838"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1835.451, "latencies_ms": [1835.451], "images_per_second": 0.545, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, moving towards the background. The snow trail cuts through the snow, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.912, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T14:11:50.522679"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2380.199, "latencies_ms": [2380.199], "images_per_second": 0.42, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A person is cross-country skiing on a snowy trail, wearing a white hat, dark jacket, and bright green boots. They are using ski poles and traversing a relatively flat area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.866, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T14:11:54.924036"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2704.581, "latencies_ms": [2704.581], "images_per_second": 0.37, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The skier is wearing bright green ski boots. The lighting is bright and sunny, creating a clear view of the snowy landscape. The skier is equipped with ski poles and appears to be cross-country skiing on a relatively flat snow-covered slope.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12505.3, "ram_available_mb": 50335.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.149, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 7.092}, "timestamp": "2026-01-19T14:11:59.665890"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1718.531, "latencies_ms": [1718.531], "images_per_second": 0.582, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "An orange and black BNSF freight train travels through a wooded area, passing through a field with dry grass and bare trees.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12505.5, "ram_available_mb": 50335.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.368, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.226}, "timestamp": "2026-01-19T14:12:03.415506"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3258.661, "latencies_ms": [3258.661], "images_per_second": 0.307, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Train: 2\nTrain car: 2\nTrain engine: 1\nTrain wheels: 4\nTrain tracks: 1\nTrain windows: 2\nTrain cab: 1\nTrain number: 6009", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.78, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 6.862}, "timestamp": "2026-01-19T14:12:08.734447"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2235.012, "latencies_ms": [2235.012], "images_per_second": 0.447, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The orange and black BNSF train is positioned in the foreground, moving from left to right across the image. The background consists of bare trees and a clear blue sky, creating a contrast with the vibrant colors of the train.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.436, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.58}, "timestamp": "2026-01-19T14:12:12.989460"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2100.832, "latencies_ms": [2100.832], "images_per_second": 0.476, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "An orange and black BNSF freight train travels through a rural landscape, passing through a wooded area with bare trees. The clear blue sky indicates a bright, sunny day.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12507.7, "ram_available_mb": 50333.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.309, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.534}, "timestamp": "2026-01-19T14:12:17.117091"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1979.845, "latencies_ms": [1979.845], "images_per_second": 0.505, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The train is primarily orange with black and yellow accents. The lighting suggests it is likely daytime. The train appears to be made of metal and has a visible engine and multiple cars.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.428, "power_cpu_cv_mean_watts": 1.495, "power_sys_5v0_mean_watts": 6.491}, "timestamp": "2026-01-19T14:12:21.137725"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2060.359, "latencies_ms": [2060.359], "images_per_second": 0.485, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A wooden table holds a white plate with a slice of seeded bread topped with creamy avocado spread, and a small blue bowl filled with steamed broccoli.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.447, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.898}, "timestamp": "2026-01-19T14:12:25.246576"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2787.614, "latencies_ms": [2787.614], "images_per_second": 0.359, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "toast: 2\navocado spread: 1\ncream cheese: 1\nbroccoli: 6\nbowl: 1\ntable: 1\ntext: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.058, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:12:30.098530"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2689.792, "latencies_ms": [2689.792], "images_per_second": 0.372, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The avocado spread is positioned to the left of the bowl, closer to the viewer. The broccoli is situated to the right of the bowl, further away from the viewer. The arrangement suggests a balanced composition, with the avocado spread providing a contrasting texture and color to the broccoli.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.367, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T14:12:34.808420"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2485.891, "latencies_ms": [2485.891], "images_per_second": 0.402, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a simple, healthy meal consisting of a piece of whole grain toast topped with avocado, a small bowl of roasted broccoli, and a small bowl of white cream cheese. The meal is served on a wooden table.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.445, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T14:12:39.322826"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2781.447, "latencies_ms": [2781.447], "images_per_second": 0.36, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The plate features a light blue rim and a white interior. The food items include green guacamole, a creamy white spread, and a vibrant green broccoli floret. The plate rests on a wooden surface, and the lighting creates a warm, inviting ambiance.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.0, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.178, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.977}, "timestamp": "2026-01-19T14:12:44.166252"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1798.19, "latencies_ms": [1798.19], "images_per_second": 0.556, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A person is sleeping on a wooden bench, wrapped in an orange blanket, with a blue backpack placed beside them and a parking meter nearby.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12508.0, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.708, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.782}, "timestamp": "2026-01-19T14:12:48.014572"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2913.611, "latencies_ms": [2913.611], "images_per_second": 0.343, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "park bench: 2\nparking meter: 2\nperson: 1\nblanket: 1\nbackpack: 1\ncar: 1\ngrass: 1\nfence: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.037, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.068}, "timestamp": "2026-01-19T14:12:52.952186"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1992.925, "latencies_ms": [1992.925], "images_per_second": 0.502, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bench is positioned in the foreground, slightly to the right of the image. The park bench is situated in the background, further away and slightly to the right of the bench.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.447, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T14:12:56.983752"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1906.14, "latencies_ms": [1906.14], "images_per_second": 0.525, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A person is sleeping on a wooden bench in a park-like setting. The bench is situated near a parking meter and has a backpack placed on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.622, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.827}, "timestamp": "2026-01-19T14:13:00.916476"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2483.426, "latencies_ms": [2483.426], "images_per_second": 0.403, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The bench is light brown and appears to be made of wood. The lighting suggests it's daytime, and the colors are vibrant, reflecting the outdoor environment. The materials appear to be sturdy and weather-resistant, suitable for outdoor use.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.4, "ram_available_mb": 50332.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.46, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:13:05.416222"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1934.893, "latencies_ms": [1934.893], "images_per_second": 0.517, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A vibrant vase with dried flowers and leaves sits on a white pedestal, accompanied by smaller vases and decorative items, against a brown wall.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12507.9, "ram_available_mb": 50333.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.122, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.734}, "timestamp": "2026-01-19T14:13:09.413650"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3784.581, "latencies_ms": [3784.581], "images_per_second": 0.264, "prompt_tokens": 21, "response_tokens_est": 53, "n_tiles": 1, "output_text": "vase: 1\nlotus seed pod: 2\nstalk: 2\nbush: 2\nwhisk: 1\nlotus seed pod: 1\nlotus seed pod: 1\nlotus seed pod: 1\nlotus seed pod: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.506, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 7.179}, "timestamp": "2026-01-19T14:13:15.259513"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2469.857, "latencies_ms": [2469.857], "images_per_second": 0.405, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The main object is a vase positioned in the foreground, slightly to the right of the viewer. The background features other ceramic items and displays, suggesting a larger display or collection. The vase is situated near a wall with additional decorative elements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.645, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 6.985}, "timestamp": "2026-01-19T14:13:19.782353"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2907.531, "latencies_ms": [2907.531], "images_per_second": 0.344, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a display of handcrafted pottery and dried floral arrangements in a gallery or showroom. The arrangement features a variety of dried plants in shades of brown and beige, complemented by decorative elements like dried seed pods and a small bird figurine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.1, "ram_available_mb": 50332.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.138, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.098}, "timestamp": "2026-01-19T14:13:24.752822"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2933.063, "latencies_ms": [2933.063], "images_per_second": 0.341, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The vase is primarily dark brown and gold, showcasing a blend of earthy tones. The arrangement includes dried grasses and seed pods, creating a harmonious and textured display. The lighting highlights the colors and textures of the materials, enhancing the visual appeal of the arrangement.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.17, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.089}, "timestamp": "2026-01-19T14:13:29.710681"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1940.87, "latencies_ms": [1940.87], "images_per_second": 0.515, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A young man in blue jeans and a white shirt skillfully maneuvers his skateboard on a concrete ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12507.1, "ram_available_mb": 50333.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.409, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:13:33.706636"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3043.21, "latencies_ms": [3043.21], "images_per_second": 0.329, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "helmet: 1\nknee pads: 2\nshin guards: 2\nskateboard: 1\njeans: 1\nshirt: 1\nfence: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.845, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.04}, "timestamp": "2026-01-19T14:13:38.767642"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3153.889, "latencies_ms": [3153.889], "images_per_second": 0.317, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground of the image, maneuvering through the concrete bowl. The skateboard is situated near the center of the image, partially obscured by the bowl's curves. The skateboarder is facing the camera, capturing the moment as he rides through the bowl.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.3, "ram_available_mb": 50333.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.747, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.087}, "timestamp": "2026-01-19T14:13:43.967218"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2596.612, "latencies_ms": [2596.612], "images_per_second": 0.385, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A skateboarder is performing a trick on a curved concrete ramp at a skatepark. Another person is visible in the background, possibly watching the skateboarder. The setting suggests an outdoor skatepark environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.5, "ram_available_mb": 50332.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.192, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T14:13:48.607070"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2183.771, "latencies_ms": [2183.771], "images_per_second": 0.458, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The skateboarder is wearing a white shirt, blue jeans, and a black helmet. The concrete surface is gray, and the lighting suggests it might be late afternoon or early evening.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.178, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:13:52.835154"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1889.242, "latencies_ms": [1889.242], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A large Christmas tree adorned with twinkling lights stands tall in the heart of a bustling city square, surrounded by people enjoying the festive atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.787, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.861}, "timestamp": "2026-01-19T14:13:56.785853"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2641.227, "latencies_ms": [2641.227], "images_per_second": 0.379, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "clock tower: 2\nchristmas tree: 1\nlights: 10\nstreet: 5\nbuildings: 5\npeople: 2\ncars: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.519, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.017}, "timestamp": "2026-01-19T14:14:01.478574"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2611.247, "latencies_ms": [2611.247], "images_per_second": 0.383, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The large Christmas tree is positioned in the foreground, slightly to the right of the clock tower. The clock tower is situated in the background, slightly to the left of the tree. The street and surrounding buildings are visible in the background, extending beyond the immediate foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.9, "ram_available_mb": 50330.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.365, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.032}, "timestamp": "2026-01-19T14:14:06.125385"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2954.62, "latencies_ms": [2954.62], "images_per_second": 0.338, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a city square at night, illuminated by festive string lights. A large Christmas tree adorned with lights stands prominently in the center of the square, surrounded by people enjoying the holiday atmosphere. The surrounding buildings feature modern architecture and signage, indicating a bustling commercial area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.9, "ram_available_mb": 50330.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.122, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.064}, "timestamp": "2026-01-19T14:14:11.101456"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2560.803, "latencies_ms": [2560.803], "images_per_second": 0.391, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The Christmas tree is decorated with blue and white lights, creating a festive atmosphere. The clock tower is illuminated with warm yellow lights, adding to the overall warmth of the scene. The wet street reflects the lights and creates a reflective surface.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.979}, "timestamp": "2026-01-19T14:14:15.683793"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1943.512, "latencies_ms": [1943.512], "images_per_second": 0.515, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A young boy in a blue shirt and black shorts is playing tennis, swinging his racket to hit a yellow tennis ball on a green court.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.599, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.81}, "timestamp": "2026-01-19T14:14:19.682867"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3318.416, "latencies_ms": [3318.416], "images_per_second": 0.301, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 2\nTennis player: 1\nTennis shoes: 2\nTennis net: 1\nTrees: 2\nFence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.799, "power_cpu_cv_mean_watts": 1.706, "power_sys_5v0_mean_watts": 7.127}, "timestamp": "2026-01-19T14:14:25.017139"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2832.241, "latencies_ms": [2832.241], "images_per_second": 0.353, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The tennis player is positioned on the right side of the image, facing left. The tennis ball is in the air, near the player's racket, suggesting they are about to hit it or have just hit it. The tennis court extends into the background, providing a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.197, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 7.073}, "timestamp": "2026-01-19T14:14:29.882437"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2614.461, "latencies_ms": [2614.461], "images_per_second": 0.382, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "A young boy is playing tennis on a court. He is wearing a blue shirt and black shorts, swinging his racket to hit a tennis ball. The setting appears to be a park or recreational area with a chain-link fence and trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.404, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.065}, "timestamp": "2026-01-19T14:14:34.537254"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2740.605, "latencies_ms": [2740.605], "images_per_second": 0.365, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The tennis court appears to be made of dark gray or black material. The lighting suggests an overcast day, which might add a slightly subdued atmosphere to the scene. The tennis racket is yellow, contrasting with the blue shirt worn by the player.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.222, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.982}, "timestamp": "2026-01-19T14:14:39.314823"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1690.678, "latencies_ms": [1690.678], "images_per_second": 0.591, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The living room features a white fireplace with green marble surround, flanked by built-in bookshelves filled with books and framed artwork.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.307, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 6.234}, "timestamp": "2026-01-19T14:14:43.035254"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2581.11, "latencies_ms": [2581.11], "images_per_second": 0.387, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "bookcase: 6\nfireplace: 2\nlamp: 2\narmchair: 1\nsofa: 1\nplant: 2\nside table: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.577, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 6.705}, "timestamp": "2026-01-19T14:14:47.656628"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2029.618, "latencies_ms": [2029.618], "images_per_second": 0.493, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The bookshelves are positioned on the left side of the image, while the armchair is situated in the foreground. The fireplace is situated in the background, slightly further away than the bookshelves.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.49, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 6.533}, "timestamp": "2026-01-19T14:14:51.744734"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2496.718, "latencies_ms": [2496.718], "images_per_second": 0.401, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The living room features a white fireplace with green marble surround, surrounded by built-in bookshelves filled with books. The room is furnished with beige armchairs and matching couches, complemented by wooden side tables and lamps.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.374, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.647}, "timestamp": "2026-01-19T14:14:56.280286"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2000.039, "latencies_ms": [2000.039], "images_per_second": 0.5, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The room features a green marble fireplace mantel, white walls, and beige upholstered furniture. The lighting is soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.989, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.394}, "timestamp": "2026-01-19T14:15:00.327712"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1712.649, "latencies_ms": [1712.649], "images_per_second": 0.584, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Three zebras are grazing on grass in a field, with one actively eating while the other two stand nearby.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.483, "power_cpu_cv_mean_watts": 1.059, "power_sys_5v0_mean_watts": 6.602}, "timestamp": "2026-01-19T14:15:04.091913"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2303.865, "latencies_ms": [2303.865], "images_per_second": 0.434, "prompt_tokens": 21, "response_tokens_est": 25, "n_tiles": 1, "output_text": "zebra: 3\ngrass: 2\ndirt: 1\ntree: 1\nbush: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.869, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T14:15:08.417223"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2526.001, "latencies_ms": [2526.001], "images_per_second": 0.396, "prompt_tokens": 25, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close proximity to each other, with the zebra on the left closest to the viewer and the zebra on the right further away. The foreground is dominated by the grassy area, while the background features more sparse vegetation and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.234, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T14:15:13.005419"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2199.213, "latencies_ms": [2199.213], "images_per_second": 0.455, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Three zebras are grazing on grass in a savanna-like environment. The zebras are standing near a dirt patch and surrounded by dry grass and sparse vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.472, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.972}, "timestamp": "2026-01-19T14:15:17.225739"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2981.206, "latencies_ms": [2981.206], "images_per_second": 0.335, "prompt_tokens": 18, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The zebras exhibit distinct black and white stripes, creating a striking visual pattern. The lighting in the image appears to be natural daylight, enhancing the visibility of the zebras' stripes. The scene is set in a grassy area with sparse vegetation, typical of a savanna or grassland habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.216, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.076}, "timestamp": "2026-01-19T14:15:22.219818"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1707.075, "latencies_ms": [1707.075], "images_per_second": 0.586, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of people, mostly older adults, are gathered around a wooden table in a cozy restaurant, enjoying a meal and conversation.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.05, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T14:15:25.968815"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2940.367, "latencies_ms": [2940.367], "images_per_second": 0.34, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "table: 6\nchairs: 4\npeople: 10\nserving dishes: 2\nserving cups: 2\nbottles: 2\nclocks: 1\nframes: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.372, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.068}, "timestamp": "2026-01-19T14:15:30.947723"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2737.415, "latencies_ms": [2737.415], "images_per_second": 0.365, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective in the image. The foreground features the seated people, while the background includes other tables, chairs, and additional individuals. The chairs are placed at various distances from the foreground, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12509.0, "ram_available_mb": 50331.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.476, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T14:15:35.719560"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3031.612, "latencies_ms": [3031.612], "images_per_second": 0.33, "prompt_tokens": 19, "response_tokens_est": 58, "n_tiles": 1, "output_text": "A group of people are gathered around a long wooden table in a restaurant, enjoying a meal together. The restaurant has a rustic atmosphere with exposed brick walls and wooden floors. Various items like cups, bottles, and cutlery are placed on the table, indicating a casual dining experience.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12508.3, "ram_available_mb": 50332.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.04, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 7.084}, "timestamp": "2026-01-19T14:15:40.787501"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2736.166, "latencies_ms": [2736.166], "images_per_second": 0.365, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The restaurant has a warm and inviting atmosphere with wooden floors and exposed brick walls. The lighting is warm and inviting, complementing the cozy ambiance. The tables are set with plates, cups, and condiments, further enhancing the dining experience.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.2, "ram_available_mb": 50333.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.39, "power_cpu_cv_mean_watts": 1.568, "power_sys_5v0_mean_watts": 7.033}, "timestamp": "2026-01-19T14:15:45.541222"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2011.982, "latencies_ms": [2011.982], "images_per_second": 0.497, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A flock of twelve elegant white swans glides gracefully across the dark water, their gleaming bodies contrasting beautifully with the surrounding environment.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.328, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.873}, "timestamp": "2026-01-19T14:15:49.628519"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2362.542, "latencies_ms": [2362.542], "images_per_second": 0.423, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "swans: 12\nboats: 6\nsailboats: 4\ndock: 1\nshore: 1\nsand: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.926, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T14:15:54.047678"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1819.821, "latencies_ms": [1819.821], "images_per_second": 0.55, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The swans are primarily in the foreground, occupying a significant portion of the image. The boats are situated in the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.5, "ram_available_mb": 50334.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12505.6, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.794, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.768}, "timestamp": "2026-01-19T14:15:57.893411"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2624.822, "latencies_ms": [2624.822], "images_per_second": 0.381, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a serene harbor with a flock of white swans swimming in the dark water.  Several boats are docked in the background, and a stone wall separates the harbor from a small area with people. The setting is peaceful and picturesque.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12505.6, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.517, "power_cpu_cv_mean_watts": 1.831, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T14:16:02.557395"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2966.323, "latencies_ms": [2966.323], "images_per_second": 0.337, "prompt_tokens": 18, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The water is a dark blue-purple color, creating a striking contrast with the white swans. The lighting suggests it might be near sunrise or sunset, casting a warm glow on the scene. The swans appear to be swimming leisurely, and the overall atmosphere is serene and picturesque.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.922, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 7.089}, "timestamp": "2026-01-19T14:16:07.581696"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1706.331, "latencies_ms": [1706.331], "images_per_second": 0.586, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A newlywed couple cuts their wedding cake together at their reception, surrounded by the festive atmosphere of the event.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.836, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.629}, "timestamp": "2026-01-19T14:16:11.331073"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3706.68, "latencies_ms": [3706.68], "images_per_second": 0.27, "prompt_tokens": 21, "response_tokens_est": 50, "n_tiles": 1, "output_text": "Cake: 3\nWedding dress: 1\nBride: 1\nGroom: 1\nTable: 1\nCandles: 1\nSpeaker: 1\nMusical instruments: 2\nFlags: 2\nDance floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.452, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 7.176}, "timestamp": "2026-01-19T14:16:17.064700"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1835.689, "latencies_ms": [1835.689], "images_per_second": 0.545, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The bride and groom are in the foreground, while the music setup and guests are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.863, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:16:20.931184"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2190.662, "latencies_ms": [2190.662], "images_per_second": 0.456, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A bride and groom are cutting their wedding cake inside a tent decorated with colorful pennants.  A band is playing in the background, and guests are mingling and observing the celebration.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.022, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T14:16:25.167043"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2268.611, "latencies_ms": [2268.611], "images_per_second": 0.441, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The wedding cake is multi-colored and appears to be made of glass or metal. The lighting in the tent creates a warm, inviting atmosphere. The cake is positioned on a table covered with a white tablecloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.782, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T14:16:29.463799"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2085.455, "latencies_ms": [2085.455], "images_per_second": 0.48, "prompt_tokens": 8, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The living room features a blue sofa, a wooden coffee table, a glass-topped side table with a lamp, a potted plant, a vase, and a framed picture on the wall.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12506.7, "ram_available_mb": 50334.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.411, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T14:16:33.617983"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2699.79, "latencies_ms": [2699.79], "images_per_second": 0.37, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "plant: 2\nlamp: 1\ntable: 2\ncouch: 2\nrug: 1\nside table: 1\npicture: 2\nbook: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12505.9, "ram_available_mb": 50335.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.62, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.028}, "timestamp": "2026-01-19T14:16:38.337425"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2641.974, "latencies_ms": [2641.974], "images_per_second": 0.379, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The sofa is positioned in the foreground, facing the window and lamp. The coffee table is situated near the sofa, partially obscured by the sofa. The window and lamp are located in the background, offering a view and light to the room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.348, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.979}, "timestamp": "2026-01-19T14:16:43.004552"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2794.631, "latencies_ms": [2794.631], "images_per_second": 0.358, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The living room features a cozy and vibrant atmosphere with red walls, multiple windows, and several pieces of furniture including a blue sofa, a coffee table, and a side table with a lamp and plant. The scene suggests a comfortable and inviting space for relaxation and conversation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.8, "ram_available_mb": 50334.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12506.4, "ram_available_mb": 50334.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.176, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 7.064}, "timestamp": "2026-01-19T14:16:47.839413"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3081.494, "latencies_ms": [3081.494], "images_per_second": 0.325, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The room features a deep red wall, complemented by white lace curtains. The lighting is soft and warm, creating a cozy atmosphere. The furniture, including dark blue sofas and a wooden coffee table, is crafted from natural materials, adding a touch of elegance to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.728, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.071}, "timestamp": "2026-01-19T14:16:52.963508"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1707.323, "latencies_ms": [1707.323], "images_per_second": 0.586, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two dolls with red hair and round eyes are sitting together, holding hands and looking at each other.", "error": null, "sys_before": {"cpu_percent": 8.6, "ram_used_mb": 12505.8, "ram_available_mb": 50335.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.367, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T14:16:56.722634"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2824.07, "latencies_ms": [2824.07], "images_per_second": 0.354, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "clock: 10\nperson: 2\nbook: 5\nhair: 2\nface: 2\neyes: 2\nclock hands: 5\ntable: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.258, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.024}, "timestamp": "2026-01-19T14:17:01.583598"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2517.687, "latencies_ms": [2517.687], "images_per_second": 0.397, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The left object appears to be a clock positioned close to the viewer, while the right object, resembling a doll, is further away and positioned in the background. The foreground is relatively empty, while the background is filled with additional elements, creating a layered effect.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12506.0, "ram_available_mb": 50334.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.823, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T14:17:06.146061"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2300.707, "latencies_ms": [2300.707], "images_per_second": 0.435, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The scene depicts two dolls with clock faces superimposed, sitting side by side on a wooden surface. The clocks show different times and positions, creating a surreal and dreamlike effect.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.38, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T14:17:10.480182"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4082.524, "latencies_ms": [4082.524], "images_per_second": 0.245, "prompt_tokens": 18, "response_tokens_est": 90, "n_tiles": 1, "output_text": "The dominant colors are warm hues of orange and red, contrasted by the cool yellowish tones of the clock faces. The lighting creates a soft, dreamy effect, enhancing the surreal and artistic nature of the image. The materials appear to be fabric and possibly paper, giving the composition a slightly textured and layered look. The weather is not explicitly visible in the image, but the overall mood and atmosphere are suggestive of a warm, cozy setting.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.056, "power_cpu_cv_mean_watts": 1.838, "power_sys_5v0_mean_watts": 7.147}, "timestamp": "2026-01-19T14:17:16.592921"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1847.014, "latencies_ms": [1847.014], "images_per_second": 0.541, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A young boy, wearing a black helmet and tan jacket, sits on a black motor scooter, gripping the handlebars and looking to the left.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.241, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.377}, "timestamp": "2026-01-19T14:17:20.492574"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2838.746, "latencies_ms": [2838.746], "images_per_second": 0.352, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "helmet: 1\nmotorcycle: 1\nman: 1\npants: 1\nshoes: 1\njacket: 1\nmirror: 1\nseat: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.527, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 6.745}, "timestamp": "2026-01-19T14:17:25.367732"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1877.526, "latencies_ms": [1877.526], "images_per_second": 0.533, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The scooter is positioned in the foreground, slightly to the right of the main subject. The background includes other motorcycles and people, suggesting a public setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.187, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.384}, "timestamp": "2026-01-19T14:17:29.279634"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2719.76, "latencies_ms": [2719.76], "images_per_second": 0.368, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A young boy is riding a scooter in a busy area, possibly a city street. He wears a tan jacket and beige pants, sitting comfortably on the scooter while looking to his left. Other people are visible in the background, suggesting a public setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.36, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 6.735}, "timestamp": "2026-01-19T14:17:34.029541"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1739.204, "latencies_ms": [1739.204], "images_per_second": 0.575, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The scooter is primarily black and silver. The lighting appears to be natural daylight. The scooter appears to be made of metal.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12504.9, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.059, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 6.296}, "timestamp": "2026-01-19T14:17:37.796466"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1343.867, "latencies_ms": [1343.867], "images_per_second": 0.744, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A large pizza with melted cheese and herbs is being sliced and served on a wooden table.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12504.9, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.933, "power_cpu_cv_mean_watts": 0.921, "power_sys_5v0_mean_watts": 5.907}, "timestamp": "2026-01-19T14:17:41.164272"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4036.772, "latencies_ms": [4036.772], "images_per_second": 0.248, "prompt_tokens": 21, "response_tokens_est": 60, "n_tiles": 1, "output_text": "Pizza: 8\nCheese: 8\nSpinach: 8\nTomato sauce: 8\nTomatoes: 8\nBasil: 8\nCheese: 8\nSauce: 8\nOlive oil: 8\nBaking pan: 8\nPizza stone: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.2, "ram_available_mb": 50335.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.943, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T14:17:47.219408"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1952.003, "latencies_ms": [1952.003], "images_per_second": 0.512, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main object is a large, freshly baked pizza, positioned prominently in the foreground. The background features kitchen elements and a partially visible person's arm, suggesting the setting is a professional kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.7, "ram_available_mb": 50335.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.666, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.526}, "timestamp": "2026-01-19T14:17:51.208335"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1847.855, "latencies_ms": [1847.855], "images_per_second": 0.541, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A large pizza with green toppings is being prepared on a wooden table in a dimly lit kitchen. A person is visible in the background, seemingly involved in the pizza-making process.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12505.0, "ram_available_mb": 50335.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.24, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.39}, "timestamp": "2026-01-19T14:17:55.107804"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2114.744, "latencies_ms": [2114.744], "images_per_second": 0.473, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The cheese pizza has a golden-brown crust and vibrant green toppings, likely spinach. The lighting is dim, creating a cozy atmosphere. The pizza appears to be freshly baked and ready to be served.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.214, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.409}, "timestamp": "2026-01-19T14:17:59.252536"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2011.703, "latencies_ms": [2011.703], "images_per_second": 0.497, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A female tennis player, dressed in white, is captured mid-serve on a grass court, holding a tennis racket and poised to hit the ball.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.064, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.413}, "timestamp": "2026-01-19T14:18:03.338839"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3058.35, "latencies_ms": [3058.35], "images_per_second": 0.327, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis skirt: 1\nTennis shoes: 2\nTennis visor: 1\nTennis court: 2\nTennis net: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12505.4, "ram_available_mb": 50335.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.663, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 6.786}, "timestamp": "2026-01-19T14:18:08.434689"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2076.251, "latencies_ms": [2076.251], "images_per_second": 0.482, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the image, reaching up with her right arm to hit the ball. The tennis court extends into the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.1, "ram_available_mb": 50335.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.261, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.439}, "timestamp": "2026-01-19T14:18:12.530661"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1979.426, "latencies_ms": [1979.426], "images_per_second": 0.505, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A woman in a white tennis outfit is playing tennis on a grass court, reaching up to hit the ball with her racket. The setting appears to be a sunny day at the tennis court.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12504.7, "ram_available_mb": 50336.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.214, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.419}, "timestamp": "2026-01-19T14:18:16.554515"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1826.49, "latencies_ms": [1826.49], "images_per_second": 0.547, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The tennis player is wearing a white outfit. The tennis court is green and appears to be well-maintained. The lighting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12504.3, "ram_available_mb": 50336.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.107, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.337}, "timestamp": "2026-01-19T14:18:20.425259"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1649.63, "latencies_ms": [1649.63], "images_per_second": 0.606, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white toilet is situated next to a white bathtub with a yellow shower curtain in a small, well-lit bathroom.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.488, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.699}, "timestamp": "2026-01-19T14:18:24.101187"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3475.375, "latencies_ms": [3475.375], "images_per_second": 0.288, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "toilet: 1\nshower curtain: 1\nbathroom towel rack: 2\ntoilet paper: 1\nbathtub: 1\ncloset: 3\nbedspread: 1\nshower curtain: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12502.9, "ram_available_mb": 50338.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.304, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 7.08}, "timestamp": "2026-01-19T14:18:29.605598"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1855.758, "latencies_ms": [1855.758], "images_per_second": 0.539, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The toilet is positioned to the left of the shower and bathtub. The closet is located to the right of the toilet, separated by a narrow doorway.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.884, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T14:18:33.485540"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2073.305, "latencies_ms": [2073.305], "images_per_second": 0.482, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The bathroom features a white toilet, a bathtub with a shower curtain, and a closet with wire shelving. Towels hang on a towel rack above the toilet.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.324, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T14:18:37.600148"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2975.859, "latencies_ms": [2975.859], "images_per_second": 0.336, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The bathroom features a pale yellow color scheme, creating a warm and inviting atmosphere. The lighting appears to be soft and diffused, enhancing the overall ambiance. The materials used include white fixtures for the toilet and shower, beige tiles for the floor, and metal shelving for storage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.138, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T14:18:42.615785"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1459.338, "latencies_ms": [1459.338], "images_per_second": 0.685, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "Two people are standing in a room, holding wine glasses and smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.971, "power_cpu_cv_mean_watts": 0.91, "power_sys_5v0_mean_watts": 6.625}, "timestamp": "2026-01-19T14:18:46.124345"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2959.359, "latencies_ms": [2959.359], "images_per_second": 0.338, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Wine glass: 2\nWine bottle: 1\nWine: 2\nTable: 2\nChair: 1\nWindow: 1\nMan: 3\nWoman: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12503.3, "ram_available_mb": 50337.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.074, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.089}, "timestamp": "2026-01-19T14:18:51.124794"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2242.258, "latencies_ms": [2242.258], "images_per_second": 0.446, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the woman holding a wine glass slightly in front of her and the man standing behind her. The background includes other individuals and elements of a room, suggesting a social setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.4, "ram_available_mb": 50338.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12502.6, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.156, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.876}, "timestamp": "2026-01-19T14:18:55.377574"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2473.902, "latencies_ms": [2473.902], "images_per_second": 0.404, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a casual gathering in a home or restaurant, where two people are holding wine glasses and smiling at the camera. The setting appears to be a relaxed social environment, possibly a wine tasting or informal get-together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12502.6, "ram_available_mb": 50338.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.642, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 7.0}, "timestamp": "2026-01-19T14:18:59.894487"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2821.236, "latencies_ms": [2821.236], "images_per_second": 0.354, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The wine glasses are clear with red wine inside. The lighting is soft and warm, creating a pleasant atmosphere. The glasses appear to be made of glass and have a simple design. The overall setting suggests a casual, relaxed environment, possibly a wine tasting event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12503.1, "ram_available_mb": 50337.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.146, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.034}, "timestamp": "2026-01-19T14:19:04.769784"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1932.664, "latencies_ms": [1932.664], "images_per_second": 0.517, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A surfer skillfully rides a wave on a surfboard, showcasing their expertise and balance as they navigate the powerful force of the ocean.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.838, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T14:19:08.727586"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2502.214, "latencies_ms": [2502.214], "images_per_second": 0.4, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "wave: 1\nsurfer: 1\nsurfboard: 1\nwater: 1\nsand: 1\nsky: 1\npeople: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.516, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.984}, "timestamp": "2026-01-19T14:19:13.281913"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2725.807, "latencies_ms": [2725.807], "images_per_second": 0.367, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave that extends into the background. The wave is curling over, creating a tunnel-like effect. The surfer is relatively close to the wave, navigating it within the curling crest.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.985, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.968}, "timestamp": "2026-01-19T14:19:18.051883"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2489.236, "latencies_ms": [2489.236], "images_per_second": 0.402, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A surfer skillfully rides a wave in the ocean, wearing a wetsuit and riding a light-colored surfboard. The wave is breaking, creating a dramatic scene with clear blue water and a sandy beach in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12503.2, "ram_available_mb": 50337.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.623, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 7.061}, "timestamp": "2026-01-19T14:19:22.575224"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2786.862, "latencies_ms": [2786.862], "images_per_second": 0.359, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The water is a vibrant teal color, creating a striking contrast with the white foam of the wave. The lighting is bright and clear, illuminating the surfer and the wave's curves. The surfboard appears to be made of a light-colored wood or composite material.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.423, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T14:19:27.405455"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1687.024, "latencies_ms": [1687.024], "images_per_second": 0.593, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A wooden table holds six open laptops, some with visible keyboards and screens, and a red and black backpack.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.302, "power_cpu_cv_mean_watts": 1.14, "power_sys_5v0_mean_watts": 6.823}, "timestamp": "2026-01-19T14:19:31.124118"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3536.819, "latencies_ms": [3536.819], "images_per_second": 0.283, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "laptop: 5\nbackpack: 1\ncables: 2\nwires: 2\nlaptop charger: 1\nlaptop power adapter: 1\nlaptop keyboard: 4\nlaptop screen: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12503.8, "ram_available_mb": 50337.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.526, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 7.108}, "timestamp": "2026-01-19T14:19:36.686262"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2152.447, "latencies_ms": [2152.447], "images_per_second": 0.465, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned in a somewhat haphazard arrangement, with the backpack in the foreground and the laptops in the background. The laptops are spread out across the table, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12504.2, "ram_available_mb": 50336.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.067, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.865}, "timestamp": "2026-01-19T14:19:40.877106"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2493.121, "latencies_ms": [2493.121], "images_per_second": 0.401, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A group of laptops is arranged on a wooden table, showcasing various sizes and models. A red and black backpack is placed next to the laptops, partially obscuring the view. The setting appears to be an indoor workspace or study area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12504.0, "ram_available_mb": 50336.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.594, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T14:19:45.408675"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2187.656, "latencies_ms": [2187.656], "images_per_second": 0.457, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The laptops are primarily black and silver. The lighting in the room appears to be artificial, possibly from overhead fixtures. The laptops appear to be made of metal and plastic. The floor appears to be carpeted.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.1, "ram_available_mb": 50336.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.18, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.916}, "timestamp": "2026-01-19T14:19:49.621029"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1894.318, "latencies_ms": [1894.318], "images_per_second": 0.528, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A skier in an orange and green jacket is performing an impressive jump, crossing their skis in the air while holding ski poles.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.385, "power_cpu_cv_mean_watts": 1.122, "power_sys_5v0_mean_watts": 6.72}, "timestamp": "2026-01-19T14:19:53.563928"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3816.448, "latencies_ms": [3816.448], "images_per_second": 0.262, "prompt_tokens": 21, "response_tokens_est": 55, "n_tiles": 1, "output_text": "skier: 2\nskis: 2\nsnowboard: 1\nsnowboarder: 1\nsnowboard: 1\nsnowboard poles: 1\nsnowboard bindings: 1\nsnowboard boots: 1\nsnowboard: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12503.9, "ram_available_mb": 50337.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12504.8, "ram_available_mb": 50336.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.295, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.141}, "timestamp": "2026-01-19T14:19:59.408565"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2572.481, "latencies_ms": [2572.481], "images_per_second": 0.389, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, mid-air, performing a jump. The background features another skier further away, appearing smaller due to distance. The foreground is dominated by the snow, while the background is mostly clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12504.8, "ram_available_mb": 50336.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.479, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.017}, "timestamp": "2026-01-19T14:20:04.026802"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2167.916, "latencies_ms": [2167.916], "images_per_second": 0.461, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A skier is performing an impressive aerial trick, showcasing their skill and athleticism. The scene takes place on a snowy slope, with another skier visible in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12504.6, "ram_available_mb": 50336.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.527, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.961}, "timestamp": "2026-01-19T14:20:08.223551"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2705.943, "latencies_ms": [2705.943], "images_per_second": 0.37, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The skier is wearing bright orange and green clothing. The lighting is bright and clear, creating a visually striking image. The skis appear to be made of metal and have a sleek design. The snow is bright white, indicative of a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12505.6, "ram_available_mb": 50335.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.8, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.061, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T14:20:12.988590"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1659.452, "latencies_ms": [1659.452], "images_per_second": 0.603, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A small bird perches on the window sill of a boat, gazing out at the calm, dark blue water.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12506.1, "ram_available_mb": 50334.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12506.6, "ram_available_mb": 50334.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.214, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 6.308}, "timestamp": "2026-01-19T14:20:16.671656"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2653.025, "latencies_ms": [2653.025], "images_per_second": 0.377, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "porthole: 1\nbird: 1\nwater: 1\nmetal: 1\nframe: 1\npipes: 1\nsign: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12506.6, "ram_available_mb": 50334.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.691, "power_cpu_cv_mean_watts": 1.907, "power_sys_5v0_mean_watts": 6.768}, "timestamp": "2026-01-19T14:20:21.359439"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2343.372, "latencies_ms": [2343.372], "images_per_second": 0.427, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The bird is positioned near the window, seemingly observing the water. The window is situated in the foreground, offering a view of the water beyond. The background is relatively dark, suggesting the photo was taken in a dimly lit environment.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12507.6, "ram_available_mb": 50333.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.426, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 6.631}, "timestamp": "2026-01-19T14:20:25.757520"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2057.714, "latencies_ms": [2057.714], "images_per_second": 0.486, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A bird is perched on a rusty porthole window, gazing out at the calm, greyish-blue water. A rocky coastline is visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.8, "ram_available_mb": 50333.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.414, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 6.508}, "timestamp": "2026-01-19T14:20:29.859289"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2003.785, "latencies_ms": [2003.785], "images_per_second": 0.499, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The window frame is rusty brown. The water appears dark and somewhat choppy. The overall lighting is dim, suggesting an overcast or shaded environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12507.4, "ram_available_mb": 50333.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.264, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 6.382}, "timestamp": "2026-01-19T14:20:33.885752"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1560.862, "latencies_ms": [1560.862], "images_per_second": 0.641, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A man is cleaning a bathroom stall while another man stands nearby, possibly observing or waiting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12507.0, "ram_available_mb": 50333.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12508.0, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.857, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.678}, "timestamp": "2026-01-19T14:20:37.508503"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4717.756, "latencies_ms": [4717.756], "images_per_second": 0.212, "prompt_tokens": 21, "response_tokens_est": 63, "n_tiles": 1, "output_text": "toilet: 1\ntoilet paper: 2\ntoilet brush: 1\ntoilet cleaner: 1\ntoilet cleaner bucket: 1\ntoilet cleaner mop: 1\ntoilet cleaner shelf: 2\ntoilet lid: 1\ntoilet seat: 1\ntoilet seat cover: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12508.0, "ram_available_mb": 50332.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.696, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 7.219}, "timestamp": "2026-01-19T14:20:44.266297"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2500.641, "latencies_ms": [2500.641], "images_per_second": 0.4, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of spatial relationships. The toilet is located in the foreground, while the cleaning supplies are positioned on a shelf in the background. The man is positioned near the toilet, seemingly cleaning or preparing to clean it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.561, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.889}, "timestamp": "2026-01-19T14:20:48.791580"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2000.638, "latencies_ms": [2000.638], "images_per_second": 0.5, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two men are working in a bathroom, cleaning and organizing the space. One man is cleaning the floor, while the other is reaching into a toilet stall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.472, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.885}, "timestamp": "2026-01-19T14:20:52.819244"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3249.59, "latencies_ms": [3249.59], "images_per_second": 0.308, "prompt_tokens": 18, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The bathroom appears to have light-colored walls and flooring. The lighting seems somewhat dim, possibly from overhead fixtures or natural light filtering in through the open door. The materials visible include wood for the door and shelving, plastic for the toilet and cleaning supplies, and metal for the mop and bucket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.471, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.059}, "timestamp": "2026-01-19T14:20:58.117083"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1891.919, "latencies_ms": [1891.919], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A man is standing in a hallway, holding an open umbrella aloft amidst the rain, shielding himself from the downpour.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.265, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.982}, "timestamp": "2026-01-19T14:21:02.069416"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2989.957, "latencies_ms": [2989.957], "images_per_second": 0.334, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Umbrella: 1\nPerson: 1\nDoor: 2\nWall: 2\nPicture frame: 1\nRadiator: 1\nFloor: 1\nDoor handle: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.7, "ram_available_mb": 50330.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.374, "power_cpu_cv_mean_watts": 1.698, "power_sys_5v0_mean_watts": 7.084}, "timestamp": "2026-01-19T14:21:07.091927"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2895.414, "latencies_ms": [2895.414], "images_per_second": 0.345, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The man is standing in the foreground of the image, holding an umbrella that partially obscures him. The umbrella is positioned above him, creating a sense of depth and perspective. The background features a hallway with red walls, doors, and framed pictures, adding to the overall setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.7, "ram_available_mb": 50330.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.157, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 7.11}, "timestamp": "2026-01-19T14:21:12.036270"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2122.961, "latencies_ms": [2122.961], "images_per_second": 0.471, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A man is standing in a hallway, holding an umbrella to shield himself from the rain. The hallway has red walls and features framed pictures and mirrors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.873, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.801}, "timestamp": "2026-01-19T14:21:16.206035"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2934.48, "latencies_ms": [2934.48], "images_per_second": 0.341, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The walls are painted a reddish-pink color. The lighting is dim, creating a moody atmosphere. The umbrella is black and appears to be made of a sturdy material, likely metal or plastic. The rain is visible, falling from the ceiling and creating the visual effect.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.822, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 6.98}, "timestamp": "2026-01-19T14:21:21.160557"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2061.185, "latencies_ms": [2061.185], "images_per_second": 0.485, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two hikers, one with an orange jacket and the other with a blue backpack, are standing on a rocky trail near a stream, looking up at the surrounding foliage.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.6, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:21:25.253873"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2856.261, "latencies_ms": [2856.261], "images_per_second": 0.35, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "stairs: 5\nsign: 4\nman: 1\nbackpack: 1\npole: 1\nwater: 1\nrocks: 5\nvegetation: 5", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.113, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.012}, "timestamp": "2026-01-19T14:21:30.126483"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3078.25, "latencies_ms": [3078.25], "images_per_second": 0.325, "prompt_tokens": 25, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The man in the foreground is standing near the stream and looking upwards, possibly contemplating his next step or observing the surroundings. The man in the background is further away, standing near the stairs and looking towards the stream. The foreground and background are relatively close together, while the man in the foreground is slightly further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.041, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 7.067}, "timestamp": "2026-01-19T14:21:35.230629"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2294.696, "latencies_ms": [2294.696], "images_per_second": 0.436, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Two hikers, one in an orange jacket and the other in a yellow robe, are walking along a trail in a lush, forested area. The trail is partially covered in rocks and surrounded by dense greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.938, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:21:39.563874"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2559.346, "latencies_ms": [2559.346], "images_per_second": 0.391, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The man is wearing an orange jacket and blue jeans. The scene is lit by natural sunlight, creating a warm and inviting atmosphere. The setting appears to be outdoors in a natural environment, possibly a forest or park, with lush greenery and rocks visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.442, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.984}, "timestamp": "2026-01-19T14:21:44.184508"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1544.364, "latencies_ms": [1544.364], "images_per_second": 0.648, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Four men in business attire are standing together in a room, smiling and posing for a photo.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.759, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.837}, "timestamp": "2026-01-19T14:21:47.795410"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2601.491, "latencies_ms": [2601.491], "images_per_second": 0.384, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "man: 3\nman: 2\nman: 1\nman: 1\nman: 1\nman: 1\nman: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.033, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.123}, "timestamp": "2026-01-19T14:21:52.431944"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2081.521, "latencies_ms": [2081.521], "images_per_second": 0.48, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The four men are standing close together in the foreground, with a bar and chairs visible in the background. The bar is positioned to the left of the men, while the chairs are placed towards the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.8, "ram_available_mb": 50328.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.933, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 7.02}, "timestamp": "2026-01-19T14:21:56.556114"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2596.549, "latencies_ms": [2596.549], "images_per_second": 0.385, "prompt_tokens": 19, "response_tokens_est": 57, "n_tiles": 1, "output_text": "Four men are standing together in a room, possibly at a social gathering or event. They are posing for a photo, with some smiling and others looking directly at the camera. The setting appears to be a casual indoor space with tables, chairs, and a bar visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.8, "ram_available_mb": 50328.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.094, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.094}, "timestamp": "2026-01-19T14:22:01.186064"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2431.118, "latencies_ms": [2431.118], "images_per_second": 0.411, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The men are wearing light-colored shirts and suits. The lighting is bright, likely from overhead fixtures. The chairs appear to be made of wood and fabric. The setting suggests an indoor event, possibly a meeting or gathering.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.267, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 7.096}, "timestamp": "2026-01-19T14:22:05.650956"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1598.993, "latencies_ms": [1598.993], "images_per_second": 0.625, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A yellow traffic sign is mounted on a black pole at an intersection, with cars and buses visible in the background.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12510.7, "ram_available_mb": 50330.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.52, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.831}, "timestamp": "2026-01-19T14:22:09.319535"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2926.238, "latencies_ms": [2926.238], "images_per_second": 0.342, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "pole: 1\nsign: 1\nbus: 1\ncar: 2\nstreet light: 1\nbuildings: 5\nbus stop: 1\npedestrians: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.7, "ram_available_mb": 50330.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.957, "power_cpu_cv_mean_watts": 1.586, "power_sys_5v0_mean_watts": 7.014}, "timestamp": "2026-01-19T14:22:14.279905"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2136.514, "latencies_ms": [2136.514], "images_per_second": 0.468, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The foreground features a damaged traffic signal pole, positioned near the center of the image. The background showcases a typical city street scene with buildings, parked cars, and traffic lights.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.177, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.872}, "timestamp": "2026-01-19T14:22:18.443038"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2455.67, "latencies_ms": [2455.67], "images_per_second": 0.407, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a city street with buildings lining both sides. A yellow traffic sign is partially obscured by a damaged pole on the left side of the road. Several vehicles, including cars and a bus, are visible traveling down the street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.658, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T14:22:22.916397"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3018.455, "latencies_ms": [3018.455], "images_per_second": 0.331, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The street is paved with asphalt and appears wet, likely due to recent rain. The buildings lining the street are primarily brick and feature various storefronts with signs and lighting fixtures. The scene is illuminated by streetlights, giving the impression of an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.816, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 6.983}, "timestamp": "2026-01-19T14:22:27.998197"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1789.269, "latencies_ms": [1789.269], "images_per_second": 0.559, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A young man in a white shirt and cap is poised to hit a tennis ball with a red racket on a green court.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.855, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.789}, "timestamp": "2026-01-19T14:22:31.848504"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2818.307, "latencies_ms": [2818.307], "images_per_second": 0.355, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 2\nFence: 2\nSign: 2\nPerson: 1\nGrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.093, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.021}, "timestamp": "2026-01-19T14:22:36.703666"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2503.597, "latencies_ms": [2503.597], "images_per_second": 0.399, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the image, facing the left side of the court. The tennis racket is held in his right hand, positioned in the foreground. The tennis court extends into the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.625, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T14:22:41.229538"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2365.996, "latencies_ms": [2365.996], "images_per_second": 0.423, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A young man is playing tennis on a green court at night. He holds a tennis racket and appears to be preparing to hit a ball. The court is enclosed by a fence, and there are signs visible in the background.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.911, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T14:22:45.617507"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2356.697, "latencies_ms": [2356.697], "images_per_second": 0.424, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The tennis court is green and appears to be well-lit by artificial lighting. The court's surface is smooth and appears to be made of a durable material. The overall scene suggests an outdoor tennis court at night.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.763, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T14:22:50.023246"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2113.812, "latencies_ms": [2113.812], "images_per_second": 0.473, "prompt_tokens": 8, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Two skiers, one in a black jacket and the other in a white and gray outfit, greet each other with a high-five while standing near a blue fence on a snowy slope.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.603, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.931}, "timestamp": "2026-01-19T14:22:54.194311"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3343.88, "latencies_ms": [3343.88], "images_per_second": 0.299, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "helmet: 2\ngloves: 2\nski poles: 4\nskis: 2\nsnow: 2\ngoggles: 2\nbib: 1\nbib: 1\nbib: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.81, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.088}, "timestamp": "2026-01-19T14:22:59.561231"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1805.301, "latencies_ms": [1805.301], "images_per_second": 0.554, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the skiers interacting between them. The skiers are located in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12509.1, "ram_available_mb": 50331.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.427, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.876}, "timestamp": "2026-01-19T14:23:03.423866"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1824.081, "latencies_ms": [1824.081], "images_per_second": 0.548, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two skiers are congratulating each other after completing a race. They are standing on a snowy slope surrounded by ski equipment and barriers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12508.7, "ram_available_mb": 50332.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.453, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.897}, "timestamp": "2026-01-19T14:23:07.289872"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3149.433, "latencies_ms": [3149.433], "images_per_second": 0.318, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The skiers are wearing bright, colorful gear that stands out against the snowy background. The lighting is bright enough to illuminate their faces and equipment clearly. The skiers are wearing helmets and goggles, indicating safety precautions. The snow appears well-groomed and relatively undisturbed.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12508.9, "ram_available_mb": 50332.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.977, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.087}, "timestamp": "2026-01-19T14:23:12.493663"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1662.356, "latencies_ms": [1662.356], "images_per_second": 0.602, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A large blue semi-truck is driving down a wet residential street, passing parked cars and houses.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12508.8, "ram_available_mb": 50332.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.776, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.59}, "timestamp": "2026-01-19T14:23:16.200590"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3325.566, "latencies_ms": [3325.566], "images_per_second": 0.301, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "Truck: 1\nCar: 1\nBus: 1\nTrees: 2\nHouses: 2\nStreet: 2\nSidewalk: 2\nGrass: 2\nLamp post: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.458, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 7.089}, "timestamp": "2026-01-19T14:23:21.551961"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2570.316, "latencies_ms": [2570.316], "images_per_second": 0.389, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The main object, a blue truck, is positioned in the foreground of the image, moving down the street. The background features residential houses and parked cars, creating a residential setting. The truck is relatively close to the viewer, emphasizing its presence in the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.3, "ram_available_mb": 50331.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.405, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.036}, "timestamp": "2026-01-19T14:23:26.143633"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2355.437, "latencies_ms": [2355.437], "images_per_second": 0.425, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A large blue semi-truck is driving down a wet residential street, passing parked cars and houses. The scene suggests a typical suburban environment with residential homes and businesses lining the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.741, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:23:30.519529"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2056.606, "latencies_ms": [2056.606], "images_per_second": 0.486, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The truck is primarily blue and silver. The scene is lit by natural daylight, suggesting an overcast day. The truck appears to be carrying cargo on its trailer.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.5, "ram_available_mb": 50331.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.084, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.842}, "timestamp": "2026-01-19T14:23:34.595571"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1790.652, "latencies_ms": [1790.652], "images_per_second": 0.558, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A large commercial airplane is approaching the runway, preparing for takeoff amidst a hazy sky and distant mountains.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.228, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T14:23:38.450820"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2310.637, "latencies_ms": [2310.637], "images_per_second": 0.433, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "airplane: 1\nrunway: 1\nlights: 4\nmountains: 1\ngrass: 1\nfog: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.46, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 6.987}, "timestamp": "2026-01-19T14:23:42.792500"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2569.104, "latencies_ms": [2569.104], "images_per_second": 0.389, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main object, the airplane, is positioned in the foreground, appearing relatively large against the background of the hazy sky and distant mountains. The foreground features several orange and silver lights, possibly guiding the plane or signaling important information.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.346, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:23:47.412933"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1991.703, "latencies_ms": [1991.703], "images_per_second": 0.502, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A large passenger jet is approaching a runway, possibly taxiing. The scene is set in a mountainous area, with hazy skies and distant mountains visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.474, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T14:23:51.442893"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2197.076, "latencies_ms": [2197.076], "images_per_second": 0.455, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The plane is primarily white and blue. The runway is wet, indicating recent rain or moisture. The scene is illuminated by several orange floodlights, enhancing visibility on the runway.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.175, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T14:23:55.668311"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1857.3, "latencies_ms": [1857.3], "images_per_second": 0.538, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Two women are standing on a sandy beach, one holding a tennis racket and appearing angry, while the other holds a towel and looks concerned.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.099, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.321}, "timestamp": "2026-01-19T14:23:59.574288"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3054.882, "latencies_ms": [3054.882], "images_per_second": 0.327, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "American flag: 1\nLife guard tower: 1\nTennis racket: 1\nTowel: 1\nWater bottle: 1\nPeople: 6\nTrees: 1\nMountains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.711, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 6.794}, "timestamp": "2026-01-19T14:24:04.655295"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1971.249, "latencies_ms": [1971.249], "images_per_second": 0.507, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The woman on the left is positioned in the foreground, while the woman on the right is further in the background. Both are located on the sandy beach, with the lifeguard stand and American flag in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.589, "power_cpu_cv_mean_watts": 1.496, "power_sys_5v0_mean_watts": 6.538}, "timestamp": "2026-01-19T14:24:08.645716"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1905.012, "latencies_ms": [1905.012], "images_per_second": 0.525, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene takes place on a sandy beach with mountains in the background. Two young women are in the foreground, one holding a tennis racket and the other appearing to be in a heated exchange.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12510.9, "ram_available_mb": 50330.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.243, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 6.464}, "timestamp": "2026-01-19T14:24:12.571705"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2535.107, "latencies_ms": [2535.107], "images_per_second": 0.394, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The scene is bathed in warm sunlight, creating a vibrant atmosphere. The colors are predominantly earthy tones, complementing the natural surroundings. The lighting is soft and diffused, enhancing the overall ambiance of the beach setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.9, "ram_available_mb": 50330.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.73, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 6.763}, "timestamp": "2026-01-19T14:24:17.133752"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1890.739, "latencies_ms": [1890.739], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A male tennis player, dressed in blue and white, stands on a blue tennis court, holding a tennis racket and appearing contemplative.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.413, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.773}, "timestamp": "2026-01-19T14:24:21.062509"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3421.077, "latencies_ms": [3421.077], "images_per_second": 0.292, "prompt_tokens": 21, "response_tokens_est": 48, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis shoes: 2\nTennis court: 1\nTennis player: 1\nTennis headband: 1\nTennis shorts: 1\nTennis socks: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.5, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 7.146}, "timestamp": "2026-01-19T14:24:26.518672"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2576.283, "latencies_ms": [2576.283], "images_per_second": 0.388, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the image, facing the left side of the court. The tennis ball is held in his right hand, further away from the player. The tennis court extends into the background, creating a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.559, "power_cpu_cv_mean_watts": 1.87, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T14:24:31.128928"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2536.731, "latencies_ms": [2536.731], "images_per_second": 0.394, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A tennis player, dressed in blue and white, is seen on a blue tennis court, appearing somewhat dejected or contemplative. He holds a tennis racket in his right hand and looks downwards.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.255, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 6.984}, "timestamp": "2026-01-19T14:24:35.705946"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2405.194, "latencies_ms": [2405.194], "images_per_second": 0.416, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The tennis court is painted a light blue color. The lighting in the image is bright and creates a strong contrast with the blue surface. The tennis racket appears to be made of metal and has a classic design.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12514.9, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.679, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:24:40.127416"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1683.973, "latencies_ms": [1683.973], "images_per_second": 0.594, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A woman in a pink shirt and khaki shorts is standing in a kitchen, preparing food on a black stove.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12514.9, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.884, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.681}, "timestamp": "2026-01-19T14:24:43.864556"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3829.226, "latencies_ms": [3829.226], "images_per_second": 0.261, "prompt_tokens": 21, "response_tokens_est": 54, "n_tiles": 1, "output_text": "oven: 2\npan: 1\nkettle: 1\ncup: 1\nsaucepan: 1\nwooden spoon: 1\nwooden spoon rest: 1\nwooden spoon: 1\nwooden spoon: 1\nwooden spoon: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.434, "power_cpu_cv_mean_watts": 1.815, "power_sys_5v0_mean_watts": 7.122}, "timestamp": "2026-01-19T14:24:49.754448"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2844.906, "latencies_ms": [2844.906], "images_per_second": 0.352, "prompt_tokens": 25, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The woman is positioned to the left of the stove, seemingly preparing food. The stove occupies the central foreground, extending from the left edge to the center-right of the image. The kitchen area extends from the right side of the image towards the back, partially obscured by the stove.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.408, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.095}, "timestamp": "2026-01-19T14:24:54.633940"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2354.541, "latencies_ms": [2354.541], "images_per_second": 0.425, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A woman is cooking on a large, black wood-burning stove in a cozy kitchen. The stove is situated beneath a black metal hood, and there are various kitchen items and utensils scattered around.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.867, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.902}, "timestamp": "2026-01-19T14:24:59.027896"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2160.301, "latencies_ms": [2160.301], "images_per_second": 0.463, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The kitchen features a black wood-burning stove with exposed brick underneath. The walls are painted white, and the overall lighting is soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.342, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T14:25:03.212004"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1749.473, "latencies_ms": [1749.473], "images_per_second": 0.572, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two giraffes stand tall and majestic in a zoo enclosure, surrounded by rocks and trees, with a tan building in the background.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.313, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:25:06.990334"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2311.054, "latencies_ms": [2311.054], "images_per_second": 0.433, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "giraffe: 2\nbuilding: 1\nrocks: 10\ntrees: 5\ngrass: 2\nfence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.803, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 7.112}, "timestamp": "2026-01-19T14:25:11.331841"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1964.438, "latencies_ms": [1964.438], "images_per_second": 0.509, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with a building in the background. The giraffes are situated in a relatively open area with rocks and grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.184, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.935}, "timestamp": "2026-01-19T14:25:15.328243"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1668.076, "latencies_ms": [1668.076], "images_per_second": 0.599, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "Two giraffes stand in a zoo enclosure, surrounded by rocks and trees. A tan building is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.764, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.737}, "timestamp": "2026-01-19T14:25:19.035500"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3104.416, "latencies_ms": [3104.416], "images_per_second": 0.322, "prompt_tokens": 18, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The giraffes exhibit a rich brown coloration with lighter spots. The lighting in the image appears to be natural, possibly from overcast skies, giving the scene a soft, diffused quality. The giraffes are standing on a rocky terrain, which adds texture and depth to the image.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.344, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.104}, "timestamp": "2026-01-19T14:25:24.179998"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1768.248, "latencies_ms": [1768.248], "images_per_second": 0.566, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young baseball player in a green and yellow uniform is swinging a bat, preparing to hit a baseball that is mid-air.", "error": null, "sys_before": {"cpu_percent": 8.1, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.427, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T14:25:28.006985"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3432.227, "latencies_ms": [3432.227], "images_per_second": 0.291, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball: 1\nbaseball glove: 1\nbaseball: 1\nbaseball field: 1\nbaseball diamond: 1\nchain link fence: 2\ngrass: 2\nbase: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.638, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 7.16}, "timestamp": "2026-01-19T14:25:33.476195"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2183.121, "latencies_ms": [2183.121], "images_per_second": 0.458, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, facing the incoming baseball. The baseball is in the air, near the batter. The background features a chain-link fence, grass, and a parked vehicle.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.359, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T14:25:37.695041"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1902.086, "latencies_ms": [1902.086], "images_per_second": 0.526, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A young baseball player is swinging a bat at a ball during a game. The setting is a baseball field with a chain-link fence and grassy areas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.576, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T14:25:41.626212"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2009.541, "latencies_ms": [2009.541], "images_per_second": 0.498, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The batter is wearing a green and yellow uniform. The lighting appears to be natural daylight, creating a bright and clear atmosphere. The baseball bat is blue, and the ground is dirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.875, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T14:25:45.668353"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1777.301, "latencies_ms": [1777.301], "images_per_second": 0.563, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A vintage car is parked next to a red and white bus on a cobblestone street, with several people walking nearby.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.363, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:25:49.477105"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2937.148, "latencies_ms": [2937.148], "images_per_second": 0.34, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "car: 3\nbus: 1\nmotorcycle: 2\ntank: 1\nhistorical vehicle: 1\nhistorical building: 1\ntrees: 4\nflags: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.906, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.035}, "timestamp": "2026-01-19T14:25:54.436247"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2164.289, "latencies_ms": [2164.289], "images_per_second": 0.462, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The black vintage cars are positioned in the foreground, slightly to the left of the center. The cobblestone street extends into the background, separating the vehicles from the people and the buildings.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.224, "power_cpu_cv_mean_watts": 1.273, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T14:25:58.629390"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3172.75, "latencies_ms": [3172.75], "images_per_second": 0.315, "prompt_tokens": 19, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The scene depicts a vintage car show or gathering, featuring various antique vehicles parked on a cobblestone street.  People are milling about, admiring the vehicles, and walking around the area. A red double-decker bus and military vehicles are also present, adding to the historical atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.528, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.071}, "timestamp": "2026-01-19T14:26:03.845188"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2389.738, "latencies_ms": [2389.738], "images_per_second": 0.418, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The cobblestone street is illuminated by sunlight, creating a warm, inviting atmosphere.  The vehicles, including vintage cars and buses, are parked in a way that suggests a historical or themed event.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.529, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.881}, "timestamp": "2026-01-19T14:26:08.271750"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1749.961, "latencies_ms": [1749.961], "images_per_second": 0.571, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "The setting sun casts a warm glow over the city street, illuminating the blurred lights and creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.965, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.681}, "timestamp": "2026-01-19T14:26:12.090315"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2432.719, "latencies_ms": [2432.719], "images_per_second": 0.411, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Parking meter: 2\nSunset: 1\nBuildings: 2\nLights: 4\nCar: 1\nRoad: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.682, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T14:26:16.551096"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2219.484, "latencies_ms": [2219.484], "images_per_second": 0.451, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The parking meters are positioned in the foreground, slightly to the right of the viewer. The setting sun in the background creates a warm glow and soft light, enhancing the overall ambiance of the scene.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.933, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.814}, "timestamp": "2026-01-19T14:26:20.808937"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1923.466, "latencies_ms": [1923.466], "images_per_second": 0.52, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The scene is set at sunset, with two parking meters in the foreground. The sun is setting in the background, casting a warm glow over the urban landscape.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.943, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:26:24.775780"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2305.414, "latencies_ms": [2305.414], "images_per_second": 0.434, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The parking meters are dark brown or black. The lighting suggests it's either sunrise or sunset, creating a warm, golden glow. The scene appears to be outdoors, possibly on a street or in a parking lot.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.11, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.904}, "timestamp": "2026-01-19T14:26:29.122925"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1755.785, "latencies_ms": [1755.785], "images_per_second": 0.57, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A couple stands next to a large brown suitcase with travel stickers, positioned in front of a Fidelity Investments building.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.08, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.84}, "timestamp": "2026-01-19T14:26:32.919765"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2936.342, "latencies_ms": [2936.342], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "suitcase: 1\nstatue: 1\nman: 2\nwoman: 2\nman: 1\nwoman: 1\nman: 1\nwoman: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.8, "ram_available_mb": 50330.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.058, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.072}, "timestamp": "2026-01-19T14:26:37.907648"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2518.106, "latencies_ms": [2518.106], "images_per_second": 0.397, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The large suitcase is positioned in the foreground, slightly to the left of the couple. The couple stands in the background, slightly to the right of the suitcase. The suitcase and couple are situated on a raised platform or plinth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12511.0, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.194, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T14:26:42.461648"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2795.766, "latencies_ms": [2795.766], "images_per_second": 0.358, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A large brown suitcase adorned with various travel stickers sits on a pedestal in a public area, possibly a plaza or square. A couple stands nearby, seemingly admiring the suitcase. A Fidelity Investments sign is visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12511.0, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12510.9, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.215, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.025}, "timestamp": "2026-01-19T14:26:47.285471"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3690.086, "latencies_ms": [3690.086], "images_per_second": 0.271, "prompt_tokens": 18, "response_tokens_est": 71, "n_tiles": 1, "output_text": "The suitcase is brown and adorned with various stickers, showcasing a mix of colors. The lighting in the image is bright, highlighting the details of the suitcase and the stickers. The suitcase appears to be made of leather or a similar material. The overall scene suggests a public space, possibly a plaza or sidewalk, where people have gathered to admire the artistic display.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.9, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.389, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 7.147}, "timestamp": "2026-01-19T14:26:53.013279"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1834.11, "latencies_ms": [1834.11], "images_per_second": 0.545, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The dish includes grilled chicken, saut\u00e9ed mushrooms, fresh broccoli, and parsley, all served on a white plate.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12511.2, "ram_available_mb": 50329.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.11, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.861}, "timestamp": "2026-01-19T14:26:56.887965"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2746.002, "latencies_ms": [2746.002], "images_per_second": 0.364, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Mushrooms: 8\nBroccoli: 2\nChicken: 2\nParsley: 2\nBlack pepper: 2\nWhite wine: 1\nWhite sauce: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.334, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 7.033}, "timestamp": "2026-01-19T14:27:01.670949"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2261.647, "latencies_ms": [2261.647], "images_per_second": 0.442, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the mushrooms and broccoli arranged around them. The mushrooms are located to the left and foreground, while the broccoli is on the right side of the image. The arrangement creates a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.159, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T14:27:05.957353"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2256.065, "latencies_ms": [2256.065], "images_per_second": 0.443, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The scene features a plate of grilled fish with mushrooms and broccoli, garnished with fresh parsley. The dish is presented on a dark surface, possibly a table or countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.472, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T14:27:10.244684"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3412.016, "latencies_ms": [3412.016], "images_per_second": 0.293, "prompt_tokens": 18, "response_tokens_est": 70, "n_tiles": 1, "output_text": "The dish features a mix of vibrant colors, including green broccoli, white fish, and brown mushrooms. The lighting is warm and inviting, enhancing the visual appeal of the meal. The fish appears to be seasoned with herbs and spices, and the mushrooms are saut\u00e9ed alongside the fish. The overall presentation suggests a carefully prepared and appetizing dish.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.765, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.131}, "timestamp": "2026-01-19T14:27:15.693626"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2003.865, "latencies_ms": [2003.865], "images_per_second": 0.499, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A wooden crate brims with an assortment of fresh vegetables, including leafy greens, carrots, cauliflower, and broccoli, arranged in neat piles.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.456, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.478}, "timestamp": "2026-01-19T14:27:19.719182"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3115.754, "latencies_ms": [3115.754], "images_per_second": 0.321, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "carrots: 10\nbroccoli: 2\ncabbage: 1\nlettuce: 1\nonions: 4\nasparagus: 1\nspinach: 1\nbroccoli florets: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.738, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 6.858}, "timestamp": "2026-01-19T14:27:24.880110"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2683.093, "latencies_ms": [2683.093], "images_per_second": 0.373, "prompt_tokens": 25, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The carrots are positioned in the foreground, slightly to the right of the image. The broccoli and cabbage are placed in the background, extending towards the left side of the image. The arrangement creates a sense of depth and perspective, with the carrots and broccoli in the foreground and the cabbage and broccoli further back.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.596, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 6.724}, "timestamp": "2026-01-19T14:27:29.601084"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2940.187, "latencies_ms": [2940.187], "images_per_second": 0.34, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a vibrant display of fresh produce at a market or grocery store. The produce includes carrots, leafy greens, and cabbage, arranged in baskets and crates. The setting suggests a bustling marketplace where customers can browse and purchase fresh, healthy items.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.731, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 6.77}, "timestamp": "2026-01-19T14:27:34.557396"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1648.781, "latencies_ms": [1648.781], "images_per_second": 0.607, "prompt_tokens": 18, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The carrots are bright orange and appear to be freshly picked. The vegetables are arranged in baskets with natural light illuminating them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.875, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.141}, "timestamp": "2026-01-19T14:27:38.247843"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1857.695, "latencies_ms": [1857.695], "images_per_second": 0.538, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A conveyor belt carries freshly made glazed doughnuts through a bustling bakery, passing through a series of machines and oven areas.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12511.0, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.214, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.411}, "timestamp": "2026-01-19T14:27:42.153701"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2277.101, "latencies_ms": [2277.101], "images_per_second": 0.439, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "donuts: 10\nconveyor belt: 10\noven: 10\nshelves: 10\npeople: 5\nglass: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12511.0, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.704, "power_cpu_cv_mean_watts": 1.624, "power_sys_5v0_mean_watts": 6.68}, "timestamp": "2026-01-19T14:27:46.454359"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2130.295, "latencies_ms": [2130.295], "images_per_second": 0.469, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the conveyor belt and doughnut-making equipment extending into the background. The doughnuts are moving along the conveyor belt, moving from left to right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.85, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 6.641}, "timestamp": "2026-01-19T14:27:50.602810"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3034.736, "latencies_ms": [3034.736], "images_per_second": 0.33, "prompt_tokens": 19, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The scene depicts a busy bakery or doughnut factory with several conveyor belts carrying freshly made doughnuts. Workers can be seen attending to tasks and machinery, while customers are visible in the background. The environment is well-lit and organized, typical of a commercial food production setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.759, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 6.85}, "timestamp": "2026-01-19T14:27:55.683879"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2954.913, "latencies_ms": [2954.913], "images_per_second": 0.338, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The donuts on the conveyor belt are golden-brown, indicating they are freshly baked. The lighting in the bakery is bright, illuminating the donuts and creating an inviting atmosphere. The machinery appears to be stainless steel, reflecting the cleanliness and efficiency of the production process.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.648, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 6.762}, "timestamp": "2026-01-19T14:28:00.658116"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1787.703, "latencies_ms": [1787.703], "images_per_second": 0.559, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man in green is preparing to throw an orange frisbee in a wooded area, surrounded by tall trees and fallen leaves.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.941, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T14:28:04.495426"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2880.621, "latencies_ms": [2880.621], "images_per_second": 0.347, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "tree: 1\nthrowing disc: 1\nperson: 1\nfrisbee: 1\nground: 1\nleaves: 1\nbranches: 1\nleaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12510.9, "ram_available_mb": 50330.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.005, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.98}, "timestamp": "2026-01-19T14:28:09.408586"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2692.402, "latencies_ms": [2692.402], "images_per_second": 0.371, "prompt_tokens": 25, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The man is positioned near the center of the image, facing the left side of the frame. The ground is mostly covered in fallen leaves and twigs, creating a natural, wooded environment. The man is holding a disc, positioned slightly to the right of the center of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.9, "ram_available_mb": 50330.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.494, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T14:28:14.124507"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2511.942, "latencies_ms": [2511.942], "images_per_second": 0.398, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A man is playing disc golf in a wooded area. He's positioned near a fallen tree, preparing to throw a disc. The setting appears to be a natural, wooded area with pine trees and leaf-covered ground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.603, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.975}, "timestamp": "2026-01-19T14:28:18.664533"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2799.772, "latencies_ms": [2799.772], "images_per_second": 0.357, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene is bathed in natural daylight, creating a warm and inviting atmosphere. The ground is covered with fallen leaves and pine needles, hinting at a season of changing seasons. The man is dressed in casual attire, blending into the forest setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.024, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.003}, "timestamp": "2026-01-19T14:28:23.501182"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1752.118, "latencies_ms": [1752.118], "images_per_second": 0.571, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The bathroom features a white sink, toilet, and shower with striped curtains, complemented by beige tiles on the floor.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.826, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.739}, "timestamp": "2026-01-19T14:28:27.290836"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4609.958, "latencies_ms": [4609.958], "images_per_second": 0.217, "prompt_tokens": 21, "response_tokens_est": 66, "n_tiles": 1, "output_text": "sink: 1\ntoilet: 1\nshower: 1\nbathroom mirror: 1\nshower curtain: 1\ntoilet paper holder: 1\ntoilet brush holder: 1\ntoilet cleaner: 1\nAjax: 1\nsoap dispenser: 1\ntowel rack: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.852, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 7.219}, "timestamp": "2026-01-19T14:28:33.926461"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1964.801, "latencies_ms": [1964.801], "images_per_second": 0.509, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The sink is located on the left side of the image, while the toilet is positioned in the background. The bathroom is relatively narrow and positioned close to the shower and bathtub.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.439, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.8}, "timestamp": "2026-01-19T14:28:37.907410"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2598.217, "latencies_ms": [2598.217], "images_per_second": 0.385, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The bathroom features a white sink, toilet, and bathtub with striped shower curtains. The walls are painted a light yellow, and the floor is tiled in a beige color. Various cleaning supplies are scattered across the countertop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.2, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.33, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 7.012}, "timestamp": "2026-01-19T14:28:42.533540"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2613.383, "latencies_ms": [2613.383], "images_per_second": 0.383, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The bathroom features a beige color scheme with blue accents. The lighting is soft and diffused, creating a calm atmosphere. The materials include beige tiles, beige countertops, and white fixtures. The weather appears to be sunny and dry.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.503, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T14:28:47.186931"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2096.711, "latencies_ms": [2096.711], "images_per_second": 0.477, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The kitchen features a wooden island with a sink, silver faucet, and black countertop, complemented by wooden cabinets and a window providing natural light.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.203, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T14:28:51.316460"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3414.185, "latencies_ms": [3414.185], "images_per_second": 0.293, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "kitchen sink: 2\nwooden cabinets: 4\ncountertop: 2\nwooden island: 1\nfaucet: 1\nwindow: 2\ntable: 1\nchairs: 2\ntoaster: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.339, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.059}, "timestamp": "2026-01-19T14:28:56.748267"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2863.892, "latencies_ms": [2863.892], "images_per_second": 0.349, "prompt_tokens": 25, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The sink is located in the foreground, positioned between the left and central sides of the image. The wooden counter extends from the sink towards the background, providing a countertop area for cooking and food preparation. The kitchen is well-lit and features natural light coming from the windows in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.495, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.047}, "timestamp": "2026-01-19T14:29:01.637014"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2786.907, "latencies_ms": [2786.907], "images_per_second": 0.359, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The kitchen features a modern design with light wood cabinetry, a dark countertop, and a large island with a sink and faucet. A dining area with wooden chairs and a table is visible in the background, adjacent to windows that offer natural light.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.406, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.043}, "timestamp": "2026-01-19T14:29:06.442136"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2549.4, "latencies_ms": [2549.4], "images_per_second": 0.392, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The kitchen features a light wood countertop with a dark granite top. The lighting is bright, likely from overhead fixtures, creating a well-lit space. The materials appear to be natural wood and granite, contributing to the warm and inviting ambiance.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.723, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 7.081}, "timestamp": "2026-01-19T14:29:11.006544"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1574.79, "latencies_ms": [1574.79], "images_per_second": 0.635, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A person is sleeping peacefully on a bed covered with a black comforter and white daisies.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.026, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.762}, "timestamp": "2026-01-19T14:29:14.626633"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2816.198, "latencies_ms": [2816.198], "images_per_second": 0.355, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Bed: 2\nPillow: 1\nBlanket: 2\nBedspread: 2\nChild: 1\nNightstand: 1\nCord: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.456, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.042}, "timestamp": "2026-01-19T14:29:19.457816"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1776.328, "latencies_ms": [1776.328], "images_per_second": 0.563, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The child is lying in bed near the foot of the bed. The bed occupies the foreground, while the child's face is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.512, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.811}, "timestamp": "2026-01-19T14:29:23.257436"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2020.041, "latencies_ms": [2020.041], "images_per_second": 0.495, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A young child is sleeping peacefully on a bed covered with a dark blanket adorned with white daisy-like flowers. The room is dimly lit, creating a cozy and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.674, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.885}, "timestamp": "2026-01-19T14:29:27.310926"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1938.362, "latencies_ms": [1938.362], "images_per_second": 0.516, "prompt_tokens": 18, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The bedspread is dark blue with white daisy patterns. The lighting is dim, creating a cozy atmosphere. The material appears to be soft and possibly cotton.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.838, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T14:29:31.263308"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1877.391, "latencies_ms": [1877.391], "images_per_second": 0.533, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young skateboarder in white shoes and cargo shorts is captured mid-trick on a concrete ramp in a skate park.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.57, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.787}, "timestamp": "2026-01-19T14:29:35.188027"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2897.668, "latencies_ms": [2897.668], "images_per_second": 0.345, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "shoe: 1\nskateboard: 1\nskater: 1\nshorts: 1\nsocks: 1\nbuilding: 1\ntrees: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12514.2, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.14, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.093}, "timestamp": "2026-01-19T14:29:40.119702"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2767.659, "latencies_ms": [2767.659], "images_per_second": 0.361, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The skateboarder is positioned in the foreground, moving towards the left side of the image. The background features buildings and a clear sky, suggesting an urban setting. The skateboarder's shadow is cast on the ground, indicating a relatively bright and sunny day.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12514.2, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.366, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.046}, "timestamp": "2026-01-19T14:29:44.910307"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2364.771, "latencies_ms": [2364.771], "images_per_second": 0.423, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a skateboarder performing a trick on a concrete ramp in a skate park. Another person is visible in the background, possibly watching the skateboarder or waiting for their turn.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.785, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T14:29:49.319556"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2271.275, "latencies_ms": [2271.275], "images_per_second": 0.44, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The skateboarder is wearing light-colored shoes and shorts. The scene appears to be outdoors in bright sunlight. The skateboard is sleek and appears to be made of metal or plastic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.289, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.938}, "timestamp": "2026-01-19T14:29:53.615058"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1880.229, "latencies_ms": [1880.229], "images_per_second": 0.532, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A man is lying on the floor, relaxing and surrounded by various objects, including a laptop, camera, cell phone, book, and sports equipment.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.916, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T14:29:57.573289"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3323.621, "latencies_ms": [3323.621], "images_per_second": 0.301, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "laptop: 2\ncamera: 2\ncell phone: 1\nlaptop: 1\nracket: 1\nkey: 1\nbook: 1\nbag: 1\nwater bottle: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.442, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 7.104}, "timestamp": "2026-01-19T14:30:02.925955"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3646.591, "latencies_ms": [3646.591], "images_per_second": 0.274, "prompt_tokens": 25, "response_tokens_est": 85, "n_tiles": 1, "output_text": "The man is positioned on the left side of the image, lying down with his head resting on the ground. The objects surrounding him are placed at various distances, creating a sense of depth and perspective. The foreground includes a tennis racket, a cell phone, a laptop, a camera, a book, a water bottle, and a bag. The background features additional items like a calendar, a camera, and a cell phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.8, "ram_available_mb": 50325.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.54, "power_cpu_cv_mean_watts": 1.789, "power_sys_5v0_mean_watts": 7.163}, "timestamp": "2026-01-19T14:30:08.621156"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2893.981, "latencies_ms": [2893.981], "images_per_second": 0.346, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "A man is lying on the floor surrounded by various items, including a laptop displaying a plant, a camera, a cell phone, a book, a tennis racket, a water bottle, a bag, and a calendar. The scene suggests a casual, relaxed setting, possibly a home or office.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.125, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.016}, "timestamp": "2026-01-19T14:30:13.531611"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2170.503, "latencies_ms": [2170.503], "images_per_second": 0.461, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene features a beige carpet with soft lighting, creating a warm and inviting atmosphere. The objects are primarily black, white, and red, giving a modern and stylish feel to the setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.068, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T14:30:17.754548"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2042.93, "latencies_ms": [2042.93], "images_per_second": 0.489, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A black electric stovetop with four burners sits on a countertop, accompanied by a spice rack, a utensil holder, and a towel rack.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.548, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.879}, "timestamp": "2026-01-19T14:30:21.824658"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3327.217, "latencies_ms": [3327.217], "images_per_second": 0.301, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "spice rack: 5\noven: 4\ncountertop: 4\noven handle: 1\noven knob: 1\noven handle: 1\noven handle: 1\noven handle: 1\noven handle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.709, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 7.142}, "timestamp": "2026-01-19T14:30:27.184718"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2088.902, "latencies_ms": [2088.902], "images_per_second": 0.479, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The spice rack is positioned to the left of the stove, near the foreground. The backsplash is behind the stove and extends to the top of the image, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.398, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T14:30:31.290759"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2187.081, "latencies_ms": [2187.081], "images_per_second": 0.457, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene depicts a modern kitchen with a black electric cooktop, a spice rack, and a black range hood above. The counter is neatly organized with various kitchen utensils and spices.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.045, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T14:30:35.512704"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2614.367, "latencies_ms": [2614.367], "images_per_second": 0.383, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The kitchen features a light-colored, marbled backsplash in shades of beige, gray, and brown. The lighting is soft and warm, creating a cozy atmosphere. The countertop appears to be made of dark material, possibly granite or slate.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.766, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.036}, "timestamp": "2026-01-19T14:30:40.168034"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2223.789, "latencies_ms": [2223.789], "images_per_second": 0.45, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A young man is sitting at a table in a bakery, enjoying a plate of assorted donuts, including chocolate and sprinkled varieties, while sipping coffee.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12519.5, "ram_available_mb": 50321.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.986, "power_cpu_cv_mean_watts": 1.366, "power_sys_5v0_mean_watts": 6.913}, "timestamp": "2026-01-19T14:30:44.420493"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3883.741, "latencies_ms": [3883.741], "images_per_second": 0.257, "prompt_tokens": 21, "response_tokens_est": 57, "n_tiles": 1, "output_text": "Donut: 2\nChocolate glazed donut: 1\nChocolate frosted donut: 1\nChocolate sprinkles: 1\nCoffee cup: 1\nSoda: 1\nBrown paper bag: 1\nWooden chair: 1\nTable: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12519.5, "ram_available_mb": 50321.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.27, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.194}, "timestamp": "2026-01-19T14:30:50.322657"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2031.349, "latencies_ms": [2031.349], "images_per_second": 0.492, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The donuts are placed in the foreground of the image, with the person eating them in the background. The table and chairs are positioned in the background, further away from the main focus.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.348, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T14:30:54.386755"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3077.015, "latencies_ms": [3077.015], "images_per_second": 0.325, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene takes place in a brightly lit cafe or bakery, where a person is enjoying a selection of donuts on trays and plates. A man is seated at a table, partially visible in the image, eating a donut and holding a donut in his hand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.973, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.068}, "timestamp": "2026-01-19T14:30:59.488896"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2676.006, "latencies_ms": [2676.006], "images_per_second": 0.374, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The donuts are primarily in shades of brown and dark chocolate. The lighting in the image is warm and slightly dim, creating a cozy atmosphere. The donuts appear to be made of dough and have a glossy glaze, suggesting they are freshly baked.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.425, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 6.969}, "timestamp": "2026-01-19T14:31:04.204395"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1977.874, "latencies_ms": [1977.874], "images_per_second": 0.506, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A white sink with a glass top is mounted on a metal stand, accompanied by a toilet with a cow-print lid and a decorative bowl with sea creatures.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.477, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.766}, "timestamp": "2026-01-19T14:31:08.244221"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2732.96, "latencies_ms": [2732.96], "images_per_second": 0.366, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "sink: 2\ntoilet: 1\nchair: 1\nglass: 1\ndecorative plate: 1\nfloor tiles: 2\nwall tiles: 2", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.423, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.973}, "timestamp": "2026-01-19T14:31:13.005386"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2499.933, "latencies_ms": [2499.933], "images_per_second": 0.4, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The sink and toilet are placed close together, while the cow-print toilet seat is positioned further away, emphasizing the distance between the objects.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.724, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 6.975}, "timestamp": "2026-01-19T14:31:17.535500"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2364.893, "latencies_ms": [2364.893], "images_per_second": 0.423, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a bathroom with a modern design, featuring white sinks, a glass-topped counter, and a cow-print toilet seat. The bathroom is situated on a black and white checkered floor.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.653, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T14:31:21.963075"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2466.176, "latencies_ms": [2466.176], "images_per_second": 0.405, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The bathroom features a predominantly white color scheme with black accents. The lighting is bright and evenly distributed, creating a clean and functional space. The materials appear to be modern and sleek, contributing to the overall contemporary aesthetic.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.402, "power_cpu_cv_mean_watts": 1.382, "power_sys_5v0_mean_watts": 6.869}, "timestamp": "2026-01-19T14:31:26.453057"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2112.7, "latencies_ms": [2112.7], "images_per_second": 0.473, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Three stuffed animals are perched atop a weathered wooden cross, adorned with a white beaded necklace, situated in a grassy area near a brick border and a tree.", "error": null, "sys_before": {"cpu_percent": 8.8, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12519.3, "ram_available_mb": 50321.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.575, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.943}, "timestamp": "2026-01-19T14:31:30.633223"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2705.971, "latencies_ms": [2705.971], "images_per_second": 0.37, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "cross: 3\nbears: 3\nstone: 1\nsign: 2\ngrass: 2\npath: 1\nbush: 1\ntree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.3, "ram_available_mb": 50321.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12519.2, "ram_available_mb": 50321.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.348, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 7.047}, "timestamp": "2026-01-19T14:31:35.384029"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2038.009, "latencies_ms": [2038.009], "images_per_second": 0.491, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The stuffed animals are positioned prominently in the foreground, contrasting with the more distant background elements. The cross stands at the center, partially obscuring the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.2, "ram_available_mb": 50321.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.097, "power_cpu_cv_mean_watts": 1.176, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T14:31:39.441890"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2813.5, "latencies_ms": [2813.5], "images_per_second": 0.355, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene depicts a grave with a wooden cross adorned with stuffed animals, symbolizing a memorial for Joseph Panis, a mystic malulant. The cross is situated in a grassy area near a walkway and surrounded by trees and shrubs.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.212, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T14:31:44.284086"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2510.325, "latencies_ms": [2510.325], "images_per_second": 0.398, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The cross appears to be made of light brown or tan stone. The lighting in the image is soft and diffused, suggesting an overcast day. The material of the cross appears to be weathered and aged, contributing to its overall appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.556, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.969}, "timestamp": "2026-01-19T14:31:48.841485"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1693.432, "latencies_ms": [1693.432], "images_per_second": 0.591, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A large group of people are gathered in a spacious, modern restaurant, enjoying a meal and engaging in lively conversation.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.909, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.659}, "timestamp": "2026-01-19T14:31:52.591445"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2846.193, "latencies_ms": [2846.193], "images_per_second": 0.351, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "large clock: 8\nmetal beams: 8\nwooden chairs: 8\ntable: 8\npeople: 8\ncounter: 8\nmenu: 1\nlight fixture: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.02, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 7.073}, "timestamp": "2026-01-19T14:31:57.496665"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2584.83, "latencies_ms": [2584.83], "images_per_second": 0.387, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The large clock dominates the background, positioned near the center and slightly to the right of the main seating area. The foreground features tables and chairs arranged around the clock, providing a space for patrons to sit and enjoy their meals.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.497, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:32:02.123161"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2826.916, "latencies_ms": [2826.916], "images_per_second": 0.354, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a bustling caf\u00e9 or restaurant with numerous patrons seated at tables and chairs. A large clock is prominently displayed on the wall, serving as a unique focal point in the space. The atmosphere is lively, with people engaged in conversation and enjoying their meals.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.336, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 7.091}, "timestamp": "2026-01-19T14:32:06.983075"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2673.362, "latencies_ms": [2673.362], "images_per_second": 0.374, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The interior of the caf\u00e9 is illuminated by warm lighting, creating a cozy and inviting atmosphere. The walls are painted in a light beige color, and the ceiling features exposed metal beams. The large clock on the wall adds a unique architectural element to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.386, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.024}, "timestamp": "2026-01-19T14:32:11.698199"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1576.598, "latencies_ms": [1576.598], "images_per_second": 0.634, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A man and a child are enjoying a day of snowboarding down a snowy hill, surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.558, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.694}, "timestamp": "2026-01-19T14:32:15.346454"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3038.678, "latencies_ms": [3038.678], "images_per_second": 0.329, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "snowboard: 2\nperson: 2\nsnow: 6\ntree: 4\nrocks: 2\nsnowboard: 2\nskis: 2\ngoggles: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.957, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.08}, "timestamp": "2026-01-19T14:32:20.428942"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1861.492, "latencies_ms": [1861.492], "images_per_second": 0.537, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the child on the left and the adult on the right. The background is relatively empty and includes some snow and rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.492, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.733}, "timestamp": "2026-01-19T14:32:24.329599"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1931.174, "latencies_ms": [1931.174], "images_per_second": 0.518, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Two people are snowboarding down a snowy slope in a wooded area. The scene is bright and sunny, with snow-covered trees and a clear sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.65, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T14:32:28.288833"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1767.595, "latencies_ms": [1767.595], "images_per_second": 0.566, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The snow is bright white, indicating good lighting conditions. The snow appears smooth and undisturbed, suggesting good weather conditions for skiing.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.452, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.789}, "timestamp": "2026-01-19T14:32:32.090716"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1685.007, "latencies_ms": [1685.007], "images_per_second": 0.593, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A pair of feet wearing flip-flops is standing on a wooden floor, accompanied by three cell phones, one of which appears to be broken.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.122, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.21}, "timestamp": "2026-01-19T14:32:35.813339"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3779.139, "latencies_ms": [3779.139], "images_per_second": 0.265, "prompt_tokens": 21, "response_tokens_est": 57, "n_tiles": 1, "output_text": "Cell phone: 3\nFlip phone: 2\nCell phone cover: 1\nCell phone body: 1\nFlip phone: 1\nFlip phone screen: 1\nFlip phone buttons: 4\nFlip phone flip: 1\nFlip phone flip cover: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 10.004, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 6.971}, "timestamp": "2026-01-19T14:32:41.621337"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1980.781, "latencies_ms": [1980.781], "images_per_second": 0.505, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The person's feet are positioned in the foreground, partially obscuring the background. The flip-flops are placed near the center and slightly to the right of the feet.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.242, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 6.437}, "timestamp": "2026-01-19T14:32:45.631537"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2284.53, "latencies_ms": [2284.53], "images_per_second": 0.438, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a person's feet wearing flip-flops on a wooden floor, alongside two cell phones, one open with internal components visible, and the other closed. The setting appears to be a casual, everyday environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.616, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 6.512}, "timestamp": "2026-01-19T14:32:49.939321"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2461.289, "latencies_ms": [2461.289], "images_per_second": 0.406, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The wooden floor is brown and appears worn. The lighting is soft and diffused, suggesting natural light. The cell phones are black and appear to be made of plastic or metal. The phone's internal components are visible.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.357, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.607}, "timestamp": "2026-01-19T14:32:54.452425"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2134.453, "latencies_ms": [2134.453], "images_per_second": 0.469, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The Palace of Westminster, home to the British Parliament, is illuminated by warm lights and stands majestically on the banks of the River Thames in London, with boats passing by in the foreground.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.522, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.587}, "timestamp": "2026-01-19T14:32:58.630755"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2306.077, "latencies_ms": [2306.077], "images_per_second": 0.434, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "building: 8\ntower: 1\nclock: 2\nflag: 1\nboat: 3\nwater: 4\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.526, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 6.557}, "timestamp": "2026-01-19T14:33:02.965433"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2059.338, "latencies_ms": [2059.338], "images_per_second": 0.486, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned across the river, with the Palace of Westminster situated in the background. The foreground features several boats moored on the river, while the background includes additional buildings along the riverbank.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.614, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.486}, "timestamp": "2026-01-19T14:33:07.063439"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2235.082, "latencies_ms": [2235.082], "images_per_second": 0.447, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene depicts the Palace of Westminster in London, illuminated at night. Boats are moored along the riverbank, and Big Ben is visible in the background. The atmosphere is serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.348, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 6.546}, "timestamp": "2026-01-19T14:33:11.333414"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2128.46, "latencies_ms": [2128.46], "images_per_second": 0.47, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The buildings are primarily illuminated in warm yellow light, creating a striking contrast against the muted, cloudy sky. The river reflects the soft light, giving the scene a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.45, "power_cpu_cv_mean_watts": 1.555, "power_sys_5v0_mean_watts": 6.534}, "timestamp": "2026-01-19T14:33:15.480419"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1944.456, "latencies_ms": [1944.456], "images_per_second": 0.514, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The living room features a wooden floor, a ceiling fan, a green recliner, a gray couch, a coffee table, a television, and various decorative items.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12516.2, "ram_available_mb": 50324.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.435, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.786}, "timestamp": "2026-01-19T14:33:19.449403"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3769.237, "latencies_ms": [3769.237], "images_per_second": 0.265, "prompt_tokens": 21, "response_tokens_est": 51, "n_tiles": 1, "output_text": "chair: 2\ncouch: 2\ntelevision: 1\ncoffee table: 1\nmirror: 1\ntv stand: 1\nshelving unit: 1\nplant: 2\nbicycle: 1\nceiling fan: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.259, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.16}, "timestamp": "2026-01-19T14:33:25.233244"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2922.041, "latencies_ms": [2922.041], "images_per_second": 0.342, "prompt_tokens": 25, "response_tokens_est": 66, "n_tiles": 1, "output_text": "The main objects are positioned in a somewhat haphazard manner, with some items in the foreground and others in the background. The foreground includes a red chair, a bicycle, and a coffee table. The background features two windows, a ceiling fan, and a television set. The television is situated near the center of the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.054, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T14:33:30.185238"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3172.591, "latencies_ms": [3172.591], "images_per_second": 0.315, "prompt_tokens": 19, "response_tokens_est": 67, "n_tiles": 1, "output_text": "The living room features a wooden floor, a ceiling fan, and several windows that let in natural light. The room is furnished with a green recliner, a gray armchair, a coffee table, and a television set.  A bicycle is leaning against a wall, and various plants add a touch of greenery to the space.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.805, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.091}, "timestamp": "2026-01-19T14:33:35.380164"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2846.661, "latencies_ms": [2846.661], "images_per_second": 0.351, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The room features a warm color scheme, with light-colored walls and hardwood flooring. The lighting is natural and diffused, creating a cozy atmosphere. Various materials like wood, metal, and fabric are visible, contributing to the room's overall aesthetic.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12514.5, "ram_available_mb": 50326.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.108, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T14:33:40.249978"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1577.728, "latencies_ms": [1577.728], "images_per_second": 0.634, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A red metal parking meter post with two attached parking meters stands on the sidewalk in front of a brick building.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.191, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.568}, "timestamp": "2026-01-19T14:33:43.861843"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3167.77, "latencies_ms": [3167.77], "images_per_second": 0.316, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Parking meter: 2\nBicycle rack: 1\nStreet sign: 1\nBuilding: 1\nBushes: 2\nSidewalk: 1\nStreet: 1\nCrack in pavement: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.792, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 7.149}, "timestamp": "2026-01-19T14:33:49.080588"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2590.111, "latencies_ms": [2590.111], "images_per_second": 0.386, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The parking meters are positioned in the foreground, slightly to the left of the red post. The building in the background occupies the upper portion of the image, extending from the left edge to the center. The parking meters are located in the foreground, while the building is further back.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.539, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T14:33:53.725045"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1724.248, "latencies_ms": [1724.248], "images_per_second": 0.58, "prompt_tokens": 19, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A red parking meter stands on a sidewalk in front of a brick building. The building displays a large sign celebrating 40 years of saving lives.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.488, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T14:33:57.460465"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1959.026, "latencies_ms": [1959.026], "images_per_second": 0.51, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The parking meters are black and silver. The red metal post stands out against the brick sidewalk. The scene is well-lit, suggesting sunny weather.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.549, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.911}, "timestamp": "2026-01-19T14:34:01.460367"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1976.981, "latencies_ms": [1976.981], "images_per_second": 0.506, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man and woman are sitting together on a couch, playing a video game on a Nintendo Wii console, while enjoying snacks and drinks.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.648, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T14:34:05.484283"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4888.182, "latencies_ms": [4888.182], "images_per_second": 0.205, "prompt_tokens": 21, "response_tokens_est": 72, "n_tiles": 1, "output_text": "television: 1\ncouch: 2\nman: 1\nwoman: 1\ncandle: 2\npotted poinsettia: 1\nsoda can: 1\nsoda bottle: 1\nsoda bag: 1\nsoda glass: 1\ncandle holder: 1\ncandle holder: 1\nserving tray: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.2, "ram_available_mb": 50325.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.615, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 7.213}, "timestamp": "2026-01-19T14:34:12.415228"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1977.929, "latencies_ms": [1977.929], "images_per_second": 0.506, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The television is positioned to the left of the couch, near the foreground. The man and woman are seated on the couch in the background, slightly blurred due to motion.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.749, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.879}, "timestamp": "2026-01-19T14:34:16.419053"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2314.295, "latencies_ms": [2314.295], "images_per_second": 0.432, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A man and a woman are sitting on a couch in a living room, watching television together. They are surrounded by various items, including a poinsettia, snacks, drinks, and a lit candle, creating a cozy and relaxed atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.995, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:34:20.747420"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2414.22, "latencies_ms": [2414.22], "images_per_second": 0.414, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The room is lit with warm lighting, creating a cozy atmosphere. The walls are painted a light color, and the overall decor includes various colors and textures. The scene suggests a casual, comfortable living space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.846, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T14:34:25.179410"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1551.296, "latencies_ms": [1551.296], "images_per_second": 0.645, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A hand is holding a silver control panel with six circular buttons, likely for a modern toilet control system.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.857, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T14:34:28.762595"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4625.211, "latencies_ms": [4625.211], "images_per_second": 0.216, "prompt_tokens": 21, "response_tokens_est": 62, "n_tiles": 1, "output_text": "toilet: 1\ntoilet seat: 1\ntoilet lid: 1\ntoilet seat cover: 1\ntoilet seat: 1\ntoilet seat cover: 1\ntoilet seat: 1\ntoilet seat cover: 1\ntoilet seat: 1\ntoilet seat cover: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.78, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 7.219}, "timestamp": "2026-01-19T14:34:35.406976"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2268.055, "latencies_ms": [2268.055], "images_per_second": 0.441, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, with the hand holding the control panel behind it. The control panel is situated near the toilet, slightly out of focus. The background consists of white walls and a wooden floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.036, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T14:34:39.701398"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2061.841, "latencies_ms": [2061.841], "images_per_second": 0.485, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A person is holding a control panel with buttons, likely for a toilet or bidet. The control panel is mounted on a stand and positioned next to a toilet lid.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12514.3, "ram_available_mb": 50326.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.451, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.885}, "timestamp": "2026-01-19T14:34:43.787267"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2352.317, "latencies_ms": [2352.317], "images_per_second": 0.425, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The bathroom features a white color scheme with silver accents. The lighting is soft and diffused, creating a calm atmosphere. The materials appear to be modern and sleek, contributing to the clean aesthetic of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12512.8, "ram_available_mb": 50328.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.696, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T14:34:48.180731"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1752.635, "latencies_ms": [1752.635], "images_per_second": 0.571, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two snowboarders are captured mid-air, performing a thrilling trick against a backdrop of snowy mountains and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12512.8, "ram_available_mb": 50328.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.74, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T14:34:51.976927"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3141.558, "latencies_ms": [3141.558], "images_per_second": 0.318, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Snowboard: 2\nSnowboarder: 2\nSnowboard: 1\nSnowboard ramp: 2\nSnowboard: 1\nSnowboarders: 2\nSpectators: 10", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.73, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 7.102}, "timestamp": "2026-01-19T14:34:57.136489"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2714.086, "latencies_ms": [2714.086], "images_per_second": 0.368, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The snowboarder is positioned in the foreground, performing a trick near the camera. The spectators are located in the background, watching the snowboarders. The terrain is relatively flat and snowy, with snowboarders performing stunts and jumps.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.261, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 6.996}, "timestamp": "2026-01-19T14:35:01.904863"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2387.081, "latencies_ms": [2387.081], "images_per_second": 0.419, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "Two snowboarders are performing aerial tricks on a snow-covered slope, drawing the attention of a crowd of spectators. The scene takes place outdoors on a sunny day, with snow-covered terrain and clear skies.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.741, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.902}, "timestamp": "2026-01-19T14:35:06.333162"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3372.401, "latencies_ms": [3372.401], "images_per_second": 0.297, "prompt_tokens": 18, "response_tokens_est": 68, "n_tiles": 1, "output_text": "The snowboarders are wearing bright red jackets. The scene is brightly lit by the sun, creating a vibrant atmosphere. The snowboarders are performing tricks off a snow-covered ramp, which appears to be constructed from snow and possibly some type of material. The weather is sunny and clear, enhancing the overall visual appeal of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.8, "ram_available_mb": 50331.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.578, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.099}, "timestamp": "2026-01-19T14:35:11.728527"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1860.393, "latencies_ms": [1860.393], "images_per_second": 0.538, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A wooden desk with a computer setup, a lamp, and a chair occupies a small corner room, accompanied by a potted plant and a partially visible white couch.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.05, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.908}, "timestamp": "2026-01-19T14:35:15.646194"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3451.514, "latencies_ms": [3451.514], "images_per_second": 0.29, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "desk: 2\nlaptop: 1\nchair: 1\nlamp: 1\ncomputer monitor: 1\nkeyboard: 1\nmouse: 1\nplant: 1\nbookshelf: 1\ncouch: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.689, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 7.146}, "timestamp": "2026-01-19T14:35:21.126404"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2335.023, "latencies_ms": [2335.023], "images_per_second": 0.428, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main objects are positioned in a corner of the room, with the desk and chair situated between the sofa and the wall. The desk and chair are placed in the foreground, while the sofa and bookshelf are situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.044, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 7.028}, "timestamp": "2026-01-19T14:35:25.482701"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2555.376, "latencies_ms": [2555.376], "images_per_second": 0.391, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a home office setup with a desk, computer equipment, a lamp, and a chair. A laptop and a mouse are also present on the desk. The room is furnished with a couch and a potted plant, creating a comfortable and functional workspace.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.631, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.032}, "timestamp": "2026-01-19T14:35:30.077035"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2652.797, "latencies_ms": [2652.797], "images_per_second": 0.377, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The room features a light wood desk with a black chair and a black lamp. The desk is illuminated by a warm lamp, creating a cozy atmosphere. The carpet is light-colored and appears clean. The overall color scheme is neutral and calming.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.784, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.036}, "timestamp": "2026-01-19T14:35:34.741072"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1714.35, "latencies_ms": [1714.35], "images_per_second": 0.583, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two motorcyclists are riding down a dirt road that winds through a mountainous landscape, surrounded by lush greenery and rolling hills.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.303, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T14:35:38.486765"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2549.976, "latencies_ms": [2549.976], "images_per_second": 0.392, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "motorcycle: 2\nperson: 1\nroad: 1\nhills: 4\ntrees: 2\nsky: 1\nclouds: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.44, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T14:35:43.078547"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2609.49, "latencies_ms": [2609.49], "images_per_second": 0.383, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main object is a motorcycle positioned near the foreground of the image. The motorcycle is situated on a dirt road that extends into the background, offering a view of the surrounding landscape. The motorcycle is further away, suggesting the road extends further into the distance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.2, "ram_available_mb": 50330.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.842, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 7.036}, "timestamp": "2026-01-19T14:35:47.714861"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2870.77, "latencies_ms": [2870.77], "images_per_second": 0.348, "prompt_tokens": 19, "response_tokens_est": 57, "n_tiles": 1, "output_text": "Two motorcyclists are riding on a dirt road that winds through a mountainous landscape. The riders are positioned on separate motorcycles, one closer to the left side of the road and the other further to the right. The surrounding terrain is rugged and features rolling hills and patches of greenery.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.111, "power_cpu_cv_mean_watts": 1.568, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T14:35:52.625892"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2387.805, "latencies_ms": [2387.805], "images_per_second": 0.419, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The sky is a bright blue with scattered white clouds. The lighting suggests it is likely daytime. The terrain is rocky and uneven, composed of gravel and dirt. The overall atmosphere appears serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.907, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.992}, "timestamp": "2026-01-19T14:35:57.030280"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1519.176, "latencies_ms": [1519.176], "images_per_second": 0.658, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A wooden dining table with a bowl of fresh fruit, including oranges and bananas, is situated in the center of the kitchen.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 12510.0, "ram_available_mb": 50330.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.047, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 6.216}, "timestamp": "2026-01-19T14:36:00.593173"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3463.606, "latencies_ms": [3463.606], "images_per_second": 0.289, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "oven: 1\nstove: 1\nrange hood: 1\ncabinets: 6\ncountertops: 2\nsink: 1\nfridge: 1\ntable: 1\nchairs: 2\nfruit bowl: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.6, "ram_available_mb": 50331.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.887, "power_cpu_cv_mean_watts": 1.874, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T14:36:06.087578"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1739.364, "latencies_ms": [1739.364], "images_per_second": 0.575, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The kitchen is positioned to the right of the dining table. The dining table occupies the foreground, while the kitchen counters and appliances extend into the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.586, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 6.35}, "timestamp": "2026-01-19T14:36:09.883829"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2025.438, "latencies_ms": [2025.438], "images_per_second": 0.494, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The kitchen and dining area are well-lit and clean, creating a bright and welcoming atmosphere.  A bowl of fresh fruit sits on the dining table, ready to be enjoyed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.339, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.482}, "timestamp": "2026-01-19T14:36:13.943536"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2825.264, "latencies_ms": [2825.264], "images_per_second": 0.354, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The kitchen features light brown wooden cabinets, white appliances, and a light-colored countertop. The lighting is bright, illuminating the space. The materials appear to be standard kitchen elements like wood, tile, and stainless steel. The weather is sunny, contributing to the bright and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.737, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 6.898}, "timestamp": "2026-01-19T14:36:18.795754"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1878.265, "latencies_ms": [1878.265], "images_per_second": 0.532, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A female tennis player, dressed in black and white, is poised to hit a yellow tennis ball with her racket on a blue court.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.572, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.766}, "timestamp": "2026-01-19T14:36:22.709773"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3724.291, "latencies_ms": [3724.291], "images_per_second": 0.269, "prompt_tokens": 21, "response_tokens_est": 53, "n_tiles": 1, "output_text": "Tennis ball: 1\nTennis racket: 1\nTennis skirt: 1\nTennis player: 1\nTennis court: 1\nTennis ball: 1\nTennis ball: 1\nTennis player: 1\nTennis player: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.47, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 7.173}, "timestamp": "2026-01-19T14:36:28.482129"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2571.488, "latencies_ms": [2571.488], "images_per_second": 0.389, "prompt_tokens": 25, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground, reaching up towards the tennis ball. The tennis court extends into the background, creating a sense of depth and space. The player's attire and the presence of a ball suggest they are actively engaged in a tennis match.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12509.9, "ram_available_mb": 50331.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.501, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T14:36:33.092621"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2603.773, "latencies_ms": [2603.773], "images_per_second": 0.384, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "A female tennis player is serving a tennis ball on a green court. She is wearing a white top and black skirt and holds a tennis racket in her right hand. The word \"POLO\" is visible on a sign in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.294, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.996}, "timestamp": "2026-01-19T14:36:37.737605"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2100.476, "latencies_ms": [2100.476], "images_per_second": 0.476, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The tennis court is green, lit by bright sunlight. The player is wearing a white top and black skirt. The ball is visible in the air, indicating a serve in progress.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.3, "ram_available_mb": 50330.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.482, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T14:36:41.873517"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1523.402, "latencies_ms": [1523.402], "images_per_second": 0.656, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A red fire hydrant with a white cap is situated on a sidewalk next to a yellow pedestrian crossing sign.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.047, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.132}, "timestamp": "2026-01-19T14:36:45.451277"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2966.019, "latencies_ms": [2966.019], "images_per_second": 0.337, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "fire hydrant: 1\ncrosswalk sign: 1\nstreet sign: 1\nchild crossing sign: 1\nperson walking: 1\nbuildings: 2\ntrees: 2\nsidewalk: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.816, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 6.863}, "timestamp": "2026-01-19T14:36:50.460516"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2699.793, "latencies_ms": [2699.793], "images_per_second": 0.37, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The red fire hydrant is positioned in the foreground, slightly to the right of the viewer. The sidewalk extends into the background, separating the viewer from the street and buildings. A pedestrian crossing sign is visible near the fire hydrant, further emphasizing the urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.578, "power_cpu_cv_mean_watts": 1.784, "power_sys_5v0_mean_watts": 6.767}, "timestamp": "2026-01-19T14:36:55.216777"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2167.298, "latencies_ms": [2167.298], "images_per_second": 0.461, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A red fire hydrant is situated on a sidewalk next to a tree. A pedestrian crossing sign is visible nearby, indicating a pedestrian crossing area. A person can be seen walking on the sidewalk in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.305, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.49}, "timestamp": "2026-01-19T14:36:59.425898"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1710.862, "latencies_ms": [1710.862], "images_per_second": 0.585, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The fire hydrant is red and appears to be made of metal. The surrounding area is well-lit, suggesting sunny weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.906, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 6.203}, "timestamp": "2026-01-19T14:37:03.166387"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1929.584, "latencies_ms": [1929.584], "images_per_second": 0.518, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A white toilet with a closed lid is situated in a small bathroom, accompanied by a white toilet brush, a green wastebasket, and a white toilet paper dispenser.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.321, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 6.41}, "timestamp": "2026-01-19T14:37:07.127754"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4184.932, "latencies_ms": [4184.932], "images_per_second": 0.239, "prompt_tokens": 21, "response_tokens_est": 55, "n_tiles": 1, "output_text": "toilet: 1\ntoilet paper dispenser: 1\ntoilet brush: 1\ntoilet seat: 1\ntoilet tank: 1\ntoilet lid: 1\ntoilet seat cover: 1\ntoilet seat: 1\ntoilet paper: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.857, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T14:37:13.337071"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1969.044, "latencies_ms": [1969.044], "images_per_second": 0.508, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The toilet is positioned to the right of the toilet paper dispenser. The toilet is situated further back in the bathroom, partially obscured by the toilet paper dispenser.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.27, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 6.424}, "timestamp": "2026-01-19T14:37:17.330529"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2521.96, "latencies_ms": [2521.96], "images_per_second": 0.397, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a small bathroom with a white toilet, toilet brush, toilet paper dispenser, and a small turquoise wastebasket. The toilet is positioned centrally in the image, and the overall setting appears clean and functional.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.337, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 6.678}, "timestamp": "2026-01-19T14:37:21.890875"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2508.01, "latencies_ms": [2508.01], "images_per_second": 0.399, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The toilet is white and appears to be made of plastic or ceramic. The lighting in the bathroom is soft and diffused, creating a calm atmosphere. The walls are painted a light color, and the floor is carpeted in a neutral tone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.9, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.348, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 6.609}, "timestamp": "2026-01-19T14:37:26.440781"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1664.629, "latencies_ms": [1664.629], "images_per_second": 0.601, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A person dressed in a bright red snowsuit is skiing up a snow-covered mountain, leaving a trail behind them.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12511.9, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.362, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.644}, "timestamp": "2026-01-19T14:37:30.131901"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2789.96, "latencies_ms": [2789.96], "images_per_second": 0.358, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "person: 1\nski: 1\nsnow: 2\nmountains: 1\nsky: 1\nclouds: 0\ntrees: 0\nhills: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.459, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.086}, "timestamp": "2026-01-19T14:37:34.984749"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1938.895, "latencies_ms": [1938.895], "images_per_second": 0.516, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, moving towards the left side of the image. The snow-covered mountain rises in the background, creating a sense of distance and scale.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.649, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.867}, "timestamp": "2026-01-19T14:37:38.969485"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2180.591, "latencies_ms": [2180.591], "images_per_second": 0.459, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A person is skiing down a snow-covered mountain, wearing bright red clothing and carrying ski poles. The mountain is covered in snow and has a distinct peak in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.917, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.812}, "timestamp": "2026-01-19T14:37:43.178810"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3580.032, "latencies_ms": [3580.032], "images_per_second": 0.279, "prompt_tokens": 18, "response_tokens_est": 72, "n_tiles": 1, "output_text": "The skier is wearing a bright red jacket, which stands out against the white snow. The lighting is bright and clear, illuminating the scene and highlighting the snow-covered mountain. The materials appear to be typical skiing gear, including skis, poles, and a backpack. The weather is sunny and clear, contributing to the overall bright and serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.086, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.069}, "timestamp": "2026-01-19T14:37:48.808647"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1986.242, "latencies_ms": [1986.242], "images_per_second": 0.503, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A man wearing a red and white top and black pants is cross-country skiing through a snowy forest, skillfully maneuvering his skis and poles.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.652, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 6.93}, "timestamp": "2026-01-19T14:37:52.830039"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2934.085, "latencies_ms": [2934.085], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "man: 2\nskis: 2\nsnow: 8\ntrees: 8\nsnow covered ground: 8\ngloves: 2\nhat: 1\nbib: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12516.0, "ram_available_mb": 50324.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.073, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.106}, "timestamp": "2026-01-19T14:37:57.783398"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2705.193, "latencies_ms": [2705.193], "images_per_second": 0.37, "prompt_tokens": 25, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The main object is a skier positioned in the foreground of the image, moving towards the left side of the frame. The background consists of snow-covered trees and a snowy landscape, creating a sense of depth and distance. Another skier is visible in the distance, further back in the scene.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12516.0, "ram_available_mb": 50324.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12516.0, "ram_available_mb": 50324.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.35, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T14:38:02.503367"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2430.64, "latencies_ms": [2430.64], "images_per_second": 0.411, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A man is cross-country skiing through a snowy forest, wearing a red and white top and dark pants. Another person is visible in the distance, also skiing. The scene is set in a mountainous area with snow-covered trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.0, "ram_available_mb": 50324.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.581, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.939}, "timestamp": "2026-01-19T14:38:06.992955"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2650.409, "latencies_ms": [2650.409], "images_per_second": 0.377, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The snow is white and appears quite fresh. The lighting suggests an overcast day, with diffused light that doesn't cast harsh shadows. The materials appear to be primarily wood and possibly some synthetic materials used for clothing and equipment.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12515.3, "ram_available_mb": 50325.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.536, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T14:38:11.670992"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1596.127, "latencies_ms": [1596.127], "images_per_second": 0.627, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A computer setup, including a monitor displaying a photo, a keyboard, and a mouse, is arranged on a wooden desk.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.055, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.637}, "timestamp": "2026-01-19T14:38:15.310242"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2902.498, "latencies_ms": [2902.498], "images_per_second": 0.345, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "keyboard: 2\nmouse: 1\ncomputer monitor: 1\ndesk: 2\nlaptop: 1\nmousepad: 1\ncord: 1\ntable: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.024, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T14:38:20.242932"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1789.549, "latencies_ms": [1789.549], "images_per_second": 0.559, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The keyboard and mouse are positioned in the foreground, closer to the viewer. The monitor is situated in the background, slightly elevated and closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.225, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.811}, "timestamp": "2026-01-19T14:38:24.047481"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2566.499, "latencies_ms": [2566.499], "images_per_second": 0.39, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene depicts a workspace with a computer setup on a desk. A monitor displays an image of a desk with a computer and keyboard, while a mouse sits in front of the keyboard. The overall setting suggests a professional or home office environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.499, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.017}, "timestamp": "2026-01-19T14:38:28.626965"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2660.836, "latencies_ms": [2660.836], "images_per_second": 0.376, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The computer setup is primarily in grayscale, creating a monochrome aesthetic. The lighting appears to be soft and diffused, contributing to a calm and focused atmosphere. The materials appear to be sleek and modern, complementing the minimalist design of the workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.384, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.046}, "timestamp": "2026-01-19T14:38:33.320580"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1704.515, "latencies_ms": [1704.515], "images_per_second": 0.587, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A woman in a red shirt is sitting at a table in a train, holding a bagel and smiling while enjoying her breakfast.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12515.1, "ram_available_mb": 50325.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.332, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T14:38:37.051736"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2552.236, "latencies_ms": [2552.236], "images_per_second": 0.392, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "bagel: 1\nwoman: 1\ncup: 1\ntable: 1\nwindow: 1\nman: 1\nman in red shirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.8, "ram_available_mb": 50326.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.615, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.993}, "timestamp": "2026-01-19T14:38:41.647614"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2388.385, "latencies_ms": [2388.385], "images_per_second": 0.419, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, holding the bagel and smiling. The train car is behind her, slightly blurred, suggesting movement. Additionally, a man is visible in the background, further away from the woman.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.586, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.914}, "timestamp": "2026-01-19T14:38:46.072727"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1623.508, "latencies_ms": [1623.508], "images_per_second": 0.616, "prompt_tokens": 19, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A woman is enjoying a bagel and coffee while traveling on a train. Other passengers are visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.695, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.745}, "timestamp": "2026-01-19T14:38:49.710765"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2021.277, "latencies_ms": [2021.277], "images_per_second": 0.495, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The woman is wearing a maroon shirt. The bagel is light brown. The train interior has warm lighting. The bagel appears to have a cream filling.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.0, "ram_available_mb": 50325.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.376, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.835}, "timestamp": "2026-01-19T14:38:53.758190"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1661.193, "latencies_ms": [1661.193], "images_per_second": 0.602, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Two zebras are grazing on green grass in a field, displaying their distinctive black and white stripes.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.625, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.703}, "timestamp": "2026-01-19T14:38:57.448331"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2949.689, "latencies_ms": [2949.689], "images_per_second": 0.339, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "zebra: 2\ngrass: 2\nfence: 1\nzebra: 1\nzebra: 1\nzebra: 1\nzebra: 1\nzebra: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.054, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T14:39:02.442895"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2642.914, "latencies_ms": [2642.914], "images_per_second": 0.378, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The zebras are positioned close together in the foreground, grazing on the grass. The background is slightly blurred, drawing focus to the zebras. The zebras are relatively close to the viewer, suggesting they are in a relatively close proximity.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.653, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.075}, "timestamp": "2026-01-19T14:39:07.123880"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1961.188, "latencies_ms": [1961.188], "images_per_second": 0.51, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two zebras are grazing on green grass in a grassy field. The zebras are facing away from the camera, focused on their meal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.002, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:39:11.109027"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2240.223, "latencies_ms": [2240.223], "images_per_second": 0.446, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The zebras have black and white stripes. The lighting appears to be natural, possibly sunlight, giving the scene a bright and lively atmosphere. The grass appears to be short and green, suggesting a healthy environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.935, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T14:39:15.378954"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1932.946, "latencies_ms": [1932.946], "images_per_second": 0.517, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two young men in white shirts and dark pants are riding a green bicycle down a busy city street, surrounded by other vehicles and pedestrians.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.653, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.72}, "timestamp": "2026-01-19T14:39:19.341170"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3245.863, "latencies_ms": [3245.863], "images_per_second": 0.308, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "bicycle: 2\nmotorcycle: 3\nscooter: 2\nman: 2\nwoman: 1\nhelmet: 1\nbag: 1\nsunglasses: 1\nstorefront: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.684, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 7.041}, "timestamp": "2026-01-19T14:39:24.633305"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2075.18, "latencies_ms": [2075.18], "images_per_second": 0.482, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the Coca-Cola store and storefronts in the background. The street scene extends into the background, suggesting an urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.377, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T14:39:28.725877"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1785.581, "latencies_ms": [1785.581], "images_per_second": 0.56, "prompt_tokens": 19, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Two young men in uniform are riding a green bicycle on a busy city street, surrounded by other motorcycles and pedestrians.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.941, "power_cpu_cv_mean_watts": 1.145, "power_sys_5v0_mean_watts": 6.811}, "timestamp": "2026-01-19T14:39:32.573920"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2700.021, "latencies_ms": [2700.021], "images_per_second": 0.37, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene is brightly lit, likely by natural or artificial light. The colors are vibrant and varied, contributing to the lively atmosphere. The materials appear to be primarily metal and plastic, typical of urban transportation. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.499, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T14:39:37.293254"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1550.657, "latencies_ms": [1550.657], "images_per_second": 0.645, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two tennis players are engaged in a match on a grass court, with spectators watching from the stands.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.526, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.694}, "timestamp": "2026-01-19T14:39:40.911922"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2838.881, "latencies_ms": [2838.881], "images_per_second": 0.352, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "chair: 2\nnet: 1\ntennis ball: 1\ntennis racket: 1\ntennis player: 2\nspectators: 10\ntennis court: 6", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.336, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.064}, "timestamp": "2026-01-19T14:39:45.767055"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2754.232, "latencies_ms": [2754.232], "images_per_second": 0.363, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The tennis court is positioned centrally in the image, with a player on the left side preparing to serve the ball. The audience is seated in stands surrounding the court, observing the match. The foreground includes chairs and equipment, while the background features the stands and spectators.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.32, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.043}, "timestamp": "2026-01-19T14:39:50.570325"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2194.284, "latencies_ms": [2194.284], "images_per_second": 0.456, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts a tennis match taking place on a grass court, with two players actively engaged in a rally. Spectators are seated in stands, watching the match unfold.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.16, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 6.91}, "timestamp": "2026-01-19T14:39:54.810137"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2289.704, "latencies_ms": [2289.704], "images_per_second": 0.437, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The tennis court is green and appears to be well-maintained. The lighting is bright, illuminating both the players and the court surface. The materials used are likely durable and suitable for the outdoor conditions.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.115, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T14:39:59.112477"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2021.484, "latencies_ms": [2021.484], "images_per_second": 0.495, "prompt_tokens": 8, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The living room features a brown sofa, a wooden coffee table with a sewing machine, a flat-screen TV, and several potted plants, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.325, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T14:40:03.185457"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3269.779, "latencies_ms": [3269.779], "images_per_second": 0.306, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "couch: 1\ntelevision: 1\ncurtains: 2\nwindow: 1\ntable: 1\nsewing machine: 1\npillow: 1\nplants: 2\ncarpet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.609, "power_cpu_cv_mean_watts": 1.751, "power_sys_5v0_mean_watts": 7.123}, "timestamp": "2026-01-19T14:40:08.473337"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2402.347, "latencies_ms": [2402.347], "images_per_second": 0.416, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The sofa and coffee table are positioned close to the window, providing a cozy and intimate seating area. The TV and sewing machine are placed further back in the room, creating a sense of separation from the seating area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.678, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:40:12.895011"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2411.038, "latencies_ms": [2411.038], "images_per_second": 0.415, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The living room features a brown sofa, a wooden coffee table with a sewing machine, and a flat-screen TV on a stand. Various plants are scattered throughout the space, adding a touch of greenery and color.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.697, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.976}, "timestamp": "2026-01-19T14:40:17.333294"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2173.123, "latencies_ms": [2173.123], "images_per_second": 0.46, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The room features a warm color scheme, with brown furniture, white curtains, and natural light coming in through the window. The lighting appears soft and diffused, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.778, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T14:40:21.537756"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1944.362, "latencies_ms": [1944.362], "images_per_second": 0.514, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A female tennis player in a red dress and white visor stands on a clay court, holding a tennis racket and appearing to celebrate a point.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.569, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.8}, "timestamp": "2026-01-19T14:40:25.522146"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2955.249, "latencies_ms": [2955.249], "images_per_second": 0.338, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "woman: 1\ntennis racket: 1\ntennis dress: 1\ntennis visor: 1\ntennis court: 1\nclothing: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.904, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.043}, "timestamp": "2026-01-19T14:40:30.528824"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1833.361, "latencies_ms": [1833.361], "images_per_second": 0.545, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground of the image, near the baseline. The tennis court extends into the background, creating a sense of depth and space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.783, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.786}, "timestamp": "2026-01-19T14:40:34.423854"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1989.828, "latencies_ms": [1989.828], "images_per_second": 0.503, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A woman in a red tennis dress and visor is standing on a clay tennis court, holding a tennis racket and appearing to be in the middle of a tennis match.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.049, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.885}, "timestamp": "2026-01-19T14:40:38.462517"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1897.489, "latencies_ms": [1897.489], "images_per_second": 0.527, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The tennis player is wearing a bright red dress and a white visor. The clay court is reddish-brown, and the lighting appears to be natural sunlight.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.621, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T14:40:42.376384"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2033.448, "latencies_ms": [2033.448], "images_per_second": 0.492, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A bustling city street lined with brick buildings, cars, and pedestrians, features a prominent OmniFest billboard and a Heinz restaurant.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.272, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T14:40:46.466475"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2833.832, "latencies_ms": [2833.832], "images_per_second": 0.353, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "billboard: 1\nstreet light: 2\ncar: 3\nbuilding: 6\nrestaurant: 2\npeople: 2\ntable: 1\nchairs: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.968, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.968}, "timestamp": "2026-01-19T14:40:51.335911"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2186.637, "latencies_ms": [2186.637], "images_per_second": 0.457, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The cars are parked or moving along the street, occupying the foreground. The buildings, billboards, and streetlights are positioned in the background, creating a layered perspective of the street scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.757, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.927}, "timestamp": "2026-01-19T14:40:55.547312"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2197.015, "latencies_ms": [2197.015], "images_per_second": 0.455, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The scene depicts a bustling city street lined with colorful buildings, busy with cars and pedestrians. The atmosphere suggests a lively urban environment, possibly during a special event or festival.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.318, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T14:40:59.767532"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2519.217, "latencies_ms": [2519.217], "images_per_second": 0.397, "prompt_tokens": 18, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The buildings exhibit a mix of colors, including red, brown, and beige. The lighting is relatively even across the scene, suggesting an overcast day. The buildings appear to be constructed of brick and concrete, contributing to the urban feel.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12518.3, "ram_available_mb": 50322.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.827, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T14:41:04.331225"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1938.185, "latencies_ms": [1938.185], "images_per_second": 0.516, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A female tennis player in a red outfit and white visor is poised to hit a yellow tennis ball on a blue and green court.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12518.3, "ram_available_mb": 50322.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.492, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.827}, "timestamp": "2026-01-19T14:41:08.311047"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2833.045, "latencies_ms": [2833.045], "images_per_second": 0.353, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 2\nTennis player: 1\nTennis shoes: 2\nTennis visor: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.955, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 6.981}, "timestamp": "2026-01-19T14:41:13.160692"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1960.555, "latencies_ms": [1960.555], "images_per_second": 0.51, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The tennis player is positioned near the center of the image, facing the tennis ball. The tennis court extends into the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.225, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.835}, "timestamp": "2026-01-19T14:41:17.150104"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2316.435, "latencies_ms": [2316.435], "images_per_second": 0.432, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A woman in a red tennis outfit is playing tennis on a blue and green court, poised to hit a yellow tennis ball. She is wearing a visor and holding a tennis racket.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.913, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.876}, "timestamp": "2026-01-19T14:41:21.493128"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2122.041, "latencies_ms": [2122.041], "images_per_second": 0.471, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The tennis player is wearing a vibrant red outfit and white shoes. The green tennis court is well-lit, and the bright yellow tennis ball is visible in mid-air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.223, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.812}, "timestamp": "2026-01-19T14:41:25.654623"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1577.723, "latencies_ms": [1577.723], "images_per_second": 0.634, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A blue and silver train travels along a curving track, passing through a lush green forest.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.641, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.683}, "timestamp": "2026-01-19T14:41:29.287704"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3373.728, "latencies_ms": [3373.728], "images_per_second": 0.296, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Train: 2\nTrain car: 2\nTrain tracks: 2\nTrain windows: 6\nTrain headlights: 2\nTrain door: 2\nTrain engine: 1\nTrain conductor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.109, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 7.16}, "timestamp": "2026-01-19T14:41:34.674333"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1980.527, "latencies_ms": [1980.527], "images_per_second": 0.505, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The blue and silver train is positioned in the foreground, moving towards the viewer. The train tracks are visible in the background, curving gently through the vegetation.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.672, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 6.835}, "timestamp": "2026-01-19T14:41:38.695873"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2218.7, "latencies_ms": [2218.7], "images_per_second": 0.451, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A blue and silver train travels along a narrow, winding track through a lush, wooded area. The train appears to be moving from left to right, passing through greenery and surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12516.5, "ram_available_mb": 50324.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.552, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.961}, "timestamp": "2026-01-19T14:41:42.937789"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1981.359, "latencies_ms": [1981.359], "images_per_second": 0.505, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The train is primarily silver and blue with orange accents. The lighting suggests it might be daytime. The train appears to be made of metal and has a modern design.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.5, "ram_available_mb": 50324.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.85, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.917}, "timestamp": "2026-01-19T14:41:46.937459"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1806.711, "latencies_ms": [1806.711], "images_per_second": 0.553, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two cats, one tabby and one striped, sleep peacefully on a pink blanket atop a red couch, accompanied by two remote controls.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.024, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.933}, "timestamp": "2026-01-19T14:41:50.776592"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2372.925, "latencies_ms": [2372.925], "images_per_second": 0.421, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "remote: 2\ncouch: 2\nblanket: 2\ncat: 2\npaws: 2\nfur: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.888, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 6.902}, "timestamp": "2026-01-19T14:41:55.179950"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2231.697, "latencies_ms": [2231.697], "images_per_second": 0.448, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The cats are positioned close together on the pink blanket, with the cat on the left partially covering the remote control. The cats are lying down on the blanket, which occupies the foreground of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.027, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 6.977}, "timestamp": "2026-01-19T14:41:59.442711"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2475.771, "latencies_ms": [2475.771], "images_per_second": 0.404, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "Two tabby cats are sleeping on a pink blanket on a red couch. One cat is curled up on the left, while the other is curled up on the right. A remote control is visible on the couch near the cats.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.545, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T14:42:03.943753"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1752.077, "latencies_ms": [1752.077], "images_per_second": 0.571, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The cats are resting on a bright pink blanket. The lighting in the image appears to be soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.397, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.674}, "timestamp": "2026-01-19T14:42:07.759873"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1826.328, "latencies_ms": [1826.328], "images_per_second": 0.548, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Two surfers navigate rapids in a river, surrounded by lush greenery and trees, with one skillfully riding a wave and the other holding a blue surfboard.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.271, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.343}, "timestamp": "2026-01-19T14:42:11.628677"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2685.95, "latencies_ms": [2685.95], "images_per_second": 0.372, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "river: 2\nbridge: 1\nbench: 1\nperson: 1\nsurfboard: 1\ntree: 1\nground: 1\nleaves: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.633, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 6.726}, "timestamp": "2026-01-19T14:42:16.355772"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2338.877, "latencies_ms": [2338.877], "images_per_second": 0.428, "prompt_tokens": 25, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main object is a person surfing in a river, positioned in the foreground. The river flows in the background, separating the foreground from the background. Additionally, a bridge is visible in the background, further separating the foreground from the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.678, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.668}, "timestamp": "2026-01-19T14:42:20.724644"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2621.753, "latencies_ms": [2621.753], "images_per_second": 0.381, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene depicts a river with rapids, where two people are engaged in surfing. One person is riding a wave on a surfboard, while another person stands nearby holding a blue surfboard. The setting is outdoors, surrounded by trees and a stone bridge in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 10.4, "ram_used_mb": 12622.9, "ram_available_mb": 50218.0, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.778, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T14:42:25.372747"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2683.104, "latencies_ms": [2683.104], "images_per_second": 0.373, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The water appears murky and brown, suggesting possible pollution or sedimentation. The lighting is subdued, likely due to overcast conditions or shade from the surrounding trees. The material appears to be natural rock or concrete, contrasting with the man-made structures in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12622.9, "ram_available_mb": 50218.0, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12643.6, "ram_available_mb": 50197.2, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.56, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 6.785}, "timestamp": "2026-01-19T14:42:30.072528"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1760.617, "latencies_ms": [1760.617], "images_per_second": 0.568, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A woman in a black jacket and blue jeans is holding a colorful kite while standing in a grassy field with a young girl.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12643.6, "ram_available_mb": 50197.2, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12645.3, "ram_available_mb": 50195.6, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.994, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T14:42:33.892740"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2509.734, "latencies_ms": [2509.734], "images_per_second": 0.398, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "woman: 2\nkite: 1\nchild: 1\ngrass: 1\ntrees: 4\nfence: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12645.3, "ram_available_mb": 50195.6, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12659.8, "ram_available_mb": 50181.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.541, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 7.015}, "timestamp": "2026-01-19T14:42:38.452403"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1944.435, "latencies_ms": [1944.435], "images_per_second": 0.514, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The woman and child are standing in the foreground of the image. The kite is positioned in the background, slightly further away than the woman and child.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12659.8, "ram_available_mb": 50181.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12661.4, "ram_available_mb": 50179.5, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.622, "power_cpu_cv_mean_watts": 1.308, "power_sys_5v0_mean_watts": 6.834}, "timestamp": "2026-01-19T14:42:42.426224"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1906.226, "latencies_ms": [1906.226], "images_per_second": 0.525, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A woman and a child are flying a colorful butterfly kite in a park. The park is surrounded by trees, and several other people are visible in the distance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12661.4, "ram_available_mb": 50179.5, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12661.5, "ram_available_mb": 50179.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.862, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.814}, "timestamp": "2026-01-19T14:42:46.367644"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2117.45, "latencies_ms": [2117.45], "images_per_second": 0.472, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The kite is brightly colored with pink, orange, and blue patterns. The woman and child are standing on a grassy field under a clear, sunny sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12660.5, "ram_available_mb": 50180.4, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 8.0, "ram_used_mb": 12671.5, "ram_available_mb": 50169.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.363, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T14:42:50.512628"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2154.448, "latencies_ms": [2154.448], "images_per_second": 0.464, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A young male tennis player, wearing a white shirt and maroon cap, is crouched low and poised to hit a tennis ball with his yellow racket on a blue court.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12671.7, "ram_available_mb": 50169.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 16.9, "ram_used_mb": 13153.5, "ram_available_mb": 49687.4, "ram_percent": 20.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.473, "power_cpu_cv_mean_watts": 3.253, "power_sys_5v0_mean_watts": 7.358}, "timestamp": "2026-01-19T14:42:54.728069"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3700.863, "latencies_ms": [3700.863], "images_per_second": 0.27, "prompt_tokens": 21, "response_tokens_est": 51, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis court: 1\nNet: 1\nTennis player: 1\nTennis racket: 1\nTennis ball: 1\nTennis ball: 1\nTennis player: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13154.0, "ram_available_mb": 49686.9, "ram_percent": 20.9}, "sys_after": {"cpu_percent": 8.6, "ram_used_mb": 13172.9, "ram_available_mb": 49668.0, "ram_percent": 21.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.271, "power_cpu_cv_mean_watts": 2.3, "power_sys_5v0_mean_watts": 7.235}, "timestamp": "2026-01-19T14:43:00.470005"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2492.541, "latencies_ms": [2492.541], "images_per_second": 0.401, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The tennis player is positioned in the foreground, near the net, preparing to hit the ball. The tennis ball is in the air, near the player's racket. The background features a green curtain and a banner advertising \"National Masters.\"", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13172.9, "ram_available_mb": 49668.0, "ram_percent": 21.0}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 13173.8, "ram_available_mb": 49667.1, "ram_percent": 21.0}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.52, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T14:43:05.011127"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3094.277, "latencies_ms": [3094.277], "images_per_second": 0.323, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A young male tennis player is crouching low and preparing to hit a tennis ball during a match on a blue court. He wears a white shirt and a maroon cap. Behind him, a green fence displays a banner reading \"Are you next? National Masters.\"", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13173.8, "ram_available_mb": 49667.1, "ram_percent": 21.0}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 13090.2, "ram_available_mb": 49750.7, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.514, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 7.075}, "timestamp": "2026-01-19T14:43:10.161426"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2366.253, "latencies_ms": [2366.253], "images_per_second": 0.423, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The tennis court is painted blue. The lighting appears to be natural sunlight, creating a bright and clear atmosphere. The materials appear to be standard tennis court surface and netting. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13090.2, "ram_available_mb": 49750.7, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13090.4, "ram_available_mb": 49750.5, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.719, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T14:43:14.560380"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1647.92, "latencies_ms": [1647.92], "images_per_second": 0.607, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "The room is filled with boxes, furniture, and personal belongings, indicating a recent move or reorganization.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 13090.4, "ram_available_mb": 49750.5, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13090.0, "ram_available_mb": 49750.9, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.893, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.728}, "timestamp": "2026-01-19T14:43:18.234599"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3441.234, "latencies_ms": [3441.234], "images_per_second": 0.291, "prompt_tokens": 21, "response_tokens_est": 48, "n_tiles": 1, "output_text": "bed: 2\npillows: 2\nbrown comforter: 1\nwooden door: 1\nbrick wall: 1\ncardboard boxes: 2\nchair: 1\nmirror: 1\nwooden floor: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13090.0, "ram_available_mb": 49750.9, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 12616.0, "ram_available_mb": 50224.9, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.591, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 7.156}, "timestamp": "2026-01-19T14:43:23.693328"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2137.009, "latencies_ms": [2137.009], "images_per_second": 0.468, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned to the left of the image. The chair is situated in the background, near a doorway. The bed and chair are located relatively close to each other.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12616.0, "ram_available_mb": 50224.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12616.5, "ram_available_mb": 50224.4, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.892, "power_cpu_cv_mean_watts": 1.225, "power_sys_5v0_mean_watts": 6.765}, "timestamp": "2026-01-19T14:43:27.856072"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2571.606, "latencies_ms": [2571.606], "images_per_second": 0.389, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The room appears to be in the midst of moving or renovation, evidenced by the presence of boxes, furniture, and debris scattered across the floor. The room features a rustic brick wall and a wooden door, suggesting an older or industrial-style space.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12617.0, "ram_available_mb": 50223.9, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 12621.8, "ram_available_mb": 50219.1, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.516, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.027}, "timestamp": "2026-01-19T14:43:32.471667"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2193.58, "latencies_ms": [2193.58], "images_per_second": 0.456, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The room features a rustic brick wall and a wooden floor. The lighting is dim, creating a cozy atmosphere. The room is filled with various materials, including cardboard boxes, furniture, and personal belongings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12621.8, "ram_available_mb": 50219.1, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 12714.3, "ram_available_mb": 50126.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.494, "power_cpu_cv_mean_watts": 2.781, "power_sys_5v0_mean_watts": 7.269}, "timestamp": "2026-01-19T14:43:36.691236"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1740.438, "latencies_ms": [1740.438], "images_per_second": 0.575, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A rider wearing a red and green shirt and helmet is guiding a brown horse over a wooden obstacle in a verdant field.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12714.3, "ram_available_mb": 50126.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12719.6, "ram_available_mb": 50121.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.207, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T14:43:40.469322"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2959.498, "latencies_ms": [2959.498], "images_per_second": 0.338, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Horse: 1\nJockey: 1\nFence: 1\nFlowers: 1\nPost: 1\nSign: 1\nGround: 1\nTrees: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12719.6, "ram_available_mb": 50121.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12719.6, "ram_available_mb": 50121.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.02, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.035}, "timestamp": "2026-01-19T14:43:45.461037"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1884.755, "latencies_ms": [1884.755], "images_per_second": 0.531, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The horse and rider are positioned in the foreground, jumping over a wooden obstacle. The background features trees and greenery, creating a natural setting for the event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12719.6, "ram_available_mb": 50121.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 10.2, "ram_used_mb": 12992.6, "ram_available_mb": 49848.3, "ram_percent": 20.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.702, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T14:43:49.381342"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2065.236, "latencies_ms": [2065.236], "images_per_second": 0.484, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A rider in a red and green jacket is guiding a brown horse over a wooden obstacle in a wooded area. The horse is mid-jump, showcasing its athleticism and skill.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 12994.6, "ram_available_mb": 49846.3, "ram_percent": 20.7}, "sys_after": {"cpu_percent": 12.2, "ram_used_mb": 13065.6, "ram_available_mb": 49775.3, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.611, "power_cpu_cv_mean_watts": 2.922, "power_sys_5v0_mean_watts": 7.317}, "timestamp": "2026-01-19T14:43:53.492534"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2297.339, "latencies_ms": [2297.339], "images_per_second": 0.435, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The horse is brown, adorned with a colorful saddle and bridle. The scene is brightly lit, suggesting sunny weather conditions. The wooden obstacle adds a rustic touch to the overall setting.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13065.6, "ram_available_mb": 49775.3, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 13098.8, "ram_available_mb": 49742.1, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.577, "power_cpu_cv_mean_watts": 1.914, "power_sys_5v0_mean_watts": 7.039}, "timestamp": "2026-01-19T14:43:57.827958"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1477.889, "latencies_ms": [1477.889], "images_per_second": 0.677, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Two men are seated under a large umbrella, conversing in front of a small cart filled with various items.", "error": null, "sys_before": {"cpu_percent": 26.3, "ram_used_mb": 13099.3, "ram_available_mb": 49741.6, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 13089.5, "ram_available_mb": 49751.4, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.139, "power_cpu_cv_mean_watts": 1.42, "power_sys_5v0_mean_watts": 6.103}, "timestamp": "2026-01-19T14:44:01.331958"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2720.329, "latencies_ms": [2720.329], "images_per_second": 0.368, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Umbrella: 2\nMen: 2\nChair: 1\nCar: 1\nBicycle: 1\nStreet: 1\nSign: 1\nBox: 1", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 13089.5, "ram_available_mb": 49751.4, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13090.5, "ram_available_mb": 49750.4, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.723, "power_cpu_cv_mean_watts": 1.748, "power_sys_5v0_mean_watts": 6.785}, "timestamp": "2026-01-19T14:44:06.075385"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2044.886, "latencies_ms": [2044.886], "images_per_second": 0.489, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the vendor's setup situated behind them.  The vendor is situated near the center of the image, while the main objects are located in the foreground and background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13090.5, "ram_available_mb": 49750.4, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13091.0, "ram_available_mb": 49749.9, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.413, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 6.501}, "timestamp": "2026-01-19T14:44:10.144868"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2377.204, "latencies_ms": [2377.204], "images_per_second": 0.421, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two men are seated under a large umbrella on a city sidewalk, seemingly engaged in conversation or observing something. Various items are displayed on tables and crates nearby, suggesting they are selling goods or providing services.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13091.0, "ram_available_mb": 49749.9, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 13041.4, "ram_available_mb": 49799.5, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.467, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.589}, "timestamp": "2026-01-19T14:44:14.551962"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2143.047, "latencies_ms": [2143.047], "images_per_second": 0.467, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene is black and white, highlighting the contrast between the dark clothing and the lighter background. The lighting appears to be natural, casting soft shadows and highlighting the textures of the objects and clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13041.4, "ram_available_mb": 49799.5, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 13033.5, "ram_available_mb": 49807.4, "ram_percent": 20.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.402, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 6.682}, "timestamp": "2026-01-19T14:44:18.711309"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2181.416, "latencies_ms": [2181.416], "images_per_second": 0.458, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The kitchen features a white refrigerator, stove, dishwasher, and cabinets, complemented by a black ceiling fan, tiled floor, and yellow backsplash.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13033.5, "ram_available_mb": 49807.4, "ram_percent": 20.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 13034.5, "ram_available_mb": 49806.4, "ram_percent": 20.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.755, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T14:44:22.957418"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3362.566, "latencies_ms": [3362.566], "images_per_second": 0.297, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "kitchen: 8\ncountertop: 2\ncabinets: 8\nrefrigerator: 1\ntoaster: 1\noven: 2\ndishwasher: 1\nwindow: 2\nceiling fan: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13034.5, "ram_available_mb": 49806.4, "ram_percent": 20.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13035.0, "ram_available_mb": 49805.9, "ram_percent": 20.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.763, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.113}, "timestamp": "2026-01-19T14:44:28.367119"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2506.387, "latencies_ms": [2506.387], "images_per_second": 0.399, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close-knit arrangement, with the stove and refrigerator situated close to the viewer. The kitchen also features cabinets and countertops that extend into the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13035.0, "ram_available_mb": 49805.9, "ram_percent": 20.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13035.2, "ram_available_mb": 49805.7, "ram_percent": 20.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.621, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 7.041}, "timestamp": "2026-01-19T14:44:32.923558"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2547.687, "latencies_ms": [2547.687], "images_per_second": 0.393, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The kitchen is clean, well-lit, and features white cabinets, a black countertop, and various appliances, including a refrigerator, oven, and dishwasher. The ceiling fan adds a touch of elegance to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13035.2, "ram_available_mb": 49805.7, "ram_percent": 20.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13041.3, "ram_available_mb": 49799.6, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.461, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T14:44:37.501264"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2503.821, "latencies_ms": [2503.821], "images_per_second": 0.399, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The kitchen features white cabinets and dark gray tile flooring. The lighting is primarily from overhead fixtures, creating a warm ambiance. The kitchen is equipped with modern appliances, including a refrigerator and a dishwasher.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13041.3, "ram_available_mb": 49799.6, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13042.2, "ram_available_mb": 49798.7, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.58, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.889}, "timestamp": "2026-01-19T14:44:42.019968"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1753.385, "latencies_ms": [1753.385], "images_per_second": 0.57, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A young child sleeps peacefully on a bed with a blue and white floral comforter, smiling while holding a pacifier.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 13042.2, "ram_available_mb": 49798.7, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13042.4, "ram_available_mb": 49798.5, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.361, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.831}, "timestamp": "2026-01-19T14:44:45.797059"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3094.144, "latencies_ms": [3094.144], "images_per_second": 0.323, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "bed: 2\nblanket: 2\npillow: 1\ntoddler: 1\npacifier: 1\ntelevision: 1\nwall: 1\ncord: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13042.4, "ram_available_mb": 49798.5, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13042.9, "ram_available_mb": 49798.0, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.685, "power_cpu_cv_mean_watts": 1.618, "power_sys_5v0_mean_watts": 7.023}, "timestamp": "2026-01-19T14:44:50.923821"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2206.243, "latencies_ms": [2206.243], "images_per_second": 0.453, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The main object is a child lying in bed near a wall. The bed occupies the foreground, while the wall is in the background. The child is positioned close to the wall, suggesting they are close by.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 13042.9, "ram_available_mb": 49798.0, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13042.7, "ram_available_mb": 49798.2, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.198, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.943}, "timestamp": "2026-01-19T14:44:55.156989"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1861.062, "latencies_ms": [1861.062], "images_per_second": 0.537, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A young child is sleeping peacefully on a bed with a train-themed bedding. The child is smiling and has a pacifier in their mouth.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 13042.7, "ram_available_mb": 49798.2, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 13053.8, "ram_available_mb": 49787.1, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.301, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.719}, "timestamp": "2026-01-19T14:44:59.037725"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2211.788, "latencies_ms": [2211.788], "images_per_second": 0.452, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The child's bed is covered with a blue and white floral blanket. The lighting in the room is dim, creating a cozy atmosphere. The child is wearing a white tank top and appears to be sleeping peacefully.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13053.8, "ram_available_mb": 49787.1, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 13056.1, "ram_available_mb": 49784.8, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.387, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 7.014}, "timestamp": "2026-01-19T14:45:03.287935"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2078.959, "latencies_ms": [2078.959], "images_per_second": 0.481, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A green highway sign with graffiti reading \"Quesens Bronx\" and a \"No Trucks\" sign above it indicates no trucks are allowed in the area.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 13056.1, "ram_available_mb": 49784.8, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13057.3, "ram_available_mb": 49783.6, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.439, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 6.634}, "timestamp": "2026-01-19T14:45:07.416730"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2594.844, "latencies_ms": [2594.844], "images_per_second": 0.385, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "No trucks: 1\nEast: 1\nQueens Bronx: 1\n278: 1\nSign: 1\nGraffiti: 1\nMetal structure: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13057.3, "ram_available_mb": 49783.6, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13058.4, "ram_available_mb": 49782.5, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.615, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 6.7}, "timestamp": "2026-01-19T14:45:12.037643"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1698.423, "latencies_ms": [1698.423], "images_per_second": 0.589, "prompt_tokens": 25, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The green sign is positioned in the foreground, slightly to the right of the main sign. The background is mostly empty and light-colored.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 13058.4, "ram_available_mb": 49782.5, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 13059.9, "ram_available_mb": 49781.0, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.956, "power_cpu_cv_mean_watts": 1.259, "power_sys_5v0_mean_watts": 6.213}, "timestamp": "2026-01-19T14:45:15.782183"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2320.542, "latencies_ms": [2320.542], "images_per_second": 0.431, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene depicts a highway sign displaying \"No Trucks\" above a green sign indicating the direction to Queens Bronx. A smaller sign above the main one reads \"East 278.\"", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13059.9, "ram_available_mb": 49781.0, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13061.4, "ram_available_mb": 49779.5, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.531, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.615}, "timestamp": "2026-01-19T14:45:20.134253"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1828.404, "latencies_ms": [1828.404], "images_per_second": 0.547, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The green highway sign is brightly lit, contrasting against the overcast sky. The sign appears to be made of metal and shows signs of wear and graffiti.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13061.4, "ram_available_mb": 49779.5, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 13059.2, "ram_available_mb": 49781.6, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.414, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.379}, "timestamp": "2026-01-19T14:45:23.991104"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1829.48, "latencies_ms": [1829.48], "images_per_second": 0.547, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A red Chevrolet pickup truck is parked in a lot, facing away from the camera, with other vehicles and tents visible in the background.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 13059.2, "ram_available_mb": 49781.6, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 13059.0, "ram_available_mb": 49781.9, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.649, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T14:45:27.869541"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3270.225, "latencies_ms": [3270.225], "images_per_second": 0.306, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Truck: 2\nTires: 4\nWheels: 2\nTailgate: 1\nChrome: 1\nLicense plate: 1\nMirror: 1\nStreet light: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 13059.0, "ram_available_mb": 49781.9, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13059.7, "ram_available_mb": 49781.2, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.654, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 7.129}, "timestamp": "2026-01-19T14:45:33.162628"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2630.392, "latencies_ms": [2630.392], "images_per_second": 0.38, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main object is a red Chevrolet pickup truck parked in the foreground, positioned slightly to the right of the viewer. The background features other vehicles, including a blue car and a green tent, suggesting an outdoor setting, possibly a car show or gathering.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 13059.7, "ram_available_mb": 49781.2, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 13060.2, "ram_available_mb": 49780.7, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.482, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T14:45:37.836143"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2460.468, "latencies_ms": [2460.468], "images_per_second": 0.406, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a vintage red Chevrolet pickup truck parked in a parking lot, possibly at a car show or similar event. Other vehicles, including a blue car and a green tent, are also visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.2, "ram_available_mb": 49780.7, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13060.9, "ram_available_mb": 49779.9, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.44, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T14:45:42.335745"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2574.872, "latencies_ms": [2574.872], "images_per_second": 0.388, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The red pickup truck stands out against the light blue sky. Its shiny chrome wheels and polished body reflect the sunlight, adding to its vintage charm. The truck is parked in a parking lot, suggesting it is in a public space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13060.9, "ram_available_mb": 49779.9, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 13061.4, "ram_available_mb": 49779.5, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.963, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T14:45:46.921020"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1630.412, "latencies_ms": [1630.412], "images_per_second": 0.613, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "Three cows are visible behind a barbed wire fence, grazing in a field with tall grass.", "error": null, "sys_before": {"cpu_percent": 10.5, "ram_used_mb": 13061.4, "ram_available_mb": 49779.5, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12660.6, "ram_available_mb": 50180.3, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.21, "power_cpu_cv_mean_watts": 1.078, "power_sys_5v0_mean_watts": 6.745}, "timestamp": "2026-01-19T14:45:50.577777"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3321.785, "latencies_ms": [3321.785], "images_per_second": 0.301, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Barbed wire fence: 5\nCow ears: 4\nCow head: 3\nCow body: 2\nCow tail: 1\nGrass: 6\nTrees: 1\nSky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12660.6, "ram_available_mb": 50180.3, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12662.2, "ram_available_mb": 50178.7, "ram_percent": 20.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.562, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.097}, "timestamp": "2026-01-19T14:45:55.963962"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1972.709, "latencies_ms": [1972.709], "images_per_second": 0.507, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the barbed wire fence separating them from the background. The cows are situated near the fence, partially obscured by it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12662.2, "ram_available_mb": 50178.7, "ram_percent": 20.1}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12665.4, "ram_available_mb": 50175.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.323, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.841}, "timestamp": "2026-01-19T14:45:59.981557"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1842.564, "latencies_ms": [1842.564], "images_per_second": 0.543, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Three cows are seen behind a barbed wire fence in a field. The black and white image captures a pastoral scene with grazing cattle.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12665.4, "ram_available_mb": 50175.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 9.7, "ram_used_mb": 12751.6, "ram_available_mb": 50089.2, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.569, "power_cpu_cv_mean_watts": 2.633, "power_sys_5v0_mean_watts": 7.106}, "timestamp": "2026-01-19T14:46:03.868815"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1869.863, "latencies_ms": [1869.863], "images_per_second": 0.535, "prompt_tokens": 18, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The cows are primarily black and white. The lighting suggests a sunny day. The cows are seen behind a barbed wire fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12751.6, "ram_available_mb": 50089.2, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12753.9, "ram_available_mb": 50087.0, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.492, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.767}, "timestamp": "2026-01-19T14:46:07.794143"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1704.729, "latencies_ms": [1704.729], "images_per_second": 0.587, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The room features a cozy and inviting atmosphere with a warm color scheme, a comfortable bed, a fireplace, a television, and two chairs.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12753.9, "ram_available_mb": 50087.0, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12764.9, "ram_available_mb": 50076.0, "ram_percent": 20.3}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.576, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T14:46:11.529555"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2840.811, "latencies_ms": [2840.811], "images_per_second": 0.352, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bed: 6\nchair: 2\nwindow: 2\nfireplace: 1\ntelevision: 1\nclock: 1\nlamp: 1\nsofa: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12764.9, "ram_available_mb": 50076.0, "ram_percent": 20.3}, "sys_after": {"cpu_percent": 10.9, "ram_used_mb": 12954.3, "ram_available_mb": 49886.6, "ram_percent": 20.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.142, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.073}, "timestamp": "2026-01-19T14:46:16.410040"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2279.199, "latencies_ms": [2279.199], "images_per_second": 0.439, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The main objects are positioned in a balanced and harmonious manner, with the bed dominating the left side of the image and the seating area on the right. The seating area is situated closer to the viewer, creating a sense of proximity and comfort.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12954.3, "ram_available_mb": 49886.6, "ram_percent": 20.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12946.0, "ram_available_mb": 49894.9, "ram_percent": 20.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.243, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 7.077}, "timestamp": "2026-01-19T14:46:20.710145"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1861.258, "latencies_ms": [1861.258], "images_per_second": 0.537, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The scene depicts a cozy bedroom with a large bed, wooden furniture, and a fireplace. The room is lit by warm lighting, creating a comfortable and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12946.0, "ram_available_mb": 49894.9, "ram_percent": 20.6}, "sys_after": {"cpu_percent": 8.4, "ram_used_mb": 13051.2, "ram_available_mb": 49789.6, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.542, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.767}, "timestamp": "2026-01-19T14:46:24.604582"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2405.993, "latencies_ms": [2405.993], "images_per_second": 0.416, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The room features a warm color scheme with brown and beige tones. The lighting is soft and warm, creating a cozy atmosphere. The furniture includes wooden elements and a stone fireplace, adding a rustic touch to the space.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13052.2, "ram_available_mb": 49788.7, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 14.5, "ram_used_mb": 13127.8, "ram_available_mb": 49713.1, "ram_percent": 20.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.622, "power_cpu_cv_mean_watts": 2.343, "power_sys_5v0_mean_watts": 7.086}, "timestamp": "2026-01-19T14:46:29.026621"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1528.609, "latencies_ms": [1528.609], "images_per_second": 0.654, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Three black birds with white speckled feathers are walking across a dry, grassy hillside.", "error": null, "sys_before": {"cpu_percent": 24.2, "ram_used_mb": 13127.8, "ram_available_mb": 49713.1, "ram_percent": 20.9}, "sys_after": {"cpu_percent": 15.9, "ram_used_mb": 13118.1, "ram_available_mb": 49722.8, "ram_percent": 20.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.026, "power_cpu_cv_mean_watts": 2.838, "power_sys_5v0_mean_watts": 7.039}, "timestamp": "2026-01-19T14:46:32.593314"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1964.269, "latencies_ms": [1964.269], "images_per_second": 0.509, "prompt_tokens": 21, "response_tokens_est": 19, "n_tiles": 1, "output_text": "bird: 3\ngrass: 2\ntree: 1\nbush: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 13118.1, "ram_available_mb": 49722.8, "ram_percent": 20.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 13086.2, "ram_available_mb": 49754.7, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.89, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T14:46:36.567545"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1773.562, "latencies_ms": [1773.562], "images_per_second": 0.564, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the background slightly blurred. The birds are located near the center, slightly to the right of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.5, "ram_available_mb": 49755.4, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13085.2, "ram_available_mb": 49755.7, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.112, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.717}, "timestamp": "2026-01-19T14:46:40.363860"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2061.098, "latencies_ms": [2061.098], "images_per_second": 0.485, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Three black birds with blue heads and necks are walking across a dry, grassy hillside.  The birds appear to be grazing or foraging in the sparse vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13085.2, "ram_available_mb": 49755.7, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 13078.0, "ram_available_mb": 49762.9, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.25, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 6.885}, "timestamp": "2026-01-19T14:46:44.453479"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2317.782, "latencies_ms": [2317.782], "images_per_second": 0.431, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The birds have dark gray plumage with speckled patterns. The lighting is soft and diffused, suggesting an overcast sky. The ground is covered with dry, light brown grass.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13078.0, "ram_available_mb": 49762.9, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13078.4, "ram_available_mb": 49762.5, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.032, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T14:46:48.791013"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1567.031, "latencies_ms": [1567.031], "images_per_second": 0.638, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Three people are posing for a photo on a snowy mountain slope, wearing winter gear and holding ski poles.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 13078.4, "ram_available_mb": 49762.5, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 13077.9, "ram_available_mb": 49763.0, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.893, "power_cpu_cv_mean_watts": 1.102, "power_sys_5v0_mean_watts": 6.795}, "timestamp": "2026-01-19T14:46:52.396020"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3966.687, "latencies_ms": [3966.687], "images_per_second": 0.252, "prompt_tokens": 21, "response_tokens_est": 58, "n_tiles": 1, "output_text": "snowboard: 2\nsnowboard poles: 4\nsnowboard boots: 2\nsnowboard bindings: 2\nsnowboard: 1\nsnowboard boots: 2\nsnowboard: 1\nsnowboard poles: 4\nsnowboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13077.9, "ram_available_mb": 49763.0, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13078.0, "ram_available_mb": 49762.9, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.401, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.19}, "timestamp": "2026-01-19T14:46:58.400599"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2478.656, "latencies_ms": [2478.656], "images_per_second": 0.403, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The three people are positioned in a relatively close grouping, with the person on the left closest to the camera and the person on the right furthest away. The foreground is dominated by the snow-covered ground, while the background features snow-covered trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13078.0, "ram_available_mb": 49762.9, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 13077.1, "ram_available_mb": 49763.8, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.382, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T14:47:02.930104"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2325.872, "latencies_ms": [2325.872], "images_per_second": 0.43, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Three people are snowshoeing on a snowy slope in a forested area. They are dressed in winter gear and holding ski poles, enjoying a winter activity amidst the snow-covered trees.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13077.1, "ram_available_mb": 49763.8, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 13076.8, "ram_available_mb": 49764.1, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.905, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.896}, "timestamp": "2026-01-19T14:47:07.276001"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2323.167, "latencies_ms": [2323.167], "images_per_second": 0.43, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The snow is white and appears well-groomed. The lighting is bright and evenly distributed, illuminating the scene. The snow appears to be fresh and undisturbed, suggesting good weather conditions.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13076.8, "ram_available_mb": 49764.1, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 13076.3, "ram_available_mb": 49764.6, "ram_percent": 20.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.675, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T14:47:11.649125"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1812.979, "latencies_ms": [1812.979], "images_per_second": 0.552, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A white and blue city bus numbered 51 is parked on the side of the road, displaying \"Crosstown\" on its electronic sign.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 13076.3, "ram_available_mb": 49764.6, "ram_percent": 20.8}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12678.8, "ram_available_mb": 50162.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.74, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.013}, "timestamp": "2026-01-19T14:47:15.503126"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4285.419, "latencies_ms": [4285.419], "images_per_second": 0.233, "prompt_tokens": 21, "response_tokens_est": 52, "n_tiles": 1, "output_text": "Bus: 2\nNumber plate: 1\nLicense plate: 1\nHeadlights: 2\nWindshield wipers: 2\nBus number: 51\nBus route: 51\nBus branding: 1\nBus front bumper: 1\nBus side panel: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12678.8, "ram_available_mb": 50162.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 12679.0, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.243, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 7.208}, "timestamp": "2026-01-19T14:47:21.824961"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2325.014, "latencies_ms": [2325.014], "images_per_second": 0.43, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, facing the viewer. The building is partially visible in the background, situated to the right of the bus. The bus is parked on the street, further back from the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12679.0, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12679.5, "ram_available_mb": 50161.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.885, "power_cpu_cv_mean_watts": 1.349, "power_sys_5v0_mean_watts": 6.885}, "timestamp": "2026-01-19T14:47:26.191345"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3030.993, "latencies_ms": [3030.993], "images_per_second": 0.33, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "A white and blue bus is parked on the side of a road, displaying the number 51 and the destination \"Crosstown.\" A person can be seen standing near the bus, possibly waiting to board or observing the bus. The setting appears to be an urban environment with a brick building visible in the background.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12679.5, "ram_available_mb": 50161.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12679.5, "ram_available_mb": 50161.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.101, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.116}, "timestamp": "2026-01-19T14:47:31.259519"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2718.806, "latencies_ms": [2718.806], "images_per_second": 0.368, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The bus is primarily white with blue and green accents. The lighting appears to be bright and sunny, illuminating the bus and its surroundings. The materials appear to be standard bus construction, with clear glass windows and metal framing. The weather appears to be sunny and clear.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12679.5, "ram_available_mb": 50161.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12679.4, "ram_available_mb": 50161.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.695, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T14:47:35.998399"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2254.468, "latencies_ms": [2254.468], "images_per_second": 0.444, "prompt_tokens": 8, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A man dressed in a blue blazer, white collared shirt, striped tie, gray pleated skirt, black tights, and black shoes is standing against a white wall, holding a black purse.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12679.4, "ram_available_mb": 50161.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12679.4, "ram_available_mb": 50161.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.748, "power_cpu_cv_mean_watts": 1.624, "power_sys_5v0_mean_watts": 6.658}, "timestamp": "2026-01-19T14:47:40.311515"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2916.78, "latencies_ms": [2916.78], "images_per_second": 0.343, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Jacket: 2\nSkirt: 1\nTie: 1\nShirt: 1\nPants: 1\nTights: 1\nHandbag: 1\nShoes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12679.4, "ram_available_mb": 50161.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12679.3, "ram_available_mb": 50161.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.598, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 6.779}, "timestamp": "2026-01-19T14:47:45.245866"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2259.338, "latencies_ms": [2259.338], "images_per_second": 0.443, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The man is positioned in the foreground, wearing a school uniform and holding a handbag. The handbag is situated near his feet. The background features a white wall with a red stripe, providing a neutral backdrop.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12679.3, "ram_available_mb": 50161.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12679.2, "ram_available_mb": 50161.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.258, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.524}, "timestamp": "2026-01-19T14:47:49.516865"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2530.455, "latencies_ms": [2530.455], "images_per_second": 0.395, "prompt_tokens": 19, "response_tokens_est": 49, "n_tiles": 1, "output_text": "A young man is standing in a school uniform, wearing a blue blazer, white shirt, and striped tie. He is dressed in a gray pleated skirt and carrying a black purse. The setting appears to be a school hallway or corridor.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 12679.2, "ram_available_mb": 50161.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12679.7, "ram_available_mb": 50161.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.454, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.663}, "timestamp": "2026-01-19T14:47:54.059145"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3308.781, "latencies_ms": [3308.781], "images_per_second": 0.302, "prompt_tokens": 18, "response_tokens_est": 72, "n_tiles": 1, "output_text": "The man's attire is predominantly blue and gray, accented with red stripes. The lighting appears to be artificial, casting a soft glow on his outfit. The materials appear to be standard school uniforms, composed of fabric and possibly some synthetic elements. The weather appears to be cool and possibly rainy, as evidenced by the dark shoes and the presence of a bag.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12678.9, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12678.8, "ram_available_mb": 50162.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.882, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 6.862}, "timestamp": "2026-01-19T14:47:59.383843"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1851.121, "latencies_ms": [1851.121], "images_per_second": 0.54, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A train yard filled with multiple train cars and tracks is visible in the hazy, sepia-toned image.", "error": null, "sys_before": {"cpu_percent": 11.4, "ram_used_mb": 12678.8, "ram_available_mb": 50162.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12679.7, "ram_available_mb": 50161.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.765, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T14:48:03.274615"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2797.606, "latencies_ms": [2797.606], "images_per_second": 0.357, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Train car: 6\nTrain cars: 5\nTrain tracks: 4\nPower lines: 6\nTrees: 2\nBuilding: 1\nFog: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12679.7, "ram_available_mb": 50161.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12679.6, "ram_available_mb": 50161.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.129, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T14:48:08.106538"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1987.991, "latencies_ms": [1987.991], "images_per_second": 0.503, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the train cars extending into the background. The train tracks run parallel to the train cars, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12679.6, "ram_available_mb": 50161.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12679.9, "ram_available_mb": 50161.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.297, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.81}, "timestamp": "2026-01-19T14:48:12.121768"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3302.284, "latencies_ms": [3302.284], "images_per_second": 0.303, "prompt_tokens": 19, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The scene depicts a train yard or rail yard with multiple train cars and tracks. The image is captured in sepia tones, giving it a vintage or nostalgic feel. The hazy atmosphere and power lines suggest it might be located near a railway station or in a region with frequent train operations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12679.9, "ram_available_mb": 50161.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12679.0, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.62, "power_cpu_cv_mean_watts": 1.676, "power_sys_5v0_mean_watts": 7.029}, "timestamp": "2026-01-19T14:48:17.442121"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2503.667, "latencies_ms": [2503.667], "images_per_second": 0.399, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene is dominated by muted, brownish-gold hues, creating a somber atmosphere. The lighting suggests an early morning or late evening setting, casting a hazy glow over the train yard.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12679.0, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12679.3, "ram_available_mb": 50161.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.641, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T14:48:21.961967"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1860.821, "latencies_ms": [1860.821], "images_per_second": 0.537, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A bathroom floor is cluttered with various items, including skis, gloves, a helmet, a potted plant, a toilet, a sink, and a towel.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12679.3, "ram_available_mb": 50161.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12679.8, "ram_available_mb": 50161.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.053, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.35}, "timestamp": "2026-01-19T14:48:25.868892"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3019.029, "latencies_ms": [3019.029], "images_per_second": 0.331, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "toilet: 1\nplant: 1\nsnowboard: 1\ngloves: 2\nskis: 2\nhelmet: 1\nshoes: 4\nclothes: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12679.8, "ram_available_mb": 50161.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12679.1, "ram_available_mb": 50161.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.582, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 6.745}, "timestamp": "2026-01-19T14:48:30.951122"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1730.269, "latencies_ms": [1730.269], "images_per_second": 0.578, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The toilet is positioned to the left of the image, near the foreground. The skis are located in the background, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12679.1, "ram_available_mb": 50161.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12678.4, "ram_available_mb": 50162.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.399, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 6.304}, "timestamp": "2026-01-19T14:48:34.718334"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2162.105, "latencies_ms": [2162.105], "images_per_second": 0.463, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a bathroom with a toilet, sink, and various personal items scattered on the floor, including skis, gloves, and ski boots. A potted plant adds a touch of greenery to the space.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12678.4, "ram_available_mb": 50162.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12679.0, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.637, "power_cpu_cv_mean_watts": 1.578, "power_sys_5v0_mean_watts": 6.558}, "timestamp": "2026-01-19T14:48:38.926813"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2699.197, "latencies_ms": [2699.197], "images_per_second": 0.37, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The bathroom features a white toilet and a small plant on a stand. The floor is covered in skateboarding gear, suggesting recent use or storage. The lighting appears somewhat dim, potentially from overhead fixtures or natural light filtering in through the window.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12679.0, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12678.5, "ram_available_mb": 50162.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.688, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 6.799}, "timestamp": "2026-01-19T14:48:43.659376"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1637.411, "latencies_ms": [1637.411], "images_per_second": 0.611, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A polar bear is playing with colorful balls in a pool of water, appearing to be enjoying its time outdoors.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12678.5, "ram_available_mb": 50162.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12678.5, "ram_available_mb": 50162.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.823, "power_cpu_cv_mean_watts": 1.078, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T14:48:47.351281"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2683.502, "latencies_ms": [2683.502], "images_per_second": 0.373, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "ball: 3\npaw: 2\nball: 2\nball: 2\nball: 2\nball: 2\nball: 2\nball: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12678.5, "ram_available_mb": 50162.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12678.9, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.512, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.028}, "timestamp": "2026-01-19T14:48:52.065131"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1777.793, "latencies_ms": [1777.793], "images_per_second": 0.562, "prompt_tokens": 25, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The green and yellow balls are positioned in the foreground, close to the polar bear. The background features the rocky terrain and the sandy ground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12678.9, "ram_available_mb": 50161.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12678.9, "ram_available_mb": 50162.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.308, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T14:48:55.894896"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1822.656, "latencies_ms": [1822.656], "images_per_second": 0.549, "prompt_tokens": 19, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A polar bear is playing with colorful balls in a pool of water. The setting appears to be a zoo enclosure with rocks and sandy ground.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12678.9, "ram_available_mb": 50162.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12679.1, "ram_available_mb": 50161.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.966, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.811}, "timestamp": "2026-01-19T14:48:59.761259"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2367.141, "latencies_ms": [2367.141], "images_per_second": 0.422, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The polar bear is predominantly white, contrasting with the dark water around it. The lighting appears to be natural, suggesting daylight conditions. The bear is playing with colorful balls, which add a playful element to the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12675.6, "ram_available_mb": 50165.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12676.4, "ram_available_mb": 50164.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.844, "power_cpu_cv_mean_watts": 1.497, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T14:49:04.150927"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1813.599, "latencies_ms": [1813.599], "images_per_second": 0.551, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A person is sitting on a wooden chair wearing blue slippers and jeans, while holding a Samsung cell phone in their right hand.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12676.4, "ram_available_mb": 50164.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12677.4, "ram_available_mb": 50163.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.024, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T14:49:08.018643"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2703.196, "latencies_ms": [2703.196], "images_per_second": 0.37, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "chair: 2\nslippers: 2\nsocks: 2\nphone: 1\nwindow: 1\nwooden floor: 4\nblue jeans: 2", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 12677.4, "ram_available_mb": 50163.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12677.1, "ram_available_mb": 50163.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.056, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.978}, "timestamp": "2026-01-19T14:49:12.734756"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1903.998, "latencies_ms": [1903.998], "images_per_second": 0.525, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The chair is positioned in the foreground, while the cell phone is held in the background. The chair and cell phone are located near each other, suggesting proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12677.1, "ram_available_mb": 50163.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12676.9, "ram_available_mb": 50163.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.543, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.827}, "timestamp": "2026-01-19T14:49:16.657980"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2210.71, "latencies_ms": [2210.71], "images_per_second": 0.452, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The scene depicts a person sitting on a wooden chair, wearing blue slippers and jeans. The right side shows a Samsung cell phone being held by a hand near a window.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12676.9, "ram_available_mb": 50163.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12677.2, "ram_available_mb": 50163.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.2, "power_cpu_cv_mean_watts": 1.446, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:49:20.903068"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2184.866, "latencies_ms": [2184.866], "images_per_second": 0.458, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The chair is light brown and appears to be made of wood. The floor is made of polished wood planks. The lighting in the image is soft and natural, likely coming from a nearby window.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12677.2, "ram_available_mb": 50163.7, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12676.8, "ram_available_mb": 50164.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.134, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T14:49:25.129407"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1643.79, "latencies_ms": [1643.79], "images_per_second": 0.608, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A yellow and black train travels down a snowy track, passing through a forest of snow-covered trees and bushes.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12676.8, "ram_available_mb": 50164.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12676.1, "ram_available_mb": 50164.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.856, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.846}, "timestamp": "2026-01-19T14:49:28.815499"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2773.988, "latencies_ms": [2773.988], "images_per_second": 0.36, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Train: 1\nTrees: 6\nSnow: 6\nSky: 1\nTrain tracks: 2\nPower lines: 2\nTraffic light: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12676.1, "ram_available_mb": 50164.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12675.9, "ram_available_mb": 50164.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.084, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.104}, "timestamp": "2026-01-19T14:49:33.631328"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1995.915, "latencies_ms": [1995.915], "images_per_second": 0.501, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The train is moving from left to right, occupying the foreground of the image. The snowy landscape and trees in the background create a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12675.9, "ram_available_mb": 50164.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12675.9, "ram_available_mb": 50165.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.602, "power_cpu_cv_mean_watts": 1.177, "power_sys_5v0_mean_watts": 6.829}, "timestamp": "2026-01-19T14:49:37.658675"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2190.953, "latencies_ms": [2190.953], "images_per_second": 0.456, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A yellow train travels through a snowy landscape, passing through a forest of snow-covered trees. The scene is captured from a distance, emphasizing the vastness of the snowy environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12675.9, "ram_available_mb": 50165.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12676.5, "ram_available_mb": 50164.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.181, "power_cpu_cv_mean_watts": 1.291, "power_sys_5v0_mean_watts": 6.876}, "timestamp": "2026-01-19T14:49:41.877438"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2619.913, "latencies_ms": [2619.913], "images_per_second": 0.382, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The train is yellow and appears to be moving through the snowy landscape. The lighting is soft and diffused, suggesting an overcast day. The scene is dominated by shades of white and gray, reflecting the snow and sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12676.5, "ram_available_mb": 50164.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12677.2, "ram_available_mb": 50163.7, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.651, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.998}, "timestamp": "2026-01-19T14:49:46.525828"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1709.467, "latencies_ms": [1709.467], "images_per_second": 0.585, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "People are walking through a large pile of snow on a city street, highlighting the significant snowfall in the area.", "error": null, "sys_before": {"cpu_percent": 13.8, "ram_used_mb": 12677.0, "ram_available_mb": 50163.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12677.0, "ram_available_mb": 50163.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.393, "power_cpu_cv_mean_watts": 1.017, "power_sys_5v0_mean_watts": 6.707}, "timestamp": "2026-01-19T14:49:50.284839"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2486.036, "latencies_ms": [2486.036], "images_per_second": 0.402, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "snow: 10\nfire hydrant: 1\npiles of snow: 5\npeople walking: 4\ncar: 1\nbuilding: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12677.0, "ram_available_mb": 50163.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12676.3, "ram_available_mb": 50164.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.826, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 7.0}, "timestamp": "2026-01-19T14:49:54.822683"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2368.845, "latencies_ms": [2368.845], "images_per_second": 0.422, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The snow pile is positioned to the left of the foreground, extending towards the right side of the image. The people walking in the background are further away and appear smaller in comparison to the snow pile and the people in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12676.3, "ram_available_mb": 50164.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12675.6, "ram_available_mb": 50165.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.654, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.865}, "timestamp": "2026-01-19T14:49:59.221007"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2353.821, "latencies_ms": [2353.821], "images_per_second": 0.425, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A group of people are walking through a large snow pile on a city street. The snow is piled high around cars and buildings, indicating a significant snowfall. The scene suggests a wintery urban environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12675.6, "ram_available_mb": 50165.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12675.7, "ram_available_mb": 50165.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.865, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.864}, "timestamp": "2026-01-19T14:50:03.592413"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2733.142, "latencies_ms": [2733.142], "images_per_second": 0.366, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The snow is white and appears quite thick and heavy. The lighting suggests an overcast day, with diffused light that doesn't cast harsh shadows. The snow appears to be made of compressed snow and ice, potentially indicating recent snowfall.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12675.1, "ram_available_mb": 50165.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12675.0, "ram_available_mb": 50165.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.221, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.014}, "timestamp": "2026-01-19T14:50:08.385949"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1617.244, "latencies_ms": [1617.244], "images_per_second": 0.618, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A yellow and black sign with a cartoonish mouth is attached to a metal pole near a tree and building.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12675.0, "ram_available_mb": 50165.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12674.7, "ram_available_mb": 50166.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.629, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.141}, "timestamp": "2026-01-19T14:50:12.072072"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2457.026, "latencies_ms": [2457.026], "images_per_second": 0.407, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Tow Zone: 1\nNo Parking sign: 1\nYellow sign: 1\nStreet light: 1\nBuilding: 1\nTrees: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12674.7, "ram_available_mb": 50166.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12674.0, "ram_available_mb": 50166.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.614, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 6.652}, "timestamp": "2026-01-19T14:50:16.592480"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2103.869, "latencies_ms": [2103.869], "images_per_second": 0.475, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The large tree on the left dominates the foreground, partially obscuring the background buildings. The tow zone sign is positioned further back, partially obscured by the tree and pole.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12674.0, "ram_available_mb": 50166.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12674.0, "ram_available_mb": 50166.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.333, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.546}, "timestamp": "2026-01-19T14:50:20.730670"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2250.328, "latencies_ms": [2250.328], "images_per_second": 0.444, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a street corner with two signs: a no parking sign and a yellow and black sign attached to a pole. The signs are situated amidst lush green trees, creating a pleasant and visually appealing environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12674.0, "ram_available_mb": 50166.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12673.1, "ram_available_mb": 50167.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.593, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.619}, "timestamp": "2026-01-19T14:50:25.001133"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1716.306, "latencies_ms": [1716.306], "images_per_second": 0.583, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The sign is primarily white with a red border. The lighting suggests a sunny day. The sign appears to be made of metal and has a simple design.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12673.1, "ram_available_mb": 50167.8, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12673.0, "ram_available_mb": 50167.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.552, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 6.435}, "timestamp": "2026-01-19T14:50:28.766647"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1793.469, "latencies_ms": [1793.469], "images_per_second": 0.558, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A beige teddy bear wearing glasses sits on a red surface with a white iPod, a black microphone, a keyboard, and a pink mouse.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12673.0, "ram_available_mb": 50167.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12673.0, "ram_available_mb": 50167.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.27, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.328}, "timestamp": "2026-01-19T14:50:32.587600"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2940.42, "latencies_ms": [2940.42], "images_per_second": 0.34, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "keyboard: 8\nteddy bear: 1\nglasses: 1\niPod: 1\nmicrophone: 1\nmouse: 1\nmousepad: 1\nheadphones: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12673.0, "ram_available_mb": 50167.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12673.0, "ram_available_mb": 50167.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.698, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 6.816}, "timestamp": "2026-01-19T14:50:37.560775"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1920.715, "latencies_ms": [1920.715], "images_per_second": 0.521, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The teddy bear is positioned in the foreground, slightly to the right of the keyboard. The keyboard and teddy bear are placed close together, creating a sense of proximity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12673.0, "ram_available_mb": 50167.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12672.6, "ram_available_mb": 50168.3, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.107, "power_cpu_cv_mean_watts": 1.308, "power_sys_5v0_mean_watts": 6.363}, "timestamp": "2026-01-19T14:50:41.521827"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1886.895, "latencies_ms": [1886.895], "images_per_second": 0.53, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A teddy bear wearing glasses sits on a red surface, connected to a computer via cables. A microphone and a small device are also present on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12672.6, "ram_available_mb": 50168.3, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12671.9, "ram_available_mb": 50169.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.267, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.377}, "timestamp": "2026-01-19T14:50:45.453354"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2430.925, "latencies_ms": [2430.925], "images_per_second": 0.411, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The teddy bear is light brown and wears glasses. The lighting is dim, creating a moody atmosphere. The materials appear to be plush fabric and plastic. The teddy bear is sitting on what looks like a red surface.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12671.9, "ram_available_mb": 50169.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12671.7, "ram_available_mb": 50169.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.454, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.627}, "timestamp": "2026-01-19T14:50:49.909685"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1920.032, "latencies_ms": [1920.032], "images_per_second": 0.521, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A skier in an orange suit and helmet is captured mid-air, performing a trick on a snowy slope with trees and a rocky hillside in the background.", "error": null, "sys_before": {"cpu_percent": 13.0, "ram_used_mb": 12671.7, "ram_available_mb": 50169.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12671.7, "ram_available_mb": 50169.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.439, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.457}, "timestamp": "2026-01-19T14:50:53.869540"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3117.25, "latencies_ms": [3117.25], "images_per_second": 0.321, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "skier: 2\nskis: 2\nsnow: 2\nhill: 1\ntree: 1\nlog: 1\nsnowboard: 0\ngloves: 2\nhelmet: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12671.7, "ram_available_mb": 50169.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12671.9, "ram_available_mb": 50169.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.691, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 6.765}, "timestamp": "2026-01-19T14:50:59.025021"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2113.978, "latencies_ms": [2113.978], "images_per_second": 0.473, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, mid-jump, with the snowy mountain and trees in the background. The image captures the dynamic motion of the skier against the serene, snowy landscape.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12671.9, "ram_available_mb": 50169.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12671.7, "ram_available_mb": 50169.2, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.285, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.475}, "timestamp": "2026-01-19T14:51:03.193121"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2073.194, "latencies_ms": [2073.194], "images_per_second": 0.482, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A skier in an orange suit is captured mid-air, performing a trick on a snowy slope. The scene is set against a backdrop of a snow-covered mountain under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12671.7, "ram_available_mb": 50169.2, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12672.4, "ram_available_mb": 50168.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.143, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.445}, "timestamp": "2026-01-19T14:51:07.281748"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2771.247, "latencies_ms": [2771.247], "images_per_second": 0.361, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The skier is wearing bright orange clothing. The lighting is bright and sunny, creating a contrast against the white snow. The skier is captured mid-air, showcasing their skill and athleticism. The snowy mountain landscape adds to the picturesque setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12672.4, "ram_available_mb": 50168.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12672.5, "ram_available_mb": 50168.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.371, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 6.644}, "timestamp": "2026-01-19T14:51:12.084088"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1984.887, "latencies_ms": [1984.887], "images_per_second": 0.504, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two surfers in wetsuits ride waves in the ocean, one standing on a green surfboard and the other crouched on a yellow surfboard.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12672.5, "ram_available_mb": 50168.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12672.5, "ram_available_mb": 50168.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.127, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T14:51:16.128978"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2083.057, "latencies_ms": [2083.057], "images_per_second": 0.48, "prompt_tokens": 21, "response_tokens_est": 23, "n_tiles": 1, "output_text": "waves: 2\nsurfers: 2\nsurfboards: 2\nwater: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12672.5, "ram_available_mb": 50168.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12672.5, "ram_available_mb": 50168.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.647, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.889}, "timestamp": "2026-01-19T14:51:20.268250"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1842.215, "latencies_ms": [1842.215], "images_per_second": 0.543, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the ocean extending in the background. The foreground is closer and larger compared to the background, suggesting depth and perspective.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12672.5, "ram_available_mb": 50168.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12672.4, "ram_available_mb": 50168.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.863, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.834}, "timestamp": "2026-01-19T14:51:24.154285"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2090.736, "latencies_ms": [2090.736], "images_per_second": 0.478, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "Two surfers are riding waves in the ocean. The scene is dynamic and energetic, capturing the thrill of surfing amidst the vastness of the sea.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12672.4, "ram_available_mb": 50168.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12671.8, "ram_available_mb": 50169.1, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.507, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:51:28.262947"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2275.256, "latencies_ms": [2275.256], "images_per_second": 0.44, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The ocean is a deep blue, suggesting potentially cold or stormy weather. The lighting is soft and diffused, possibly indicating overcast conditions or early morning/late evening light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12671.8, "ram_available_mb": 50169.1, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12671.1, "ram_available_mb": 50169.8, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.27, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.865}, "timestamp": "2026-01-19T14:51:32.555226"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2295.115, "latencies_ms": [2295.115], "images_per_second": 0.436, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A freshly baked pizza with cheese, tomato sauce, onions, and pineapple chunks sits on a metal tray, accompanied by a fork, knife, and salt shaker on a blue table.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12671.0, "ram_available_mb": 50169.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12670.4, "ram_available_mb": 50170.5, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.716, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:51:36.896266"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4311.114, "latencies_ms": [4311.114], "images_per_second": 0.232, "prompt_tokens": 21, "response_tokens_est": 62, "n_tiles": 1, "output_text": "Pizza: 8\nPizza sauce: 1\nCheese: 1\nTomato sauce: 1\nPepper: 1\nSausage: 1\nOnions: 1\nBasil: 1\nPeppers: 1\nFork: 1\nKnife: 1\nNapkin: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12670.4, "ram_available_mb": 50170.5, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 12670.3, "ram_available_mb": 50170.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.886, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 7.196}, "timestamp": "2026-01-19T14:51:43.251082"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1995.635, "latencies_ms": [1995.635], "images_per_second": 0.501, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The pizza is positioned in the foreground, slightly to the right of the table. The table occupies the middle ground of the image, and the background is blurred and out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12670.3, "ram_available_mb": 50170.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12670.3, "ram_available_mb": 50170.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.573, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.873}, "timestamp": "2026-01-19T14:51:47.305512"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2398.596, "latencies_ms": [2398.596], "images_per_second": 0.417, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is set in a dimly lit restaurant or bar, showcasing a freshly baked pizza with toppings on a metal tray, accompanied by a salt shaker and a fork. The atmosphere is casual and relaxed.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12670.3, "ram_available_mb": 50170.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12670.5, "ram_available_mb": 50170.4, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.741, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T14:51:51.726786"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2056.178, "latencies_ms": [2056.178], "images_per_second": 0.486, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The pizza is topped with vibrant red sauce, melted cheese, and chunks of pineapple. The table is dark blue, and the lighting creates a warm, inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12670.5, "ram_available_mb": 50170.4, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12669.9, "ram_available_mb": 50171.0, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.576, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T14:51:55.819752"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1797.21, "latencies_ms": [1797.21], "images_per_second": 0.556, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A black metal clock with Roman numerals and ornate detailing is mounted on a pole on the left side of the image, partially covered in snow.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12669.9, "ram_available_mb": 50171.0, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12670.0, "ram_available_mb": 50170.9, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.737, "power_cpu_cv_mean_watts": 1.145, "power_sys_5v0_mean_watts": 6.709}, "timestamp": "2026-01-19T14:51:59.652607"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2582.986, "latencies_ms": [2582.986], "images_per_second": 0.387, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "clock: 1\nstreet light: 1\nbuildings: 4\ncars: 2\ntrees: 1\nsnow: 2\npots: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12670.0, "ram_available_mb": 50170.9, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12670.3, "ram_available_mb": 50170.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.897}, "timestamp": "2026-01-19T14:52:04.269185"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1844.987, "latencies_ms": [1844.987], "images_per_second": 0.542, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The clock is positioned in the foreground, slightly to the left of the image. The street and buildings extend into the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12670.3, "ram_available_mb": 50170.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12670.3, "ram_available_mb": 50170.6, "ram_percent": 20.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.114, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.789}, "timestamp": "2026-01-19T14:52:08.128894"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3154.784, "latencies_ms": [3154.784], "images_per_second": 0.317, "prompt_tokens": 19, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The scene depicts a snowy street in a small town or village, lined with brick buildings and a clock displaying the time. The street is relatively empty, with only a few parked cars and a few pedestrians visible. The overall atmosphere is peaceful and quiet, typical of a quiet winter day in a small town.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12670.3, "ram_available_mb": 50170.6, "ram_percent": 20.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12529.8, "ram_available_mb": 50311.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.774, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.075}, "timestamp": "2026-01-19T14:52:13.316541"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2751.261, "latencies_ms": [2751.261], "images_per_second": 0.363, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The buildings are primarily brick, exhibiting a reddish-brown hue. The street is lit by streetlights, creating a warm glow against the cold, snowy backdrop. The scene is peaceful and serene, capturing a quiet moment in a winter town.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12529.8, "ram_available_mb": 50311.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12529.0, "ram_available_mb": 50311.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.22, "power_cpu_cv_mean_watts": 1.493, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T14:52:18.099782"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1788.784, "latencies_ms": [1788.784], "images_per_second": 0.559, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A baseball player in a white uniform with blue accents is swinging his bat, attempting to hit a pitched ball during a game.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12529.0, "ram_available_mb": 50311.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12528.7, "ram_available_mb": 50312.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.082, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T14:52:21.957050"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3596.79, "latencies_ms": [3596.79], "images_per_second": 0.278, "prompt_tokens": 21, "response_tokens_est": 49, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball: 1\nbaseball glove: 1\nbaseball: 1\nbaseball field: 1\nbaseball player: 1\nbaseball umpire: 1\nbaseball umpire's mask: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12528.7, "ram_available_mb": 50312.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12528.7, "ram_available_mb": 50312.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.526, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.126}, "timestamp": "2026-01-19T14:52:27.578677"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1729.845, "latencies_ms": [1729.845], "images_per_second": 0.578, "prompt_tokens": 25, "response_tokens_est": 24, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, facing the pitcher. The catcher is positioned in the background, behind the batter.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12528.7, "ram_available_mb": 50312.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12528.7, "ram_available_mb": 50312.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.146, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.707}, "timestamp": "2026-01-19T14:52:31.343493"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2665.635, "latencies_ms": [2665.635], "images_per_second": 0.375, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A baseball game is in progress on a sunny day. A batter in a white uniform with blue accents is swinging at a pitched ball, while a catcher in a red uniform is crouched behind home plate, ready to receive the pitch.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12528.7, "ram_available_mb": 50312.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12528.8, "ram_available_mb": 50312.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.038, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 6.895}, "timestamp": "2026-01-19T14:52:36.048406"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2740.118, "latencies_ms": [2740.118], "images_per_second": 0.365, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The baseball player is wearing a white and blue uniform. The lighting appears to be natural daylight, creating a bright and clear atmosphere on the field. The baseball is visible mid-flight, indicating a powerful swing. The overall setting suggests a sunny day at a baseball game.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12528.8, "ram_available_mb": 50312.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12528.1, "ram_available_mb": 50312.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.203, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 6.941}, "timestamp": "2026-01-19T14:52:40.831462"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1879.01, "latencies_ms": [1879.01], "images_per_second": 0.532, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A brown teddy bear with a red bow tie sits comfortably on a wicker chair with a dark red cushion, positioned against a striped curtain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12528.1, "ram_available_mb": 50312.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12528.3, "ram_available_mb": 50312.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.734, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.8}, "timestamp": "2026-01-19T14:52:44.750927"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2517.141, "latencies_ms": [2517.141], "images_per_second": 0.397, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "chair: 2\nteddy bear: 1\nwicker: 2\nred cushion: 1\nbow tie: 1\ncurtains: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12528.3, "ram_available_mb": 50312.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12528.0, "ram_available_mb": 50312.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.303, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.889}, "timestamp": "2026-01-19T14:52:49.291429"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2094.361, "latencies_ms": [2094.361], "images_per_second": 0.477, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The brown teddy bear is positioned in the foreground, slightly to the right of the wicker chair. The chair is situated in the background, partially obscured by the teddy bear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12528.0, "ram_available_mb": 50312.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12527.4, "ram_available_mb": 50313.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.153, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.937}, "timestamp": "2026-01-19T14:52:53.433465"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2180.623, "latencies_ms": [2180.623], "images_per_second": 0.459, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A brown teddy bear with a red bow sits on a wicker chair with a dark wooden backrest and armrests. A blue and white striped curtain is visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12527.4, "ram_available_mb": 50313.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12527.3, "ram_available_mb": 50313.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.133, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.927}, "timestamp": "2026-01-19T14:52:57.651625"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2037.805, "latencies_ms": [2037.805], "images_per_second": 0.491, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The chair features a combination of brown and red colors. The lighting appears to be soft and warm, creating a cozy atmosphere. The chair is made of wicker and has a plush cushion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12526.9, "ram_available_mb": 50314.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12526.5, "ram_available_mb": 50314.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.522, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T14:53:01.725091"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2066.691, "latencies_ms": [2066.691], "images_per_second": 0.484, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Two snowboarders, dressed in red jackets and helmets, stand on a snowy mountain peak, preparing to descend the slopes under a bright, sunny sky.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12526.5, "ram_available_mb": 50314.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12526.3, "ram_available_mb": 50314.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.314, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.47}, "timestamp": "2026-01-19T14:53:05.838021"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3105.193, "latencies_ms": [3105.193], "images_per_second": 0.322, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "person: 2\nsnowboard: 1\nhelmet: 1\ngloves: 1\nboots: 1\nsnow: 1\nmountain: 1\nrock: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12526.3, "ram_available_mb": 50314.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 12528.3, "ram_available_mb": 50312.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.807, "power_cpu_cv_mean_watts": 1.81, "power_sys_5v0_mean_watts": 6.761}, "timestamp": "2026-01-19T14:53:10.976244"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2094.937, "latencies_ms": [2094.937], "images_per_second": 0.477, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the snowy mountain range in the background. The man and woman are standing relatively close to the foreground, seemingly preparing to snowboard or ski down the mountain.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12528.3, "ram_available_mb": 50312.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12528.1, "ram_available_mb": 50312.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.402, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.498}, "timestamp": "2026-01-19T14:53:15.097480"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2256.408, "latencies_ms": [2256.408], "images_per_second": 0.443, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two snowboarders are standing on a snow-covered mountain peak, enjoying the bright sunlight and breathtaking mountain views. They are likely preparing for a snowboarding adventure or taking a break from their descent.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12528.1, "ram_available_mb": 50312.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.393, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.552}, "timestamp": "2026-01-19T14:53:19.417097"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2338.045, "latencies_ms": [2338.045], "images_per_second": 0.428, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The snowboarders are wearing bright red jackets. The sun is shining brightly, creating a lens flare effect. The snowboard is black and appears to be made of metal. The weather is sunny and clear.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.236, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.501}, "timestamp": "2026-01-19T14:53:23.766870"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1805.511, "latencies_ms": [1805.511], "images_per_second": 0.554, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A cluster of ripe, red apples hangs from a tree branch, surrounded by green leaves and partially obscured by a textured brown tree trunk.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12526.5, "ram_available_mb": 50314.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.88, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T14:53:27.608058"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2214.208, "latencies_ms": [2214.208], "images_per_second": 0.452, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "apples: 5\ntree: 1\nleaves: 4\nbranches: 6\nfruit: 5\nhole: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12526.5, "ram_available_mb": 50314.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12525.9, "ram_available_mb": 50315.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.866, "power_cpu_cv_mean_watts": 1.29, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T14:53:31.862731"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1866.579, "latencies_ms": [1866.579], "images_per_second": 0.536, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The apples are positioned in the foreground, slightly to the left of the viewer. The background is blurred, drawing focus to the apples and the tree trunk.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12525.9, "ram_available_mb": 50315.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.078, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.874}, "timestamp": "2026-01-19T14:53:35.772506"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2303.756, "latencies_ms": [2303.756], "images_per_second": 0.434, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The scene depicts an apple tree with ripe, red apples hanging from its branches. The background features a blurred view of other trees and foliage, suggesting an outdoor setting, possibly in a garden or orchard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.949, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T14:53:40.103085"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2613.387, "latencies_ms": [2613.387], "images_per_second": 0.383, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The apples are predominantly red, contrasting with the brown and gray tones of the tree bark and leaves. The lighting suggests an outdoor setting, possibly during late afternoon or early evening. The apples appear to be ripe and ready for picking.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.577, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T14:53:44.753137"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1707.4, "latencies_ms": [1707.4], "images_per_second": 0.586, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Two chefs are working diligently in a commercial kitchen, preparing food using various cooking utensils and equipment.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.301, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.815}, "timestamp": "2026-01-19T14:53:48.496115"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2931.923, "latencies_ms": [2931.923], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "kitchen: 3\nstove: 2\noven: 1\ntongs: 2\nplates: 2\ncontainers: 2\nshelves: 2\nplates: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12526.0, "ram_available_mb": 50314.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.174, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.081}, "timestamp": "2026-01-19T14:53:53.465801"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2299.321, "latencies_ms": [2299.321], "images_per_second": 0.435, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective in the image. The foreground features the chef preparing food, while the background showcases the kitchen's layout with various utensils and equipment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12526.0, "ram_available_mb": 50314.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.911, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.871}, "timestamp": "2026-01-19T14:53:57.777835"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2952.318, "latencies_ms": [2952.318], "images_per_second": 0.339, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts a busy commercial kitchen where two chefs are actively working, preparing food. The kitchen is equipped with various cooking equipment, including a large grill, pots, and pans. The chefs are wearing white shirts and appear to be focused on their tasks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.908, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T14:54:02.758459"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2678.118, "latencies_ms": [2678.118], "images_per_second": 0.373, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The kitchen is brightly lit with yellow fluorescent lights, creating a warm and inviting atmosphere. The stainless steel surfaces and utensils suggest a modern and efficient design. The overall appearance is clean and organized, reflecting a well-maintained professional kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.567, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.092}, "timestamp": "2026-01-19T14:54:07.479036"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1639.574, "latencies_ms": [1639.574], "images_per_second": 0.61, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A group of motorcyclists has gathered on the side of a road, sitting and standing near their parked motorcycles.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12525.8, "ram_available_mb": 50315.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12525.3, "ram_available_mb": 50315.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.18, "power_cpu_cv_mean_watts": 1.235, "power_sys_5v0_mean_watts": 6.165}, "timestamp": "2026-01-19T14:54:11.152495"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2697.789, "latencies_ms": [2697.789], "images_per_second": 0.371, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "motorcycle: 8\nbike: 8\nhelmet: 2\nperson: 4\nroad: 8\nsky: 8\nclouds: 8\nflag: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12525.3, "ram_available_mb": 50315.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12524.6, "ram_available_mb": 50316.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.633, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T14:54:15.888281"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2254.964, "latencies_ms": [2254.964], "images_per_second": 0.443, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The main objects are positioned primarily on the right side of the image, extending into the background. The foreground features several motorcycles parked on the side of the road, while a pickup truck is parked further back on the right side.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12524.6, "ram_available_mb": 50316.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12524.5, "ram_available_mb": 50316.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.503, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.574}, "timestamp": "2026-01-19T14:54:20.209293"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2920.032, "latencies_ms": [2920.032], "images_per_second": 0.342, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "A group of motorcyclists is gathered on a roadside near a body of water, enjoying a ride together.  They are parked alongside a paved road, with some motorcycles parked on the shoulder and others closer to the water's edge. The sky is overcast, creating a somewhat dramatic backdrop for the scene.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12524.5, "ram_available_mb": 50316.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12524.5, "ram_available_mb": 50316.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.932, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 6.812}, "timestamp": "2026-01-19T14:54:25.151830"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2297.5, "latencies_ms": [2297.5], "images_per_second": 0.435, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The sky is cloudy and gray, creating a muted atmosphere. The motorcycles are parked in a somewhat haphazard manner, showcasing a variety of colors and styles. The setting appears to be outdoors on a cloudy day.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12524.5, "ram_available_mb": 50316.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12525.0, "ram_available_mb": 50315.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.614, "power_cpu_cv_mean_watts": 1.646, "power_sys_5v0_mean_watts": 6.681}, "timestamp": "2026-01-19T14:54:29.483410"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1980.615, "latencies_ms": [1980.615], "images_per_second": 0.505, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A small, single-engine propeller plane with registration number G-RVMZ is captured in mid-flight, leaving a trail of smoke behind it.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12524.8, "ram_available_mb": 50316.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12524.1, "ram_available_mb": 50316.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.273, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.741}, "timestamp": "2026-01-19T14:54:33.522899"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2305.08, "latencies_ms": [2305.08], "images_per_second": 0.434, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "plane: 1\nclouds: 2\nsmoke: 1\nperson: 1\nwings: 2\npropeller: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12524.1, "ram_available_mb": 50316.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12523.4, "ram_available_mb": 50317.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.022, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T14:54:37.872259"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2085.996, "latencies_ms": [2085.996], "images_per_second": 0.479, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The small propeller plane is positioned in the foreground, moving from left to right across the image. The vast sky and clouds form the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12523.4, "ram_available_mb": 50317.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.962, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T14:54:41.984808"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2375.403, "latencies_ms": [2375.403], "images_per_second": 0.421, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "A small, single-engine propeller plane is captured in mid-flight, moving from left to right across a cloudy sky. The image is in sepia tones, giving it a vintage or timeless feel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.61, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T14:54:46.397943"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2152.335, "latencies_ms": [2152.335], "images_per_second": 0.465, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The plane is primarily white with black accents. The sky is cloudy, with varying shades of gray. The image appears to be taken in sepia tones, giving it a vintage feel.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.175, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T14:54:50.591930"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1891.421, "latencies_ms": [1891.421], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A group of four sheep, including two adult sheep and two younger ones, are standing on a grassy hill overlooking a serene blue lake surrounded by majestic mountains.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.489, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T14:54:54.520503"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2305.618, "latencies_ms": [2305.618], "images_per_second": 0.434, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "mountains: 5\nwater: 1\nsheep: 4\nrocks: 6\ngrass: 6\nsky: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12523.5, "ram_available_mb": 50317.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.715, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.87}, "timestamp": "2026-01-19T14:54:58.862013"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1798.532, "latencies_ms": [1798.532], "images_per_second": 0.556, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the mountains and lake in the background. The sheep are situated near the edge of the foreground, closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12523.5, "ram_available_mb": 50317.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12523.8, "ram_available_mb": 50317.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.994, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.782}, "timestamp": "2026-01-19T14:55:02.716957"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1947.902, "latencies_ms": [1947.902], "images_per_second": 0.513, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A group of sheep is grazing on a grassy hillside overlooking a turquoise lake. The landscape features rolling hills and mountains, creating a picturesque and serene setting.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12523.8, "ram_available_mb": 50317.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12523.9, "ram_available_mb": 50316.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.864, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T14:55:06.704070"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2173.343, "latencies_ms": [2173.343], "images_per_second": 0.46, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The mountains are predominantly brown and appear dry. The sky is clear and blue, suggesting a sunny day. The scene is peaceful and picturesque, with sheep grazing on the grassy hillside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.41, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.943}, "timestamp": "2026-01-19T14:55:10.895944"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1333.257, "latencies_ms": [1333.257], "images_per_second": 0.75, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A woman in a wheelchair is preparing to serve a tennis ball during a game.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.184, "power_cpu_cv_mean_watts": 0.841, "power_sys_5v0_mean_watts": 6.622}, "timestamp": "2026-01-19T14:55:14.296308"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2850.784, "latencies_ms": [2850.784], "images_per_second": 0.351, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "woman: 2\ntennis racket: 1\nwheelchair: 2\nbasketball hoop: 1\nball: 1\nshorts: 1\nshirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.916, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 6.959}, "timestamp": "2026-01-19T14:55:19.179520"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2445.51, "latencies_ms": [2445.51], "images_per_second": 0.409, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The woman is positioned in the foreground of the image, holding a tennis racket and facing the camera. The background includes another woman in a wheelchair, suggesting they are playing tennis together. The foreground and background are relatively close together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12521.1, "ram_available_mb": 50319.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.662, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.97}, "timestamp": "2026-01-19T14:55:23.638667"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2124.398, "latencies_ms": [2124.398], "images_per_second": 0.471, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two women are playing wheelchair tennis in a gymnasium. One woman is seated in a wheelchair holding a tennis racket, while the other woman is standing and watching.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 12521.1, "ram_available_mb": 50319.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12520.1, "ram_available_mb": 50320.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.103, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.777}, "timestamp": "2026-01-19T14:55:27.796394"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2036.758, "latencies_ms": [2036.758], "images_per_second": 0.491, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The woman is wearing a gray t-shirt. The tennis racket she's holding is black and red. The setting appears to be a gymnasium with natural lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.1, "ram_available_mb": 50320.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12520.1, "ram_available_mb": 50320.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.421, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.835}, "timestamp": "2026-01-19T14:55:31.869746"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1919.099, "latencies_ms": [1919.099], "images_per_second": 0.521, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A young girl, dressed in a pink plaid shirt and blue jeans, sits confidently on a brown leather saddle atop a horse wearing a purple blanket.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12520.1, "ram_available_mb": 50320.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12520.4, "ram_available_mb": 50320.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.916, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.894}, "timestamp": "2026-01-19T14:55:35.845482"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3185.462, "latencies_ms": [3185.462], "images_per_second": 0.314, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "helmet: 1\npony saddle: 1\nsaddle: 1\nboot: 1\njewelry: 1\njeans: 1\nshirt: 1\nbracelet: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.4, "ram_available_mb": 50320.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.206, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 7.102}, "timestamp": "2026-01-19T14:55:41.040888"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2148.071, "latencies_ms": [2148.071], "images_per_second": 0.466, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The child is positioned near the center of the image, sitting on the saddle and facing the left side of the image. The horse and saddle are in the foreground, while the background consists of trees and greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.266, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T14:55:45.231506"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1920.506, "latencies_ms": [1920.506], "images_per_second": 0.521, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A young child is sitting on a horse's saddle, wearing a helmet and pink plaid shirt. The setting appears to be a wooded area with a purple saddle blanket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12520.9, "ram_available_mb": 50320.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.773, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T14:55:49.179969"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2232.988, "latencies_ms": [2232.988], "images_per_second": 0.448, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The child is wearing a pink and white plaid shirt and blue jeans. The child is sitting on a brown leather saddle. The saddle is on a purple blanket. The child is wearing brown boots.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.9, "ram_available_mb": 50320.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12520.9, "ram_available_mb": 50320.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.155, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T14:55:53.452298"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1614.1, "latencies_ms": [1614.1], "images_per_second": 0.62, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Three surfers in wetsuits ride waves in the deep blue ocean of Raglan, New Zealand.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.9, "ram_available_mb": 50320.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.246, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.165}, "timestamp": "2026-01-19T14:55:57.092259"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2212.524, "latencies_ms": [2212.524], "images_per_second": 0.452, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "waves: 2\nsurfers: 3\nsurfboards: 2\nwater: 1\nsky: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.52, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.599}, "timestamp": "2026-01-19T14:56:01.332937"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1657.465, "latencies_ms": [1657.465], "images_per_second": 0.603, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the ocean extending behind them. Surfers can be seen in the background, further away from the main focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.275, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 6.311}, "timestamp": "2026-01-19T14:56:05.009255"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2529.592, "latencies_ms": [2529.592], "images_per_second": 0.395, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "Two surfers are riding waves in the ocean, wearing wetsuits and skillfully maneuvering their surfboards. The scene is set in Raglan, New Zealand, showcasing the sport's popularity in this coastal location.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.615, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 6.673}, "timestamp": "2026-01-19T14:56:09.564399"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2144.957, "latencies_ms": [2144.957], "images_per_second": 0.466, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The ocean is a deep blue color. The lighting suggests a sunny day with bright sunlight. The surfers are wearing wetsuits, indicating a potentially cold or chilly environment.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.284, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 6.427}, "timestamp": "2026-01-19T14:56:13.736639"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1278.484, "latencies_ms": [1278.484], "images_per_second": 0.782, "prompt_tokens": 8, "response_tokens_est": 14, "n_tiles": 1, "output_text": "A kitchen with an open window reveals a view of a building outside.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.223, "power_cpu_cv_mean_watts": 0.841, "power_sys_5v0_mean_watts": 6.582}, "timestamp": "2026-01-19T14:56:17.059368"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2765.809, "latencies_ms": [2765.809], "images_per_second": 0.362, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "window: 4\ncupboard: 2\nshelf: 2\npot: 1\nplant: 1\ntoaster: 1\noven: 1\ncounter: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.16, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.021}, "timestamp": "2026-01-19T14:56:21.872235"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1981.272, "latencies_ms": [1981.272], "images_per_second": 0.505, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The kitchen is positioned to the right of the window, extending from the foreground to the background. The window occupies a significant portion of the background, offering a view beyond the kitchen.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.901, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.797}, "timestamp": "2026-01-19T14:56:25.879256"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2861.792, "latencies_ms": [2861.792], "images_per_second": 0.349, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a cozy kitchen with warm lighting and a large window offering a view of the outside. The window is slightly open, revealing a glimpse of the outside world. Various kitchen items and appliances are visible, including a stove, cabinets, and small plants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.105, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 7.039}, "timestamp": "2026-01-19T14:56:30.767489"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2305.331, "latencies_ms": [2305.331], "images_per_second": 0.434, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The room is dimly lit, creating a warm and cozy atmosphere. The window is frosted, suggesting recent rain or mist. The wooden cabinets and appliances add a rustic charm to the space.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12521.1, "ram_available_mb": 50319.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.222, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.893}, "timestamp": "2026-01-19T14:56:35.099537"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1984.219, "latencies_ms": [1984.219], "images_per_second": 0.504, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A pineapple, oranges, incense sticks, and red cups are arranged on a table, symbolizing a traditional Chinese religious setting.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 12521.1, "ram_available_mb": 50319.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12521.6, "ram_available_mb": 50319.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.397, "power_cpu_cv_mean_watts": 1.176, "power_sys_5v0_mean_watts": 6.722}, "timestamp": "2026-01-19T14:56:39.146004"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2750.727, "latencies_ms": [2750.727], "images_per_second": 0.364, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "pineapple: 1\nred cups: 4\nincense sticks: 8\norange: 4\nred bowl: 1\nred plate: 1\nred background: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12521.6, "ram_available_mb": 50319.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.093, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.978}, "timestamp": "2026-01-19T14:56:43.928213"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2224.441, "latencies_ms": [2224.441], "images_per_second": 0.45, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The pineapple is positioned to the left of the incense sticks and oranges. The pineapple and oranges are placed in the foreground, while the incense sticks and container are situated in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.987, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.884}, "timestamp": "2026-01-19T14:56:48.169146"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2999.962, "latencies_ms": [2999.962], "images_per_second": 0.333, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The scene depicts a traditional Chinese altar or shrine. A pineapple, incense sticks, oranges, and small red cups are arranged on a red surface, possibly a table or shelf. The setting suggests a religious or cultural context, possibly a home altar or a temple.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.953, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.085}, "timestamp": "2026-01-19T14:56:53.200510"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2931.264, "latencies_ms": [2931.264], "images_per_second": 0.341, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene features a vibrant red background, contrasted by the green pineapple and the bright orange fruits. Red cups are arranged near the pineapple and oranges, suggesting offerings or refreshments. The lighting creates a warm and inviting atmosphere, enhancing the visual appeal of the items.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.97, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T14:56:58.157811"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1774.171, "latencies_ms": [1774.171], "images_per_second": 0.564, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A man is holding a plate with a sandwich, fries, and a small cup of sauce, smiling at the camera in a casual restaurant setting.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12521.8, "ram_available_mb": 50319.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12522.0, "ram_available_mb": 50318.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.079, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 6.789}, "timestamp": "2026-01-19T14:57:01.964990"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2897.843, "latencies_ms": [2897.843], "images_per_second": 0.345, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "man: 2\nfries: 1\ntostada: 1\nsauce: 1\nplate: 1\ntable: 1\nmenu: 1\nclock: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 12522.0, "ram_available_mb": 50318.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.819, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T14:57:06.924845"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2052.795, "latencies_ms": [2052.795], "images_per_second": 0.487, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The man is holding the plate of food in his right hand. The plate of food is in the foreground, while the background features other patrons and elements of a restaurant setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.346, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T14:57:11.015468"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1916.457, "latencies_ms": [1916.457], "images_per_second": 0.522, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A man is taking a selfie while holding a plate with a sandwich, fries, and a small cup of sauce. The setting appears to be a casual restaurant or diner.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 12523.9, "ram_available_mb": 50317.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.995, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T14:57:14.945100"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2498.576, "latencies_ms": [2498.576], "images_per_second": 0.4, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The man is wearing glasses and has a beard. The food on his plate includes golden-brown fries and a fried cheese ball. The lighting in the image is bright, likely from overhead lighting, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12523.9, "ram_available_mb": 50317.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12524.7, "ram_available_mb": 50316.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.601, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 6.965}, "timestamp": "2026-01-19T14:57:19.470617"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1656.911, "latencies_ms": [1656.911], "images_per_second": 0.604, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two individuals are walking on a wet sidewalk, holding umbrellas to shield themselves from the rain.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12524.7, "ram_available_mb": 50316.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12525.4, "ram_available_mb": 50315.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.114, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.621}, "timestamp": "2026-01-19T14:57:23.186216"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2627.355, "latencies_ms": [2627.355], "images_per_second": 0.381, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "building: 5\nmetal structure: 2\nbicycles: 3\nperson: 2\nperson with umbrella: 1\ngrass: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12525.4, "ram_available_mb": 50315.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12525.7, "ram_available_mb": 50315.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.497, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.988}, "timestamp": "2026-01-19T14:57:27.846678"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2975.348, "latencies_ms": [2975.348], "images_per_second": 0.336, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The main objects are positioned in a manner that creates a sense of depth and perspective. The foreground features the metal grate and bike rack, while the background includes other buildings and trees. The perspective suggests the viewer is looking out from behind a window, observing the scene from a distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.7, "ram_available_mb": 50315.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12525.7, "ram_available_mb": 50315.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.853, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T14:57:32.859999"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2541.765, "latencies_ms": [2541.765], "images_per_second": 0.393, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene depicts a modern, gray building complex on a rainy day. Two individuals are walking on the wet pavement while holding umbrellas.  Bicycles are parked near a metal railing in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.7, "ram_available_mb": 50315.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12526.4, "ram_available_mb": 50314.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.268, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.935}, "timestamp": "2026-01-19T14:57:37.430276"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2111.847, "latencies_ms": [2111.847], "images_per_second": 0.474, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The building exterior is primarily gray, with some sections appearing lighter in color. The scene is illuminated by natural light, suggesting an overcast or rainy day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12526.4, "ram_available_mb": 50314.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.08, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.824}, "timestamp": "2026-01-19T14:57:41.569791"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1786.771, "latencies_ms": [1786.771], "images_per_second": 0.56, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A generous amount of creamy white mayonnaise is spread across a piece of bread, accompanied by a fork and knife on the side.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.879, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.666}, "timestamp": "2026-01-19T14:57:45.403372"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1902.821, "latencies_ms": [1902.821], "images_per_second": 0.526, "prompt_tokens": 21, "response_tokens_est": 17, "n_tiles": 1, "output_text": "fork: 3\nknife: 1\nbread: 1\nmayonnaise: 8", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.355, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 6.706}, "timestamp": "2026-01-19T14:57:49.324391"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2221.782, "latencies_ms": [2221.782], "images_per_second": 0.45, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The left foreground is dominated by the creamy substance, likely mayonnaise. The background is blurred, drawing focus to the foreground object. The object is positioned near the center of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12526.3, "ram_available_mb": 50314.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.911, "power_cpu_cv_mean_watts": 1.268, "power_sys_5v0_mean_watts": 6.803}, "timestamp": "2026-01-19T14:57:53.573906"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1945.202, "latencies_ms": [1945.202], "images_per_second": 0.514, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The scene is set on a plate with a fork and knife nearby. The focus is on a generous amount of mayonnaise spread on a piece of bread.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12526.3, "ram_available_mb": 50314.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12525.2, "ram_available_mb": 50315.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.048, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.721}, "timestamp": "2026-01-19T14:57:57.567649"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2889.866, "latencies_ms": [2889.866], "images_per_second": 0.346, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The mayonnaise is a pale yellow color. The lighting in the image is soft and diffused, creating a gentle glow on the food. The mayonnaise appears to be made of a smooth, creamy texture, possibly from a dairy product like mayonnaise or sour cream.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.2, "ram_available_mb": 50315.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.104, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T14:58:02.505202"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1889.096, "latencies_ms": [1889.096], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A silver laptop with a green leaf background is open on a white desk, accompanied by a black mouse, a keyboard, and a mousepad with a red design.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.435, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.726}, "timestamp": "2026-01-19T14:58:06.448608"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3027.657, "latencies_ms": [3027.657], "images_per_second": 0.33, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "laptop: 1\nkeyboard: 1\nmouse: 1\nmousepad: 1\nspeaker: 1\nmonitor: 2\ncord: 2\nbottle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12526.2, "ram_available_mb": 50314.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12525.5, "ram_available_mb": 50315.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.005, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T14:58:11.514543"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2372.942, "latencies_ms": [2372.942], "images_per_second": 0.421, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively close-packed arrangement, with the laptop and monitor being the most prominent in the foreground. The mouse and keyboard are placed further back, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.5, "ram_available_mb": 50315.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12525.2, "ram_available_mb": 50315.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.821, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T14:58:15.922971"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2393.354, "latencies_ms": [2393.354], "images_per_second": 0.418, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a workspace with a laptop displaying a green leaf background, a desktop computer monitor, a keyboard, a mouse, and a speaker. The laptop is open and positioned on a desk with a window nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12525.2, "ram_available_mb": 50315.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12525.4, "ram_available_mb": 50315.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.137, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T14:58:20.327703"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2408.863, "latencies_ms": [2408.863], "images_per_second": 0.415, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The laptop is silver and has a green leaf-themed screen. The desk is white and appears to be made of wood or laminate. The lighting is bright, likely from natural light coming in through a window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12525.4, "ram_available_mb": 50315.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.697, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.918}, "timestamp": "2026-01-19T14:58:24.779393"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1375.288, "latencies_ms": [1375.288], "images_per_second": 0.727, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A young girl is sitting on a bed in a cozy bedroom, playing with toys.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.082, "power_cpu_cv_mean_watts": 0.947, "power_sys_5v0_mean_watts": 6.643}, "timestamp": "2026-01-19T14:58:28.203541"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2810.125, "latencies_ms": [2810.125], "images_per_second": 0.356, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bed: 2\npillows: 2\nnightstand: 1\nlamp: 1\ntoys: 2\ntable: 1\nchair: 1\nfloor: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.352, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.003}, "timestamp": "2026-01-19T14:58:33.032478"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1768.97, "latencies_ms": [1768.97], "images_per_second": 0.565, "prompt_tokens": 25, "response_tokens_est": 28, "n_tiles": 1, "output_text": "The bed occupies the foreground, while the girl is seated on the bed in the background. The table and lamp are positioned near the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.794, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 6.724}, "timestamp": "2026-01-19T14:58:36.827135"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2286.575, "latencies_ms": [2286.575], "images_per_second": 0.437, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A young girl is sitting on a bed in a room with orange walls. The room has a simple decor, featuring a bed, a nightstand, and a small table with a lamp. Various toys are scattered around the room.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.864, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T14:58:41.158092"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2241.308, "latencies_ms": [2241.308], "images_per_second": 0.446, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The room features warm orange walls and warm lighting, creating a cozy atmosphere. The bed is adorned with a brown and red patterned bedspread, and there are toys scattered around, suggesting recent play.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.176, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.871}, "timestamp": "2026-01-19T14:58:45.432349"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2157.055, "latencies_ms": [2157.055], "images_per_second": 0.464, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A batter in a red uniform is poised to swing at a pitch, while a catcher in black and an umpire in blue stand ready behind him.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.956, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.826}, "timestamp": "2026-01-19T14:58:49.652650"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3164.253, "latencies_ms": [3164.253], "images_per_second": 0.316, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "batter: 1\ncatcher: 1\numpire: 1\nbaseball bat: 1\nbaseball glove: 1\nbaseball field: 1\nbase: 1\nhome plate: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.82, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 7.087}, "timestamp": "2026-01-19T14:58:54.846022"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2019.977, "latencies_ms": [2019.977], "images_per_second": 0.495, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The batter is positioned to the left of the catcher, close to the foreground. The umpire is situated to the right of the catcher, further back in the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12524.7, "ram_available_mb": 50316.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.499, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 6.911}, "timestamp": "2026-01-19T14:58:58.906441"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2345.292, "latencies_ms": [2345.292], "images_per_second": 0.426, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A baseball game is in progress on a sunny day. A batter in a red uniform is swinging at a pitch, while a catcher in gray and an umpire in black observe the play.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12524.7, "ram_available_mb": 50316.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12524.3, "ram_available_mb": 50316.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.905, "power_cpu_cv_mean_watts": 1.475, "power_sys_5v0_mean_watts": 6.971}, "timestamp": "2026-01-19T14:59:03.310940"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2721.273, "latencies_ms": [2721.273], "images_per_second": 0.367, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The baseball game is played under bright sunlight, creating a vibrant and energetic atmosphere. The field is well-maintained and appears to be made of dirt or clay. The players' uniforms are predominantly red and white, contrasting with the green grass of the outfield.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12524.3, "ram_available_mb": 50316.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.912, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.074}, "timestamp": "2026-01-19T14:59:08.073631"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1282.725, "latencies_ms": [1282.725], "images_per_second": 0.78, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "A white and brown cat is eating a dead small bird on a concrete surface.", "error": null, "sys_before": {"cpu_percent": 8.7, "ram_used_mb": 12524.4, "ram_available_mb": 50316.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12523.8, "ram_available_mb": 50317.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.334, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 5.977}, "timestamp": "2026-01-19T14:59:11.406786"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2388.542, "latencies_ms": [2388.542], "images_per_second": 0.419, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "cat: 1\nbird: 1\nfeather: 1\ntape: 1\nground: 1\nnet: 1\nleaves: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12523.8, "ram_available_mb": 50317.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.425, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.61}, "timestamp": "2026-01-19T14:59:15.837506"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1892.325, "latencies_ms": [1892.325], "images_per_second": 0.528, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the bird. The bird is lying on the ground near the cat. The cat is situated in the background, partially obscured by the bird.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12523.3, "ram_available_mb": 50317.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12523.4, "ram_available_mb": 50317.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.481, "power_cpu_cv_mean_watts": 1.495, "power_sys_5v0_mean_watts": 6.451}, "timestamp": "2026-01-19T14:59:19.753750"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1657.296, "latencies_ms": [1657.296], "images_per_second": 0.603, "prompt_tokens": 19, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A white and gray cat is eating a small bird on a concrete surface. The bird is positioned near the cat's paws.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12523.4, "ram_available_mb": 50317.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12523.1, "ram_available_mb": 50317.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.998, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 6.203}, "timestamp": "2026-01-19T14:59:23.425022"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2157.866, "latencies_ms": [2157.866], "images_per_second": 0.463, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The cat's fur is predominantly white and gray. The lighting suggests a sunny outdoor setting. The cat is eating a dead bird, which appears to be brown and gray in color.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12523.1, "ram_available_mb": 50317.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12523.6, "ram_available_mb": 50317.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.392, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.507}, "timestamp": "2026-01-19T14:59:27.631623"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2038.213, "latencies_ms": [2038.213], "images_per_second": 0.491, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A hand holds a freshly made sandwich with slices of tomato, fresh spinach, and a creamy white substance, possibly mozzarella, on a white plate.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12523.6, "ram_available_mb": 50317.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12523.0, "ram_available_mb": 50317.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.397, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 6.829}, "timestamp": "2026-01-19T14:59:31.699658"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2791.003, "latencies_ms": [2791.003], "images_per_second": 0.358, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "tomato: 1\nbasil: 1\nmozzarella: 1\nbread: 2\nmayonnaise: 1\ncheese: 1\ngreen: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12523.0, "ram_available_mb": 50317.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12522.9, "ram_available_mb": 50318.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.124, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.038}, "timestamp": "2026-01-19T14:59:36.527812"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2150.176, "latencies_ms": [2150.176], "images_per_second": 0.465, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The hand is holding the sandwich in the foreground, while the background features a stove and possibly a cutting board. The sandwich is positioned near the stove, suggesting it is being prepared or consumed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.9, "ram_available_mb": 50318.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.269, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.884}, "timestamp": "2026-01-19T14:59:40.692908"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1926.953, "latencies_ms": [1926.953], "images_per_second": 0.519, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A hand is holding a sandwich with tomato, basil, and cheese on a white cutting board. The sandwich is being prepared or eaten in a kitchen setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.733, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.847}, "timestamp": "2026-01-19T14:59:44.633097"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2469.877, "latencies_ms": [2469.877], "images_per_second": 0.405, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The sandwich features a vibrant mix of colors: the red tomato, green basil, and white cheese contrast beautifully against the light-colored bread. The lighting is soft and somewhat dim, enhancing the visual appeal of the ingredients.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.741, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T14:59:49.141004"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1531.103, "latencies_ms": [1531.103], "images_per_second": 0.653, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "Two young girls are sitting on the edge of a boat, enjoying the blue ocean and wearing hats.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.281, "power_cpu_cv_mean_watts": 1.168, "power_sys_5v0_mean_watts": 6.224}, "timestamp": "2026-01-19T14:59:52.724245"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2957.141, "latencies_ms": [2957.141], "images_per_second": 0.338, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Hat: 1\nJeans: 2\nShirt: 1\nPants: 1\nLife preserver: 1\nRope: 2\nBoat: 1\nWater: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.531, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 6.829}, "timestamp": "2026-01-19T14:59:57.735694"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2204.558, "latencies_ms": [2204.558], "images_per_second": 0.454, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned close together on the boat, with the woman on the left leaning over the railing and the girl on the right sitting further back. The boat is situated in the background, and the water extends to the horizon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.615, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.557}, "timestamp": "2026-01-19T15:00:01.971858"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2402.399, "latencies_ms": [2402.399], "images_per_second": 0.416, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Two young girls are sitting on the edge of a white boat, enjoying the blue ocean. They are wearing casual summer clothing and hats. The scene suggests a leisurely boat ride or outing on the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12521.9, "ram_available_mb": 50319.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.414, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.622}, "timestamp": "2026-01-19T15:00:06.415156"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1933.74, "latencies_ms": [1933.74], "images_per_second": 0.517, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The boat is primarily white, contrasting with the deep blue of the ocean. The lighting suggests a sunny day, and the materials appear to be sturdy rope and fabric.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.9, "ram_available_mb": 50319.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12522.1, "ram_available_mb": 50318.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.963, "power_cpu_cv_mean_watts": 1.377, "power_sys_5v0_mean_watts": 6.363}, "timestamp": "2026-01-19T15:00:10.375175"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1451.727, "latencies_ms": [1451.727], "images_per_second": 0.689, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A white sheep with pink ears stands on a grassy hill, gazing directly at the camera.", "error": null, "sys_before": {"cpu_percent": 9.7, "ram_used_mb": 12522.1, "ram_available_mb": 50318.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.968, "power_cpu_cv_mean_watts": 0.946, "power_sys_5v0_mean_watts": 6.671}, "timestamp": "2026-01-19T15:00:13.887762"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2555.088, "latencies_ms": [2555.088], "images_per_second": 0.391, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "Sheep: 1\nStone wall: 2\nGrass: 2\nGround: 2\nBushes: 2\nYellow lichen: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.5, "ram_available_mb": 50318.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.621, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T15:00:18.473750"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2324.059, "latencies_ms": [2324.059], "images_per_second": 0.43, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The main object, a white sheep, stands in the foreground, positioned slightly to the right of the viewer. The sheep is situated near a stone wall, which extends into the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12521.9, "ram_available_mb": 50319.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.832}, "timestamp": "2026-01-19T15:00:22.824147"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1721.774, "latencies_ms": [1721.774], "images_per_second": 0.581, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A white sheep stands in a grassy field, facing the camera. A stone wall with yellow lichen is visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.9, "ram_available_mb": 50319.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.27, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T15:00:26.561384"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2496.891, "latencies_ms": [2496.891], "images_per_second": 0.4, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The sheep is predominantly white. Its wool appears soft and fluffy. The lighting suggests a sunny day, with bright sunlight illuminating the scene. The sheep is standing on a grassy area, which appears to be well-maintained.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.761, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.97}, "timestamp": "2026-01-19T15:00:31.105553"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1440.292, "latencies_ms": [1440.292], "images_per_second": 0.694, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "Two men are loading a large black pipe onto a truck in a parking lot.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.115, "power_cpu_cv_mean_watts": 0.91, "power_sys_5v0_mean_watts": 6.607}, "timestamp": "2026-01-19T15:00:34.591213"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2990.273, "latencies_ms": [2990.273], "images_per_second": 0.334, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Pipe: 2\nCooler: 2\nTruck: 1\nMan: 1\nTrees: 2\nBuilding: 1\nCargo: 1\nShipping container: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.845, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.015}, "timestamp": "2026-01-19T15:00:39.629013"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2103.319, "latencies_ms": [2103.319], "images_per_second": 0.475, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the truck transporting them further back. The truck is parked in a parking lot, indicating a relatively close proximity between the objects and the viewer.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.293, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.89}, "timestamp": "2026-01-19T15:00:43.764662"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2158.769, "latencies_ms": [2158.769], "images_per_second": 0.463, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Two men are loading a large pipe onto a flatbed truck in a parking lot. The truck is carrying several gray cases and has a yellow platform underneath the pipe.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.3, "ram_available_mb": 50319.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.292, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.895}, "timestamp": "2026-01-19T15:00:47.963936"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2153.899, "latencies_ms": [2153.899], "images_per_second": 0.464, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The truck is primarily black and yellow. The lighting appears to be natural daylight. The materials include black pipes, gray plastic cases, and yellow supports. The weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.221, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.788}, "timestamp": "2026-01-19T15:00:52.132503"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1729.66, "latencies_ms": [1729.66], "images_per_second": 0.578, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Three giraffes walk along a dirt path near a pond in a lush, wooded area, accompanied by a resting deer.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.882, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.695}, "timestamp": "2026-01-19T15:00:55.890502"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2697.065, "latencies_ms": [2697.065], "images_per_second": 0.371, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "giraffe: 3\ntree: 2\npond: 1\nrocks: 1\ndeer: 1\nfence: 1\npath: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.221, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.996}, "timestamp": "2026-01-19T15:01:00.634358"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2063.778, "latencies_ms": [2063.778], "images_per_second": 0.485, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The giraffes are positioned in the foreground, moving towards the left side of the image. The pond and rocks are located in the background, providing a natural setting for the animals.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12520.1, "ram_available_mb": 50320.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.622, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.879}, "timestamp": "2026-01-19T15:01:04.735093"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2496.03, "latencies_ms": [2496.03], "images_per_second": 0.401, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Three giraffes are walking along a dirt path near a pond in a wooded area. A deer is resting nearby, observing the giraffes. The scene suggests a zoo or wildlife park environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.1, "ram_available_mb": 50320.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.781, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.985}, "timestamp": "2026-01-19T15:01:09.288400"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2647.812, "latencies_ms": [2647.812], "images_per_second": 0.378, "prompt_tokens": 18, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The giraffes have distinctive brown and white patterns. The lighting appears to be natural, possibly overcast, creating a soft, diffused effect. The giraffes are walking on a dirt path near a body of water, which reflects the surrounding greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.348, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.01}, "timestamp": "2026-01-19T15:01:13.979333"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2038.068, "latencies_ms": [2038.068], "images_per_second": 0.491, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A delicious pizza topped with mushrooms, artichokes, and ham is served on a white plate, accompanied by two glasses of beer, in a cozy restaurant setting.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12520.4, "ram_available_mb": 50320.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.498, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.873}, "timestamp": "2026-01-19T15:01:18.045836"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3119.913, "latencies_ms": [3119.913], "images_per_second": 0.321, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Pizza: 2\nWine glass: 2\nBeer glass: 1\nTablecloth: 2\nChairs: 2\nCutlery: 1\nBowl: 1\nPerson: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.4, "ram_available_mb": 50320.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.6, "ram_used_mb": 12520.3, "ram_available_mb": 50320.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.639, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 7.067}, "timestamp": "2026-01-19T15:01:23.206392"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1930.937, "latencies_ms": [1930.937], "images_per_second": 0.518, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the pizza and wine glass placed close together. The background features additional tables and chairs, suggesting a restaurant setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.3, "ram_available_mb": 50320.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.498, "power_cpu_cv_mean_watts": 1.226, "power_sys_5v0_mean_watts": 6.778}, "timestamp": "2026-01-19T15:01:27.170431"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2303.859, "latencies_ms": [2303.859], "images_per_second": 0.434, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene depicts a restaurant setting with a table set for a meal, featuring a pizza with various toppings and two glasses of beer. The restaurant appears well-stocked with wine bottles and has a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.022, "power_cpu_cv_mean_watts": 1.446, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:01:31.505092"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2876.691, "latencies_ms": [2876.691], "images_per_second": 0.348, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The pizza is topped with vibrant red sauce, creamy white cheese, and colorful vegetables like artichokes and mushrooms. The table setting includes blue tablecloths, wine glasses, and a beer glass. The lighting is warm and inviting, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.874, "power_cpu_cv_mean_watts": 1.586, "power_sys_5v0_mean_watts": 6.967}, "timestamp": "2026-01-19T15:01:36.416158"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1733.324, "latencies_ms": [1733.324], "images_per_second": 0.577, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A black cat with white paws is drinking water from a running faucet in a white sink, accompanied by a bottle of soap.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.539, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.666}, "timestamp": "2026-01-19T15:01:40.183043"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2789.072, "latencies_ms": [2789.072], "images_per_second": 0.359, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "sink: 2\nfaucet: 1\nbottle: 1\nsoap dispenser: 1\nbowl: 1\ncat: 1\nwater: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.003, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.946}, "timestamp": "2026-01-19T15:01:45.029693"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2128.808, "latencies_ms": [2128.808], "images_per_second": 0.47, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The black cat is positioned in the foreground, close to the water faucet and sink. The sink and faucet are situated in the background, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12521.5, "ram_available_mb": 50319.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.318, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.842}, "timestamp": "2026-01-19T15:01:49.191117"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1897.294, "latencies_ms": [1897.294], "images_per_second": 0.527, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A black cat is drinking water from a faucet in a bathroom sink. A bottle of soap and a small white dish are also present on the counter.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12521.5, "ram_available_mb": 50319.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12521.5, "ram_available_mb": 50319.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.677, "power_cpu_cv_mean_watts": 1.308, "power_sys_5v0_mean_watts": 6.948}, "timestamp": "2026-01-19T15:01:53.134124"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2590.973, "latencies_ms": [2590.973], "images_per_second": 0.386, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The sink is white and appears to be made of porcelain or ceramic. The lighting in the bathroom is soft and diffused, creating a calm atmosphere. The cat is drinking from the faucet, which appears to be chrome or stainless steel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.613, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:01:57.786804"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1655.849, "latencies_ms": [1655.849], "images_per_second": 0.604, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Two people are riding in a horse-drawn carriage through a muddy field, guided by a person holding a whip.", "error": null, "sys_before": {"cpu_percent": 5.7, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.639, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.66}, "timestamp": "2026-01-19T15:02:01.492737"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2897.185, "latencies_ms": [2897.185], "images_per_second": 0.345, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "carriage: 2\nhorse: 1\nperson: 2\nhelmet: 1\nfence: 1\npuddle: 1\nbuilding: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12519.5, "ram_available_mb": 50321.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.17, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 7.018}, "timestamp": "2026-01-19T15:02:06.407117"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2119.549, "latencies_ms": [2119.549], "images_per_second": 0.472, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The horse and carriage are positioned in the foreground, moving towards the background. The horses and carriage are situated in a muddy area, which suggests a rural or agricultural setting.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12519.5, "ram_available_mb": 50321.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.577, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.883}, "timestamp": "2026-01-19T15:02:10.558289"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2605.277, "latencies_ms": [2605.277], "images_per_second": 0.384, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "Two people are riding in a horse-drawn carriage through a muddy field. The carriage is pulled by a brown horse, and there are puddles reflecting the scene. In the background, a barn and trees are visible under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.69, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T15:02:15.184267"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2328.041, "latencies_ms": [2328.041], "images_per_second": 0.43, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The horse and carriage are brown, appearing to be made of wood. The scene is lit by natural sunlight, creating a warm, inviting atmosphere. The overall setting suggests a rural or agricultural setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.201, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:02:19.531489"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1791.405, "latencies_ms": [1791.405], "images_per_second": 0.558, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A newlywed couple stands under a black and white umbrella, smiling and holding each other's hands, dressed in formal wedding attire.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.822, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.738}, "timestamp": "2026-01-19T15:02:23.370478"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2846.465, "latencies_ms": [2846.465], "images_per_second": 0.351, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bride: 1\ngroom: 1\numbrella: 1\ndress: 1\nflowers: 1\ngrass: 1\nhouse: 1\npeople: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.951, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 6.968}, "timestamp": "2026-01-19T15:02:28.257369"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2126.152, "latencies_ms": [2126.152], "images_per_second": 0.47, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The bride is positioned to the left of the groom, standing in the foreground. The couple is standing near a house in the background. The foreground is primarily grass, while the background features a stone building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.177, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T15:02:32.443400"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2135.589, "latencies_ms": [2135.589], "images_per_second": 0.468, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A bride and groom are walking on a grassy area under a black and white umbrella, likely at an outdoor wedding ceremony. A stone building is visible in the background, and several guests are present in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.5, "ram_available_mb": 50320.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.892, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T15:02:36.616017"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2541.182, "latencies_ms": [2541.182], "images_per_second": 0.394, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The bride is wearing a white dress and holding a bouquet of orange and yellow flowers. The groom is wearing a dark suit and holding a black and white umbrella. The scene appears to be outdoors on a sunny day, with grass and a stone building in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12519.3, "ram_available_mb": 50321.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.764, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 7.0}, "timestamp": "2026-01-19T15:02:41.180187"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1643.225, "latencies_ms": [1643.225], "images_per_second": 0.609, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Two people are enjoying a day at the beach, one lying on the sand and the other sitting up playing with a colorful kite.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12519.3, "ram_available_mb": 50321.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.721, "power_cpu_cv_mean_watts": 1.14, "power_sys_5v0_mean_watts": 6.063}, "timestamp": "2026-01-19T15:02:44.897578"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2393.61, "latencies_ms": [2393.61], "images_per_second": 0.418, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "kite: 2\nperson: 2\nwatch: 1\nshorts: 1\nsand: 6\nocean: 2\nwaves: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.298, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.541}, "timestamp": "2026-01-19T15:02:49.311402"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1711.561, "latencies_ms": [1711.561], "images_per_second": 0.584, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The man is lying on the sand in the foreground, close to the water. The kite is positioned in the background, slightly to the right of the man.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.09, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.218}, "timestamp": "2026-01-19T15:02:53.039561"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2518.538, "latencies_ms": [2518.538], "images_per_second": 0.397, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene takes place on a sandy beach near the ocean, where two people are enjoying a kite-flying activity. One person is lying down on the sand, while another is crouched down, seemingly preparing to launch the kite.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.574, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 6.632}, "timestamp": "2026-01-19T15:02:57.597462"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1990.418, "latencies_ms": [1990.418], "images_per_second": 0.502, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The kite is multicolored with blue, red, and green ribbons. The lighting suggests a sunny day, and the sand appears to be dry and light brown.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12520.6, "ram_available_mb": 50320.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12520.7, "ram_available_mb": 50320.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.481, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.464}, "timestamp": "2026-01-19T15:03:01.601526"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1788.093, "latencies_ms": [1788.093], "images_per_second": 0.559, "prompt_tokens": 8, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The living room features a brown sofa, a red armchair, a black coffee table, a lamp, a television, and two windows with wooden shutters.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12520.7, "ram_available_mb": 50320.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.357, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.393}, "timestamp": "2026-01-19T15:03:05.454731"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2885.507, "latencies_ms": [2885.507], "images_per_second": 0.347, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "sofa: 2\nlamp: 5\ntable: 1\nchair: 1\nstools: 2\nwindow shutters: 2\ntelevision: 1\nfloor lamp: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.528, "power_cpu_cv_mean_watts": 1.793, "power_sys_5v0_mean_watts": 6.749}, "timestamp": "2026-01-19T15:03:10.375284"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1768.502, "latencies_ms": [1768.502], "images_per_second": 0.565, "prompt_tokens": 25, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The brown couch is positioned to the left of the image, occupying the foreground. The television is situated in the background, near the right edge of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12520.3, "ram_available_mb": 50320.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.157, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.35}, "timestamp": "2026-01-19T15:03:14.161518"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2149.016, "latencies_ms": [2149.016], "images_per_second": 0.465, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The living room features a cozy atmosphere with a brown sofa, red armchair, coffee table, and floor lamp. The room is lit by natural light from the windows, which have wooden shutters.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12520.3, "ram_available_mb": 50320.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.308, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 6.504}, "timestamp": "2026-01-19T15:03:18.350317"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2158.793, "latencies_ms": [2158.793], "images_per_second": 0.463, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The room features light beige walls and wooden shutters. The lighting is warm and inviting, illuminating the space. A brown sofa, red armchair, and black table provide seating options.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.591, "power_cpu_cv_mean_watts": 1.578, "power_sys_5v0_mean_watts": 6.587}, "timestamp": "2026-01-19T15:03:22.558885"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1467.575, "latencies_ms": [1467.575], "images_per_second": 0.681, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A man is enjoying a slice of cake while sitting in a park, surrounded by lush greenery.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12519.6, "ram_available_mb": 50321.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12519.8, "ram_available_mb": 50321.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.332, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.597}, "timestamp": "2026-01-19T15:03:26.062912"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2552.862, "latencies_ms": [2552.862], "images_per_second": 0.392, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "cake: 1\nspoon: 1\nplate: 1\nt-shirt: 1\ngrass: 1\ntrees: 2\nsky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.8, "ram_available_mb": 50321.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.746, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.993}, "timestamp": "2026-01-19T15:03:30.650443"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2310.695, "latencies_ms": [2310.695], "images_per_second": 0.433, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The man is positioned in the foreground, eating a piece of cake with a spoon. The cake is situated on the plate in front of him. The background consists of green trees and grass, creating a natural setting for the scene.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.968, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 6.912}, "timestamp": "2026-01-19T15:03:35.015899"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2066.911, "latencies_ms": [2066.911], "images_per_second": 0.484, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A man is enjoying a slice of cake outdoors in a park-like setting with green grass and trees. He's using a white plastic fork to eat the cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.749, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T15:03:39.110902"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2283.652, "latencies_ms": [2283.652], "images_per_second": 0.438, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The man is wearing a blue shirt. The cake is topped with white frosting and appears to have a raspberry or berry filling. The setting is outdoors with natural lighting filtering through the trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.712, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 7.033}, "timestamp": "2026-01-19T15:03:43.435888"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1515.545, "latencies_ms": [1515.545], "images_per_second": 0.66, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A man stands next to a brown donkey carrying a woven basket filled with various bags and luggage.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.322, "power_cpu_cv_mean_watts": 1.165, "power_sys_5v0_mean_watts": 6.139}, "timestamp": "2026-01-19T15:03:46.988082"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2484.123, "latencies_ms": [2484.123], "images_per_second": 0.403, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "donkey: 3\nbags: 2\nblanket: 2\nhiking boots: 1\nman: 1\nground: 1\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.394, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.658}, "timestamp": "2026-01-19T15:03:51.510194"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2143.533, "latencies_ms": [2143.533], "images_per_second": 0.467, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The man is standing to the left of the donkey. The donkey is positioned in the foreground, partially obscuring the man's face. The background consists of bare trees and a dirt path.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.12, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.516}, "timestamp": "2026-01-19T15:03:55.693363"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1800.781, "latencies_ms": [1800.781], "images_per_second": 0.555, "prompt_tokens": 19, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man stands next to a donkey carrying various bags and luggage. The scene takes place outdoors in a natural setting with trees and rocks.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.099, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.249}, "timestamp": "2026-01-19T15:03:59.550517"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1956.564, "latencies_ms": [1956.564], "images_per_second": 0.511, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The donkey is brown and has a woven basket on its back. The man is wearing purple and gray clothing. The scene is outdoors in natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.294, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 6.404}, "timestamp": "2026-01-19T15:04:03.522931"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1695.159, "latencies_ms": [1695.159], "images_per_second": 0.59, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A brightly lit blue bridge spans across a calm river at night, reflecting the vibrant lights and creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.566, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.11}, "timestamp": "2026-01-19T15:04:07.260273"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2364.6, "latencies_ms": [2364.6], "images_per_second": 0.423, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "bridge: 4\nriver: 2\nboat: 1\npeople: 6\nlights: 5\ntrees: 1\nroad: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.066, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.552}, "timestamp": "2026-01-19T15:04:11.677322"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2581.558, "latencies_ms": [2581.558], "images_per_second": 0.387, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The foreground features a paved walkway with people walking along it. In the background, the blue-lit bridge spans across the river, creating a striking contrast against the dark night sky. The bridge appears distant and elevated, emphasizing its presence in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.669, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 6.717}, "timestamp": "2026-01-19T15:04:16.298942"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2179.712, "latencies_ms": [2179.712], "images_per_second": 0.459, "prompt_tokens": 19, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The scene is set at night, featuring a brightly lit blue bridge spanning a river. A boat is docked at the riverbank, and several people are gathered on the walkway near the water's edge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.425, "power_cpu_cv_mean_watts": 1.578, "power_sys_5v0_mean_watts": 6.569}, "timestamp": "2026-01-19T15:04:20.499748"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2622.863, "latencies_ms": [2622.863], "images_per_second": 0.381, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The bridge is illuminated with vibrant blue lights, creating a striking contrast against the dark night sky. The water reflects the lights of the bridge, creating a mesmerizing pattern. The scene is lively, with people gathered on the walkway near the water's edge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.815, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 6.74}, "timestamp": "2026-01-19T15:04:25.154635"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1821.179, "latencies_ms": [1821.179], "images_per_second": 0.549, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A person's foot is visible, wearing a pink shoe with a bow on top, and paired with blue jeans, resting on a weathered wooden bench.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.329, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.35}, "timestamp": "2026-01-19T15:04:29.010819"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2302.146, "latencies_ms": [2302.146], "images_per_second": 0.434, "prompt_tokens": 21, "response_tokens_est": 25, "n_tiles": 1, "output_text": "shoe: 1\nbow: 1\npants: 1\nbench: 4\nwood: 4\npaint: 4", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.169, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 6.507}, "timestamp": "2026-01-19T15:04:33.343756"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2079.398, "latencies_ms": [2079.398], "images_per_second": 0.481, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The pink shoe is positioned in the foreground, close to the person's leg. The blue wooden surface forms the background, with the person's leg and shoe occupying the central and foreground areas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.285, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 6.492}, "timestamp": "2026-01-19T15:04:37.456606"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2086.423, "latencies_ms": [2086.423], "images_per_second": 0.479, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A person is sitting on worn wooden benches with peeling paint, wearing bright pink flats and blue jeans. The scene suggests a casual, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12516.5, "ram_available_mb": 50324.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.167, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.427}, "timestamp": "2026-01-19T15:04:41.563632"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1842.492, "latencies_ms": [1842.492], "images_per_second": 0.543, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The pink shoe stands out against the blue and green painted wooden surface. The lighting appears to be natural, possibly sunlight, giving the scene a vibrant feel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.5, "ram_available_mb": 50324.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.013, "power_cpu_cv_mean_watts": 1.259, "power_sys_5v0_mean_watts": 6.3}, "timestamp": "2026-01-19T15:04:45.421060"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1754.97, "latencies_ms": [1754.97], "images_per_second": 0.57, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A woman in a green sweater and purple pants is holding a knife and standing next to a young boy in a blue plaid shirt.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12516.3, "ram_available_mb": 50324.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.026, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.804}, "timestamp": "2026-01-19T15:04:49.207704"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2427.732, "latencies_ms": [2427.732], "images_per_second": 0.412, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "woman: 2\nknife: 1\ntable: 1\ncake: 1\ncup: 1\nboy: 1\nchair: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.506, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T15:04:53.694576"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2143.969, "latencies_ms": [2143.969], "images_per_second": 0.466, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, holding the knife. The boy stands in the background, slightly further away. The table occupies the foreground, with a cup and a cake placed on it.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.039, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.836}, "timestamp": "2026-01-19T15:04:57.864279"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1844.206, "latencies_ms": [1844.206], "images_per_second": 0.542, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A woman is holding a knife and appears to be preparing to cut a cake in a home setting. A young boy stands nearby, observing the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.023, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.868}, "timestamp": "2026-01-19T15:05:01.722176"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2825.123, "latencies_ms": [2825.123], "images_per_second": 0.354, "prompt_tokens": 18, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The room has a red wall and soft lighting, creating a warm and inviting atmosphere. The woman is wearing a green cardigan and patterned pants, while the boy is dressed in a blue plaid shirt. A cake is visible on the table, contributing to the festive ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.055, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.999}, "timestamp": "2026-01-19T15:05:06.607936"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1479.642, "latencies_ms": [1479.642], "images_per_second": 0.676, "prompt_tokens": 8, "response_tokens_est": 15, "n_tiles": 1, "output_text": "Two elephants stand side by side in an indoor arena, facing the camera.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.572, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.57}, "timestamp": "2026-01-19T15:05:10.135208"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3123.389, "latencies_ms": [3123.389], "images_per_second": 0.32, "prompt_tokens": 21, "response_tokens_est": 42, "n_tiles": 1, "output_text": "Elephant: 2\nCircus tent: 1\nBleachers: 5\nLighting equipment: 2\nPerson in red vest: 1\nPerson in black shirt: 1\nPerson in black pants: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.882, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 7.102}, "timestamp": "2026-01-19T15:05:15.281750"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2620.195, "latencies_ms": [2620.195], "images_per_second": 0.382, "prompt_tokens": 25, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The main objects are positioned relatively close to the camera, creating a sense of proximity and closeness. The elephant in the foreground is closer to the camera than the elephant in the background. The arena setting suggests a relatively wide space, further emphasizing the proximity of the elephants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.327, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:05:19.928860"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2155.478, "latencies_ms": [2155.478], "images_per_second": 0.464, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two elephants are performing in a circus ring. A person is assisting one of the elephants, possibly performing a routine or interacting with the animal. The setting is indoors, with bleachers in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.363, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.937}, "timestamp": "2026-01-19T15:05:24.115689"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2455.506, "latencies_ms": [2455.506], "images_per_second": 0.407, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The elephants are brown and gray in color. The lighting in the arena is bright and focused, illuminating the elephants and the surrounding space. The arena appears to be constructed of concrete and metal, with bleachers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.563, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 6.995}, "timestamp": "2026-01-19T15:05:28.611541"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2098.039, "latencies_ms": [2098.039], "images_per_second": 0.477, "prompt_tokens": 8, "response_tokens_est": 34, "n_tiles": 1, "output_text": "Three jockeys on horseback are galloping along the wet sand of a beach, their horses' hooves kicking up small waves as they race towards the horizon.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.458, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T15:05:32.750486"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2423.485, "latencies_ms": [2423.485], "images_per_second": 0.413, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "Horses: 3\nJockeys: 2\nBeach: 2\nSand: 2\nWater: 2\nSky: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.283, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T15:05:37.215393"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1848.584, "latencies_ms": [1848.584], "images_per_second": 0.541, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the horses running towards the background. The horses are relatively close to the viewer, while the background is further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.381, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 6.672}, "timestamp": "2026-01-19T15:05:41.118021"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2165.727, "latencies_ms": [2165.727], "images_per_second": 0.462, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "Two jockeys on horseback are galloping across a sandy beach, their horses kicking up sand as they race. The setting appears to be a coastal area with a calm ocean in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.174, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.83}, "timestamp": "2026-01-19T15:05:45.304138"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2413.72, "latencies_ms": [2413.72], "images_per_second": 0.414, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The horses and riders are wearing light-colored clothing. The scene is illuminated by soft, diffused light, likely from the overcast sky. The sandy beach and ocean suggest a coastal setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.48, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T15:05:49.757245"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1879.736, "latencies_ms": [1879.736], "images_per_second": 0.532, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young man in a black snowsuit and goggles is talking on his cellphone while standing in a snowy area surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.728, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.787}, "timestamp": "2026-01-19T15:05:53.681614"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3477.465, "latencies_ms": [3477.465], "images_per_second": 0.288, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "Goggles: 1\nJacket: 1\nT-shirt: 1\nSnowboard: 1\nPhone: 1\nPinstripe: 1\nBrooch: 1\nTrees: 1\nSnow: 1", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.288, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 7.063}, "timestamp": "2026-01-19T15:05:59.174231"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2562.065, "latencies_ms": [2562.065], "images_per_second": 0.39, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main object is a person wearing a winter jacket, standing in the foreground of the image. The background consists of snow and trees, indicating a snowy outdoor setting. The person appears to be engaged in a phone conversation, further emphasizing the foreground placement.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.422, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T15:06:03.764611"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2131.44, "latencies_ms": [2131.44], "images_per_second": 0.469, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A young man is outdoors in a snowy setting, wearing a black winter jacket and goggles. He is talking on a cell phone while standing amidst snow-covered ground and trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.482, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T15:06:07.951672"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1989.174, "latencies_ms": [1989.174], "images_per_second": 0.503, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The snow is white and appears to be relatively undisturbed. The lighting suggests a sunny day, and the materials appear to be typical winter clothing like snow pants and gloves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12518.3, "ram_available_mb": 50322.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.447, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.791}, "timestamp": "2026-01-19T15:06:11.978950"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1694.142, "latencies_ms": [1694.142], "images_per_second": 0.59, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A white and black dirt bike is parked next to a green tent in a grassy field, with trees and a sunset in the background.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12518.3, "ram_available_mb": 50322.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.084, "power_cpu_cv_mean_watts": 1.078, "power_sys_5v0_mean_watts": 6.722}, "timestamp": "2026-01-19T15:06:15.725207"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2578.719, "latencies_ms": [2578.719], "images_per_second": 0.388, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "tent: 1\nmotorcycle: 1\nbags: 2\ntires: 2\nsunset: 1\ntrees: 4\ngrass: 4", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.459, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T15:06:20.333989"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1894.152, "latencies_ms": [1894.152], "images_per_second": 0.528, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The green tent is positioned in the foreground, slightly to the left of the motorcycle. The motorcycle is situated in the background, closer to the center and slightly to the right.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.701, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.787}, "timestamp": "2026-01-19T15:06:24.286034"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2119.497, "latencies_ms": [2119.497], "images_per_second": 0.472, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The scene depicts a camping area in a wooded area during sunset. A green tent is set up next to a parked motorcycle, providing a peaceful and adventurous setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.893, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.771}, "timestamp": "2026-01-19T15:06:28.439060"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2398.741, "latencies_ms": [2398.741], "images_per_second": 0.417, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The tent is green, and the surrounding area is covered in dry grass. The lighting suggests it's either early morning or late evening. The materials appear to be canvas and possibly a metal frame for the motorcycle.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.779, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T15:06:32.855632"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1896.0, "latencies_ms": [1896.0], "images_per_second": 0.527, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A vintage steam locomotive numbered 66371 pulls passenger cars along a track, with people waiting on the platform and buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.574, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.793}, "timestamp": "2026-01-19T15:06:36.782873"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2742.19, "latencies_ms": [2742.19], "images_per_second": 0.365, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "steam locomotive: 1\ntrain carriages: 3\npeople: 3\nplatform: 1\nsign: 1\nbuildings: 2\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.28, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 7.005}, "timestamp": "2026-01-19T15:06:41.548531"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1850.229, "latencies_ms": [1850.229], "images_per_second": 0.54, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The steam locomotive is positioned in the foreground, facing the viewer. The train station and surrounding buildings are in the background, appearing relatively distant.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.518, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.719}, "timestamp": "2026-01-19T15:06:45.461667"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2447.316, "latencies_ms": [2447.316], "images_per_second": 0.409, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The black and white image depicts a steam locomotive pulling passenger cars at a station. A sign indicates the station as \"Hornsea Town.\" The scene suggests a historical moment, possibly from the early days of rail travel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.563, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.854}, "timestamp": "2026-01-19T15:06:49.933250"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2556.161, "latencies_ms": [2556.161], "images_per_second": 0.391, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The train is primarily dark in color, contrasting with the lighter background of the station. The lighting suggests it was taken during daytime. The train appears to be made of metal and has a smokestack, indicating it might be steam-powered.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.498, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.954}, "timestamp": "2026-01-19T15:06:54.551687"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1891.716, "latencies_ms": [1891.716], "images_per_second": 0.529, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "Numerous Chinese street signs and advertisements are suspended from wires above a bustling urban street, displaying various characters and phrases.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.624, "power_cpu_cv_mean_watts": 1.148, "power_sys_5v0_mean_watts": 6.713}, "timestamp": "2026-01-19T15:06:58.485481"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2528.2, "latencies_ms": [2528.2], "images_per_second": 0.396, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "building: 10\nsign: 10\nstreet: 10\ncar: 1\nstreetlights: 2\npower lines: 2\ntrees: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.482, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.935}, "timestamp": "2026-01-19T15:07:03.047707"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3385.538, "latencies_ms": [3385.538], "images_per_second": 0.295, "prompt_tokens": 25, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The foreground features numerous signs and wires hanging from the buildings, creating a dense and intricate urban scene. The background includes buildings of varying heights and architectural styles, further emphasizing the density and complexity of the cityscape. The signs and wires are positioned at varying heights and angles, contributing to the overall sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12516.9, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.663, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.048}, "timestamp": "2026-01-19T15:07:08.461141"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2217.242, "latencies_ms": [2217.242], "images_per_second": 0.451, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The black and white image depicts a densely populated urban street scene, likely in a densely populated Asian city. Numerous signs in Chinese characters hang overhead, contributing to the bustling atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12516.9, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.937, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.904}, "timestamp": "2026-01-19T15:07:12.736422"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3451.679, "latencies_ms": [3451.679], "images_per_second": 0.29, "prompt_tokens": 18, "response_tokens_est": 64, "n_tiles": 1, "output_text": "The black and white photograph captures a dense urban environment with numerous signs and buildings. The signs display Chinese characters and appear to hang from wires above. The lighting is uneven, with some areas brighter than others, creating a dramatic effect. The buildings are constructed of concrete and metal, giving the scene a gritty and industrial feel.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.365, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.052}, "timestamp": "2026-01-19T15:07:18.223058"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1587.366, "latencies_ms": [1587.366], "images_per_second": 0.63, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A man in blue shorts and sunglasses is sitting on a concrete ledge by a body of water, relaxing in the sun.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.957, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.778}, "timestamp": "2026-01-19T15:07:21.856218"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2771.45, "latencies_ms": [2771.45], "images_per_second": 0.361, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "sign: 2\nman: 1\ngrass: 2\nwater: 1\nsign: 1\nwooden plank: 1\npolice: 1\ncross: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.369, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.025}, "timestamp": "2026-01-19T15:07:26.680073"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2146.742, "latencies_ms": [2146.742], "images_per_second": 0.466, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The man is positioned on the right side of the image, sitting on the concrete ledge near the water. The lake and park setting are in the background, creating a contrast between the man and the natural environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.089, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.938}, "timestamp": "2026-01-19T15:07:30.865367"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2514.962, "latencies_ms": [2514.962], "images_per_second": 0.398, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A man is sitting on the edge of a concrete structure near a body of water, possibly a lake or river. A sign in the foreground reads \"Laketroft Trail Closed,\" indicating a park or trail closure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.543, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:07:35.414004"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2641.362, "latencies_ms": [2641.362], "images_per_second": 0.379, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The scene is bathed in natural daylight, creating a bright and airy atmosphere. The grass appears slightly dry, suggesting it might be a sunny day. The lake's surface reflects the sunlight, adding to the overall brightness of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.075, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.922}, "timestamp": "2026-01-19T15:07:40.083098"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1834.984, "latencies_ms": [1834.984], "images_per_second": 0.545, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A golden retriever dog stands attentively in a lush green field, its tongue hanging out, alongside a majestic brown horse.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.355, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.713}, "timestamp": "2026-01-19T15:07:43.951720"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2514.816, "latencies_ms": [2514.816], "images_per_second": 0.398, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "horse: 1\ndog: 1\ngrass: 2\nsky: 1\ntrees: 1\nbelt: 1\ntongue: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12516.5, "ram_available_mb": 50324.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.38, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.94}, "timestamp": "2026-01-19T15:07:48.504375"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2060.643, "latencies_ms": [2060.643], "images_per_second": 0.485, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The dog and horse are positioned close to the foreground, creating a sense of proximity and interaction. The horse is slightly further in the background, emphasizing the vastness of the grassy field.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12516.5, "ram_available_mb": 50324.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.034, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.83}, "timestamp": "2026-01-19T15:07:52.621167"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2255.69, "latencies_ms": [2255.69], "images_per_second": 0.443, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "In the image, a brown horse and a golden retriever are standing in a green field. The horse is positioned slightly behind the dog, appearing to be observing or interacting with the dog.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12517.0, "ram_available_mb": 50323.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.132, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T15:07:56.925755"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2044.693, "latencies_ms": [2044.693], "images_per_second": 0.489, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The horse and dog are brown and white respectively. The lighting is bright and sunny, creating a pleasant atmosphere. The scene takes place in a green field under a clear sky.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.571, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.822}, "timestamp": "2026-01-19T15:08:01.002035"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1559.462, "latencies_ms": [1559.462], "images_per_second": 0.641, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A volleyball game is in progress, with players in green and blue uniforms actively participating.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.455, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 6.568}, "timestamp": "2026-01-19T15:08:04.612042"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3632.555, "latencies_ms": [3632.555], "images_per_second": 0.275, "prompt_tokens": 21, "response_tokens_est": 51, "n_tiles": 1, "output_text": "volleyball: 8\nnet: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1\nvolleyball: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.246, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.062}, "timestamp": "2026-01-19T15:08:10.287379"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2784.888, "latencies_ms": [2784.888], "images_per_second": 0.359, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The volleyball game is taking place in a large, open indoor space. The players are spread out across the court, with some closer to the foreground and others further in the background. The volleyball is positioned near the center of the court, serving as the focal point for the players.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12516.8, "ram_available_mb": 50324.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.473, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 7.047}, "timestamp": "2026-01-19T15:08:15.099444"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2219.684, "latencies_ms": [2219.684], "images_per_second": 0.451, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A group of people are playing volleyball in a large, indoor gymnasium. The players are wearing green and blue uniforms, and the game is taking place on a blue court with orange and white lines.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.066, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T15:08:19.354512"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2035.868, "latencies_ms": [2035.868], "images_per_second": 0.491, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The gym has light blue flooring and neutral lighting. The volleyball net is white, and the players are wearing various colors, including green and blue.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.716, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T15:08:23.418397"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2192.665, "latencies_ms": [2192.665], "images_per_second": 0.456, "prompt_tokens": 8, "response_tokens_est": 39, "n_tiles": 1, "output_text": "A group of zebras and wildebeests are seen grazing and walking across a grassy plain near a body of water, with a large flock of flamingos visible in the distance.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12516.9, "ram_available_mb": 50324.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.178, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T15:08:27.652872"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2769.474, "latencies_ms": [2769.474], "images_per_second": 0.361, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "zebras: 5\nflamingos: 10\nwildebeests: 4\ngrass: 8\nwater: 2\nhills: 2\ntrees: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.184, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.01}, "timestamp": "2026-01-19T15:08:32.459498"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2729.238, "latencies_ms": [2729.238], "images_per_second": 0.366, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The zebras are positioned in the foreground, moving across the grassy plain. The wildebeest are grazing in the background, near the left side of the image. The large flock of flamingos is situated in the background, near the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12518.3, "ram_available_mb": 50322.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.332, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T15:08:37.203117"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2821.344, "latencies_ms": [2821.344], "images_per_second": 0.354, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The scene depicts a vast grassy plain with zebras and wildebeests grazing and moving across the landscape. A large flock of flamingos is visible in the background, situated on a body of water. The setting appears to be a natural habitat for wildlife.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.3, "ram_available_mb": 50322.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12518.3, "ram_available_mb": 50322.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.408, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.034}, "timestamp": "2026-01-19T15:08:42.039218"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2451.265, "latencies_ms": [2451.265], "images_per_second": 0.408, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The scene is dominated by vibrant pink flamingos, which stand out against the green grass and light-colored sky. The lighting suggests a sunny day, and the materials appear to be natural, undisturbed ground and vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.3, "ram_available_mb": 50322.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.721, "power_cpu_cv_mean_watts": 1.522, "power_sys_5v0_mean_watts": 7.041}, "timestamp": "2026-01-19T15:08:46.521841"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1620.408, "latencies_ms": [1620.408], "images_per_second": 0.617, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "An orange and white cat is sitting on a wooden deck, looking at its reflection in the glass surface in front of it.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12518.6, "ram_available_mb": 50322.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.96, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.668}, "timestamp": "2026-01-19T15:08:50.213414"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3065.883, "latencies_ms": [3065.883], "images_per_second": 0.326, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "cat: 2\nmirror: 1\nwooden planks: 8\nglass: 1\nwindow: 1\nreflection: 1\ncat's fur: 2\ncat's eyes: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.764, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.048}, "timestamp": "2026-01-19T15:08:55.339455"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2163.723, "latencies_ms": [2163.723], "images_per_second": 0.462, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The orange and white cat is positioned in the foreground, looking at its reflection in the glass surface. The wooden deck extends into the background, providing a contrast to the cat's vibrant colors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.8, "ram_available_mb": 50322.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.151, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.836}, "timestamp": "2026-01-19T15:08:59.540393"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1986.365, "latencies_ms": [1986.365], "images_per_second": 0.503, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "An orange and white cat is sitting on a wooden deck, looking at its reflection in a mirror. The setting appears to be a patio or outdoor area with a wooden surface.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.297, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.81}, "timestamp": "2026-01-19T15:09:03.552470"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2120.542, "latencies_ms": [2120.542], "images_per_second": 0.472, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The cat is primarily orange and white. The lighting appears to be natural, possibly from sunlight filtering through the glass. The cat is sitting on a weathered wooden deck, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.8, "ram_available_mb": 50323.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.481, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T15:09:07.691284"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1531.969, "latencies_ms": [1531.969], "images_per_second": 0.653, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "Several boats are docked along the shore of a calm lake, with a large building visible in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.957, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.694}, "timestamp": "2026-01-19T15:09:11.297711"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2708.781, "latencies_ms": [2708.781], "images_per_second": 0.369, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Boat: 4\nLamp post: 1\nBuildings: 2\nTrees: 6\nWater: 5\nSky: 1\nHills: 2", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.331, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.097}, "timestamp": "2026-01-19T15:09:16.067746"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1823.118, "latencies_ms": [1823.118], "images_per_second": 0.549, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The main objects are positioned in the foreground, with the water and the buildings in the background. The boats are situated near the water's edge, closer to the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.022, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T15:09:19.927230"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2429.007, "latencies_ms": [2429.007], "images_per_second": 0.412, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a serene lakeside town with several boats docked along the shore. The buildings in the background suggest a resort or hotel complex. The calm water reflects the hazy sky, creating a tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.061, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.041}, "timestamp": "2026-01-19T15:09:24.385541"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2374.602, "latencies_ms": [2374.602], "images_per_second": 0.421, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The water is a calm, grayish-blue color. The lighting suggests an overcast day, with diffused light. The boats are primarily white and appear to be made of metal or fiberglass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.926, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:09:28.781029"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1308.794, "latencies_ms": [1308.794], "images_per_second": 0.764, "prompt_tokens": 8, "response_tokens_est": 17, "n_tiles": 1, "output_text": "A man walks his bicycle down a city street, wearing a towel around his waist.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 12519.5, "ram_available_mb": 50321.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.173, "power_cpu_cv_mean_watts": 1.161, "power_sys_5v0_mean_watts": 5.997}, "timestamp": "2026-01-19T15:09:32.141533"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2914.267, "latencies_ms": [2914.267], "images_per_second": 0.343, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "building: 2\nsign: 2\nbicycle: 2\nman: 1\ntowel: 1\nperson: 1\numbrella: 1\nair conditioner: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12519.5, "ram_available_mb": 50321.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.3, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.314, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 6.686}, "timestamp": "2026-01-19T15:09:37.098129"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2393.045, "latencies_ms": [2393.045], "images_per_second": 0.418, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The man is positioned in the foreground, facing the camera.  In the background, several other individuals and objects are visible, suggesting a public or semi-public space. The man is walking past a bicycle parked near a building.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.762, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 6.615}, "timestamp": "2026-01-19T15:09:41.505096"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2701.593, "latencies_ms": [2701.593], "images_per_second": 0.37, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a street scene in what appears to be a Chinese town. A man is walking with a bicycle, wearing a towel around his waist. Behind him, there are several shops and signs in Chinese characters, indicating a bustling and possibly touristy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.669, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 6.675}, "timestamp": "2026-01-19T15:09:46.234235"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2364.31, "latencies_ms": [2364.31], "images_per_second": 0.423, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is black and white. The lighting appears to be natural daylight, creating a somewhat muted atmosphere. The buildings are simple structures, possibly made of concrete or metal. The overall feel is somewhat gritty and everyday.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.024, "power_cpu_cv_mean_watts": 1.539, "power_sys_5v0_mean_watts": 6.514}, "timestamp": "2026-01-19T15:09:50.617254"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1611.447, "latencies_ms": [1611.447], "images_per_second": 0.621, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A market stall displays numerous bunches of ripe, yellow bananas hanging from blue ropes, ready for purchase.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.245, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 6.273}, "timestamp": "2026-01-19T15:09:54.287344"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2517.265, "latencies_ms": [2517.265], "images_per_second": 0.397, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bananas: 12\nclothes: 1\ntable: 1\nbalance: 1\npot: 1\nfence: 1\ndoor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.494, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 6.642}, "timestamp": "2026-01-19T15:09:58.838104"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2127.513, "latencies_ms": [2127.513], "images_per_second": 0.47, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The bananas are primarily displayed in the foreground, hanging from the ceiling and suspended from the structure above. The background features the storefront and partially visible items, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12522.6, "ram_available_mb": 50318.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.308, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.498}, "timestamp": "2026-01-19T15:10:02.993519"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2658.079, "latencies_ms": [2658.079], "images_per_second": 0.376, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a market stall displaying numerous bunches of ripe, yellow bananas hanging from the ceiling. The bananas are arranged in neat rows, creating a visually appealing display. The stall appears to be outdoors, with natural light illuminating the bananas and the surrounding area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.523, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 6.74}, "timestamp": "2026-01-19T15:10:07.665667"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2658.0, "latencies_ms": [2658.0], "images_per_second": 0.376, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The bananas are predominantly yellow, indicating they are ripe. The lighting appears to be natural, possibly sunlight, giving the bananas a vibrant appearance. The bananas are hanging from strings, suggesting they are likely for sale or display. The overall scene suggests a market setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.557, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 6.7}, "timestamp": "2026-01-19T15:10:12.339531"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1548.891, "latencies_ms": [1548.891], "images_per_second": 0.646, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "An electric train travels through a picturesque countryside, passing through a lush green field with distant mountains in the background.", "error": null, "sys_before": {"cpu_percent": 3.7, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.558, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.762}, "timestamp": "2026-01-19T15:10:15.919295"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3411.488, "latencies_ms": [3411.488], "images_per_second": 0.293, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Train car: 4\nTrain car: 2\nTrain car: 1\nTrain car: 1\nTrain car: 1\nTrain car: 1\nTrain car: 1\nTrain car: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.334, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 7.048}, "timestamp": "2026-01-19T15:10:21.369489"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2441.839, "latencies_ms": [2441.839], "images_per_second": 0.41, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main object is a train traveling from left to right in the foreground, moving past a grassy field and towards a distant mountain range in the background. The train is positioned near the center of the image, occupying a significant portion of the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12522.3, "ram_available_mb": 50318.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12521.6, "ram_available_mb": 50319.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.842, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T15:10:25.839451"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2588.878, "latencies_ms": [2588.878], "images_per_second": 0.386, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene depicts a green and white electric train traveling through a rural landscape, pulling several red freight cars along tracks. The setting includes rolling green hills, fields, and distant mountains, creating a picturesque backdrop for the train's journey.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.6, "ram_available_mb": 50319.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12521.5, "ram_available_mb": 50319.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.367, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.079}, "timestamp": "2026-01-19T15:10:30.470202"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2002.619, "latencies_ms": [2002.619], "images_per_second": 0.499, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The train is painted in green and white. The scene is lit by natural daylight, creating a serene atmosphere. The train appears to be made of sturdy metal and wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.5, "ram_available_mb": 50319.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.447, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.879}, "timestamp": "2026-01-19T15:10:34.488342"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1743.818, "latencies_ms": [1743.818], "images_per_second": 0.573, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man in khaki shorts and a green hat is standing on a sandy beach, holding a kite and possibly preparing to fly it.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12521.9, "ram_available_mb": 50319.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.013, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.3}, "timestamp": "2026-01-19T15:10:38.278348"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2657.756, "latencies_ms": [2657.756], "images_per_second": 0.376, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "kite: 1\nman: 1\nhat: 1\nsandals: 1\nbeach: 1\nocean: 2\nwaves: 2\nchair: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12521.9, "ram_available_mb": 50319.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12521.5, "ram_available_mb": 50319.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.767, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 6.701}, "timestamp": "2026-01-19T15:10:42.952581"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2114.646, "latencies_ms": [2114.646], "images_per_second": 0.473, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The man is standing on the left side of the image, facing the ocean. The kite is positioned in the background, near the right edge of the image. The man appears to be holding the kite string.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.5, "ram_available_mb": 50319.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.473, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.528}, "timestamp": "2026-01-19T15:10:47.096867"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1978.773, "latencies_ms": [1978.773], "images_per_second": 0.505, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A man is standing on a sandy beach, flying a kite while holding a kite string in his right hand. He appears to be enjoying the beach weather and the activity.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.464, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 6.489}, "timestamp": "2026-01-19T15:10:51.108254"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2719.357, "latencies_ms": [2719.357], "images_per_second": 0.368, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The beach is sandy and appears light gray. The sky is bright blue, suggesting sunny weather. The man is wearing khaki shorts and a dark shirt, and he is holding a kite string. The kite is partially visible and appears to be yellow and red.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.523, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 6.712}, "timestamp": "2026-01-19T15:10:55.868985"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1519.544, "latencies_ms": [1519.544], "images_per_second": 0.658, "prompt_tokens": 8, "response_tokens_est": 16, "n_tiles": 1, "output_text": "Two large broccoli plants are growing in raised orange plastic containers on a sandy ground.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.088, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.543}, "timestamp": "2026-01-19T15:10:59.456718"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2926.123, "latencies_ms": [2926.123], "images_per_second": 0.342, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Broccoli: 2\nLeaves: 6\nPotting soil: 2\nBroccoli plant: 2\nBroccoli plant: 2\nBroccoli plant: 2\nBroccoli plant: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.154, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.013}, "timestamp": "2026-01-19T15:11:04.401401"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1914.265, "latencies_ms": [1914.265], "images_per_second": 0.522, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the broccoli plants growing in raised orange planters. The background is primarily sandy soil.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.194, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.686}, "timestamp": "2026-01-19T15:11:08.359562"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2742.552, "latencies_ms": [2742.552], "images_per_second": 0.365, "prompt_tokens": 19, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The scene depicts a garden bed with two broccoli plants growing in raised orange plastic containers. The plants have large, green leaves and appear healthy, indicating proper care and cultivation. The ground is sandy and appears to be part of a garden or outdoor space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.7, "ram_available_mb": 50319.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12520.3, "ram_available_mb": 50320.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.991}, "timestamp": "2026-01-19T15:11:13.143012"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2823.593, "latencies_ms": [2823.593], "images_per_second": 0.354, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The broccoli plants exhibit a vibrant green color, indicating healthy growth. The lighting appears to be natural, possibly sunlight, enhancing the freshness and color of the leaves. The plants are housed in terracotta-colored plastic containers, suggesting they are being grown in a controlled environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.3, "ram_available_mb": 50320.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.317, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T15:11:18.005191"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1968.61, "latencies_ms": [1968.61], "images_per_second": 0.508, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A young boy is sitting on a small pony while an older man holds its reins and guides it, possibly preparing for a ride or training session.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.697, "power_cpu_cv_mean_watts": 1.327, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T15:11:22.028237"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2743.31, "latencies_ms": [2743.31], "images_per_second": 0.365, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "pony: 1\nman: 1\nchild: 1\nbuilding: 1\nleash: 1\nchair: 1\ntable: 1\nlantern: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.282, "power_cpu_cv_mean_watts": 1.567, "power_sys_5v0_mean_watts": 7.007}, "timestamp": "2026-01-19T15:11:26.799515"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2514.189, "latencies_ms": [2514.189], "images_per_second": 0.398, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The pony is positioned in the foreground, close to the man and child. The man and child are standing in the background, slightly further away. The pony is situated near the building, slightly further back from the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.581, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.975}, "timestamp": "2026-01-19T15:11:31.362619"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2182.737, "latencies_ms": [2182.737], "images_per_second": 0.458, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A young boy is riding a small pony outside a red building, possibly a house or stable. A man is leading the pony and guiding it through the scene.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.127, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.872}, "timestamp": "2026-01-19T15:11:35.558561"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2159.003, "latencies_ms": [2159.003], "images_per_second": 0.463, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The pony is light brown with a white blaze on its face. The man is wearing a blue shirt and dark pants. The scene appears to be outdoors in bright sunlight.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12521.6, "ram_available_mb": 50319.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.129, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.901}, "timestamp": "2026-01-19T15:11:39.752517"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1637.878, "latencies_ms": [1637.878], "images_per_second": 0.611, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young boy in a blue striped shirt is walking along a dirt path in a field of blue flowers, holding a stuffed animal.", "error": null, "sys_before": {"cpu_percent": 6.9, "ram_used_mb": 12521.6, "ram_available_mb": 50319.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12521.9, "ram_available_mb": 50319.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.577, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.73}, "timestamp": "2026-01-19T15:11:43.456999"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2940.966, "latencies_ms": [2940.966], "images_per_second": 0.34, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "bluebells: 100\npath: 100\ntoddler: 1\ntoy: 1\ngrass: 1\nleaves: 1\nshrubs: 1\nsunlight: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12521.9, "ram_available_mb": 50319.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.07, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T15:11:48.421145"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2269.609, "latencies_ms": [2269.609], "images_per_second": 0.441, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The child is walking towards a field of bluebells, creating a sense of depth and distance. The bluebells are in the foreground, while the child is further back, walking along a path.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12521.1, "ram_available_mb": 50319.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.888, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 6.809}, "timestamp": "2026-01-19T15:11:52.706792"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2050.937, "latencies_ms": [2050.937], "images_per_second": 0.488, "prompt_tokens": 19, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A young boy walks along a dirt path through a field of bluebells. He carries a stuffed animal, possibly a teddy bear, while exploring the vibrant flowers.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12521.1, "ram_available_mb": 50319.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12520.9, "ram_available_mb": 50320.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.222, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.812}, "timestamp": "2026-01-19T15:11:56.798636"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2415.966, "latencies_ms": [2415.966], "images_per_second": 0.414, "prompt_tokens": 18, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The scene is dominated by vibrant shades of blue and purple from the flowers, creating a striking contrast against the dirt path. The lighting suggests a sunny day, and the materials appear to be natural and organic, consistent with the surrounding environment.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12520.9, "ram_available_mb": 50320.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.821, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T15:12:01.258312"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1444.851, "latencies_ms": [1444.851], "images_per_second": 0.692, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A large orange rests on the edge of a parking lot, surrounded by parked cars and trees in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12521.4, "ram_available_mb": 50319.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12520.9, "ram_available_mb": 50320.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.553, "power_cpu_cv_mean_watts": 1.02, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T15:12:04.772239"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2501.422, "latencies_ms": [2501.422], "images_per_second": 0.4, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "orange: 1\ncar: 2\ntree: 3\nroad: 4\nparking lot: 5\norange: 1\nsky: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12520.9, "ram_available_mb": 50320.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.441, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.864}, "timestamp": "2026-01-19T15:12:09.295175"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1969.579, "latencies_ms": [1969.579], "images_per_second": 0.508, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The orange is positioned in the foreground, slightly to the left of the viewer. The parking lot and cars in the background are further away, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12519.3, "ram_available_mb": 50321.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.675, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T15:12:13.292174"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2067.238, "latencies_ms": [2067.238], "images_per_second": 0.484, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A large orange rests on the asphalt of a parking lot, contrasting with the surrounding cars and trees. The scene suggests a parking lot with several vehicles parked nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.3, "ram_available_mb": 50321.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.197, "power_cpu_cv_mean_watts": 1.272, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T15:12:17.379190"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2469.075, "latencies_ms": [2469.075], "images_per_second": 0.405, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The orange is predominantly orange in color. The lighting appears to be natural daylight, creating a contrast between the bright orange and the darker asphalt. The image captures the orange's texture and color, highlighting its natural appearance.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.339, "power_cpu_cv_mean_watts": 1.382, "power_sys_5v0_mean_watts": 6.869}, "timestamp": "2026-01-19T15:12:21.887087"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1833.202, "latencies_ms": [1833.202], "images_per_second": 0.545, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A man in a gray suit and tie is sitting at a wooden table, smiling at the camera while enjoying a meal and drinks.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.878, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.732}, "timestamp": "2026-01-19T15:12:25.774007"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2976.885, "latencies_ms": [2976.885], "images_per_second": 0.336, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "bowl: 1\nkeys: 2\nman: 1\ntable: 1\nbeer bottles: 2\nserving spoon: 1\nwhite shirt: 1\ntie: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12518.5, "ram_available_mb": 50322.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.32, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.039}, "timestamp": "2026-01-19T15:12:30.803806"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2821.88, "latencies_ms": [2821.88], "images_per_second": 0.354, "prompt_tokens": 25, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The main object is a man sitting at a table, positioned in the foreground of the image. The table occupies the middle ground, extending from the left to the right side of the frame. Behind the man and table, there are additional objects and elements, such as a bowl, keys, and bottles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12518.6, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.56, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.148}, "timestamp": "2026-01-19T15:12:35.663024"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2547.998, "latencies_ms": [2547.998], "images_per_second": 0.392, "prompt_tokens": 19, "response_tokens_est": 45, "n_tiles": 1, "output_text": "A man is sitting at a wooden table, wearing a gray suit and tie. He is smiling and appears to be enjoying a meal or snack. Beside him on the table are three Corona Extra beer bottles and a bowl.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12518.6, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.897, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.046}, "timestamp": "2026-01-19T15:12:40.259152"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2879.441, "latencies_ms": [2879.441], "images_per_second": 0.347, "prompt_tokens": 18, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The man is wearing a gray suit and white shirt. His suit appears to be made of a smooth, possibly synthetic material. The lighting in the image is soft and warm, creating a pleasant atmosphere. The table is light-colored wood, and there are two bottles of Corona beer visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.203, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.043}, "timestamp": "2026-01-19T15:12:45.175343"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1755.888, "latencies_ms": [1755.888], "images_per_second": 0.57, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The neatly made bed with white sheets and pillows is accompanied by a desk with a chair, a window, and a suitcase on the floor.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.793, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.71}, "timestamp": "2026-01-19T15:12:48.957517"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2874.77, "latencies_ms": [2874.77], "images_per_second": 0.348, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "bed: 2\npillows: 2\ntowels: 2\ndesk: 1\nchair: 1\nsuitcase: 1\nwindow: 1\nlight: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.82, "power_cpu_cv_mean_watts": 1.569, "power_sys_5v0_mean_watts": 6.984}, "timestamp": "2026-01-19T15:12:53.859016"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2214.324, "latencies_ms": [2214.324], "images_per_second": 0.452, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The bed occupies the foreground, positioned between the desk and chair. The desk and chair are located in the background, near the window. The bed is situated further back in the room.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.978, "power_cpu_cv_mean_watts": 1.29, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T15:12:58.113522"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1855.992, "latencies_ms": [1855.992], "images_per_second": 0.539, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The scene depicts a hotel room with two twin beds, a desk, and a chair. The room is clean and appears to be well-maintained.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.248, "power_cpu_cv_mean_watts": 1.148, "power_sys_5v0_mean_watts": 6.699}, "timestamp": "2026-01-19T15:13:02.025391"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2384.136, "latencies_ms": [2384.136], "images_per_second": 0.419, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The room features light beige walls and carpeting. The bed is covered with white linens and pillows. The lighting is soft and diffused, creating a calm atmosphere. A window provides natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.843, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T15:13:06.446600"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1778.423, "latencies_ms": [1778.423], "images_per_second": 0.562, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "Three stuffed animals, including a teddy bear, a snowman, and a polar bear, are arranged together on a blue surface against a colorful backdrop.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.156, "power_cpu_cv_mean_watts": 1.344, "power_sys_5v0_mean_watts": 6.357}, "timestamp": "2026-01-19T15:13:10.281203"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3032.612, "latencies_ms": [3032.612], "images_per_second": 0.33, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "bear: 1\npolar bear: 1\nsnowman: 1\nhat: 1\nred heart: 1\ncoca cola: 1\nbomb: 1\ngreen fabric: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.631, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 6.794}, "timestamp": "2026-01-19T15:13:15.348390"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2190.8, "latencies_ms": [2190.8], "images_per_second": 0.456, "prompt_tokens": 25, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The main objects are positioned close together in the foreground, with the Coca-Cola bear and snowman slightly behind and to the right of the bear. The background features an orange surface with painted flowers.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.473, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.522}, "timestamp": "2026-01-19T15:13:19.580307"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3095.969, "latencies_ms": [3095.969], "images_per_second": 0.323, "prompt_tokens": 19, "response_tokens_est": 60, "n_tiles": 1, "output_text": "Three stuffed animals, including a teddy bear, a polar bear, and a snowman, are arranged on a blue blanket against a vibrant orange background. The teddy bear wears a green hat and has a Coca-Cola scarf. The snowman also has a Coca-Cola hat and scarf.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.486, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 6.798}, "timestamp": "2026-01-19T15:13:24.733717"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2568.625, "latencies_ms": [2568.625], "images_per_second": 0.389, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The teddy bears are light brown and white. The lighting is soft and warm, creating a cozy atmosphere. The teddy bears appear to be made of plush fabric. The background features a vibrant orange and red design, suggesting an artistic or festive setting.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.414, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 6.658}, "timestamp": "2026-01-19T15:13:29.350825"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1549.673, "latencies_ms": [1549.673], "images_per_second": 0.645, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A clear glass bowl filled with bright, fresh oranges sits on a textured silver tablecloth.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12519.1, "ram_available_mb": 50321.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.058, "power_cpu_cv_mean_watts": 1.035, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T15:13:32.966089"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3354.302, "latencies_ms": [3354.302], "images_per_second": 0.298, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Orange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8\nOrange: 8", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12519.8, "ram_available_mb": 50321.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.52, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.045}, "timestamp": "2026-01-19T15:13:38.338284"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1671.729, "latencies_ms": [1671.729], "images_per_second": 0.598, "prompt_tokens": 25, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The main objects are positioned close together, with the oranges filling the foreground. The bowl is placed in the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.8, "ram_available_mb": 50321.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12520.3, "ram_available_mb": 50320.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.853, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 6.831}, "timestamp": "2026-01-19T15:13:42.036824"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2130.439, "latencies_ms": [2130.439], "images_per_second": 0.469, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A clear glass bowl filled with bright oranges sits on a textured silver surface, possibly a tablecloth. The oranges are arranged neatly, showcasing their vibrant color and healthy appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.3, "ram_available_mb": 50320.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.494, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 7.156}, "timestamp": "2026-01-19T15:13:46.210288"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3056.111, "latencies_ms": [3056.111], "images_per_second": 0.327, "prompt_tokens": 18, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The oranges are bright orange and appear to be ripe. The lighting is soft and diffused, creating a gentle glow on the oranges. The bowl is made of clear glass and has a dark reddish-brown rim. The surface the bowl rests on appears to be textured, possibly a tablecloth or placemat.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12520.8, "ram_available_mb": 50320.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.117, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 7.156}, "timestamp": "2026-01-19T15:13:51.285372"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1647.568, "latencies_ms": [1647.568], "images_per_second": 0.607, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A surfer skillfully rides a large, powerful wave in the ocean, showcasing their expertise amidst the crashing water.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12521.2, "ram_available_mb": 50319.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12521.1, "ram_available_mb": 50319.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.365, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 6.296}, "timestamp": "2026-01-19T15:13:54.997660"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2183.751, "latencies_ms": [2183.751], "images_per_second": 0.458, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "wave: 1\nsurfer: 1\nsurfboard: 1\nwater: 1\nsky: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12521.1, "ram_available_mb": 50319.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.369, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.557}, "timestamp": "2026-01-19T15:13:59.234081"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2333.7, "latencies_ms": [2333.7], "images_per_second": 0.429, "prompt_tokens": 25, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main object is a large wave curling over, creating a dramatic foreground scene. The background features the ocean horizon, extending far into the distance. The wave is positioned close to the viewer, emphasizing its powerful presence.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12521.0, "ram_available_mb": 50319.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12520.7, "ram_available_mb": 50320.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.488, "power_cpu_cv_mean_watts": 1.539, "power_sys_5v0_mean_watts": 6.61}, "timestamp": "2026-01-19T15:14:03.607356"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1658.525, "latencies_ms": [1658.525], "images_per_second": 0.603, "prompt_tokens": 19, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A surfer is riding a large, powerful wave in the ocean. The sky is overcast, creating a dramatic backdrop for the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12520.7, "ram_available_mb": 50320.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.06, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.21}, "timestamp": "2026-01-19T15:14:07.291410"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2769.168, "latencies_ms": [2769.168], "images_per_second": 0.361, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The ocean is a deep blue color, creating a striking contrast with the white foam of the waves. The lighting suggests an overcast sky, casting a soft, diffused light over the scene. The waves appear to be powerful and dynamic, captured in a moment of action.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.493, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 6.714}, "timestamp": "2026-01-19T15:14:12.114877"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1640.327, "latencies_ms": [1640.327], "images_per_second": 0.61, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A tabby and white cat is sitting in front of a laptop, attentively looking at the Twitter page displayed on the screen.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.929, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.637}, "timestamp": "2026-01-19T15:14:15.818193"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3079.144, "latencies_ms": [3079.144], "images_per_second": 0.325, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "laptop: 1\ncat: 1\nkeyboard: 1\nlaptop screen: 1\nTwitter logo: 1\ntext: 1\ncouch: 1\npillow: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.876, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.031}, "timestamp": "2026-01-19T15:14:20.931772"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1637.049, "latencies_ms": [1637.049], "images_per_second": 0.611, "prompt_tokens": 25, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The cat is positioned in the foreground, close to the laptop. The laptop is situated in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.272, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.629}, "timestamp": "2026-01-19T15:14:24.600536"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2467.48, "latencies_ms": [2467.48], "images_per_second": 0.405, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "A tabby and white cat is sitting on a couch, attentively looking at a laptop screen displaying the Twitter website. The laptop is positioned on a surface, possibly a table or desk, in a casual indoor setting.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.321, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.849}, "timestamp": "2026-01-19T15:14:29.092690"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2236.429, "latencies_ms": [2236.429], "images_per_second": 0.447, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The cat is primarily white with brown and gray stripes. The lighting in the image is soft and diffused, suggesting indoor lighting. The cat appears to be comfortably perched on the laptop keyboard.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.093, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T15:14:33.362077"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1554.584, "latencies_ms": [1554.584], "images_per_second": 0.643, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A group of six horses, including two brown ones and three black ones, are gathered around a hay feeder in a field.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.98, "power_cpu_cv_mean_watts": 1.168, "power_sys_5v0_mean_watts": 6.165}, "timestamp": "2026-01-19T15:14:36.945669"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2117.424, "latencies_ms": [2117.424], "images_per_second": 0.472, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "horse: 5\nhay: 2\nfence: 1\nground: 1\ntrees: 2\nhouse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.285, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.433}, "timestamp": "2026-01-19T15:14:41.098289"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2190.735, "latencies_ms": [2190.735], "images_per_second": 0.456, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned in a relatively open space, with a young horse on the left and a group of horses in the background. The horses are grouped together near the hay pile, suggesting they are in a feeding area or stable.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.348, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.563}, "timestamp": "2026-01-19T15:14:45.336352"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1863.837, "latencies_ms": [1863.837], "images_per_second": 0.537, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A group of horses, including adults and younger ones, are gathered in a field near a hay feeder. The scene suggests a rural or farm setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12520.2, "ram_available_mb": 50320.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12520.4, "ram_available_mb": 50320.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.0, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.263}, "timestamp": "2026-01-19T15:14:49.242050"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1809.381, "latencies_ms": [1809.381], "images_per_second": 0.553, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The horses are primarily dark brown or black. The lighting appears to be natural daylight. The horses are standing on a field of dry, brown grass.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12520.4, "ram_available_mb": 50320.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.129, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.292}, "timestamp": "2026-01-19T15:14:53.075043"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1919.483, "latencies_ms": [1919.483], "images_per_second": 0.521, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A man wearing a black wetsuit skillfully maneuvers a yellow surfboard, crouching low and carving through the waves in the ocean.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12520.0, "ram_available_mb": 50320.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.027, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.894}, "timestamp": "2026-01-19T15:14:57.035747"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2542.802, "latencies_ms": [2542.802], "images_per_second": 0.393, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "surfboard: 1\nperson: 1\nwater: 1\nwaves: 2\ncliff: 1\nsky: 1\nshore: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.502, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T15:15:01.594057"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1909.602, "latencies_ms": [1909.602], "images_per_second": 0.524, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave near the shore. The ocean extends in the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.9, "ram_available_mb": 50321.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12519.3, "ram_available_mb": 50321.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.575, "power_cpu_cv_mean_watts": 1.229, "power_sys_5v0_mean_watts": 6.834}, "timestamp": "2026-01-19T15:15:05.549724"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2729.243, "latencies_ms": [2729.243], "images_per_second": 0.366, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "A man is surfing on a wave in the ocean, wearing a black wetsuit. He is riding a yellow surfboard through the water, creating a splash as it cuts through the waves. The background features a sandy beach and a cliff, contributing to the coastal setting.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 12519.2, "ram_available_mb": 50321.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.24, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 6.922}, "timestamp": "2026-01-19T15:15:10.303446"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2220.199, "latencies_ms": [2220.199], "images_per_second": 0.45, "prompt_tokens": 18, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The surfer is wearing a dark-colored wetsuit. The water appears a greenish-blue, reflecting the sunlight. The sky is partly cloudy, suggesting fair weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.7, "ram_available_mb": 50321.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.868, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T15:15:14.559199"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2321.885, "latencies_ms": [2321.885], "images_per_second": 0.431, "prompt_tokens": 8, "response_tokens_est": 41, "n_tiles": 1, "output_text": "Three unique pumpkins are displayed in a hallway, each with unique decorations and carvings, including a carved jack-o-lantern, a smiling pumpkin, and a vase with pink flowers.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.759, "power_cpu_cv_mean_watts": 1.371, "power_sys_5v0_mean_watts": 6.886}, "timestamp": "2026-01-19T15:15:18.925209"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3110.155, "latencies_ms": [3110.155], "images_per_second": 0.322, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "pumpkin: 3\nflowers: 2\nperson: 1\ncarved pumpkin: 1\nglass vase: 1\npikachu: 1\nblackboard: 1\npapers: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.799, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 7.044}, "timestamp": "2026-01-19T15:15:24.064958"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2759.572, "latencies_ms": [2759.572], "images_per_second": 0.362, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The pumpkins are positioned close together, creating a sense of proximity and visual balance. The flowers are placed in the foreground, slightly in front of the pumpkins, adding a natural element to the scene. The background is slightly blurred, drawing attention to the pumpkins and flowers.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.498, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 7.019}, "timestamp": "2026-01-19T15:15:28.852336"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2813.937, "latencies_ms": [2813.937], "images_per_second": 0.355, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a Halloween-themed display featuring three carved pumpkins and a vase of pink flowers. A small figurine of a man is perched on one of the pumpkins. The pumpkins are displayed on a table or shelf alongside other Halloween decorations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.161, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T15:15:33.706097"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2312.346, "latencies_ms": [2312.346], "images_per_second": 0.432, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The pumpkins are orange and feature painted faces. The lighting appears to be artificial, creating a warm glow. The materials appear to be smooth and possibly plastic or wood. The weather appears to be sunny and pleasant.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12519.4, "ram_available_mb": 50321.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.55, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T15:15:38.082814"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1547.371, "latencies_ms": [1547.371], "images_per_second": 0.646, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The bathroom features a white sink, a mirror, a shelf with toiletries, and a black trash bag on the floor.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12519.0, "ram_available_mb": 50321.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.214, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.073}, "timestamp": "2026-01-19T15:15:41.695059"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2933.258, "latencies_ms": [2933.258], "images_per_second": 0.341, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "sink: 1\nmirror: 1\ntoiletries: 2\nshelf: 1\ndoor: 1\ntrash bag: 1\npipes: 1\nfloor: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.765, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 6.762}, "timestamp": "2026-01-19T15:15:46.661200"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1863.802, "latencies_ms": [1863.802], "images_per_second": 0.537, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The sink is positioned to the left of the mirror and further back in the room. The door is situated to the right of the sink and further back in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.9, "ram_available_mb": 50322.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.161, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.33}, "timestamp": "2026-01-19T15:15:50.581164"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2119.911, "latencies_ms": [2119.911], "images_per_second": 0.472, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The bathroom appears to be in a state of disrepair or abandonment.  A sink, mirror, and door are present, along with a trash bag on the floor. The walls show signs of wear and tear.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.192, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.475}, "timestamp": "2026-01-19T15:15:54.762972"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2235.731, "latencies_ms": [2235.731], "images_per_second": 0.447, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The walls are painted a pale yellow. The lighting in the room is soft and warm, creating a calm atmosphere. The bathroom appears to have a simple design with a white sink, a mirror, and a door.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.0, "ram_available_mb": 50322.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.259, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 6.462}, "timestamp": "2026-01-19T15:15:59.041639"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1467.918, "latencies_ms": [1467.918], "images_per_second": 0.681, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A young child sits on a bed, focused intently on a laptop screen in front of them.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.156, "power_cpu_cv_mean_watts": 0.947, "power_sys_5v0_mean_watts": 6.607}, "timestamp": "2026-01-19T15:16:02.571946"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2957.99, "latencies_ms": [2957.99], "images_per_second": 0.338, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "laptop: 1\nbed: 1\ntoddler: 1\nchild: 1\nhair clip: 1\ntoys: 1\nwindow: 1\nwall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.755, "power_cpu_cv_mean_watts": 1.569, "power_sys_5v0_mean_watts": 6.934}, "timestamp": "2026-01-19T15:16:07.545146"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2008.002, "latencies_ms": [2008.002], "images_per_second": 0.498, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The baby is positioned near the laptop, seemingly observing its screen. The laptop is placed on a surface that extends from the foreground towards the background, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.224, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.797}, "timestamp": "2026-01-19T15:16:11.597145"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1609.089, "latencies_ms": [1609.089], "images_per_second": 0.621, "prompt_tokens": 19, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A young child is sitting on a bed, focused on a laptop screen. The setting appears to be a bedroom or home environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.715, "power_cpu_cv_mean_watts": 0.986, "power_sys_5v0_mean_watts": 6.574}, "timestamp": "2026-01-19T15:16:15.271001"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1904.392, "latencies_ms": [1904.392], "images_per_second": 0.525, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The baby is wearing a white shirt. The laptop is silver. The background is plain white. The lighting is soft and diffused.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.826, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.76}, "timestamp": "2026-01-19T15:16:19.219673"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1642.55, "latencies_ms": [1642.55], "images_per_second": 0.609, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A skier in a brown jacket and black pants is carving down a snowy slope, leaving a trail of snow behind him.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.522, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 6.28}, "timestamp": "2026-01-19T15:16:22.913701"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3228.066, "latencies_ms": [3228.066], "images_per_second": 0.31, "prompt_tokens": 21, "response_tokens_est": 44, "n_tiles": 1, "output_text": "skier: 1\nsnowboard: 0\ngloves: 2\ngloves: 1\nski poles: 2\nskis: 2\ntree: 1\nsnow: 1\ngoggles: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.913, "power_cpu_cv_mean_watts": 1.825, "power_sys_5v0_mean_watts": 6.809}, "timestamp": "2026-01-19T15:16:28.180179"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1831.438, "latencies_ms": [1831.438], "images_per_second": 0.546, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The skier is positioned in the foreground, moving towards the left side of the image. The snowy slope and trees in the background create a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.329, "power_cpu_cv_mean_watts": 1.259, "power_sys_5v0_mean_watts": 6.336}, "timestamp": "2026-01-19T15:16:32.054693"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2242.141, "latencies_ms": [2242.141], "images_per_second": 0.446, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A skier is carving down a snowy slope amidst snow-covered trees. The scene is bright and sunny, highlighting the contrast between the skier's brown jacket and the white snow.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.06, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 6.546}, "timestamp": "2026-01-19T15:16:36.319569"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2367.488, "latencies_ms": [2367.488], "images_per_second": 0.422, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The skier is wearing a brown jacket and dark pants. The lighting is bright and sunny, creating a contrast against the white snow. The skier is skiing down a snow-covered slope with trees in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.256, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.536}, "timestamp": "2026-01-19T15:16:40.718708"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2090.482, "latencies_ms": [2090.482], "images_per_second": 0.478, "prompt_tokens": 8, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The hotel room features a king-sized bed with white linens, a wooden headboard, and blue and gray pillows, accompanied by a blue armchair and a black suitcase.", "error": null, "sys_before": {"cpu_percent": 5.3, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.14, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.457}, "timestamp": "2026-01-19T15:16:44.849323"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2923.71, "latencies_ms": [2923.71], "images_per_second": 0.342, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "bed: 1\npillows: 4\nlamp: 2\narmchair: 1\nsuitcase: 1\nwindow: 1\ncurtains: 1\ncarpet: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.648, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 6.762}, "timestamp": "2026-01-19T15:16:49.812231"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2444.825, "latencies_ms": [2444.825], "images_per_second": 0.409, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main objects are positioned in a balanced and harmonious manner, with the bed occupying the foreground and the chair and suitcase placed near the left side of the image. The window and lamp are situated in the background, creating a sense of depth and perspective.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.394, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 6.632}, "timestamp": "2026-01-19T15:16:54.289123"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1990.021, "latencies_ms": [1990.021], "images_per_second": 0.503, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The scene depicts a hotel room with a large bed, a blue armchair, and a window providing natural light. The room is clean and organized, with a lamp providing soft lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.1, "ram_available_mb": 50323.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.514, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 6.375}, "timestamp": "2026-01-19T15:16:58.335100"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2566.227, "latencies_ms": [2566.227], "images_per_second": 0.39, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The room features a light-colored bed with white linens and several pillows in blue, green, and white. The lighting is soft and diffused, creating a calm and inviting atmosphere. The bed and chair are made of wood, and the carpet is a neutral color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.901, "power_cpu_cv_mean_watts": 1.755, "power_sys_5v0_mean_watts": 6.782}, "timestamp": "2026-01-19T15:17:02.948184"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2072.231, "latencies_ms": [2072.231], "images_per_second": 0.483, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A skier in vibrant orange pants and a white jacket skillfully maneuvers a red rail on a snowy slope, surrounded by other winter sports enthusiasts.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.247, "power_cpu_cv_mean_watts": 1.227, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T15:17:07.075460"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3193.964, "latencies_ms": [3193.964], "images_per_second": 0.313, "prompt_tokens": 21, "response_tokens_est": 41, "n_tiles": 1, "output_text": "red pipe: 1\nskier: 1\nsnowboarder: 1\nfence: 1\nski lift: 1\nsnow: 1\nskiers: 2\nclear sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.3, "ram_available_mb": 50323.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.308, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.003}, "timestamp": "2026-01-19T15:17:12.285007"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2146.159, "latencies_ms": [2146.159], "images_per_second": 0.466, "prompt_tokens": 25, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The red object dominates the foreground, positioned to the left of the main subject. The background features more snow skiers and ski lifts, indicating a ski resort environment.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.292, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T15:17:16.463740"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3336.868, "latencies_ms": [3336.868], "images_per_second": 0.3, "prompt_tokens": 19, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The scene depicts a snowy slope with several people skiing and snowboarding. A prominent feature is a red, curved rail or ramp that serves as a challenge for skiers and snowboarders. The setting appears to be a ski resort or mountain area with ski lifts and other winter sports infrastructure visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.1, "ram_available_mb": 50324.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12516.2, "ram_available_mb": 50324.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.581, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.106}, "timestamp": "2026-01-19T15:17:21.820824"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2149.777, "latencies_ms": [2149.777], "images_per_second": 0.465, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The snow is bright white, indicative of clear, sunny weather. The red metal feature stands out against the snowy landscape, adding a pop of color to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.2, "ram_available_mb": 50324.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.844, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.831}, "timestamp": "2026-01-19T15:17:26.004129"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1638.746, "latencies_ms": [1638.746], "images_per_second": 0.61, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A parking meter with graffiti on its side is mounted on a metal pole against a graffiti-covered wall.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12515.9, "ram_available_mb": 50325.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.15, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 6.66}, "timestamp": "2026-01-19T15:17:29.718356"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2831.658, "latencies_ms": [2831.658], "images_per_second": 0.353, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "Parking meter: 2\nGraffiti: 5\nMetal fence: 1\nStreet sign: 1\nPole: 1\nBuilding: 1\nGround: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.247, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 6.99}, "timestamp": "2026-01-19T15:17:34.563367"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1797.441, "latencies_ms": [1797.441], "images_per_second": 0.556, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The parking meter is positioned in the foreground, slightly to the right of the graffiti wall. The graffiti wall extends into the background, creating a layered effect.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12516.0, "ram_available_mb": 50324.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.142, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.832}, "timestamp": "2026-01-19T15:17:38.391799"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2451.922, "latencies_ms": [2451.922], "images_per_second": 0.408, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a vibrant urban street corner with a parking meter covered in graffiti. The graffiti is predominantly in black, white, blue, and yellow, covering the side of the building and adding to the overall artistic atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.0, "ram_available_mb": 50324.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.182, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.02}, "timestamp": "2026-01-19T15:17:42.895959"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2649.815, "latencies_ms": [2649.815], "images_per_second": 0.377, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The building's exterior is covered in vibrant graffiti in shades of black, blue, yellow, and white. The lighting appears to be natural daylight, creating a contrast against the darker colors of the graffiti. The materials appear to be metal and concrete, typical for urban environments.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12515.7, "ram_available_mb": 50325.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 12516.2, "ram_available_mb": 50324.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.424, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.022}, "timestamp": "2026-01-19T15:17:47.594665"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1892.194, "latencies_ms": [1892.194], "images_per_second": 0.528, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A surfer in a black wetsuit rides a wave on a white surfboard, skillfully carving through the deep blue ocean.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12516.2, "ram_available_mb": 50324.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.706, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.686}, "timestamp": "2026-01-19T15:17:51.516748"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2212.011, "latencies_ms": [2212.011], "images_per_second": 0.452, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "person: 1\nsurfboard: 1\nwave: 1\nwater: 1\nsky: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.18, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T15:17:55.761671"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2264.518, "latencies_ms": [2264.518], "images_per_second": 0.442, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The surfer is positioned near the center of the image, riding a wave that extends towards the right side of the frame. The ocean occupies the majority of the background, creating a sense of depth and vastness.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.89, "power_cpu_cv_mean_watts": 1.357, "power_sys_5v0_mean_watts": 6.893}, "timestamp": "2026-01-19T15:18:00.086576"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2236.583, "latencies_ms": [2236.583], "images_per_second": 0.447, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "A surfer is riding a wave in the deep blue ocean. The scene is captured from a distance, emphasizing the vastness of the ocean and the surfer's skillful maneuver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.366, "power_cpu_cv_mean_watts": 1.414, "power_sys_5v0_mean_watts": 6.978}, "timestamp": "2026-01-19T15:18:04.337653"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2342.295, "latencies_ms": [2342.295], "images_per_second": 0.427, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The ocean is a deep blue color, creating a striking contrast with the white foam of the waves. The lighting appears to be soft and diffused, possibly suggesting an overcast sky or twilight conditions.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.757, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 6.91}, "timestamp": "2026-01-19T15:18:08.715347"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1557.742, "latencies_ms": [1557.742], "images_per_second": 0.642, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A yellow double-decker bus is stopped at a bus stop, picking up passengers.", "error": null, "sys_before": {"cpu_percent": 10.3, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.393, "power_cpu_cv_mean_watts": 0.935, "power_sys_5v0_mean_watts": 6.534}, "timestamp": "2026-01-19T15:18:12.322901"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2461.853, "latencies_ms": [2461.853], "images_per_second": 0.406, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "bus: 2\nstreet: 2\nbuildings: 2\nbus stop: 1\nman: 2\nwoman: 1\nflowers: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.484, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.904}, "timestamp": "2026-01-19T15:18:16.799490"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3025.576, "latencies_ms": [3025.576], "images_per_second": 0.331, "prompt_tokens": 25, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The double-decker bus is positioned in the foreground, moving towards the viewer. The bus is situated near a bus stop, offering a clear view of the street and surrounding environment. The bus is further back in the scene, suggesting it is at a bus stop or in a designated bus lane.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.905, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.039}, "timestamp": "2026-01-19T15:18:21.839325"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2748.835, "latencies_ms": [2748.835], "images_per_second": 0.364, "prompt_tokens": 19, "response_tokens_est": 53, "n_tiles": 1, "output_text": "A yellow double-decker bus is stopped at a bus stop, picking up passengers. The bus is labeled \"Lytham\" and \"St Annes.\" Two men are waiting at the bus stop, one near the front and the other near the back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.277, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.065}, "timestamp": "2026-01-19T15:18:26.634302"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2488.709, "latencies_ms": [2488.709], "images_per_second": 0.402, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The bus is primarily yellow and black. The lighting appears to be overcast, creating a somewhat muted atmosphere. The bus's materials appear to be standard, durable construction. The weather appears to be overcast, contributing to the subdued lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.9, "ram_available_mb": 50323.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.662, "power_cpu_cv_mean_watts": 1.382, "power_sys_5v0_mean_watts": 6.859}, "timestamp": "2026-01-19T15:18:31.145142"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2067.34, "latencies_ms": [2067.34], "images_per_second": 0.484, "prompt_tokens": 8, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A yellow and red single-engine propeller airplane with the registration SP-AWF is captured in mid-flight, moving from left to right with a slight downward tilt.", "error": null, "sys_before": {"cpu_percent": 5.0, "ram_used_mb": 12518.2, "ram_available_mb": 50322.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.365, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.967}, "timestamp": "2026-01-19T15:18:35.264884"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2602.228, "latencies_ms": [2602.228], "images_per_second": 0.384, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "airplane: 1\npropeller: 1\nwings: 2\ntail: 1\nbody: 1\nwheel: 2\ntext: SP-AWF", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.461, "power_cpu_cv_mean_watts": 1.621, "power_sys_5v0_mean_watts": 7.051}, "timestamp": "2026-01-19T15:18:39.901887"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2156.759, "latencies_ms": [2156.759], "images_per_second": 0.464, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The main object is a yellow and red propeller plane flying in the sky. The plane is positioned in the foreground, slightly to the right of the viewer. The background is primarily a light gray sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.5, "ram_available_mb": 50323.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.156, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.848}, "timestamp": "2026-01-19T15:18:44.090408"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2166.041, "latencies_ms": [2166.041], "images_per_second": 0.462, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A yellow and blue propeller plane with the registration SP-AWF is flying through a cloudy sky. The plane appears to be in motion, moving from left to right in the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.01, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.866}, "timestamp": "2026-01-19T15:18:48.279064"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1753.261, "latencies_ms": [1753.261], "images_per_second": 0.57, "prompt_tokens": 18, "response_tokens_est": 25, "n_tiles": 1, "output_text": "The plane is predominantly yellow with red and blue accents. The lighting conditions appear to be overcast, creating a muted atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.7, "ram_available_mb": 50323.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.709, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.717}, "timestamp": "2026-01-19T15:18:52.068292"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1777.563, "latencies_ms": [1777.563], "images_per_second": 0.563, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "An aerial view from an airplane window showcases a vast parking lot filled with numerous cars, stretching from the foreground to the horizon.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.968, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.796}, "timestamp": "2026-01-19T15:18:55.893195"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2661.91, "latencies_ms": [2661.91], "images_per_second": 0.376, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "airplane wing: 1\nbuildings: 2\nparking lot: 10\ncars: 20\ntrees: 5\nfields: 2\nsky: 2", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.306, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.897}, "timestamp": "2026-01-19T15:19:00.567724"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2946.854, "latencies_ms": [2946.854], "images_per_second": 0.339, "prompt_tokens": 25, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The airplane wing is positioned to the left of the image, occupying a significant portion of the foreground. The parking lot and residential area are situated in the background, extending across the image's width. The vast expanse of the parking lot and the residential area suggest a considerable distance between the plane and the viewer.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12518.7, "ram_available_mb": 50322.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12518.4, "ram_available_mb": 50322.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.005, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.064}, "timestamp": "2026-01-19T15:19:05.550486"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2684.693, "latencies_ms": [2684.693], "images_per_second": 0.372, "prompt_tokens": 19, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene depicts an aerial view of an airport runway with a large parking lot filled with cars, adjacent to residential buildings. A portion of an airplane wing is visible in the top left corner, suggesting the image was taken from a plane flying over the airport.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.366, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 6.996}, "timestamp": "2026-01-19T15:19:10.284226"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2592.658, "latencies_ms": [2592.658], "images_per_second": 0.386, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The sky is blue with a few scattered clouds. The parking lot is filled with various colored cars, reflecting the vibrant atmosphere of the location. The image appears to be taken from an airplane, capturing the expansive view from the wing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12518.1, "ram_available_mb": 50322.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.497, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 6.984}, "timestamp": "2026-01-19T15:19:14.916169"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1480.085, "latencies_ms": [1480.085], "images_per_second": 0.676, "prompt_tokens": 8, "response_tokens_est": 19, "n_tiles": 1, "output_text": "A person is holding a pink flip phone with a picture of Disney Princess Aurora on the screen.", "error": null, "sys_before": {"cpu_percent": 4.8, "ram_used_mb": 12517.6, "ram_available_mb": 50323.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.631, "power_cpu_cv_mean_watts": 1.019, "power_sys_5v0_mean_watts": 5.938}, "timestamp": "2026-01-19T15:19:18.419837"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2740.297, "latencies_ms": [2740.297], "images_per_second": 0.365, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Cell phone: 1\nGift bag: 1\nCup: 1\nChair: 1\nJeans: 2\nSweater: 1\nGift tag: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.651, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 6.694}, "timestamp": "2026-01-19T15:19:23.192643"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2656.021, "latencies_ms": [2656.021], "images_per_second": 0.377, "prompt_tokens": 25, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The pink flip phone is held in the foreground, positioned between the person's hands. The background includes a person's legs and a table with a cup, suggesting the scene is indoors. The phone is held by the person in the foreground, further emphasizing the proximity of the objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.724, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 6.726}, "timestamp": "2026-01-19T15:19:27.869385"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2324.275, "latencies_ms": [2324.275], "images_per_second": 0.43, "prompt_tokens": 19, "response_tokens_est": 48, "n_tiles": 1, "output_text": "Two people are sitting on the floor, enjoying a pink flip phone with a Disney princess image displayed on its screen. A pink dragon-shaped object is held by one of the individuals. The setting appears to be a casual gathering or party.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12517.2, "ram_available_mb": 50323.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.57, "power_cpu_cv_mean_watts": 1.624, "power_sys_5v0_mean_watts": 6.697}, "timestamp": "2026-01-19T15:19:32.231856"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2539.729, "latencies_ms": [2539.729], "images_per_second": 0.394, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The pink flip phone is prominently featured in the image. The lighting is dim, creating a cozy atmosphere. The phone appears to be made of plastic and has a small screen displaying a Disney princess image. The overall scene suggests a casual, intimate gathering.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12517.4, "ram_available_mb": 50323.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.73, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 6.676}, "timestamp": "2026-01-19T15:19:36.795582"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1669.595, "latencies_ms": [1669.595], "images_per_second": 0.599, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "Two zebras stand in a field of tall, dry grass, their black and white stripes contrasting with the golden hues.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12516.7, "ram_available_mb": 50324.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.178, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.784}, "timestamp": "2026-01-19T15:19:40.521160"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2186.005, "latencies_ms": [2186.005], "images_per_second": 0.457, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "zebra: 2\ntall grass: 2\ntree: 1\nleaves: 1\nsky: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.267, "power_cpu_cv_mean_watts": 1.446, "power_sys_5v0_mean_watts": 6.972}, "timestamp": "2026-01-19T15:19:44.735014"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2315.923, "latencies_ms": [2315.923], "images_per_second": 0.432, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The zebra on the left is positioned closer to the viewer, while the zebra on the right is further away, creating a sense of depth. The foreground is dominated by the tall, dry grass, while the background features more vegetation and trees.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12516.6, "ram_available_mb": 50324.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.991, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 6.928}, "timestamp": "2026-01-19T15:19:49.095588"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2142.888, "latencies_ms": [2142.888], "images_per_second": 0.467, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Two zebras stand in a field of tall, dry grass, facing the camera. The setting appears to be a savanna-like environment with scattered trees and shrubs in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.845, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.812}, "timestamp": "2026-01-19T15:19:53.254805"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1910.323, "latencies_ms": [1910.323], "images_per_second": 0.523, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The zebras are black and white, and the grass is a light brown color. The lighting suggests a sunny day, and the materials appear to be natural vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12516.4, "ram_available_mb": 50324.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.756, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.8}, "timestamp": "2026-01-19T15:19:57.196629"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1566.314, "latencies_ms": [1566.314], "images_per_second": 0.638, "prompt_tokens": 8, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A man in black shorts carries a yellow surfboard towards the ocean, preparing to enter the waves.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12515.5, "ram_available_mb": 50325.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.589, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.618}, "timestamp": "2026-01-19T15:20:00.790929"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2475.449, "latencies_ms": [2475.449], "images_per_second": 0.404, "prompt_tokens": 21, "response_tokens_est": 30, "n_tiles": 1, "output_text": "surfboard: 1\nperson: 1\nwater: 6\nwaves: 4\nsky: 1\nsand: 1\nocean: 6", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12515.4, "ram_available_mb": 50325.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.762, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.95}, "timestamp": "2026-01-19T15:20:05.317199"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2610.395, "latencies_ms": [2610.395], "images_per_second": 0.383, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The man is walking towards the ocean, carrying a yellow surfboard. The ocean extends behind him, creating a sense of distance between the man and the water. The surfboard is positioned in the foreground, contrasting with the expansive ocean in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12514.7, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.346, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.955}, "timestamp": "2026-01-19T15:20:09.955734"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2143.033, "latencies_ms": [2143.033], "images_per_second": 0.467, "prompt_tokens": 19, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A man is walking into the ocean with a yellow surfboard, preparing to surf the waves. The ocean is blue and choppy, with waves breaking around him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.034, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.878}, "timestamp": "2026-01-19T15:20:14.125704"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1965.272, "latencies_ms": [1965.272], "images_per_second": 0.509, "prompt_tokens": 18, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The surfer is wearing a yellow shirt and dark shorts. The ocean is a dark blue, and the sky is light blue, suggesting fair weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.047, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T15:20:18.121681"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1415.766, "latencies_ms": [1415.766], "images_per_second": 0.706, "prompt_tokens": 8, "response_tokens_est": 18, "n_tiles": 1, "output_text": "A black and white cow stands calmly on a sandy beach, gazing directly at the camera.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.716, "power_cpu_cv_mean_watts": 0.874, "power_sys_5v0_mean_watts": 6.542}, "timestamp": "2026-01-19T15:20:21.578244"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2736.075, "latencies_ms": [2736.075], "images_per_second": 0.365, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Cow: 1\nSand: 1\nWater: 1\nGround: 1\nPlant: 1\nPlant: 1\nPlant: 1\nPlant: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.239, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 6.909}, "timestamp": "2026-01-19T15:20:26.343998"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1726.229, "latencies_ms": [1726.229], "images_per_second": 0.579, "prompt_tokens": 25, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The cow is positioned near the foreground, facing the viewer. The body of water in the background extends into the distance, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.484, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.745}, "timestamp": "2026-01-19T15:20:30.094314"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1705.317, "latencies_ms": [1705.317], "images_per_second": 0.586, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A black and white cow stands on a sandy beach, facing the camera. The calm water in the background creates a serene and picturesque setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.054, "power_cpu_cv_mean_watts": 1.078, "power_sys_5v0_mean_watts": 6.776}, "timestamp": "2026-01-19T15:20:33.847567"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2153.719, "latencies_ms": [2153.719], "images_per_second": 0.464, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The cow is black and white. The lighting is soft and diffused, creating a calm atmosphere. The cow is standing on a sandy beach, which adds to the overall serene and peaceful setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.345, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.884}, "timestamp": "2026-01-19T15:20:38.046713"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1838.405, "latencies_ms": [1838.405], "images_per_second": 0.544, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A woman, dressed in winter attire, stands confidently in the snow, holding skis and poles, ready for a skiing adventure.", "error": null, "sys_before": {"cpu_percent": 13.6, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.921, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.236}, "timestamp": "2026-01-19T15:20:41.910123"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2818.646, "latencies_ms": [2818.646], "images_per_second": 0.355, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "woman: 2\nskis: 1\nsnowboard: 1\ngloves: 1\nski poles: 1\nbelt: 1\nskis: 1\ntree: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.598, "power_cpu_cv_mean_watts": 1.707, "power_sys_5v0_mean_watts": 6.683}, "timestamp": "2026-01-19T15:20:46.753284"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2002.477, "latencies_ms": [2002.477], "images_per_second": 0.499, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The woman is positioned in the foreground, holding ski poles and standing near a pair of skis. The background features trees and a cloudy sky, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.164, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.432}, "timestamp": "2026-01-19T15:20:50.776369"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1925.227, "latencies_ms": [1925.227], "images_per_second": 0.519, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A woman is posing in a snowy setting, dressed in ski gear and holding skis and poles. She appears to be enjoying a skiing adventure.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.787, "power_cpu_cv_mean_watts": 1.228, "power_sys_5v0_mean_watts": 6.236}, "timestamp": "2026-01-19T15:20:54.736897"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2193.395, "latencies_ms": [2193.395], "images_per_second": 0.456, "prompt_tokens": 18, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The woman is wearing black and white clothing. The lighting appears to be natural, possibly from the sky, creating a contrast against the darker background. The image also shows snow and pine branches, suggesting an outdoor winter setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.415, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.518}, "timestamp": "2026-01-19T15:20:58.962871"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1477.072, "latencies_ms": [1477.072], "images_per_second": 0.677, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A black and white dog is standing on a sandy beach, holding a yellow frisbee in its mouth.", "error": null, "sys_before": {"cpu_percent": 4.2, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.188, "power_cpu_cv_mean_watts": 0.947, "power_sys_5v0_mean_watts": 6.735}, "timestamp": "2026-01-19T15:21:02.480940"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2605.836, "latencies_ms": [2605.836], "images_per_second": 0.384, "prompt_tokens": 21, "response_tokens_est": 34, "n_tiles": 1, "output_text": "yellow frisbee: 1\nsand: 6\nocean: 6\ndog: 1\npink nose: 1\nwaves: 2\nisland: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.632, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 6.974}, "timestamp": "2026-01-19T15:21:07.130840"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2460.827, "latencies_ms": [2460.827], "images_per_second": 0.406, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The dog is positioned in the foreground, facing the camera. The yellow frisbee is held in the dog's mouth, close to the dog's nose. The beach extends in the background, meeting the turquoise ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.664, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.945}, "timestamp": "2026-01-19T15:21:11.638151"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2264.123, "latencies_ms": [2264.123], "images_per_second": 0.442, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene is set on a sandy beach near the ocean, where a dog is holding a yellow frisbee in its mouth. The ocean is visible in the background, with waves gently lapping at the shore.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.36, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T15:21:15.942234"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2782.808, "latencies_ms": [2782.808], "images_per_second": 0.359, "prompt_tokens": 18, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The dog is primarily black and white with patches of gray. The beach is sandy and appears wet, suggesting recent rain or ocean spray. The lighting is bright, likely from overcast skies, giving the scene a cool and somewhat muted tone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.094, "power_cpu_cv_mean_watts": 1.568, "power_sys_5v0_mean_watts": 6.972}, "timestamp": "2026-01-19T15:21:20.761292"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1228.51, "latencies_ms": [1228.51], "images_per_second": 0.814, "prompt_tokens": 8, "response_tokens_est": 14, "n_tiles": 1, "output_text": "A group of people are gathered in a kitchen, preparing food together.", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.935, "power_cpu_cv_mean_watts": 0.756, "power_sys_5v0_mean_watts": 6.608}, "timestamp": "2026-01-19T15:21:24.033660"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2972.137, "latencies_ms": [2972.137], "images_per_second": 0.336, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "Refrigerator: 2\nCountertop: 1\nPot: 1\nGlass: 1\nBowl: 1\nBox: 1\nLid: 1\nShelves: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.957, "power_cpu_cv_mean_watts": 1.698, "power_sys_5v0_mean_watts": 7.06}, "timestamp": "2026-01-19T15:21:29.051030"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2145.738, "latencies_ms": [2145.738], "images_per_second": 0.466, "prompt_tokens": 25, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The large stainless steel refrigerator occupies the central foreground, positioned between the people and the countertop. The kitchen area extends beyond the refrigerator, occupying the background of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.551, "power_cpu_cv_mean_watts": 1.343, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T15:21:33.247264"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1869.659, "latencies_ms": [1869.659], "images_per_second": 0.535, "prompt_tokens": 19, "response_tokens_est": 32, "n_tiles": 1, "output_text": "A group of people are gathered in a kitchen, preparing food. A large stainless steel refrigerator is prominently visible, along with various kitchen items and utensils.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.023, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.793}, "timestamp": "2026-01-19T15:21:37.138496"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2288.952, "latencies_ms": [2288.952], "images_per_second": 0.437, "prompt_tokens": 18, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The kitchen is equipped with stainless steel appliances and features natural lighting, creating a bright and clean atmosphere. The walls are painted in a light color, contributing to the overall brightness of the space.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.905, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.928}, "timestamp": "2026-01-19T15:21:41.465324"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1776.638, "latencies_ms": [1776.638], "images_per_second": 0.563, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A bathroom features a white toilet, neatly arranged toiletries on a shelf, and a towel rack with folded white towels.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.115, "power_cpu_cv_mean_watts": 1.171, "power_sys_5v0_mean_watts": 6.784}, "timestamp": "2026-01-19T15:21:45.266519"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3469.817, "latencies_ms": [3469.817], "images_per_second": 0.288, "prompt_tokens": 21, "response_tokens_est": 45, "n_tiles": 1, "output_text": "toilet: 1\ntowel: 2\nsoap dispenser: 4\nshampoo bottle: 2\nlipstick: 2\nmini towel: 2\ntoilet paper: 1\nbathroom phone: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.577, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 7.138}, "timestamp": "2026-01-19T15:21:50.760511"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2395.549, "latencies_ms": [2395.549], "images_per_second": 0.417, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, slightly to the right of the shelf. The shelf is situated in the background, slightly to the left of the toilet. The toilet is situated further back in the image, near the edge of the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.4, "ram_available_mb": 50330.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 12510.9, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.484, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 6.875}, "timestamp": "2026-01-19T15:21:55.188616"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2419.126, "latencies_ms": [2419.126], "images_per_second": 0.413, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The bathroom features a modern design with beige tile walls, a white toilet, and a built-in shelf with toiletries and towels. A telephone is mounted on the wall, and a toilet brush and holder are positioned nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.9, "ram_available_mb": 50329.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.681, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 7.0}, "timestamp": "2026-01-19T15:21:59.653839"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2759.386, "latencies_ms": [2759.386], "images_per_second": 0.362, "prompt_tokens": 18, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The bathroom features a beige color scheme, creating a warm and inviting atmosphere. The lighting is soft and diffused, enhancing the cleanliness and comfort of the space. The materials appear to be high-quality tiles and polished metal, contributing to the sleek and modern aesthetic.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.1, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 7.033}, "timestamp": "2026-01-19T15:22:04.430372"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1645.402, "latencies_ms": [1645.402], "images_per_second": 0.608, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "A woman in a green top hat sits in the driver's seat of a decorated truck, accompanied by her beagle wearing a green hat.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 12510.6, "ram_available_mb": 50330.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.182, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 6.296}, "timestamp": "2026-01-19T15:22:08.107416"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2924.978, "latencies_ms": [2924.978], "images_per_second": 0.342, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "woman: 1\ndog: 1\nhat: 1\nIrish flag: 1\nmirror: 1\nshamrock: 1\ntruck: 1\nwindshield wiper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.831, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 6.846}, "timestamp": "2026-01-19T15:22:13.064142"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2393.984, "latencies_ms": [2393.984], "images_per_second": 0.418, "prompt_tokens": 25, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The woman and dog are positioned in the left foreground of the image. The Irish flag and shamrock decoration are placed near the vehicle's side mirror and window, suggesting the context of a parade or celebration.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.277, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.578}, "timestamp": "2026-01-19T15:22:17.477197"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2170.699, "latencies_ms": [2170.699], "images_per_second": 0.461, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A woman and a beagle are sitting in the back of a truck decorated for St. Patrick's Day. The truck is adorned with green shamrocks and an Irish flag, creating a festive atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.779, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.563}, "timestamp": "2026-01-19T15:22:21.684009"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2278.459, "latencies_ms": [2278.459], "images_per_second": 0.439, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The vehicle is decorated with green and orange colors, reflecting the Irish flag. The lighting suggests an outdoor setting, likely during daytime. The materials appear to be metal and plastic, typical for vehicles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.592, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 6.529}, "timestamp": "2026-01-19T15:22:25.985401"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1569.405, "latencies_ms": [1569.405], "images_per_second": 0.637, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "An adult elephant is walking through a shallow pool of water in a zoo enclosure, surrounded by rocks and dirt.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.146, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.66}, "timestamp": "2026-01-19T15:22:29.611894"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3124.706, "latencies_ms": [3124.706], "images_per_second": 0.32, "prompt_tokens": 21, "response_tokens_est": 39, "n_tiles": 1, "output_text": "Elephant: 1\nLog: 1\nWater: 1\nRocks: 3\nGround: 2\nFence: 1\nGround: 1\nPlants: 2\nPeople: 2", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.686, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.027}, "timestamp": "2026-01-19T15:22:34.774883"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2145.558, "latencies_ms": [2145.558], "images_per_second": 0.466, "prompt_tokens": 25, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The elephant is positioned in the foreground, facing the viewer. The background features other elements like rocks, trees, and people, suggesting the setting is a zoo or wildlife park.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12514.0, "ram_available_mb": 50326.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.528, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.907}, "timestamp": "2026-01-19T15:22:38.960861"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2396.39, "latencies_ms": [2396.39], "images_per_second": 0.417, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The scene depicts an elephant in a zoo enclosure, walking through a shallow pool of water near rocks. The enclosure features a dirt ground, trees, and fencing, with visitors observing the elephant from nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.58, "power_cpu_cv_mean_watts": 1.382, "power_sys_5v0_mean_watts": 6.894}, "timestamp": "2026-01-19T15:22:43.396255"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2845.281, "latencies_ms": [2845.281], "images_per_second": 0.351, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The elephant is gray and appears to be wet. The lighting is bright, likely from sunlight, creating a contrast against the gray of the elephant and the brown of the ground. The enclosure is constructed with natural materials like rocks and dirt, enhancing the overall natural feel of the habitat.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.299, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.021}, "timestamp": "2026-01-19T15:22:48.267906"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1847.867, "latencies_ms": [1847.867], "images_per_second": 0.541, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "Four people in winter gear, including skis, stand on a snowy mountain slope, smiling and enjoying their skiing adventure.", "error": null, "sys_before": {"cpu_percent": 3.8, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.651, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.71}, "timestamp": "2026-01-19T15:22:52.150457"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2589.069, "latencies_ms": [2589.069], "images_per_second": 0.386, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "person: 4\nski: 2\nsnow: 6\nmountain: 5\nsky: 1\ntrees: 1\nski lift: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.574, "power_cpu_cv_mean_watts": 1.43, "power_sys_5v0_mean_watts": 6.974}, "timestamp": "2026-01-19T15:22:56.782435"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2027.984, "latencies_ms": [2027.984], "images_per_second": 0.493, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The skiers are positioned in the foreground of the image, with the snow-covered mountain range in the background. The skiers are standing relatively close together, creating a sense of proximity.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.371, "power_cpu_cv_mean_watts": 1.176, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T15:23:00.841381"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2603.471, "latencies_ms": [2603.471], "images_per_second": 0.384, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "A group of four people are standing on a snowy mountain, wearing ski gear and holding ski poles. They are likely taking a break from skiing or posing for a photo. The mountain is covered in snow, with snow-capped peaks visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.421, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 6.878}, "timestamp": "2026-01-19T15:23:05.461873"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2814.334, "latencies_ms": [2814.334], "images_per_second": 0.355, "prompt_tokens": 18, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The group is wearing bright, colorful winter clothing. The lighting is bright and sunny, creating a pleasant atmosphere. The snow appears to be well-groomed and smooth, typical of ski slopes. The weather appears to be clear and sunny, ideal for skiing activities.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 12513.9, "ram_available_mb": 50327.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.126, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.016}, "timestamp": "2026-01-19T15:23:10.335032"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1508.086, "latencies_ms": [1508.086], "images_per_second": 0.663, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "A person is holding a black iPhone in their hand, displaying a photo of a tree on the screen.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.49, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.644}, "timestamp": "2026-01-19T15:23:13.907103"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2787.238, "latencies_ms": [2787.238], "images_per_second": 0.359, "prompt_tokens": 21, "response_tokens_est": 33, "n_tiles": 1, "output_text": "phone: 2\nkeyboard: 1\nmirror: 1\nhand: 1\ntree: 1\nsky: 1\nwindow: 1\nbutton: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.023, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 6.978}, "timestamp": "2026-01-19T15:23:18.712235"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2080.602, "latencies_ms": [2080.602], "images_per_second": 0.481, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main object is a smartphone held in the left foreground, partially obscuring a keyboard in the background. The smartphone is positioned near the keyboard, suggesting the photo was taken close to the keyboard.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.576, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.942}, "timestamp": "2026-01-19T15:23:22.808836"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2027.618, "latencies_ms": [2027.618], "images_per_second": 0.493, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A person is holding a black iPhone in their hand, displaying a photo of a tree and a keyboard. The photo appears to be taken indoors, possibly on a desk or table.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.221, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.816}, "timestamp": "2026-01-19T15:23:26.871137"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2472.837, "latencies_ms": [2472.837], "images_per_second": 0.404, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The phone's screen displays a black and white image, likely taken in low light conditions. The reflection shows a person's hand and a keyboard, suggesting the phone is held in a dimly lit environment. The phone appears to be made of metal.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.499, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.008}, "timestamp": "2026-01-19T15:23:31.393806"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1853.724, "latencies_ms": [1853.724], "images_per_second": 0.539, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A Denver's Road Home parking meter is mounted on a metal pole beside a sidewalk, with a sign urging people to end homelessness.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.053, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.84}, "timestamp": "2026-01-19T15:23:35.286048"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2629.928, "latencies_ms": [2629.928], "images_per_second": 0.38, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Parking meter: 1\nSign: 1\nPlants: 2\nFence: 1\nSidewalk: 1\nTrees: 2\nGround: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.555, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 7.041}, "timestamp": "2026-01-19T15:23:39.935435"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2185.621, "latencies_ms": [2185.621], "images_per_second": 0.458, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The parking meter is positioned in the foreground, slightly to the right of the image. The sign is situated in the background, near the parking meter. The parking meter and sign are located close to the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.505, "power_cpu_cv_mean_watts": 1.437, "power_sys_5v0_mean_watts": 6.931}, "timestamp": "2026-01-19T15:23:44.157665"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2085.139, "latencies_ms": [2085.139], "images_per_second": 0.48, "prompt_tokens": 19, "response_tokens_est": 30, "n_tiles": 1, "output_text": "A Denver's Road Home parking meter is situated on a sidewalk near a fence and trees. A sign on the meter promotes a campaign to end homelessness.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12514.1, "ram_available_mb": 50326.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.915, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.812}, "timestamp": "2026-01-19T15:23:48.290382"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1952.715, "latencies_ms": [1952.715], "images_per_second": 0.512, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The parking meter is primarily red and gray. The lighting appears to be natural daylight. The materials appear to be metal and plastic. The weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.996, "power_cpu_cv_mean_watts": 1.176, "power_sys_5v0_mean_watts": 6.69}, "timestamp": "2026-01-19T15:23:52.272129"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1554.792, "latencies_ms": [1554.792], "images_per_second": 0.643, "prompt_tokens": 8, "response_tokens_est": 23, "n_tiles": 1, "output_text": "A group of zebras graze peacefully in a dry, grassy field surrounded by trees and shrubs.", "error": null, "sys_before": {"cpu_percent": 11.4, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.256, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 6.636}, "timestamp": "2026-01-19T15:23:55.901389"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2252.578, "latencies_ms": [2252.578], "images_per_second": 0.444, "prompt_tokens": 21, "response_tokens_est": 24, "n_tiles": 1, "output_text": "zebra: 5\ngrass: 2\ntree: 1\nbush: 1\nground: 2\nwater: 0", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.91, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.826}, "timestamp": "2026-01-19T15:24:00.191689"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2454.706, "latencies_ms": [2454.706], "images_per_second": 0.407, "prompt_tokens": 25, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The main zebra is positioned in the foreground, grazing on the dry grass. The background features other zebras, creating a sense of depth and space. The zebra is relatively close to the viewer, emphasizing its presence in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.321, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.874}, "timestamp": "2026-01-19T15:24:04.695333"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2211.399, "latencies_ms": [2211.399], "images_per_second": 0.452, "prompt_tokens": 19, "response_tokens_est": 41, "n_tiles": 1, "output_text": "A group of zebras grazes in a grassy field with scattered trees and shrubs in the background. The zebras are spread out across the field, engaged in their natural feeding behavior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.088, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 6.86}, "timestamp": "2026-01-19T15:24:08.941202"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2875.495, "latencies_ms": [2875.495], "images_per_second": 0.348, "prompt_tokens": 18, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The zebras exhibit striking black and white stripes, creating a mesmerizing pattern. The lighting in the image is bright and evenly distributed, illuminating the zebras and grass. The zebras appear to be grazing in a grassy field with scattered bushes in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.038, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T15:24:13.844312"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1865.027, "latencies_ms": [1865.027], "images_per_second": 0.536, "prompt_tokens": 8, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A surfer in a black wetsuit rides a wave on a surfboard, skillfully navigating the powerful ocean currents.", "error": null, "sys_before": {"cpu_percent": 13.8, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.358, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.767}, "timestamp": "2026-01-19T15:24:17.746924"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2328.187, "latencies_ms": [2328.187], "images_per_second": 0.43, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "surfboard: 1\nwetsuit: 1\nwater: 1\nwave: 1\nperson: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.159, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 6.966}, "timestamp": "2026-01-19T15:24:22.093961"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1842.644, "latencies_ms": [1842.644], "images_per_second": 0.543, "prompt_tokens": 25, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The surfer is positioned in the foreground of the image, riding a wave. The ocean extends in the background, creating a sense of depth and distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.824, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.753}, "timestamp": "2026-01-19T15:24:25.963895"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2316.26, "latencies_ms": [2316.26], "images_per_second": 0.432, "prompt_tokens": 19, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The scene depicts a surfer skillfully riding a wave in the ocean. The surfer is wearing a black wetsuit and is positioned on a surfboard, demonstrating their expertise in surfing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.137, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 6.965}, "timestamp": "2026-01-19T15:24:30.327134"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1832.474, "latencies_ms": [1832.474], "images_per_second": 0.546, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The surfer is wearing a black wetsuit. The ocean appears dark blue-green, and the lighting suggests a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.971, "power_cpu_cv_mean_watts": 1.148, "power_sys_5v0_mean_watts": 6.74}, "timestamp": "2026-01-19T15:24:34.187579"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1814.496, "latencies_ms": [1814.496], "images_per_second": 0.551, "prompt_tokens": 8, "response_tokens_est": 28, "n_tiles": 1, "output_text": "Two individuals in white snowsuits are standing on a snowy mountain slope, one holding a pair of skis and the other a backpack.", "error": null, "sys_before": {"cpu_percent": 8.0, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.023, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.775}, "timestamp": "2026-01-19T15:24:38.039524"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3226.649, "latencies_ms": [3226.649], "images_per_second": 0.31, "prompt_tokens": 21, "response_tokens_est": 40, "n_tiles": 1, "output_text": "skis: 2\nbackpack: 1\ngloves: 1\ngloves: 1\ncamera: 1\ncamera: 1\npole: 1\nsun: 1\nsnow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.561, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 7.063}, "timestamp": "2026-01-19T15:24:43.291586"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2001.107, "latencies_ms": [2001.107], "images_per_second": 0.5, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The skis are positioned in the foreground, while the snowboarder is further back, near the sun. The snowboarder's position suggests they are moving away from the sun.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.652, "power_cpu_cv_mean_watts": 1.352, "power_sys_5v0_mean_watts": 6.936}, "timestamp": "2026-01-19T15:24:47.338563"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2227.352, "latencies_ms": [2227.352], "images_per_second": 0.449, "prompt_tokens": 19, "response_tokens_est": 37, "n_tiles": 1, "output_text": "Two individuals in winter gear are on a snowy mountain slope, preparing for skiing or snowboarding. They are standing near ski poles and skis, with the sun setting in the background.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12511.9, "ram_available_mb": 50329.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.201, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.916}, "timestamp": "2026-01-19T15:24:51.604576"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2395.725, "latencies_ms": [2395.725], "images_per_second": 0.417, "prompt_tokens": 18, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The snow is white and appears smooth. The lighting suggests a late afternoon or early evening scene, with the sun casting a warm glow. The snow is relatively undisturbed and appears undisturbed by human activity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.179, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 6.976}, "timestamp": "2026-01-19T15:24:56.016220"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1983.124, "latencies_ms": [1983.124], "images_per_second": 0.504, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A youth baseball game is in progress, with a batter in a red uniform swinging a bat, while a catcher in black crouches behind him.", "error": null, "sys_before": {"cpu_percent": 6.5, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.447, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 6.879}, "timestamp": "2026-01-19T15:25:00.041211"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3445.04, "latencies_ms": [3445.04], "images_per_second": 0.29, "prompt_tokens": 21, "response_tokens_est": 46, "n_tiles": 1, "output_text": "baseball bat: 1\nbaseball glove: 1\nbaseball: 1\ncatcher: 1\numpire: 1\nbaseball field: 1\nfence: 2\ncars: 2\nspectators: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.565, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.132}, "timestamp": "2026-01-19T15:25:05.505959"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2739.396, "latencies_ms": [2739.396], "images_per_second": 0.365, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The batter is positioned in the foreground, facing the catcher and glove. The catcher and glove are located in the background, behind the batter. The scene is set in a baseball field, with a chain-link fence separating the field from the spectators.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.64, "power_cpu_cv_mean_watts": 1.584, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T15:25:10.270623"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3013.621, "latencies_ms": [3013.621], "images_per_second": 0.332, "prompt_tokens": 19, "response_tokens_est": 54, "n_tiles": 1, "output_text": "A youth baseball game is taking place on a field. A batter in a red uniform is swinging a bat, while a catcher in a black uniform crouches behind home plate, ready to catch the ball. Spectators are watching from the sidelines, seated in lawn chairs.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.972, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 7.076}, "timestamp": "2026-01-19T15:25:15.309574"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2230.823, "latencies_ms": [2230.823], "images_per_second": 0.448, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The batter is wearing a red uniform. The field appears to be well-maintained and appears to be made of a hard, potentially synthetic material. The lighting suggests an outdoor setting on sunny days.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.022, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.921}, "timestamp": "2026-01-19T15:25:19.556628"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2683.071, "latencies_ms": [2683.071], "images_per_second": 0.373, "prompt_tokens": 8, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A tall glass filled with a creamy beverage, possibly a milkshake or a smoothie, topped with whipped cream, sits next to a slice of layered vanilla cake on a white plate, accompanied by a fork and a napkin.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.494, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 7.01}, "timestamp": "2026-01-19T15:25:24.284752"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2793.249, "latencies_ms": [2793.249], "images_per_second": 0.358, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "Cake: 1\nMilkshake: 1\nFork: 2\nNapkin: 1\nTable: 1\nGlass: 1\nWater: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12513.8, "ram_available_mb": 50327.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.386, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.078}, "timestamp": "2026-01-19T15:25:29.107204"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2563.271, "latencies_ms": [2563.271], "images_per_second": 0.39, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The cake and milkshake are placed in the foreground of the image, with the milkshake positioned slightly behind and to the left of the cake. The background of the image is blurred, indicating a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.497, "power_cpu_cv_mean_watts": 1.583, "power_sys_5v0_mean_watts": 7.041}, "timestamp": "2026-01-19T15:25:33.691967"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2925.81, "latencies_ms": [2925.81], "images_per_second": 0.342, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a cozy setting with a table featuring a slice of layered cake, a tall glass of chocolate milkshake with whipped cream, and two forks. The table is situated in a restaurant or cafe, with other tables and chairs visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.47, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.064}, "timestamp": "2026-01-19T15:25:38.634015"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2314.986, "latencies_ms": [2314.986], "images_per_second": 0.432, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The milkshake is brown and appears creamy. The cake is light yellow and looks moist and fluffy. The table is dark brown, and the lighting is soft and warm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.096, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T15:25:42.969749"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2042.413, "latencies_ms": [2042.413], "images_per_second": 0.49, "prompt_tokens": 8, "response_tokens_est": 33, "n_tiles": 1, "output_text": "A three-tiered wedding cake, featuring white frosting, blue and gold accents, and floral decorations, sits on a table draped with a blue tablecloth.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12514.6, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.515, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.419}, "timestamp": "2026-01-19T15:25:47.065113"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2414.367, "latencies_ms": [2414.367], "images_per_second": 0.414, "prompt_tokens": 21, "response_tokens_est": 29, "n_tiles": 1, "output_text": "cake: 3\nfloral arrangement: 1\nchandelier: 1\ntablecloth: 1\nchairs: 2\nwater view: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12514.6, "ram_available_mb": 50326.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.254, "power_cpu_cv_mean_watts": 1.582, "power_sys_5v0_mean_watts": 6.552}, "timestamp": "2026-01-19T15:25:51.508759"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2387.293, "latencies_ms": [2387.293], "images_per_second": 0.419, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The large three-tiered wedding cake dominates the foreground, positioned slightly to the right of the viewer. The dining area with tables, chairs, and umbrellas extends in the background, extending beyond the cake's immediate vicinity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12514.9, "ram_available_mb": 50326.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.889, "power_cpu_cv_mean_watts": 1.644, "power_sys_5v0_mean_watts": 6.716}, "timestamp": "2026-01-19T15:25:55.946042"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2942.486, "latencies_ms": [2942.486], "images_per_second": 0.34, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The scene depicts a wedding reception held in a spacious room with large windows overlooking the ocean. A three-tiered wedding cake, featuring white and gold icing, is prominently displayed on a table covered with a blue tablecloth. The cake is adorned with flowers and has a figurine on top.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12514.2, "ram_available_mb": 50326.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.698, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 6.812}, "timestamp": "2026-01-19T15:26:00.922441"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2350.924, "latencies_ms": [2350.924], "images_per_second": 0.425, "prompt_tokens": 18, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The wedding cake is predominantly white with gold accents. The lighting in the room is warm and inviting, creating a pleasant atmosphere. The cake appears to be made of edible materials, possibly fondant or icing, and features intricate designs.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.699, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 6.674}, "timestamp": "2026-01-19T15:26:05.300650"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1617.033, "latencies_ms": [1617.033], "images_per_second": 0.618, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A woman in a red and blue sweater is cooking on a stove, skillfully stirring a pot of food.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.744, "power_cpu_cv_mean_watts": 1.016, "power_sys_5v0_mean_watts": 6.605}, "timestamp": "2026-01-19T15:26:08.994786"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3237.351, "latencies_ms": [3237.351], "images_per_second": 0.309, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "pan: 2\nplate: 1\npot: 1\nstove: 1\nsaucepan: 1\nspices: 2\nshelves: 2\nspoon: 1\nwoman: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 7.8, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.975, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 7.102}, "timestamp": "2026-01-19T15:26:14.254154"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2088.454, "latencies_ms": [2088.454], "images_per_second": 0.479, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The woman is standing near the stove, preparing food. She is positioned in the foreground of the image, with the stove and pots behind her. The kitchen setting is partially visible in the background.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.625, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 6.973}, "timestamp": "2026-01-19T15:26:18.393728"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2458.636, "latencies_ms": [2458.636], "images_per_second": 0.407, "prompt_tokens": 19, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A woman is cooking in a kitchen, using a spoon to stir food on a plate. She is wearing a red and blue sweater and gray pants. The kitchen has various items and appliances, including a stove, pots, and bottles.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.823, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:26:22.878817"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1845.289, "latencies_ms": [1845.289], "images_per_second": 0.542, "prompt_tokens": 18, "response_tokens_est": 27, "n_tiles": 1, "output_text": "The woman is wearing a red and blue sweater. The kitchen has warm lighting. The scene suggests a cozy, home-cooked meal.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12514.4, "ram_available_mb": 50326.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.705, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.827}, "timestamp": "2026-01-19T15:26:26.786440"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1757.409, "latencies_ms": [1757.409], "images_per_second": 0.569, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A woman in a pink shirt and black pants is leading a white horse across a dirt field, holding the reins securely.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.165, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.739}, "timestamp": "2026-01-19T15:26:30.593206"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2968.4, "latencies_ms": [2968.4], "images_per_second": 0.337, "prompt_tokens": 21, "response_tokens_est": 38, "n_tiles": 1, "output_text": "horse: 1\nrope: 1\nwoman: 1\npants: 1\nboots: 1\nbelt: 1\nshirt: 1\nfence: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.149, "power_cpu_cv_mean_watts": 1.634, "power_sys_5v0_mean_watts": 7.108}, "timestamp": "2026-01-19T15:26:35.602297"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2514.293, "latencies_ms": [2514.293], "images_per_second": 0.398, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The white horse is positioned to the left of the woman, who is positioned in the foreground. The horse and woman are relatively close together, with the horse being more prominent in the foreground. The background is slightly blurred, drawing focus to the woman and the horse.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.745, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 7.065}, "timestamp": "2026-01-19T15:26:40.135653"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2380.843, "latencies_ms": [2380.843], "images_per_second": 0.42, "prompt_tokens": 19, "response_tokens_est": 46, "n_tiles": 1, "output_text": "A woman is leading a white horse across a dirt field. She is wearing a pink shirt, black pants, and brown boots. The setting appears to be a fenced-in area, possibly a horse farm or training facility.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12514.6, "ram_available_mb": 50326.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.786, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 6.935}, "timestamp": "2026-01-19T15:26:44.531087"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2430.224, "latencies_ms": [2430.224], "images_per_second": 0.411, "prompt_tokens": 18, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The horse is light gray or white. The lighting is bright, likely from natural sunlight, creating a pleasant atmosphere. The woman is wearing brown boots and a pink shirt, suggesting an outdoor setting in sunny weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.7, "ram_available_mb": 50327.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.642, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.914}, "timestamp": "2026-01-19T15:26:48.995328"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1703.522, "latencies_ms": [1703.522], "images_per_second": 0.587, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A city street is lined with tall buildings, cars, and trees, with traffic signs and streetlights visible.", "error": null, "sys_before": {"cpu_percent": 4.5, "ram_used_mb": 12513.6, "ram_available_mb": 50327.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.081, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.724}, "timestamp": "2026-01-19T15:26:52.734879"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3523.217, "latencies_ms": [3523.217], "images_per_second": 0.284, "prompt_tokens": 21, "response_tokens_est": 47, "n_tiles": 1, "output_text": "7AM-7PM: 2\nBicycle: 1\nTraffic light: 2\nStreet sign: 2\nBus: 1\nCars: 4\nTruck: 1\nTrees: 4\nBuildings: 6", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12512.8, "ram_available_mb": 50328.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.758, "power_cpu_cv_mean_watts": 1.796, "power_sys_5v0_mean_watts": 7.129}, "timestamp": "2026-01-19T15:26:58.276375"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2269.511, "latencies_ms": [2269.511], "images_per_second": 0.441, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The foreground features a street with cars, trees, and street signs. The background showcases a city street with buildings, cars, and traffic lights. The street appears relatively empty of pedestrians.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12512.8, "ram_available_mb": 50328.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.224, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.949}, "timestamp": "2026-01-19T15:27:02.565790"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2350.431, "latencies_ms": [2350.431], "images_per_second": 0.425, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The scene depicts a city street on a foggy day, with cars driving down the road and buildings lining the sides. Traffic lights and street signs are visible, indicating a controlled urban environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.015, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.923}, "timestamp": "2026-01-19T15:27:06.958200"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2867.477, "latencies_ms": [2867.477], "images_per_second": 0.349, "prompt_tokens": 18, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The scene is dominated by muted colors due to the overcast sky and bare trees. The lighting is soft and diffused, typical of an overcast day. The buildings are constructed of concrete and glass, giving a modern and urban feel to the setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.354, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 7.042}, "timestamp": "2026-01-19T15:27:11.862208"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1636.345, "latencies_ms": [1636.345], "images_per_second": 0.611, "prompt_tokens": 8, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A stainless steel toilet with a lid and seat is situated in a tiled bathroom, accompanied by a blue toilet brush.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.78, "power_cpu_cv_mean_watts": 1.101, "power_sys_5v0_mean_watts": 6.132}, "timestamp": "2026-01-19T15:27:15.534224"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4437.354, "latencies_ms": [4437.354], "images_per_second": 0.225, "prompt_tokens": 21, "response_tokens_est": 61, "n_tiles": 1, "output_text": "toilet: 1\ntoilet brush: 1\ntoilet cleaner: 1\ntoilet seat: 1\ntoilet bowl: 1\ntoilet lid: 1\ntoilet flushing mechanism: 1\ntoilet base: 1\ntoilet seat cover: 1\ntoilet seat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 10.21, "power_cpu_cv_mean_watts": 2.024, "power_sys_5v0_mean_watts": 7.08}, "timestamp": "2026-01-19T15:27:21.993304"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2084.712, "latencies_ms": [2084.712], "images_per_second": 0.48, "prompt_tokens": 25, "response_tokens_est": 42, "n_tiles": 1, "output_text": "The toilet is positioned in the foreground, slightly to the right of the image. The toilet brush is situated near the toilet, closer to the viewer. The tiled floor extends from the toilet towards the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.3, "ram_available_mb": 50327.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.143, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 6.409}, "timestamp": "2026-01-19T15:27:26.105417"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1858.112, "latencies_ms": [1858.112], "images_per_second": 0.538, "prompt_tokens": 19, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The scene depicts a bathroom interior with a stainless steel toilet, tiled walls, and a metal frame. A toilet brush and cleaning supplies are also present.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.187, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.397}, "timestamp": "2026-01-19T15:27:29.981211"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1857.126, "latencies_ms": [1857.126], "images_per_second": 0.538, "prompt_tokens": 18, "response_tokens_est": 31, "n_tiles": 1, "output_text": "The bathroom features a metallic toilet bowl and silver fixtures. The floor is tiled with beige tiles. The lighting is bright, likely from overhead fixtures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.214, "power_cpu_cv_mean_watts": 1.373, "power_sys_5v0_mean_watts": 6.343}, "timestamp": "2026-01-19T15:27:33.881539"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1901.344, "latencies_ms": [1901.344], "images_per_second": 0.526, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A pink bicycle with a flower garland on the handlebars is parked in a bike shop, surrounded by other bicycles of various colors and styles.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.783, "power_cpu_cv_mean_watts": 1.255, "power_sys_5v0_mean_watts": 6.874}, "timestamp": "2026-01-19T15:27:37.841097"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3762.315, "latencies_ms": [3762.315], "images_per_second": 0.266, "prompt_tokens": 21, "response_tokens_est": 53, "n_tiles": 1, "output_text": "bicycle: 5\nbicycle wheel: 4\nbicycle seat: 2\nbicycle handlebars: 2\nbicycle frame: 1\nbicycle tire: 2\nbicycle leash: 1\nbicycle flowers: 1\nbicycle mirror: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.194, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 7.14}, "timestamp": "2026-01-19T15:27:43.629187"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2560.696, "latencies_ms": [2560.696], "images_per_second": 0.391, "prompt_tokens": 25, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The main object, a pink bicycle, is positioned in the foreground of the image. The background features other bicycles and accessories, creating a sense of depth and space. The bicycle is situated close to the viewer, drawing attention to its vibrant color and design.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.306, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 6.984}, "timestamp": "2026-01-19T15:27:48.216682"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2890.805, "latencies_ms": [2890.805], "images_per_second": 0.346, "prompt_tokens": 19, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The scene depicts a bike shop with a row of bicycles neatly parked and decorated with flowers. A woman is visible in the background, possibly browsing or shopping for bikes. The shop has a clean, minimalist design with light-colored wood floors and a white wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.004, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.035}, "timestamp": "2026-01-19T15:27:53.140635"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2125.88, "latencies_ms": [2125.88], "images_per_second": 0.47, "prompt_tokens": 18, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The pink bicycle stands out against the light wood floor. The bicycle is adorned with a floral garland, adding a touch of color and festive flair to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.9, "ram_available_mb": 50328.0, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.48, "power_cpu_cv_mean_watts": 1.367, "power_sys_5v0_mean_watts": 6.925}, "timestamp": "2026-01-19T15:27:57.304091"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1923.78, "latencies_ms": [1923.78], "images_per_second": 0.52, "prompt_tokens": 8, "response_tokens_est": 31, "n_tiles": 1, "output_text": "A majestic giraffe with a long neck and distinctive brown and tan spots stands tall in a dry savanna landscape, surrounded by sparse trees and shrubs.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.729, "power_cpu_cv_mean_watts": 1.282, "power_sys_5v0_mean_watts": 6.888}, "timestamp": "2026-01-19T15:28:01.268936"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2286.889, "latencies_ms": [2286.889], "images_per_second": 0.437, "prompt_tokens": 21, "response_tokens_est": 27, "n_tiles": 1, "output_text": "giraffe: 1\ntrees: 2\nshrubs: 2\nsky: 1\nground: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.266, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 6.932}, "timestamp": "2026-01-19T15:28:05.574323"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2410.054, "latencies_ms": [2410.054], "images_per_second": 0.415, "prompt_tokens": 25, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The giraffe is positioned in the foreground, facing right. The background consists of dry grass, trees, and bushes, creating a natural setting. The giraffe is relatively close to the foreground, emphasizing its presence in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.522, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:28:10.018140"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2023.798, "latencies_ms": [2023.798], "images_per_second": 0.494, "prompt_tokens": 19, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A giraffe stands in a dry, grassy savanna, gazing towards the right side of the frame. The landscape is sparsely vegetated with scattered trees and bushes.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 12513.1, "ram_available_mb": 50327.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.986, "power_cpu_cv_mean_watts": 1.249, "power_sys_5v0_mean_watts": 6.788}, "timestamp": "2026-01-19T15:28:14.087505"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2865.739, "latencies_ms": [2865.739], "images_per_second": 0.349, "prompt_tokens": 18, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The giraffe's coat is a mosaic of brown and tan spots. Its neck is long and slender. The lighting suggests an overcast sky, giving the scene a muted tone. The giraffe is standing in a dry, grassy field with sparse vegetation.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.194, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 7.069}, "timestamp": "2026-01-19T15:28:18.969173"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1691.099, "latencies_ms": [1691.099], "images_per_second": 0.591, "prompt_tokens": 8, "response_tokens_est": 21, "n_tiles": 1, "output_text": "Two young children are sitting on top of a luggage cart, smiling and enjoying their time amidst the traffic.", "error": null, "sys_before": {"cpu_percent": 12.0, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.423, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 6.823}, "timestamp": "2026-01-19T15:28:22.716692"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2369.147, "latencies_ms": [2369.147], "images_per_second": 0.422, "prompt_tokens": 21, "response_tokens_est": 26, "n_tiles": 1, "output_text": "car: 4\nsuitcase: 2\nluggage cart: 1\nchild: 2\nwoman: 1\nsign: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.6, "ram_available_mb": 50328.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.589, "power_cpu_cv_mean_watts": 1.413, "power_sys_5v0_mean_watts": 6.896}, "timestamp": "2026-01-19T15:28:27.110146"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2984.022, "latencies_ms": [2984.022], "images_per_second": 0.335, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The foreground features two children sitting on luggage carts.  The background includes various cars parked in a lot, suggesting the location is near a parking area or roadside.  The cars are positioned at varying distances from the children, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.308, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 7.115}, "timestamp": "2026-01-19T15:28:32.142426"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2123.588, "latencies_ms": [2123.588], "images_per_second": 0.471, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "Two young children are traveling in a luggage cart amidst a line of parked cars at a budget-friendly car park. A Budget sign is visible in the background, indicating the location.", "error": null, "sys_before": {"cpu_percent": 5.9, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.295, "power_cpu_cv_mean_watts": 1.32, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T15:28:36.295584"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2315.486, "latencies_ms": [2315.486], "images_per_second": 0.432, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The children appear to be wearing light-colored clothing. The scene is well-lit, suggesting sunny weather. The luggage is primarily dark gray or black. The overall atmosphere is bright and cheerful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.758, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.912}, "timestamp": "2026-01-19T15:28:40.660193"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1825.012, "latencies_ms": [1825.012], "images_per_second": 0.548, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A blue and yellow bus travels down a road in a small town, passing a flower bed and passing a bus stop with people waiting.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 8.956, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 6.278}, "timestamp": "2026-01-19T15:28:44.517296"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2594.27, "latencies_ms": [2594.27], "images_per_second": 0.385, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "bus: 1\nvan: 1\nstreet light: 2\nbuildings: 3\ntrees: 4\nhill: 5\ngrass: 6\nflowers: 7", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.633, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 6.691}, "timestamp": "2026-01-19T15:28:49.153609"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2403.139, "latencies_ms": [2403.139], "images_per_second": 0.416, "prompt_tokens": 25, "response_tokens_est": 53, "n_tiles": 1, "output_text": "The bus is positioned in the foreground, moving towards the left side of the image. The street and buildings are in the background, creating a sense of depth and perspective. The bus is relatively close to the viewer, while the buildings and the street are further away.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.34, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 6.605}, "timestamp": "2026-01-19T15:28:53.596037"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2863.512, "latencies_ms": [2863.512], "images_per_second": 0.349, "prompt_tokens": 19, "response_tokens_est": 60, "n_tiles": 1, "output_text": "The scene depicts a bus stop in a small town with a yellow and blue bus driving past. The town is nestled in a valley surrounded by hills, and there are several buildings, including a pub, and parked cars nearby. People can be seen walking along the sidewalks and enjoying the pleasant weather.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.772, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 6.815}, "timestamp": "2026-01-19T15:28:58.507072"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 1947.893, "latencies_ms": [1947.893], "images_per_second": 0.513, "prompt_tokens": 18, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The bus is predominantly yellow and blue. The lighting is bright, likely from street lamps. The bus appears to be made of metal and plastic. The weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4216.4, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.187, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 6.384}, "timestamp": "2026-01-19T15:29:02.466465"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1712.166, "latencies_ms": [1712.166], "images_per_second": 0.584, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A large brown bird, possibly a pelican, perches on a rocky outcropping overlooking the ocean.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.022, "power_cpu_cv_mean_watts": 1.047, "power_sys_5v0_mean_watts": 6.699}, "timestamp": "2026-01-19T15:29:06.224142"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3085.854, "latencies_ms": [3085.854], "images_per_second": 0.324, "prompt_tokens": 21, "response_tokens_est": 43, "n_tiles": 1, "output_text": "pelican: 1\nbeach: 1\nrocks: 1\nocean: 1\nhills: 1\ntrees: 1\nthatched umbrellas: 1\nwooden pier: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.972, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.039}, "timestamp": "2026-01-19T15:29:11.339258"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 1938.376, "latencies_ms": [1938.376], "images_per_second": 0.516, "prompt_tokens": 25, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The bird is positioned in the foreground, slightly to the right of the image. The beach and ocean are in the background, extending from the left to the right of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.297, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.746}, "timestamp": "2026-01-19T15:29:15.330295"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3148.377, "latencies_ms": [3148.377], "images_per_second": 0.318, "prompt_tokens": 19, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The scene depicts a coastal area with a rocky shore, a sandy beach, and calm ocean waters. A pelican is perched on a rock, gazing out at the water, while several beach umbrellas provide shade for beachgoers. The sky is partly cloudy, creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.527, "power_cpu_cv_mean_watts": 1.633, "power_sys_5v0_mean_watts": 6.997}, "timestamp": "2026-01-19T15:29:20.502367"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2369.298, "latencies_ms": [2369.298], "images_per_second": 0.422, "prompt_tokens": 18, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The sky is a mix of blue and white clouds. The water is a calm, light blue. The scene is illuminated by soft, diffused light, suggesting either early morning or late afternoon light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.5, "ram_available_mb": 50328.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.695, "power_cpu_cv_mean_watts": 1.391, "power_sys_5v0_mean_watts": 6.902}, "timestamp": "2026-01-19T15:29:24.891700"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1856.586, "latencies_ms": [1856.586], "images_per_second": 0.539, "prompt_tokens": 8, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A young man wearing glasses sits in a blue armchair, holding a toothbrush in his right hand and a brown paper bag in his left.", "error": null, "sys_before": {"cpu_percent": 9.5, "ram_used_mb": 12512.2, "ram_available_mb": 50328.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.767, "power_cpu_cv_mean_watts": 1.173, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T15:29:28.780199"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2614.128, "latencies_ms": [2614.128], "images_per_second": 0.383, "prompt_tokens": 21, "response_tokens_est": 31, "n_tiles": 1, "output_text": "bag: 1\ntoothbrush: 1\nglasses: 1\nchair: 1\nman: 1\npaper: 1\nremotes: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.403, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:29:33.409778"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2440.391, "latencies_ms": [2440.391], "images_per_second": 0.41, "prompt_tokens": 25, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The man is sitting in a chair, holding the toothbrush in his right hand and reading a newspaper in his left hand. The newspaper is positioned in the foreground, while the toothbrush and newspaper are situated in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 12511.7, "ram_available_mb": 50329.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.664, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.889}, "timestamp": "2026-01-19T15:29:37.891593"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2107.451, "latencies_ms": [2107.451], "images_per_second": 0.475, "prompt_tokens": 19, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A man is sitting in a blue armchair, holding a toothbrush in his right hand and a brown paper bag in his left. He is wearing glasses and a blue and white plaid shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12510.1, "ram_available_mb": 50330.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.174, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.872}, "timestamp": "2026-01-19T15:29:42.034836"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3514.291, "latencies_ms": [3514.291], "images_per_second": 0.285, "prompt_tokens": 18, "response_tokens_est": 76, "n_tiles": 1, "output_text": "The room is dimly lit, creating a warm ambiance. The walls appear to be a light color, possibly white or off-white. The chair is upholstered in a textured fabric, likely velvet or corduroy. The man is holding a toothbrush and a brown paper bag, suggesting he might be preparing to eat or have just finished a meal.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 12510.5, "ram_available_mb": 50330.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.536, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 7.149}, "timestamp": "2026-01-19T15:29:47.579306"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1939.961, "latencies_ms": [1939.961], "images_per_second": 0.515, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "A tennis player in an orange shirt and black shorts is poised to strike a tennis ball with a blue racket on a green court.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.096, "power_cpu_cv_mean_watts": 1.176, "power_sys_5v0_mean_watts": 6.715}, "timestamp": "2026-01-19T15:29:51.568839"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2724.147, "latencies_ms": [2724.147], "images_per_second": 0.367, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "Tennis racket: 1\nTennis ball: 1\nTennis net: 1\nTennis shoes: 2\nTennis court: 4\nTennis player: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.366, "power_cpu_cv_mean_watts": 1.62, "power_sys_5v0_mean_watts": 7.088}, "timestamp": "2026-01-19T15:29:56.355121"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2359.582, "latencies_ms": [2359.582], "images_per_second": 0.424, "prompt_tokens": 25, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The tennis player is positioned near the net, preparing to hit the ball. The tennis ball is visible in the air, near the player's racket. The player's stance suggests they are actively engaged in the game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.655, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 6.928}, "timestamp": "2026-01-19T15:30:00.734636"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2152.384, "latencies_ms": [2152.384], "images_per_second": 0.465, "prompt_tokens": 19, "response_tokens_est": 36, "n_tiles": 1, "output_text": "A tennis player is preparing to serve a tennis ball during a match on a green tennis court. The player is wearing an orange shirt, black shorts, and a matching orange cap.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.269, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 6.824}, "timestamp": "2026-01-19T15:30:04.914689"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2063.166, "latencies_ms": [2063.166], "images_per_second": 0.485, "prompt_tokens": 18, "response_tokens_est": 35, "n_tiles": 1, "output_text": "The tennis player is wearing an orange shirt and orange and white shoes. The green tennis court is well-lit, and the player appears to be focused on the incoming ball.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12509.2, "ram_available_mb": 50331.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.325, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 6.892}, "timestamp": "2026-01-19T15:30:09.022682"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1791.098, "latencies_ms": [1791.098], "images_per_second": 0.558, "prompt_tokens": 8, "response_tokens_est": 26, "n_tiles": 1, "output_text": "The kitchen is well-lit and features yellow walls, wooden cabinets, a sink, a stove, and a fire extinguisher.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 12509.7, "ram_available_mb": 50331.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.539, "power_cpu_cv_mean_watts": 1.116, "power_sys_5v0_mean_watts": 6.861}, "timestamp": "2026-01-19T15:30:12.887581"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2873.277, "latencies_ms": [2873.277], "images_per_second": 0.348, "prompt_tokens": 21, "response_tokens_est": 36, "n_tiles": 1, "output_text": "fire extinguisher: 1\nsink: 1\noven: 1\ncountertop: 1\ncupboard: 2\nrug: 1\ntable: 1\nwindow: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12509.4, "ram_available_mb": 50331.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.702, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 7.091}, "timestamp": "2026-01-19T15:30:17.772113"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2361.077, "latencies_ms": [2361.077], "images_per_second": 0.424, "prompt_tokens": 25, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The main objects are positioned in a diagonal arrangement, with the kitchen area on the left and the dining area on the right. The foreground is dominated by the dining table and chairs, while the kitchen counters and appliances are located further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.5, "ram_available_mb": 50329.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.288, "power_cpu_cv_mean_watts": 1.645, "power_sys_5v0_mean_watts": 7.114}, "timestamp": "2026-01-19T15:30:22.185674"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2951.885, "latencies_ms": [2951.885], "images_per_second": 0.339, "prompt_tokens": 19, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The scene depicts a compact, well-lit kitchen or galley area, likely within a ship or vessel. The yellow walls and wooden cabinetry contribute to a warm and inviting atmosphere. Various appliances and utensils are visible, hinting at the functionality of the space.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12511.4, "ram_available_mb": 50329.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.204, "power_cpu_cv_mean_watts": 1.585, "power_sys_5v0_mean_watts": 7.009}, "timestamp": "2026-01-19T15:30:27.163447"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2425.931, "latencies_ms": [2425.931], "images_per_second": 0.412, "prompt_tokens": 18, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The kitchen is painted in a pale yellow color. The lighting is bright and fluorescent, illuminating the space effectively. The kitchen features wooden cabinets and countertops, contributing to a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.222, "power_cpu_cv_mean_watts": 1.434, "power_sys_5v0_mean_watts": 7.061}, "timestamp": "2026-01-19T15:30:31.614845"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2126.875, "latencies_ms": [2126.875], "images_per_second": 0.47, "prompt_tokens": 8, "response_tokens_est": 40, "n_tiles": 1, "output_text": "A large sandwich, filled with layers of meat, cheese, lettuce, tomato, and pickles, sits on a white paper plate on a wooden table, accompanied by a computer keyboard and a telephone.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12511.1, "ram_available_mb": 50329.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.034, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.782}, "timestamp": "2026-01-19T15:30:35.798608"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2863.135, "latencies_ms": [2863.135], "images_per_second": 0.349, "prompt_tokens": 21, "response_tokens_est": 37, "n_tiles": 1, "output_text": "sandwich: 2\npickles: 2\ntomato: 1\nlettuce: 2\ncheese: 1\nham: 1\nbread: 2\npepper: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.02, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.009}, "timestamp": "2026-01-19T15:30:40.705898"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2421.011, "latencies_ms": [2421.011], "images_per_second": 0.413, "prompt_tokens": 25, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The main object is a large sandwich placed on a paper plate. The paper plate is positioned in the foreground, slightly to the right of the sandwich. The sandwich and plate are situated on a desk, with a computer keyboard and monitor in the background.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 12512.1, "ram_available_mb": 50328.8, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.862, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 7.013}, "timestamp": "2026-01-19T15:30:45.145506"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2124.782, "latencies_ms": [2124.782], "images_per_second": 0.471, "prompt_tokens": 19, "response_tokens_est": 38, "n_tiles": 1, "output_text": "A large sandwich, filled with layers of meat, cheese, lettuce, tomato, and pickles, is presented on a white plate on a desk next to a computer keyboard and a telephone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.986, "power_cpu_cv_mean_watts": 1.225, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T15:30:49.294892"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2664.88, "latencies_ms": [2664.88], "images_per_second": 0.375, "prompt_tokens": 18, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The sandwich is filled with vibrant colors, including red tomato slices, green lettuce, and yellow cheese. The sandwich appears freshly made and sits on a white paper plate. The lighting in the image is soft and diffused, creating a pleasant ambiance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.4, "ram_available_mb": 50328.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.022, "power_cpu_cv_mean_watts": 1.529, "power_sys_5v0_mean_watts": 6.899}, "timestamp": "2026-01-19T15:30:54.022783"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1817.21, "latencies_ms": [1817.21], "images_per_second": 0.55, "prompt_tokens": 8, "response_tokens_est": 30, "n_tiles": 1, "output_text": "The desk is equipped with two computer monitors, a keyboard, a mouse, a tablet, and various electronic devices, creating a well-equipped workspace.", "error": null, "sys_before": {"cpu_percent": 11.5, "ram_used_mb": 12511.6, "ram_available_mb": 50329.3, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.462, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.759}, "timestamp": "2026-01-19T15:30:57.913409"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2901.31, "latencies_ms": [2901.31], "images_per_second": 0.345, "prompt_tokens": 21, "response_tokens_est": 35, "n_tiles": 1, "output_text": "keyboard: 2\nmouse: 1\nmousepad: 1\ntablet: 1\nmonitor: 2\ncables: 4\nphones: 2\ncamera: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.089, "power_cpu_cv_mean_watts": 1.619, "power_sys_5v0_mean_watts": 7.056}, "timestamp": "2026-01-19T15:31:02.858644"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2164.99, "latencies_ms": [2164.99], "images_per_second": 0.462, "prompt_tokens": 25, "response_tokens_est": 39, "n_tiles": 1, "output_text": "The main objects are positioned in a way that creates a sense of depth and perspective. The left monitor is closer, while the right monitor is further away, emphasizing the spatial relationship between the devices.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 12511.8, "ram_available_mb": 50329.1, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.248, "power_cpu_cv_mean_watts": 1.438, "power_sys_5v0_mean_watts": 6.996}, "timestamp": "2026-01-19T15:31:07.061655"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2560.513, "latencies_ms": [2560.513], "images_per_second": 0.391, "prompt_tokens": 19, "response_tokens_est": 43, "n_tiles": 1, "output_text": "The scene depicts a workspace with two computer monitors, a keyboard, a mouse, and various electronic devices arranged on a desk. The monitors display different content, suggesting active use for tasks like video editing or multitasking.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.0, "ram_available_mb": 50328.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.232, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 6.964}, "timestamp": "2026-01-19T15:31:11.662360"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2127.548, "latencies_ms": [2127.548], "images_per_second": 0.47, "prompt_tokens": 18, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The desk is primarily gray, reflecting the ambient lighting. The monitors display a mix of colors, including shades of blue and white. The overall setup appears organized and functional.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.3, "ram_available_mb": 50328.6, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.988, "power_cpu_cv_mean_watts": 1.296, "power_sys_5v0_mean_watts": 6.807}, "timestamp": "2026-01-19T15:31:15.827683"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1835.68, "latencies_ms": [1835.68], "images_per_second": 0.545, "prompt_tokens": 8, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A large group of people is depicted on a tiled floor in a public restroom, appearing to be in a joyful and excited mood.", "error": null, "sys_before": {"cpu_percent": 3.6, "ram_used_mb": 12513.0, "ram_available_mb": 50327.9, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.076, "power_cpu_cv_mean_watts": 1.175, "power_sys_5v0_mean_watts": 6.82}, "timestamp": "2026-01-19T15:31:19.700927"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2506.438, "latencies_ms": [2506.438], "images_per_second": 0.399, "prompt_tokens": 21, "response_tokens_est": 28, "n_tiles": 1, "output_text": "toilet: 1\ndoor: 1\nfloor: 8\npeople: 8\nchild: 1\nman: 2\nwoman: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 12513.5, "ram_available_mb": 50327.4, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.903, "power_cpu_cv_mean_watts": 1.422, "power_sys_5v0_mean_watts": 6.919}, "timestamp": "2026-01-19T15:31:24.219663"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2204.694, "latencies_ms": [2204.694], "images_per_second": 0.454, "prompt_tokens": 25, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The large image of smiling faces is positioned in the foreground, partially obscuring the toilet and door. The toilet and door are located in the background, further away from the main image.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.468, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 7.011}, "timestamp": "2026-01-19T15:31:28.439474"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2430.129, "latencies_ms": [2430.129], "images_per_second": 0.412, "prompt_tokens": 19, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The scene depicts a public restroom with a large, colorful mural of a family on the tiled floor. The mural is vibrant and depicts various family members with arms raised, conveying a sense of joy and togetherness.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.4, "ram_available_mb": 50327.5, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.498, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 7.034}, "timestamp": "2026-01-19T15:31:32.886599"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2291.357, "latencies_ms": [2291.357], "images_per_second": 0.436, "prompt_tokens": 18, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The floor is tiled with light-colored tiles. The lighting in the image appears to be natural, possibly from overhead fixtures. The materials appear to be standard bathroom tiles. The weather is not explicitly visible in the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4249.6, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.221, "power_cpu_cv_mean_watts": 1.412, "power_sys_5v0_mean_watts": 6.944}, "timestamp": "2026-01-19T15:31:37.200889"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1573.229, "latencies_ms": [1573.229], "images_per_second": 0.636, "prompt_tokens": 8, "response_tokens_est": 22, "n_tiles": 1, "output_text": "A gray bird with a pointed beak perches on a thin branch, gazing upwards and to the left.", "error": null, "sys_before": {"cpu_percent": 7.4, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.356, "power_cpu_cv_mean_watts": 0.968, "power_sys_5v0_mean_watts": 6.601}, "timestamp": "2026-01-19T15:31:40.801322"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2513.129, "latencies_ms": [2513.129], "images_per_second": 0.398, "prompt_tokens": 21, "response_tokens_est": 32, "n_tiles": 1, "output_text": "bird: 1\nbranch: 2\ntree: 2\nleaves: 2\nfeathers: 2\neye: 1\nbeak: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.584, "power_cpu_cv_mean_watts": 1.462, "power_sys_5v0_mean_watts": 6.96}, "timestamp": "2026-01-19T15:31:45.338231"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 2152.889, "latencies_ms": [2152.889], "images_per_second": 0.464, "prompt_tokens": 25, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The main object, a bird, occupies the foreground, perched on a branch. The background is blurred, drawing focus to the bird. The bird is positioned near the center of the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.092, "power_cpu_cv_mean_watts": 1.291, "power_sys_5v0_mean_watts": 6.865}, "timestamp": "2026-01-19T15:31:49.524617"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 1820.331, "latencies_ms": [1820.331], "images_per_second": 0.549, "prompt_tokens": 19, "response_tokens_est": 29, "n_tiles": 1, "output_text": "A gray bird perches on a branch in a natural setting with blurred green foliage in the background. The bird appears to be observing its surroundings.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 12513.2, "ram_available_mb": 50327.7, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.37, "power_cpu_cv_mean_watts": 1.23, "power_sys_5v0_mean_watts": 6.818}, "timestamp": "2026-01-19T15:31:53.401384"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2324.292, "latencies_ms": [2324.292], "images_per_second": 0.43, "prompt_tokens": 18, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The bird is gray and appears to be perched on a branch. The lighting suggests an outdoor setting with natural light filtering through the leaves. The materials appear to be wood and possibly some bark or twigs.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 12512.7, "ram_available_mb": 50328.2, "ram_percent": 19.9}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4073.3, "gpu_mem_reserved_mb": 4538.0, "gpu_max_mem_alloc_mb": 4231.9, "gpu_max_mem_reserved_mb": 4538.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.656, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 6.864}, "timestamp": "2026-01-19T15:31:57.749970"}
