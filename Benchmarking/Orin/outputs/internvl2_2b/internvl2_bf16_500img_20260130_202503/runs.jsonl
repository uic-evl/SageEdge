{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2986.286, "latencies_ms": [2986.286], "images_per_second": 0.335, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image depicts a brightly lit, modern living room with a yellow wall, a wooden floor, and a dining area with a table and chairs.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13330.8, "ram_available_mb": 49510.1, "ram_percent": 21.2}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 13334.2, "ram_available_mb": 49506.7, "ram_percent": 21.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.506, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 8.222, "gpu_utilization_percent_mean": 72.16}, "timestamp": "2026-01-30T20:26:19.462723"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8934.423, "latencies_ms": [8934.423], "images_per_second": 0.112, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 6, "output_text": "- table: 1\n- vase: 1\n- chair: 3\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1\n- vase: 1\n- table: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13334.2, "ram_available_mb": 49506.7, "ram_percent": 21.2}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 13336.4, "ram_available_mb": 49504.5, "ram_percent": 21.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.705, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 7.727, "gpu_utilization_percent_mean": 66.584}, "timestamp": "2026-01-30T20:26:30.435075"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6384.621, "latencies_ms": [6384.621], "images_per_second": 0.157, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 6, "output_text": "The main objects in the image are a dining table and chairs, a vase with a flower, a television, a refrigerator, and a wall-mounted cabinet. The dining table and chairs are positioned in the foreground, with the vase and flower placed near the table. The television is on the left side of the image, and the refrigerator is in the background. The wall-mounted cabinet is located near the television.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13336.4, "ram_available_mb": 49504.5, "ram_percent": 21.2}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 13337.9, "ram_available_mb": 49503.0, "ram_percent": 21.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.557, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 7.755, "gpu_utilization_percent_mean": 68.333}, "timestamp": "2026-01-30T20:26:38.875119"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6047.363, "latencies_ms": [6047.363], "images_per_second": 0.165, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 6, "output_text": "The image depicts a brightly lit, modern living room with a warm yellow and orange color scheme. The room features a wooden floor, a large dining table with chairs, a television on a stand, a vase with a pink flower on a table, and a green vase on a table. There is a person visible in the background, seemingly engaged in an activity near the kitchen area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13337.9, "ram_available_mb": 49503.0, "ram_percent": 21.2}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 13338.9, "ram_available_mb": 49502.0, "ram_percent": 21.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.746, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.767, "gpu_utilization_percent_mean": 68.481}, "timestamp": "2026-01-30T20:26:46.959812"}
{"image_index": 0, "image_name": "000000000139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000139.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5098.799, "latencies_ms": [5098.799], "images_per_second": 0.196, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The room is brightly lit with natural light streaming in through large windows, creating a warm and inviting atmosphere. The walls are painted in a soft yellow, complemented by a green accent wall. The wooden floor adds warmth to the space, and the furniture is made of a combination of materials, including wood and metal.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 13338.9, "ram_available_mb": 49502.0, "ram_percent": 21.2}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 13340.4, "ram_available_mb": 49500.5, "ram_percent": 21.2}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 7740.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 7740.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.201, "power_cpu_cv_mean_watts": 1.631, "power_sys_5v0_mean_watts": 7.735, "gpu_utilization_percent_mean": 69.023}, "timestamp": "2026-01-30T20:26:54.104996"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2461.821, "latencies_ms": [2461.821], "images_per_second": 0.406, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The image features a close-up of a brown bear with a soft, fluffy fur coat, sitting on a grassy surface, displaying a calm and curious expression.", "error": null, "sys_before": {"cpu_percent": 17.2, "ram_used_mb": 13340.4, "ram_available_mb": 49500.5, "ram_percent": 21.2}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 13440.0, "ram_available_mb": 49400.9, "ram_percent": 21.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.258, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 6.607, "gpu_utilization_percent_mean": 71.55}, "timestamp": "2026-01-30T20:26:58.619679"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 995.279, "latencies_ms": [995.279], "images_per_second": 1.005, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 1, "output_text": "bear: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 13440.0, "ram_available_mb": 49400.9, "ram_percent": 21.4}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 13439.1, "ram_available_mb": 49401.8, "ram_percent": 21.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.502, "power_cpu_cv_mean_watts": 1.03, "power_sys_5v0_mean_watts": 5.889, "gpu_utilization_percent_mean": 73.857}, "timestamp": "2026-01-30T20:27:01.638283"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3332.669, "latencies_ms": [3332.669], "images_per_second": 0.3, "prompt_tokens": 30, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The main object in the image is a brown bear. The bear is positioned in the foreground, with its head and upper body visible. The background consists of a grassy area, indicating that the bear is likely in a natural habitat.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 13439.1, "ram_available_mb": 49401.8, "ram_percent": 21.4}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 13441.4, "ram_available_mb": 49399.5, "ram_percent": 21.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.263, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 6.765, "gpu_utilization_percent_mean": 70.63}, "timestamp": "2026-01-30T20:27:07.003726"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3476.036, "latencies_ms": [3476.036], "images_per_second": 0.288, "prompt_tokens": 24, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The image depicts a brown bear sitting on a grassy surface, likely in a natural habitat. The bear appears to be calm and relaxed, with its eyes slightly open and its mouth slightly open, possibly indicating a moment of rest or curiosity.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 13441.4, "ram_available_mb": 49399.5, "ram_percent": 21.4}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 13441.9, "ram_available_mb": 49399.0, "ram_percent": 21.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.261, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 6.771, "gpu_utilization_percent_mean": 71.103}, "timestamp": "2026-01-30T20:27:12.541896"}
{"image_index": 1, "image_name": "000000000285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000285.jpg", "image_width": 586, "image_height": 640, "image_resolution": "586x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3128.777, "latencies_ms": [3128.777], "images_per_second": 0.32, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The image features a brown bear with a textured fur coat, standing on a grassy surface. The lighting is natural, casting soft shadows on the bear's face, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 13441.9, "ram_available_mb": 49399.0, "ram_percent": 21.4}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 13443.6, "ram_available_mb": 49397.3, "ram_percent": 21.4}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 7838.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 7838.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.378, "power_cpu_cv_mean_watts": 1.795, "power_sys_5v0_mean_watts": 6.769, "gpu_utilization_percent_mean": 70.44}, "timestamp": "2026-01-30T20:27:17.699255"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5009.905, "latencies_ms": [5009.905], "images_per_second": 0.2, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The image depicts a cozy bedroom with a large window that allows natural light to flood the room, illuminating the space and creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 27.6, "ram_used_mb": 13443.6, "ram_available_mb": 49397.3, "ram_percent": 21.4}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 15754.5, "ram_available_mb": 47086.4, "ram_percent": 25.1}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 10140.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 10140.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.591, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.316, "gpu_utilization_percent_mean": 83.366}, "timestamp": "2026-01-30T20:27:24.871361"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5232.022, "latencies_ms": [5232.022], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "bed: 1\ndresser: 1\nbookshelf: 1\nwindow: 1\nplant: 1\nchair: 1\nbasket: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 15754.5, "ram_available_mb": 47086.4, "ram_percent": 25.1}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 17473.4, "ram_available_mb": 45367.5, "ram_percent": 27.8}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 11854.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 11854.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.9, "power_cpu_cv_mean_watts": 1.305, "power_sys_5v0_mean_watts": 8.465, "gpu_utilization_percent_mean": 86.395}, "timestamp": "2026-01-30T20:27:32.126574"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7752.498, "latencies_ms": [7752.498], "images_per_second": 0.129, "prompt_tokens": 30, "response_tokens_est": 81, "n_tiles": 12, "output_text": "The main objects in the image are a bed, a dresser, a bookshelf, and a window. The bed is positioned in the foreground, with its headboard and footboard visible. The dresser is situated to the left of the bed, and the bookshelf is positioned to the right of the bed. The window is in the background, allowing natural light to illuminate the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 17473.4, "ram_available_mb": 45367.5, "ram_percent": 27.8}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18591.0, "ram_available_mb": 44249.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.739, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 8.559, "gpu_utilization_percent_mean": 83.969}, "timestamp": "2026-01-30T20:27:41.899616"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7568.707, "latencies_ms": [7568.707], "images_per_second": 0.132, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The image depicts a cozy, well-organized bedroom with a large window that allows natural light to flood the room. The room is filled with various items, including a wooden dresser, a bookshelf filled with books, a small potted plant, a cushioned chair, and a basket. The overall atmosphere is warm and inviting, suggesting a comfortable and lived-in space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18591.0, "ram_available_mb": 44249.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18591.5, "ram_available_mb": 44249.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.786, "power_cpu_cv_mean_watts": 1.571, "power_sys_5v0_mean_watts": 8.554, "gpu_utilization_percent_mean": 84.508}, "timestamp": "2026-01-30T20:27:51.506953"}
{"image_index": 2, "image_name": "000000000632.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000632.jpg", "image_width": 640, "image_height": 483, "image_resolution": "640x483", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5128.346, "latencies_ms": [5128.346], "images_per_second": 0.195, "prompt_tokens": 22, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The room is bathed in natural light, creating a warm and inviting atmosphere. The walls are adorned with a floral wallpaper pattern, adding a touch of elegance to the space.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18591.5, "ram_available_mb": 44249.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18593.0, "ram_available_mb": 44247.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.226, "power_cpu_cv_mean_watts": 1.211, "power_sys_5v0_mean_watts": 8.565, "gpu_utilization_percent_mean": 87.326}, "timestamp": "2026-01-30T20:27:58.670643"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4119.309, "latencies_ms": [4119.309], "images_per_second": 0.243, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A red stop sign is mounted on a post, with a clear blue sky and green trees in the background.", "error": null, "sys_before": {"cpu_percent": 26.6, "ram_used_mb": 18592.8, "ram_available_mb": 44248.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18594.7, "ram_available_mb": 44246.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.783, "power_cpu_cv_mean_watts": 1.013, "power_sys_5v0_mean_watts": 8.638, "gpu_utilization_percent_mean": 89.706}, "timestamp": "2026-01-30T20:28:04.925247"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4858.252, "latencies_ms": [4858.252], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "stop sign: 1\ntree: 1\ntrash can: 1\nbuilding: 1\nroad: 1\npole: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18594.7, "ram_available_mb": 44246.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18595.4, "ram_available_mb": 44245.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.661, "power_cpu_cv_mean_watts": 1.152, "power_sys_5v0_mean_watts": 8.574, "gpu_utilization_percent_mean": 88.65}, "timestamp": "2026-01-30T20:28:11.814335"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7147.215, "latencies_ms": [7147.215], "images_per_second": 0.14, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main objects in the image are a stop sign and a street lamp. The stop sign is positioned in the foreground, near the sidewalk, while the street lamp is situated in the background, slightly to the left. The stop sign is closer to the viewer, while the street lamp is further away, creating a clear spatial relationship between the two objects.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18595.4, "ram_available_mb": 44245.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18595.7, "ram_available_mb": 44245.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.923, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 8.582, "gpu_utilization_percent_mean": 84.05}, "timestamp": "2026-01-30T20:28:21.000494"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7612.099, "latencies_ms": [7612.099], "images_per_second": 0.131, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The image depicts a street scene with a stop sign prominently displayed in the foreground. The sign is red with white lettering, and it is mounted on a metal pole. In the background, there is a clear blue sky, a few trees, and a parked white truck. The setting appears to be a suburban or urban area with a well-maintained sidewalk and greenery.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18595.7, "ram_available_mb": 44245.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18593.5, "ram_available_mb": 44247.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.748, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.615, "gpu_utilization_percent_mean": 83.703}, "timestamp": "2026-01-30T20:28:30.667822"}
{"image_index": 3, "image_name": "000000000724.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000724.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6759.998, "latencies_ms": [6759.998], "images_per_second": 0.148, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image features a red stop sign with white lettering, mounted on a metal pole. The sign is set against a backdrop of a clear blue sky with scattered clouds, indicating a sunny day. The surrounding area includes green trees, a sidewalk, and a road with a parked car, suggesting a suburban or urban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18593.5, "ram_available_mb": 44247.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18594.2, "ram_available_mb": 44246.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.235, "power_cpu_cv_mean_watts": 1.453, "power_sys_5v0_mean_watts": 8.603, "gpu_utilization_percent_mean": 84.625}, "timestamp": "2026-01-30T20:28:39.449331"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3353.884, "latencies_ms": [3353.884], "images_per_second": 0.298, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "The image shows a close-up of two teddy bears, one in a light brown color and the other in a darker shade, both with soft, fuzzy textures and round ears.", "error": null, "sys_before": {"cpu_percent": 26.9, "ram_used_mb": 18594.2, "ram_available_mb": 44246.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18595.0, "ram_available_mb": 44245.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.256, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 7.863, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-30T20:28:44.928515"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4556.943, "latencies_ms": [4556.943], "images_per_second": 0.219, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 6, "output_text": "1. Brown teddy bear\n2. Brown teddy bear\n3. Brown teddy bear\n4. Brown teddy bear\n5. Brown teddy bear\n6. Brown teddy bear\n7. Brown teddy bear\n8. Brown teddy bear", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18595.0, "ram_available_mb": 44245.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18595.5, "ram_available_mb": 44245.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.827, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.849, "gpu_utilization_percent_mean": 70.553}, "timestamp": "2026-01-30T20:28:51.539498"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5411.799, "latencies_ms": [5411.799], "images_per_second": 0.185, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The main objects in the image are two teddy bears. The teddy bear on the left is in the foreground, while the teddy bear on the right is slightly behind and to the right of the left one. The teddy bear on the left is closer to the viewer, while the teddy bear on the right is further away.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18595.5, "ram_available_mb": 44245.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18596.7, "ram_available_mb": 44244.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.22, "power_cpu_cv_mean_watts": 1.79, "power_sys_5v0_mean_watts": 7.815, "gpu_utilization_percent_mean": 69.4}, "timestamp": "2026-01-30T20:28:58.990109"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5488.563, "latencies_ms": [5488.563], "images_per_second": 0.182, "prompt_tokens": 24, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The image depicts a cozy scene featuring two teddy bears. One bear is lying on its back, while the other is positioned close to it, both appearing to be in a comfortable and relaxed state. The setting seems to be indoors, possibly in a bedroom or living room, with soft lighting that enhances the warm and inviting atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18596.7, "ram_available_mb": 44244.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18597.7, "ram_available_mb": 44243.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.977, "power_cpu_cv_mean_watts": 1.855, "power_sys_5v0_mean_watts": 7.847, "gpu_utilization_percent_mean": 68.935}, "timestamp": "2026-01-30T20:29:06.495056"}
{"image_index": 4, "image_name": "000000000776.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000776.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4854.374, "latencies_ms": [4854.374], "images_per_second": 0.206, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image features two teddy bears with a warm, earthy brown color palette. The lighting is soft and diffused, casting gentle shadows and highlighting the plush texture of the bears. The weather appears to be overcast, as the overall lighting is subdued and the shadows are soft.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18597.7, "ram_available_mb": 44243.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18598.7, "ram_available_mb": 44242.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.47, "power_cpu_cv_mean_watts": 1.7, "power_sys_5v0_mean_watts": 7.838, "gpu_utilization_percent_mean": 69.195}, "timestamp": "2026-01-30T20:29:13.403750"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3330.471, "latencies_ms": [3330.471], "images_per_second": 0.3, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 6, "output_text": "A person is skiing down a snowy slope, wearing a red jacket, black pants, and a black beanie, with blue and red skis and ski poles.", "error": null, "sys_before": {"cpu_percent": 34.1, "ram_used_mb": 18598.7, "ram_available_mb": 44242.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18599.6, "ram_available_mb": 44241.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.357, "power_cpu_cv_mean_watts": 1.395, "power_sys_5v0_mean_watts": 7.852, "gpu_utilization_percent_mean": 72.815}, "timestamp": "2026-01-30T20:29:18.869131"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3566.737, "latencies_ms": [3566.737], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18599.6, "ram_available_mb": 44241.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18599.9, "ram_available_mb": 44241.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.113, "power_cpu_cv_mean_watts": 1.451, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 72.862}, "timestamp": "2026-01-30T20:29:24.461609"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4681.005, "latencies_ms": [4681.005], "images_per_second": 0.214, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The main object in the foreground is a person skiing, wearing a red jacket, black pants, and a black beanie. They are holding ski poles and standing on skis. The background features a snowy landscape with a hill and a fence, indicating a ski resort setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18599.9, "ram_available_mb": 44241.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18601.1, "ram_available_mb": 44239.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.619, "power_cpu_cv_mean_watts": 1.695, "power_sys_5v0_mean_watts": 7.849, "gpu_utilization_percent_mean": 69.949}, "timestamp": "2026-01-30T20:29:31.165491"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5063.623, "latencies_ms": [5063.623], "images_per_second": 0.197, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a person skiing down a snowy slope. The individual is dressed in a red jacket, black pants, and a black beanie, with blue ski boots and black gloves. The snowy landscape is marked by orange poles and a clear sky, suggesting a sunny day suitable for skiing.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18601.1, "ram_available_mb": 44239.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18599.7, "ram_available_mb": 44241.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.39, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.858, "gpu_utilization_percent_mean": 69.381}, "timestamp": "2026-01-30T20:29:38.281290"}
{"image_index": 5, "image_name": "000000000785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000785.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4848.403, "latencies_ms": [4848.403], "images_per_second": 0.206, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The notable visual attributes of the image include a person dressed in a red jacket and black pants, wearing a black and white striped beanie, and blue and red ski boots. The person is skiing on a snowy slope, with a bright and clear sky overhead, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18599.7, "ram_available_mb": 44241.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18599.5, "ram_available_mb": 44241.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.518, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 7.857, "gpu_utilization_percent_mean": 70.225}, "timestamp": "2026-01-30T20:29:45.169383"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2779.125, "latencies_ms": [2779.125], "images_per_second": 0.36, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 6, "output_text": "The image shows a kitchen with a white refrigerator, wooden cabinets, and a white stove, all set against a beige wall.", "error": null, "sys_before": {"cpu_percent": 35.8, "ram_used_mb": 18599.5, "ram_available_mb": 44241.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18599.8, "ram_available_mb": 44241.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.513, "power_cpu_cv_mean_watts": 1.239, "power_sys_5v0_mean_watts": 7.863, "gpu_utilization_percent_mean": 76.045}, "timestamp": "2026-01-30T20:29:50.075927"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3590.439, "latencies_ms": [3590.439], "images_per_second": 0.279, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18599.8, "ram_available_mb": 44241.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18600.1, "ram_available_mb": 44240.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.06, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 7.869, "gpu_utilization_percent_mean": 72.276}, "timestamp": "2026-01-30T20:29:55.698564"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4321.862, "latencies_ms": [4321.862], "images_per_second": 0.231, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The main objects in the image are a white refrigerator and a white stove. The refrigerator is located to the right of the stove, and the stove is positioned in the foreground. The refrigerator is closer to the foreground, while the stove is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18600.1, "ram_available_mb": 44240.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18600.8, "ram_available_mb": 44240.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.039, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 7.843, "gpu_utilization_percent_mean": 70.778}, "timestamp": "2026-01-30T20:30:02.072810"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3295.174, "latencies_ms": [3295.174], "images_per_second": 0.303, "prompt_tokens": 24, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The image depicts a small kitchen with a white refrigerator and a wooden cabinet. The kitchen is well-lit, and the scene appears to be in a residential setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18600.6, "ram_available_mb": 44240.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18600.8, "ram_available_mb": 44240.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.317, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 7.859, "gpu_utilization_percent_mean": 72.333}, "timestamp": "2026-01-30T20:30:07.420138"}
{"image_index": 6, "image_name": "000000000802.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000802.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3526.042, "latencies_ms": [3526.042], "images_per_second": 0.284, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The kitchen features a warm, beige color scheme with wooden cabinets and a white refrigerator. The lighting is soft and natural, likely from a nearby window, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18600.8, "ram_available_mb": 44240.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18601.8, "ram_available_mb": 44239.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.936, "power_cpu_cv_mean_watts": 1.396, "power_sys_5v0_mean_watts": 7.834, "gpu_utilization_percent_mean": 72.103}, "timestamp": "2026-01-30T20:30:12.985933"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3532.909, "latencies_ms": [3532.909], "images_per_second": 0.283, "prompt_tokens": 12, "response_tokens_est": 52, "n_tiles": 1, "output_text": "Two baseball players are in the midst of a game, with one player in a white shirt and blue helmet running towards first base while the other player in a green shirt and blue cap is running towards second base, both wearing gloves and focused on the game.", "error": null, "sys_before": {"cpu_percent": 29.9, "ram_used_mb": 18602.0, "ram_available_mb": 44238.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18602.8, "ram_available_mb": 44238.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.439, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 6.916, "gpu_utilization_percent_mean": 67.862}, "timestamp": "2026-01-30T20:30:18.585817"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8350.17, "latencies_ms": [8350.17], "images_per_second": 0.12, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 1, "output_text": "- baseball player: 2\n- baseball: 1\n- baseball glove: 1\n- baseball uniform: 1\n- baseball cap: 1\n- baseball bat: 1\n- baseball field: 1\n- baseball glove: 1\n- baseball: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player: 1\n- baseball player:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18602.8, "ram_available_mb": 44238.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18603.5, "ram_available_mb": 44237.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.541, "power_cpu_cv_mean_watts": 2.049, "power_sys_5v0_mean_watts": 7.121, "gpu_utilization_percent_mean": 65.535}, "timestamp": "2026-01-30T20:30:28.951415"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6208.666, "latencies_ms": [6208.666], "images_per_second": 0.161, "prompt_tokens": 30, "response_tokens_est": 94, "n_tiles": 1, "output_text": "In the image, the main object, a baseball player in the foreground, is positioned near the center of the frame. The player is wearing a white shirt, gray pants, and a blue helmet. In the background, another player is seen running towards the left side of the frame. The second player is wearing a green shirt and a green cap. The player in the background is slightly farther away from the main subject, creating a sense of depth in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18603.5, "ram_available_mb": 44237.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18604.8, "ram_available_mb": 44236.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.542, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 7.075, "gpu_utilization_percent_mean": 65.865}, "timestamp": "2026-01-30T20:30:37.190536"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5764.491, "latencies_ms": [5764.491], "images_per_second": 0.173, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 1, "output_text": "The image captures a dynamic moment during a baseball game, with two players in mid-action on the field. One player, wearing a white shirt and blue helmet, is running towards first base while the other, dressed in a green shirt and blue cap, is running towards second base. The background features lush green trees and a well-maintained grassy area, indicating that the game is taking place in a park or recreational field.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18604.8, "ram_available_mb": 44236.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18605.0, "ram_available_mb": 44235.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.488, "power_cpu_cv_mean_watts": 2.02, "power_sys_5v0_mean_watts": 7.01, "gpu_utilization_percent_mean": 66.612}, "timestamp": "2026-01-30T20:30:44.980940"}
{"image_index": 7, "image_name": "000000000872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000872.jpg", "image_width": 621, "image_height": 640, "image_resolution": "621x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2695.148, "latencies_ms": [2695.148], "images_per_second": 0.371, "prompt_tokens": 22, "response_tokens_est": 38, "n_tiles": 1, "output_text": "The image depicts a baseball game with players in white and gray uniforms, running on a dirt field. The scene is brightly lit by natural sunlight, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18605.0, "ram_available_mb": 44235.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18605.7, "ram_available_mb": 44235.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.436, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 6.822, "gpu_utilization_percent_mean": 71.045}, "timestamp": "2026-01-30T20:30:49.707532"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3378.471, "latencies_ms": [3378.471], "images_per_second": 0.296, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "A tennis player is in the midst of a powerful serve, with his body leaning forward and his racket in motion, as he attempts to hit the ball with precision and power.", "error": null, "sys_before": {"cpu_percent": 37.9, "ram_used_mb": 18605.7, "ram_available_mb": 44235.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18606.2, "ram_available_mb": 44234.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.11, "power_cpu_cv_mean_watts": 1.503, "power_sys_5v0_mean_watts": 7.826, "gpu_utilization_percent_mean": 72.821}, "timestamp": "2026-01-30T20:30:55.248627"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3837.078, "latencies_ms": [3837.078], "images_per_second": 0.261, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Tennis court\n5. Spectator\n6. Advertisement board\n7. Advertisement board\n8. Advertisement board", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18606.2, "ram_available_mb": 44234.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18606.0, "ram_available_mb": 44234.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.543, "power_cpu_cv_mean_watts": 1.553, "power_sys_5v0_mean_watts": 7.816, "gpu_utilization_percent_mean": 71.312}, "timestamp": "2026-01-30T20:31:01.126831"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6816.104, "latencies_ms": [6816.104], "images_per_second": 0.147, "prompt_tokens": 30, "response_tokens_est": 93, "n_tiles": 6, "output_text": "The main object in the foreground is a tennis player in a white and blue outfit, who is in the process of hitting a tennis ball. The player is positioned on the left side of the image, with the tennis ball in the middle. The background features a blue barrier with the word \"POLO\" written on it, and a person standing near the barrier. The player's shadow is cast on the tennis court, indicating the direction of the light source.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18606.0, "ram_available_mb": 44234.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18604.1, "ram_available_mb": 44236.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.444, "power_cpu_cv_mean_watts": 1.926, "power_sys_5v0_mean_watts": 7.887, "gpu_utilization_percent_mean": 68.035}, "timestamp": "2026-01-30T20:31:09.993068"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6537.497, "latencies_ms": [6537.497], "images_per_second": 0.153, "prompt_tokens": 24, "response_tokens_est": 88, "n_tiles": 6, "output_text": "The image captures a moment during a tennis match on a well-maintained court. The player, dressed in a white shirt and blue shorts, is in the midst of a powerful serve, with his body leaning forward and his racket extended towards the ball. The background features a blue barrier with the \"J.P. Morgan\" logo, indicating sponsorship, and a few spectators are seated on the sidelines, observing the match.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18604.1, "ram_available_mb": 44236.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18603.6, "ram_available_mb": 44237.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.393, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 7.852, "gpu_utilization_percent_mean": 67.764}, "timestamp": "2026-01-30T20:31:18.584732"}
{"image_index": 8, "image_name": "000000000885.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000000885.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7015.574, "latencies_ms": [7015.574], "images_per_second": 0.143, "prompt_tokens": 22, "response_tokens_est": 96, "n_tiles": 6, "output_text": "The image captures a tennis match on a bright, sunny day. The court is marked with white lines, and the players are dressed in athletic attire, with the player in the foreground wearing a white shirt and blue shorts, and the other player in a dark shirt and white shorts. The lighting is natural, casting shadows on the court, and the colors are vivid, with the green of the court contrasting against the players' clothing and the blue of the advertisement boards.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18603.6, "ram_available_mb": 44237.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18602.9, "ram_available_mb": 44238.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.28, "power_cpu_cv_mean_watts": 1.908, "power_sys_5v0_mean_watts": 7.882, "gpu_utilization_percent_mean": 67.339}, "timestamp": "2026-01-30T20:31:27.614221"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4090.333, "latencies_ms": [4090.333], "images_per_second": 0.244, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "The image shows a group of young tennis players and their coach posing for a photo on a tennis court.", "error": null, "sys_before": {"cpu_percent": 29.3, "ram_used_mb": 18602.9, "ram_available_mb": 44238.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18601.5, "ram_available_mb": 44239.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.617, "power_cpu_cv_mean_watts": 1.013, "power_sys_5v0_mean_watts": 8.667, "gpu_utilization_percent_mean": 88.647}, "timestamp": "2026-01-30T20:31:33.857718"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5484.669, "latencies_ms": [5484.669], "images_per_second": 0.182, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 12, "output_text": "1. Tennis players\n2. Tennis rackets\n3. Tennis balls\n4. Tennis net\n5. Tennis court\n6. Tennis court net\n7. Tennis court net\n8. Tennis court net", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18601.5, "ram_available_mb": 44239.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18601.4, "ram_available_mb": 44239.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.086, "power_cpu_cv_mean_watts": 1.385, "power_sys_5v0_mean_watts": 8.673, "gpu_utilization_percent_mean": 87.109}, "timestamp": "2026-01-30T20:31:41.395261"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6226.124, "latencies_ms": [6226.124], "images_per_second": 0.161, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The main objects in the image are a group of young boys and girls standing on a tennis court. The boys are positioned in the foreground, with the girls slightly behind them. The tennis court is surrounded by a green fence, and the background features trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18601.4, "ram_available_mb": 44239.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18602.0, "ram_available_mb": 44238.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.798, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.75, "gpu_utilization_percent_mean": 84.923}, "timestamp": "2026-01-30T20:31:49.637268"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6947.922, "latencies_ms": [6947.922], "images_per_second": 0.144, "prompt_tokens": 24, "response_tokens_est": 68, "n_tiles": 12, "output_text": "The scene depicts a group of young tennis players and their coach standing on a tennis court, likely after a match or practice session. The players are dressed in athletic attire, with some holding tennis rackets, and the coach is holding a trophy. The setting is outdoors, with trees and a green fence visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18602.0, "ram_available_mb": 44238.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18602.3, "ram_available_mb": 44238.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.147, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.701, "gpu_utilization_percent_mean": 84.627}, "timestamp": "2026-01-30T20:31:58.647949"}
{"image_index": 9, "image_name": "000000001000.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001000.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6303.548, "latencies_ms": [6303.548], "images_per_second": 0.159, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a group of young athletes standing on a tennis court, with a blue surface and a green fence in the background. The lighting is bright, indicating it is a sunny day, and the shadows are cast on the court, suggesting the sun is high in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18602.3, "ram_available_mb": 44238.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18602.3, "ram_available_mb": 44238.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.581, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 8.726, "gpu_utilization_percent_mean": 86.113}, "timestamp": "2026-01-30T20:32:06.973104"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2287.735, "latencies_ms": [2287.735], "images_per_second": 0.437, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 6, "output_text": "A woman is taking a photo of a white bird standing in the water near a bridge.", "error": null, "sys_before": {"cpu_percent": 26.9, "ram_used_mb": 18602.2, "ram_available_mb": 44238.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18602.0, "ram_available_mb": 44238.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.413, "power_cpu_cv_mean_watts": 1.075, "power_sys_5v0_mean_watts": 7.885, "gpu_utilization_percent_mean": 77.789}, "timestamp": "2026-01-30T20:32:11.387268"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4574.104, "latencies_ms": [4574.104], "images_per_second": 0.219, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 6, "output_text": "1. Woman: 1\n2. Woman: 1\n3. Woman: 1\n4. Woman: 1\n5. Woman: 1\n6. Woman: 1\n7. Woman: 1\n8. Woman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18602.0, "ram_available_mb": 44238.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18603.0, "ram_available_mb": 44237.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.82, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 7.887, "gpu_utilization_percent_mean": 70.053}, "timestamp": "2026-01-30T20:32:18.005144"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3811.723, "latencies_ms": [3811.723], "images_per_second": 0.262, "prompt_tokens": 30, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The main objects in the image are a group of people sitting near a body of water, with a person taking a photo in the foreground. The water is in the background, and the people are in the foreground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18603.0, "ram_available_mb": 44237.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18601.1, "ram_available_mb": 44239.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.729, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.927, "gpu_utilization_percent_mean": 71.906}, "timestamp": "2026-01-30T20:32:23.863678"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5957.479, "latencies_ms": [5957.479], "images_per_second": 0.168, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image depicts a serene riverside scene during what appears to be either sunrise or sunset, with the sun casting a warm glow over the water. A group of people is gathered on a riverside promenade, with one person taking a photograph of a white bird. The setting is urban, with buildings and trees in the background, and the individuals are dressed casually.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18601.1, "ram_available_mb": 44239.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18601.3, "ram_available_mb": 44239.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.862, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 7.941, "gpu_utilization_percent_mean": 68.38}, "timestamp": "2026-01-30T20:32:31.852072"}
{"image_index": 10, "image_name": "000000001268.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001268.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5412.233, "latencies_ms": [5412.233], "images_per_second": 0.185, "prompt_tokens": 22, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The image features a serene scene with a woman taking a photograph of a white bird standing in a calm body of water. The lighting is soft and warm, with the sun casting a gentle glow on the scene. The woman is wearing a green dress and a brown shoulder bag, while the bird is white and stands on the water's edge.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18601.3, "ram_available_mb": 44239.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18601.6, "ram_available_mb": 44239.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.16, "power_cpu_cv_mean_watts": 1.87, "power_sys_5v0_mean_watts": 7.925, "gpu_utilization_percent_mean": 69.622}, "timestamp": "2026-01-30T20:32:39.310084"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4193.334, "latencies_ms": [4193.334], "images_per_second": 0.238, "prompt_tokens": 12, "response_tokens_est": 50, "n_tiles": 6, "output_text": "A woman is taking a selfie with a Hello Kitty phone case, wearing a white top with a black and white graphic design, and accessorized with a green and yellow bracelet, a silver watch, and a white paper in her hand.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18601.3, "ram_available_mb": 44239.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18601.0, "ram_available_mb": 44239.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.154, "power_cpu_cv_mean_watts": 1.729, "power_sys_5v0_mean_watts": 7.921, "gpu_utilization_percent_mean": 71.143}, "timestamp": "2026-01-30T20:32:45.602061"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5130.238, "latencies_ms": [5130.238], "images_per_second": 0.195, "prompt_tokens": 26, "response_tokens_est": 65, "n_tiles": 6, "output_text": "1. Phone: 1\n2. Phone Case: 1\n3. Ring: 1\n4. Watch: 1\n5. Wristband: 1\n6. Wristband: 1\n7. Wristband: 1\n8. Wristband: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18601.0, "ram_available_mb": 44239.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18601.4, "ram_available_mb": 44239.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.237, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 7.875, "gpu_utilization_percent_mean": 69.116}, "timestamp": "2026-01-30T20:32:52.746596"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4329.136, "latencies_ms": [4329.136], "images_per_second": 0.231, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The main object in the foreground is a person holding a smartphone. The smartphone is held near the person's face, with the person's left hand holding the phone. The background is blurred, indicating that the focus is on the person and the smartphone.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18601.4, "ram_available_mb": 44239.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18602.8, "ram_available_mb": 44238.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.005, "power_cpu_cv_mean_watts": 1.714, "power_sys_5v0_mean_watts": 7.878, "gpu_utilization_percent_mean": 70.583}, "timestamp": "2026-01-30T20:32:59.091341"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4817.361, "latencies_ms": [4817.361], "images_per_second": 0.208, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image depicts a young woman holding a smartphone, taking a selfie. She is wearing a white top with a graphic design and has a green and yellow bracelet on her wrist. The background is blurred, but it appears to be an outdoor setting with other people and possibly a crowd.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18602.8, "ram_available_mb": 44238.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18603.1, "ram_available_mb": 44237.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.598, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.909, "gpu_utilization_percent_mean": 70.15}, "timestamp": "2026-01-30T20:33:05.924204"}
{"image_index": 11, "image_name": "000000001296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001296.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4815.318, "latencies_ms": [4815.318], "images_per_second": 0.208, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The notable visual attributes of the image include the woman's black hair, the white and pink Hello Kitty phone case, her green and yellow chunky bracelet, and her white sleeveless top. The lighting is bright, and the background is blurred, suggesting an outdoor setting with natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18603.1, "ram_available_mb": 44237.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18603.6, "ram_available_mb": 44237.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.618, "power_cpu_cv_mean_watts": 1.763, "power_sys_5v0_mean_watts": 7.93, "gpu_utilization_percent_mean": 69.55}, "timestamp": "2026-01-30T20:33:12.752683"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4068.561, "latencies_ms": [4068.561], "images_per_second": 0.246, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "A group of children are sitting in a red and white train carriage, enjoying a ride on a train.", "error": null, "sys_before": {"cpu_percent": 32.7, "ram_used_mb": 18603.6, "ram_available_mb": 44237.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18606.7, "ram_available_mb": 44234.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.931, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.737, "gpu_utilization_percent_mean": 88.03}, "timestamp": "2026-01-30T20:33:18.979001"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5224.552, "latencies_ms": [5224.552], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18606.7, "ram_available_mb": 44234.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18607.3, "ram_available_mb": 44233.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.332, "power_cpu_cv_mean_watts": 1.348, "power_sys_5v0_mean_watts": 8.726, "gpu_utilization_percent_mean": 87.568}, "timestamp": "2026-01-30T20:33:26.232632"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7229.102, "latencies_ms": [7229.102], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main object in the foreground is a red and white toy train. The train is positioned on a track, with a black base and a small wheel visible. In the background, there is a group of children sitting on a bench, with one child standing and another sitting on a chair. The children are in a room with wooden floors and walls.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18607.3, "ram_available_mb": 44233.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18606.9, "ram_available_mb": 44234.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.841, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.684, "gpu_utilization_percent_mean": 83.661}, "timestamp": "2026-01-30T20:33:35.497219"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7311.038, "latencies_ms": [7311.038], "images_per_second": 0.137, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The image depicts a group of children sitting in a small, red and white train carriage, which is situated on a wooden floor. The children appear to be enjoying a ride, with some looking forward and others looking back, possibly at their parents or other children. The setting suggests a playful and family-friendly environment, likely a theme park or a similar recreational area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18606.9, "ram_available_mb": 44234.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18606.5, "ram_available_mb": 44234.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.987, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.748, "gpu_utilization_percent_mean": 84.131}, "timestamp": "2026-01-30T20:33:44.842548"}
{"image_index": 12, "image_name": "000000001353.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001353.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5126.04, "latencies_ms": [5126.04], "images_per_second": 0.195, "prompt_tokens": 22, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image features a vibrant red and white carousel with a shiny, glossy finish. The lighting is warm and soft, casting a gentle glow on the carousel and creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18606.5, "ram_available_mb": 44234.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18607.6, "ram_available_mb": 44233.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.388, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.734, "gpu_utilization_percent_mean": 87.86}, "timestamp": "2026-01-30T20:33:52.018529"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5064.823, "latencies_ms": [5064.823], "images_per_second": 0.197, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image shows a close-up of a slice of bread with a dark filling, possibly a dessert or a savory dish, placed on a white plate, with a blurred background.", "error": null, "sys_before": {"cpu_percent": 34.9, "ram_used_mb": 18607.6, "ram_available_mb": 44233.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18606.9, "ram_available_mb": 44234.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.498, "power_cpu_cv_mean_watts": 1.307, "power_sys_5v0_mean_watts": 8.74, "gpu_utilization_percent_mean": 86.143}, "timestamp": "2026-01-30T20:33:59.237266"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5246.025, "latencies_ms": [5246.025], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18606.9, "ram_available_mb": 44234.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18606.9, "ram_available_mb": 44234.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.319, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.725, "gpu_utilization_percent_mean": 87.395}, "timestamp": "2026-01-30T20:34:06.503547"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6645.256, "latencies_ms": [6645.256], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The main object in the foreground is a sandwich, which is placed on a white plate. The background features a blurred object, possibly a cup or container, which is out of focus. The sandwich is positioned near the center of the image, with the blurred object slightly to the right and behind it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18606.9, "ram_available_mb": 44234.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18604.2, "ram_available_mb": 44236.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.372, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.767, "gpu_utilization_percent_mean": 85.564}, "timestamp": "2026-01-30T20:34:15.170133"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6095.831, "latencies_ms": [6095.831], "images_per_second": 0.164, "prompt_tokens": 24, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image depicts a close-up of a slice of bread with a dark filling, possibly a dessert or a savory dish, placed on a white plate. The background is blurred, with indistinct shapes and colors, suggesting a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18604.2, "ram_available_mb": 44236.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18605.1, "ram_available_mb": 44235.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.649, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.739, "gpu_utilization_percent_mean": 85.333}, "timestamp": "2026-01-30T20:34:23.296052"}
{"image_index": 13, "image_name": "000000001425.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001425.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6147.098, "latencies_ms": [6147.098], "images_per_second": 0.163, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image is a black and white photograph featuring a close-up of a sandwich with a white, fluffy bread base. The lighting is soft and diffused, creating a warm and inviting atmosphere. The background is blurred, drawing attention to the sandwich in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18605.1, "ram_available_mb": 44235.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18605.5, "ram_available_mb": 44235.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.648, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.761, "gpu_utilization_percent_mean": 86.235}, "timestamp": "2026-01-30T20:34:31.472087"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1833.438, "latencies_ms": [1833.438], "images_per_second": 0.545, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 2, "output_text": "A person is standing on a paddleboard in the water, holding a paddle and wearing a wetsuit.", "error": null, "sys_before": {"cpu_percent": 24.1, "ram_used_mb": 18605.5, "ram_available_mb": 44235.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18603.9, "ram_available_mb": 44237.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.452, "power_cpu_cv_mean_watts": 1.488, "power_sys_5v0_mean_watts": 6.969, "gpu_utilization_percent_mean": 66.929}, "timestamp": "2026-01-30T20:34:35.365702"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2674.818, "latencies_ms": [2674.818], "images_per_second": 0.374, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 2, "output_text": "1. Paddleboard\n2. Person\n3. Water\n4. Surfboard\n5. Water\n6. Paddle\n7. Person\n8. Water", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18603.9, "ram_available_mb": 44237.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18603.8, "ram_available_mb": 44237.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.014, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.156, "gpu_utilization_percent_mean": 60.857}, "timestamp": "2026-01-30T20:34:40.062394"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5545.72, "latencies_ms": [5545.72], "images_per_second": 0.18, "prompt_tokens": 30, "response_tokens_est": 83, "n_tiles": 2, "output_text": "The main object in the foreground is a person standing on a paddleboard, holding a paddle. The person is wearing a wetsuit and is positioned near the center of the image. In the background, there is a body of water extending to the horizon, with a line of trees and a distant shoreline visible. The paddleboard is positioned in the middle ground, slightly to the left of the person.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18603.8, "ram_available_mb": 44237.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18603.0, "ram_available_mb": 44237.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.718, "power_cpu_cv_mean_watts": 2.108, "power_sys_5v0_mean_watts": 7.312, "gpu_utilization_percent_mean": 61.196}, "timestamp": "2026-01-30T20:34:47.620638"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3996.77, "latencies_ms": [3996.77], "images_per_second": 0.25, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 2, "output_text": "The image depicts a person standing on a paddleboard in a body of water, likely a lake or sea, with a calm and expansive horizon. The individual is dressed in a wetsuit and is holding a paddle, suggesting they are engaged in water sports or a leisure activity.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18603.0, "ram_available_mb": 44237.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18603.9, "ram_available_mb": 44237.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.046, "power_cpu_cv_mean_watts": 2.016, "power_sys_5v0_mean_watts": 7.193, "gpu_utilization_percent_mean": 61.939}, "timestamp": "2026-01-30T20:34:53.664034"}
{"image_index": 14, "image_name": "000000001490.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001490.jpg", "image_width": 640, "image_height": 315, "image_resolution": "640x315", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4317.475, "latencies_ms": [4317.475], "images_per_second": 0.232, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 2, "output_text": "The image is a black and white photograph featuring a person standing on a paddleboard in a body of water. The individual is wearing a wetsuit and holding a paddle, and the water appears calm with minimal ripples. The lighting is natural, suggesting daytime, and the overall weather seems clear and mild.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18603.9, "ram_available_mb": 44237.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18604.1, "ram_available_mb": 44236.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.023, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.237, "gpu_utilization_percent_mean": 62.086}, "timestamp": "2026-01-30T20:34:59.999900"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4997.718, "latencies_ms": [4997.718], "images_per_second": 0.2, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 12, "output_text": "The image shows a neatly arranged desk with a laptop, a white mouse, a keyboard, and a small figurine on the right side, all set against a plain background.", "error": null, "sys_before": {"cpu_percent": 34.2, "ram_used_mb": 18604.1, "ram_available_mb": 44236.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18605.8, "ram_available_mb": 44235.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.783, "power_cpu_cv_mean_watts": 1.309, "power_sys_5v0_mean_watts": 8.779, "gpu_utilization_percent_mean": 86.951}, "timestamp": "2026-01-30T20:35:07.182690"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4456.295, "latencies_ms": [4456.295], "images_per_second": 0.224, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 12, "output_text": "laptop: 1\nkeyboard: 1\nmouse: 1\nprinter: 1\ndesk: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18605.8, "ram_available_mb": 44235.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18604.9, "ram_available_mb": 44236.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.133, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.74, "gpu_utilization_percent_mean": 89.351}, "timestamp": "2026-01-30T20:35:13.687483"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6649.246, "latencies_ms": [6649.246], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The main objects in the image are a laptop, a mouse, and a keyboard. The laptop is positioned on the left side of the image, with the mouse and keyboard placed in front of it. The laptop is the closest object to the viewer, while the mouse and keyboard are further back in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18604.9, "ram_available_mb": 44236.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18605.4, "ram_available_mb": 44235.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.307, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.75, "gpu_utilization_percent_mean": 85.255}, "timestamp": "2026-01-30T20:35:22.358829"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6507.442, "latencies_ms": [6507.442], "images_per_second": 0.154, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image depicts a cluttered desk with a laptop, a white mouse, a keyboard, and a small figurine on top of the desk. The setting appears to be indoors, possibly in a home or office environment, with a window in the background allowing natural light to illuminate the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18605.4, "ram_available_mb": 44235.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18605.7, "ram_available_mb": 44235.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.478, "power_cpu_cv_mean_watts": 1.536, "power_sys_5v0_mean_watts": 8.755, "gpu_utilization_percent_mean": 85.852}, "timestamp": "2026-01-30T20:35:30.900901"}
{"image_index": 15, "image_name": "000000001503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001503.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5608.744, "latencies_ms": [5608.744], "images_per_second": 0.178, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image shows a desk with a white computer monitor, a white keyboard, a white mouse, and a white lamp. The desk is well-lit, and the overall color scheme is neutral with white and light gray tones.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18605.7, "ram_available_mb": 44235.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18604.9, "ram_available_mb": 44236.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.004, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 8.745, "gpu_utilization_percent_mean": 86.872}, "timestamp": "2026-01-30T20:35:38.535069"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5241.546, "latencies_ms": [5241.546], "images_per_second": 0.191, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image shows a busy highway with multiple vehicles, including a taxi and a black SUV, under a bridge with green directional signs indicating directions to \"North Ventura\" and \"Sunset Blvd.\"", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 18604.9, "ram_available_mb": 44236.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18605.4, "ram_available_mb": 44235.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.459, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 8.781, "gpu_utilization_percent_mean": 85.558}, "timestamp": "2026-01-30T20:35:45.924410"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4826.653, "latencies_ms": [4826.653], "images_per_second": 0.207, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 12, "output_text": "1. Taxi\n2. SUV\n3. Van\n4. Car\n5. Car\n6. Car\n7. Car\n8. Car", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18605.4, "ram_available_mb": 44235.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18605.4, "ram_available_mb": 44235.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.75, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.733, "gpu_utilization_percent_mean": 88.525}, "timestamp": "2026-01-30T20:35:52.811616"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6046.813, "latencies_ms": [6046.813], "images_per_second": 0.165, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The main objects in the image are a highway sign, a car, and a van. The car is positioned in the foreground, while the van is in the background. The highway sign is near the top of the image, and the van is further back.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18605.4, "ram_available_mb": 44235.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18606.2, "ram_available_mb": 44234.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.648, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.744, "gpu_utilization_percent_mean": 85.431}, "timestamp": "2026-01-30T20:36:00.901570"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8538.819, "latencies_ms": [8538.819], "images_per_second": 0.117, "prompt_tokens": 24, "response_tokens_est": 94, "n_tiles": 12, "output_text": "The image depicts a busy highway scene under a bridge with multiple green directional signs indicating directions to various locations such as \"North Ventura\" and \"Hollywood Blvd.\" The setting appears to be in a city, with a clear blue sky and some trees in the background. The traffic is heavy, with several vehicles visible, including a taxi and a black SUV. The road signs and the presence of a toll booth suggest that this is a major thoroughfare.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18606.2, "ram_available_mb": 44234.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18606.7, "ram_available_mb": 44234.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.503, "power_cpu_cv_mean_watts": 1.764, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 83.625}, "timestamp": "2026-01-30T20:36:11.483182"}
{"image_index": 16, "image_name": "000000001532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001532.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7201.351, "latencies_ms": [7201.351], "images_per_second": 0.139, "prompt_tokens": 22, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a sunny day on a highway with a clear blue sky. The road is covered with a concrete overpass, and there are green directional signs indicating directions to \"North Ventura\" and \"Sunset Blvd.\" The vehicles on the road include a taxi and a black SUV, and there are trees and buildings visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18606.7, "ram_available_mb": 44234.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18605.5, "ram_available_mb": 44235.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.067, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.767, "gpu_utilization_percent_mean": 84.167}, "timestamp": "2026-01-30T20:36:20.712068"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3259.654, "latencies_ms": [3259.654], "images_per_second": 0.307, "prompt_tokens": 12, "response_tokens_est": 47, "n_tiles": 1, "output_text": "A red double-decker bus, marked with the number 15 and the name \"Aldwych,\" is in motion on a city street, with a clear sky above and a few pedestrians and other vehicles in the background.", "error": null, "sys_before": {"cpu_percent": 16.3, "ram_used_mb": 18605.5, "ram_available_mb": 44235.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18606.2, "ram_available_mb": 44234.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.291, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 6.992, "gpu_utilization_percent_mean": 70.741}, "timestamp": "2026-01-30T20:36:26.038307"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3273.655, "latencies_ms": [3273.655], "images_per_second": 0.305, "prompt_tokens": 26, "response_tokens_est": 47, "n_tiles": 1, "output_text": "- Red double-decker bus: 1\n- Bus: 1\n- People: 1\n- Cars: 1\n- Trees: 1\n- Buildings: 1\n- Sky: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18606.2, "ram_available_mb": 44234.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18606.6, "ram_available_mb": 44234.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.351, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 6.973, "gpu_utilization_percent_mean": 69.593}, "timestamp": "2026-01-30T20:36:31.344570"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4888.619, "latencies_ms": [4888.619], "images_per_second": 0.205, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 1, "output_text": "The main object in the image is a red double-decker bus, which is in the foreground. The bus is moving on a road, and it is positioned near the center of the frame. In the background, there are buildings and a few people walking on the sidewalk. The bus is near the center of the image, and the buildings are further back.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18606.6, "ram_available_mb": 44234.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18607.4, "ram_available_mb": 44233.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.501, "power_cpu_cv_mean_watts": 2.13, "power_sys_5v0_mean_watts": 7.085, "gpu_utilization_percent_mean": 66.268}, "timestamp": "2026-01-30T20:36:38.287053"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4658.461, "latencies_ms": [4658.461], "images_per_second": 0.215, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 1, "output_text": "The image depicts a vibrant red double-decker bus in motion on a city street, with a clear blue sky overhead. The bus is adorned with various advertisements and a destination sign indicating it is heading to Aldwych. In the background, there are buildings, trees, and a few pedestrians, suggesting a bustling urban environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18607.4, "ram_available_mb": 44233.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18607.3, "ram_available_mb": 44233.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.362, "power_cpu_cv_mean_watts": 2.126, "power_sys_5v0_mean_watts": 7.094, "gpu_utilization_percent_mean": 69.051}, "timestamp": "2026-01-30T20:36:44.961470"}
{"image_index": 17, "image_name": "000000001584.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001584.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3708.864, "latencies_ms": [3708.864], "images_per_second": 0.27, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The red double-decker bus in the image has a striking color contrast against the overcast sky, with its bright red hue standing out. The lighting is diffused, likely due to the cloudy weather, casting a soft, even illumination on the bus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18607.3, "ram_available_mb": 44233.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18606.8, "ram_available_mb": 44234.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.333, "power_cpu_cv_mean_watts": 2.055, "power_sys_5v0_mean_watts": 7.017, "gpu_utilization_percent_mean": 69.323}, "timestamp": "2026-01-30T20:36:50.719455"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4498.125, "latencies_ms": [4498.125], "images_per_second": 0.222, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "The image shows a black and white cat with yellow eyes, resting on top of a laptop keyboard, which is partially visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 34.2, "ram_used_mb": 18606.8, "ram_available_mb": 44234.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18607.3, "ram_available_mb": 44233.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.356, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 88.432}, "timestamp": "2026-01-30T20:36:57.417674"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4823.132, "latencies_ms": [4823.132], "images_per_second": 0.207, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 12, "output_text": "1. Laptop\n2. Keyboard\n3. Mouse\n4. Laptop screen\n5. Laptop\n6. Laptop\n7. Laptop\n8. Laptop", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18607.3, "ram_available_mb": 44233.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18607.8, "ram_available_mb": 44233.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.749, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.739, "gpu_utilization_percent_mean": 88.0}, "timestamp": "2026-01-30T20:37:04.303066"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6419.794, "latencies_ms": [6419.794], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The main object in the image is a laptop, which is positioned in the foreground. The laptop is open, revealing its keyboard and screen. The keyboard is located in the foreground, with the keys clearly visible. The background is out of focus, emphasizing the laptop as the main subject.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18607.8, "ram_available_mb": 44233.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18607.4, "ram_available_mb": 44233.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.509, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 8.765, "gpu_utilization_percent_mean": 85.519}, "timestamp": "2026-01-30T20:37:12.784419"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8183.852, "latencies_ms": [8183.852], "images_per_second": 0.122, "prompt_tokens": 24, "response_tokens_est": 88, "n_tiles": 12, "output_text": "The image depicts a close-up view of a black and white cat sitting in front of a laptop keyboard. The cat's fur is predominantly black with white markings, and it has a yellowish-green eye. The laptop is open, and the keyboard is visible, with the keys in focus. The setting appears to be indoors, possibly in a home or office environment, with a blurred background that does not provide much detail.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18607.4, "ram_available_mb": 44233.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18607.5, "ram_available_mb": 44233.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.648, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.76, "gpu_utilization_percent_mean": 83.559}, "timestamp": "2026-01-30T20:37:22.989728"}
{"image_index": 18, "image_name": "000000001675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001675.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5803.79, "latencies_ms": [5803.79], "images_per_second": 0.172, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image features a black and white cat with striking yellow eyes, sitting in front of a laptop keyboard. The cat's fur is predominantly black with white accents, and the lighting is soft and natural, suggesting an indoor setting with natural light.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18607.5, "ram_available_mb": 44233.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18608.2, "ram_available_mb": 44232.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.856, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 8.75, "gpu_utilization_percent_mean": 86.792}, "timestamp": "2026-01-30T20:37:30.808512"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3260.5, "latencies_ms": [3260.5], "images_per_second": 0.307, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The image depicts a large, dark-colored steel arch bridge spanning across a body of water, with a city skyline in the background and a cloudy sky above.", "error": null, "sys_before": {"cpu_percent": 26.7, "ram_used_mb": 18608.2, "ram_available_mb": 44232.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.761, "power_cpu_cv_mean_watts": 1.556, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 73.731}, "timestamp": "2026-01-30T20:37:36.166782"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3587.445, "latencies_ms": [3587.445], "images_per_second": 0.279, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18611.1, "ram_available_mb": 44229.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.113, "power_cpu_cv_mean_watts": 1.603, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 72.621}, "timestamp": "2026-01-30T20:37:41.783769"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4627.943, "latencies_ms": [4627.943], "images_per_second": 0.216, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The main objects in the image are the Sydney Harbour Bridge and the Sydney Opera House. The Sydney Harbour Bridge is in the foreground, while the Sydney Opera House is in the background. The Sydney Opera House is located near the water, and the bridge spans over the water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.1, "ram_available_mb": 44229.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18613.0, "ram_available_mb": 44227.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.805, "power_cpu_cv_mean_watts": 1.803, "power_sys_5v0_mean_watts": 7.957, "gpu_utilization_percent_mean": 70.5}, "timestamp": "2026-01-30T20:37:48.432859"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5355.208, "latencies_ms": [5355.208], "images_per_second": 0.187, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image depicts a large, modern steel arch bridge spanning across a body of water, likely a river or bay, with a cloudy sky overhead. The bridge is a prominent feature in the foreground, while the city skyline in the background includes a distinctive building with a unique, curved design, suggesting it is the Sydney Opera House.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18613.0, "ram_available_mb": 44227.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18612.5, "ram_available_mb": 44228.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.128, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 69.067}, "timestamp": "2026-01-30T20:37:55.825700"}
{"image_index": 19, "image_name": "000000001761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001761.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3600.973, "latencies_ms": [3600.973], "images_per_second": 0.278, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The image features a large, dark-colored steel arch bridge with a cloudy sky in the background. The lighting is soft and diffused, with no harsh shadows, indicating an overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.5, "ram_available_mb": 44228.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18612.5, "ram_available_mb": 44228.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.878, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 72.5}, "timestamp": "2026-01-30T20:38:01.453855"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3434.15, "latencies_ms": [3434.15], "images_per_second": 0.291, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The image captures a zebra with its distinctive black and white stripes, standing in a natural grassy environment, showcasing the unique patterns and markings that are characteristic of the species.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18612.7, "ram_available_mb": 44228.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.337, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 72.821}, "timestamp": "2026-01-30T20:38:06.995249"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1798.906, "latencies_ms": [1798.906], "images_per_second": 0.556, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 6, "output_text": "zebra: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18612.7, "ram_available_mb": 44228.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 18613.7, "ram_available_mb": 44227.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.389, "power_cpu_cv_mean_watts": 0.801, "power_sys_5v0_mean_watts": 7.973, "gpu_utilization_percent_mean": 84.143}, "timestamp": "2026-01-30T20:38:10.829390"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7359.996, "latencies_ms": [7359.996], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 102, "n_tiles": 6, "output_text": "The main object in the foreground is a zebra, with its distinctive black and white stripes clearly visible. The zebra is positioned slightly to the left of the center of the image. In the background, there is a zebra's head visible, but it is not the primary focus. The zebra's head is slightly to the right and in the background. The zebra's legs and the grassy area are in the foreground, while the zebra's head and neck are in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18613.7, "ram_available_mb": 44227.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18611.8, "ram_available_mb": 44229.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.176, "power_cpu_cv_mean_watts": 2.029, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 67.774}, "timestamp": "2026-01-30T20:38:20.221402"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4883.58, "latencies_ms": [4883.58], "images_per_second": 0.205, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image captures a zebra in a natural setting, likely a savanna or grassland. The zebra is seen in profile, with its distinctive black and white stripes clearly visible. The background consists of tall grasses, indicating a wild, open environment typical of a zebra's natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.8, "ram_available_mb": 44229.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18612.4, "ram_available_mb": 44228.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.575, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 69.925}, "timestamp": "2026-01-30T20:38:27.119787"}
{"image_index": 20, "image_name": "000000001818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001818.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5360.588, "latencies_ms": [5360.588], "images_per_second": 0.187, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image is a black and white photograph of a zebra, showcasing its distinctive black and white striped pattern. The lighting is natural, likely from the sun, casting shadows that enhance the texture of the stripes. The zebra's coat appears to be dry and well-maintained, with no visible signs of wear or damage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.4, "ram_available_mb": 44228.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18613.1, "ram_available_mb": 44227.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.196, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 69.477}, "timestamp": "2026-01-30T20:38:34.511358"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3513.746, "latencies_ms": [3513.746], "images_per_second": 0.285, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image shows a small, cozy room with a bed, a table, and a chair, all set against a backdrop of a brick wall and a window with a view of a balcony.", "error": null, "sys_before": {"cpu_percent": 36.2, "ram_used_mb": 18613.1, "ram_available_mb": 44227.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18613.8, "ram_available_mb": 44227.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.948, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.936, "gpu_utilization_percent_mean": 72.724}, "timestamp": "2026-01-30T20:38:40.175937"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3395.804, "latencies_ms": [3395.804], "images_per_second": 0.294, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 6, "output_text": "1. Bed\n2. Bedding\n3. Bed frame\n4. Bedspread\n5. Floor\n6. Flooring\n7. Rug\n8. Rug pad", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18613.8, "ram_available_mb": 44227.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.319, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 72.821}, "timestamp": "2026-01-30T20:38:45.592413"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6216.514, "latencies_ms": [6216.514], "images_per_second": 0.161, "prompt_tokens": 30, "response_tokens_est": 83, "n_tiles": 6, "output_text": "The main objects in the image are a bed and a table. The bed is positioned in the foreground, with a colorful patterned bedspread. The table is located to the left of the bed, with a small black chair next to it. The room has a window on the left side, allowing natural light to enter. The bed is placed against a wall, and the table is positioned near the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18614.4, "ram_available_mb": 44226.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.611, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 68.365}, "timestamp": "2026-01-30T20:38:53.854206"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4799.513, "latencies_ms": [4799.513], "images_per_second": 0.208, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image depicts a cozy, well-lit room with a bed and a small table. The bed is adorned with a colorful, patterned comforter, and the room has a purple carpet. The room appears to be a bedroom, and the setting suggests a calm and comfortable environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18614.4, "ram_available_mb": 44226.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18614.4, "ram_available_mb": 44226.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.535, "power_cpu_cv_mean_watts": 1.833, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 69.85}, "timestamp": "2026-01-30T20:39:00.717317"}
{"image_index": 21, "image_name": "000000001993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000001993.jpg", "image_width": 640, "image_height": 419, "image_resolution": "640x419", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5338.824, "latencies_ms": [5338.824], "images_per_second": 0.187, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The room features a purple carpet, a bed with a colorful patterned duvet, a black metal frame bed, a wooden table with a black chair, a white door with glass panels, and a small window with white frames. The lighting is soft and natural, likely from a nearby window, and the overall atmosphere is cozy and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.4, "ram_available_mb": 44226.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.177, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 7.97, "gpu_utilization_percent_mean": 69.705}, "timestamp": "2026-01-30T20:39:08.080104"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4632.637, "latencies_ms": [4632.637], "images_per_second": 0.216, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "A purple bus with the number 96 is driving on a street, with a person in the driver's seat and another person walking on the sidewalk.", "error": null, "sys_before": {"cpu_percent": 28.8, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18615.5, "ram_available_mb": 44225.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.128, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.768, "gpu_utilization_percent_mean": 87.658}, "timestamp": "2026-01-30T20:39:14.867689"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10618.967, "latencies_ms": [10618.967], "images_per_second": 0.094, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- bus: 1\n- driver: 1\n- bus stop: 1\n- bus stop sign: 1\n- bus stop pole: 1\n- bus stop light: 1\n- bus stop signboard: 1\n- bus stop signboard pole: 1\n- bus stop signboard pole pole: 1\n- bus stop signboard pole pole pole: 1\n- bus stop signboard pole pole pole pole: 1\n- bus stop signboard pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole pole", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.5, "ram_available_mb": 44225.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.084, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 82.157}, "timestamp": "2026-01-30T20:39:27.499399"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6227.524, "latencies_ms": [6227.524], "images_per_second": 0.161, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The main object in the foreground is a purple bus with the number 96 on its front. The bus is parked on the side of a street, with a person walking in front of it. The background features a tree-lined street and a building with a chimney.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.597, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 8.755, "gpu_utilization_percent_mean": 85.731}, "timestamp": "2026-01-30T20:39:35.761926"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6187.252, "latencies_ms": [6187.252], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a purple bus with the number 96 on its destination sign, traveling on a road. A man is seen driving the bus, and another person is walking on the sidewalk. The setting appears to be a city street with buildings and trees in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.662, "power_cpu_cv_mean_watts": 1.518, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 86.308}, "timestamp": "2026-01-30T20:39:43.976439"}
{"image_index": 22, "image_name": "000000002006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5974.1, "latencies_ms": [5974.1], "images_per_second": 0.167, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The notable visual attributes of the bus include its purple color, which stands out against the background. The lighting is bright, indicating it is daytime. The materials used for the bus are likely metal and plastic, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.679, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 85.588}, "timestamp": "2026-01-30T20:39:51.978851"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3086.564, "latencies_ms": [3086.564], "images_per_second": 0.324, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image shows a close-up view of several green apples arranged in a bowl, with a focus on their smooth, glossy surfaces and uniform green color.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.911, "power_cpu_cv_mean_watts": 1.507, "power_sys_5v0_mean_watts": 7.962, "gpu_utilization_percent_mean": 74.28}, "timestamp": "2026-01-30T20:39:57.193509"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1457.582, "latencies_ms": [1457.582], "images_per_second": 0.686, "prompt_tokens": 26, "response_tokens_est": 5, "n_tiles": 6, "output_text": "apple: 8", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 2.8, "ram_used_mb": 18619.3, "ram_available_mb": 44221.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.64, "power_cpu_cv_mean_watts": 0.582, "power_sys_5v0_mean_watts": 7.872, "gpu_utilization_percent_mean": 90.727}, "timestamp": "2026-01-30T20:40:00.695325"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4458.044, "latencies_ms": [4458.044], "images_per_second": 0.224, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The main objects in the image are green apples. The apples are arranged in a way that the foreground has a few apples, while the background has more apples. The apples in the foreground are closer to the viewer, while the apples in the background are further away.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18619.3, "ram_available_mb": 44221.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18618.9, "ram_available_mb": 44222.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.989, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 70.622}, "timestamp": "2026-01-30T20:40:07.194823"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4623.556, "latencies_ms": [4623.556], "images_per_second": 0.216, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a close-up view of a white bowl filled with fresh green apples. The apples are arranged in a neat pile, with some partially overlapping each other. The setting appears to be a kitchen or a dining area, as the apples are likely being prepared for consumption.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18618.9, "ram_available_mb": 44222.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.676, "power_cpu_cv_mean_watts": 1.74, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 70.263}, "timestamp": "2026-01-30T20:40:13.841624"}
{"image_index": 23, "image_name": "000000002149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002149.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3756.244, "latencies_ms": [3756.244], "images_per_second": 0.266, "prompt_tokens": 22, "response_tokens_est": 43, "n_tiles": 6, "output_text": "The image features a bowl filled with fresh green apples, which are bright and vibrant in color. The lighting is soft and diffused, casting gentle shadows and highlighting the smooth, glossy surface of the apples.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18617.1, "ram_available_mb": 44223.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.767, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 72.097}, "timestamp": "2026-01-30T20:40:19.652901"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4776.936, "latencies_ms": [4776.936], "images_per_second": 0.209, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 12, "output_text": "A baseball player is standing on the pitcher's mound, preparing to swing at the pitch, while a umpire and catcher are positioned behind him.", "error": null, "sys_before": {"cpu_percent": 30.4, "ram_used_mb": 18617.1, "ram_available_mb": 44223.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18617.8, "ram_available_mb": 44223.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.006, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 86.462}, "timestamp": "2026-01-30T20:40:26.568073"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5431.945, "latencies_ms": [5431.945], "images_per_second": 0.184, "prompt_tokens": 26, "response_tokens_est": 43, "n_tiles": 12, "output_text": "1. Batter\n2. Catcher\n3. umpire\n4. Fielder\n5. Pitcher\n6. Infielder\n7. Outfielder\n8. Home plate", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18617.8, "ram_available_mb": 44223.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.153, "power_cpu_cv_mean_watts": 1.362, "power_sys_5v0_mean_watts": 8.744, "gpu_utilization_percent_mean": 86.778}, "timestamp": "2026-01-30T20:40:34.037091"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9768.911, "latencies_ms": [9768.911], "images_per_second": 0.102, "prompt_tokens": 30, "response_tokens_est": 114, "n_tiles": 12, "output_text": "The main object in the foreground is the baseball player, who is standing on the pitcher's mound. The player is wearing a red helmet and a white uniform with red accents. The baseball bat is held by the player, ready to swing. In the background, there is a catcher crouched behind home plate, wearing a gray uniform with a helmet. The umpire is standing near the catcher, wearing a light blue shirt and dark pants. The netting of the baseball field is visible in the foreground, separating the players from the audience.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.173, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 82.573}, "timestamp": "2026-01-30T20:40:45.820754"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7813.989, "latencies_ms": [7813.989], "images_per_second": 0.128, "prompt_tokens": 24, "response_tokens_est": 82, "n_tiles": 12, "output_text": "The image captures a baseball game in progress, with a batter at the plate preparing to swing at a pitch. The batter is wearing a red helmet and a white uniform with red accents, while the catcher and umpire are positioned behind him, ready to catch the ball. The scene takes place on a baseball field with a green outfield and a dirt infield, surrounded by a mesh fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.682, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 8.762, "gpu_utilization_percent_mean": 83.636}, "timestamp": "2026-01-30T20:40:55.694757"}
{"image_index": 24, "image_name": "000000002153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002153.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6106.352, "latencies_ms": [6106.352], "images_per_second": 0.164, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image captures a baseball game in progress, with a player in a white uniform and red helmet preparing to swing at a pitch. The field is well-maintained, with a green outfield and a dirt infield, and the lighting suggests it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18613.1, "ram_available_mb": 44227.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.553, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.756, "gpu_utilization_percent_mean": 86.0}, "timestamp": "2026-01-30T20:41:03.843684"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3752.772, "latencies_ms": [3752.772], "images_per_second": 0.266, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 6, "output_text": "The image depicts a beautifully arranged table set for a meal, featuring a variety of fresh fruits, cheeses, and bread, all neatly arranged on a red tablecloth, ready to be enjoyed.", "error": null, "sys_before": {"cpu_percent": 28.0, "ram_used_mb": 18612.9, "ram_available_mb": 44228.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18614.1, "ram_available_mb": 44226.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.641, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 71.484}, "timestamp": "2026-01-30T20:41:09.704346"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8930.338, "latencies_ms": [8930.338], "images_per_second": 0.112, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18614.1, "ram_available_mb": 44226.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18614.3, "ram_available_mb": 44226.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.728, "power_cpu_cv_mean_watts": 2.078, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 67.413}, "timestamp": "2026-01-30T20:41:20.684855"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4924.069, "latencies_ms": [4924.069], "images_per_second": 0.203, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The main object in the foreground is a white cake with a blueberry and raspberry topping. To the right of the cake, there is a plate with various cheeses, grapes, and bread. In the background, there are multiple glasses and plates, suggesting a setting for a gathering or celebration.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.3, "ram_available_mb": 44226.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.449, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 70.024}, "timestamp": "2026-01-30T20:41:27.620724"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6583.521, "latencies_ms": [6583.521], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 90, "n_tiles": 6, "output_text": "The image depicts a well-arranged outdoor dining setup with a red tablecloth. The table is set with a variety of food items, including a large white cake with fresh berries, a plate of cheese, a bowl of grapes, and a selection of bread and crackers. The scene suggests a casual, yet elegant gathering, possibly a wedding or a celebratory event, with the focus on the delicious spread of food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18614.3, "ram_available_mb": 44226.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.607, "power_cpu_cv_mean_watts": 1.981, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 68.764}, "timestamp": "2026-01-30T20:41:36.244558"}
{"image_index": 25, "image_name": "000000002157.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002157.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4295.62, "latencies_ms": [4295.62], "images_per_second": 0.233, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The image showcases a vibrant and colorful spread of food and drinks on a red tablecloth. The lighting is bright and natural, suggesting a sunny day, and the colors are vivid, with reds, blues, and greens dominating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.3, "ram_available_mb": 44226.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.334, "power_cpu_cv_mean_watts": 1.763, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 71.429}, "timestamp": "2026-01-30T20:41:42.571074"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1913.392, "latencies_ms": [1913.392], "images_per_second": 0.523, "prompt_tokens": 12, "response_tokens_est": 13, "n_tiles": 6, "output_text": "A man is surfing in the ocean, riding a wave.", "error": null, "sys_before": {"cpu_percent": 28.7, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.947, "power_cpu_cv_mean_watts": 0.908, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 82.333}, "timestamp": "2026-01-30T20:41:46.605890"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3578.214, "latencies_ms": [3578.214], "images_per_second": 0.279, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18614.1, "ram_available_mb": 44226.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.182, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 72.517}, "timestamp": "2026-01-30T20:41:52.194804"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6853.257, "latencies_ms": [6853.257], "images_per_second": 0.146, "prompt_tokens": 30, "response_tokens_est": 94, "n_tiles": 6, "output_text": "The main object in the image is a person riding a surfboard in the water. The person is positioned in the foreground, slightly to the left, and is the closest to the camera. The surfboard is also in the foreground, closer to the person. The background consists of the ocean, which is slightly blurred, indicating the depth of the water. The person is near the water's surface, and the surfboard is closer to the water's bottom.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18614.1, "ram_available_mb": 44226.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18615.3, "ram_available_mb": 44225.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.424, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 68.345}, "timestamp": "2026-01-30T20:42:01.079810"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4110.954, "latencies_ms": [4110.954], "images_per_second": 0.243, "prompt_tokens": 24, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image depicts a man in a blue surfboard riding a wave in the ocean. The scene is set on a sunny day with clear blue skies, and the water is a vibrant green color, indicating a shallow area near the shore.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18615.3, "ram_available_mb": 44225.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.445, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.176}, "timestamp": "2026-01-30T20:42:07.224800"}
{"image_index": 26, "image_name": "000000002261.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002261.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4179.724, "latencies_ms": [4179.724], "images_per_second": 0.239, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a person riding a surfboard in the ocean. The water is a vibrant green, indicating a possible algae bloom or the presence of sunlight reflecting off the water. The lighting is bright and clear, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18617.3, "ram_available_mb": 44223.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.264, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-30T20:42:13.458865"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3103.017, "latencies_ms": [3103.017], "images_per_second": 0.322, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 6, "output_text": "The image is a black and white photograph of a group of children, likely from a school, posing for a photo in front of a building with stone walls.", "error": null, "sys_before": {"cpu_percent": 34.5, "ram_used_mb": 18617.4, "ram_available_mb": 44223.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18618.0, "ram_available_mb": 44222.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.102, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 75.04}, "timestamp": "2026-01-30T20:42:18.681053"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8889.503, "latencies_ms": [8889.503], "images_per_second": 0.112, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "- 1 boy: 8\n- 1 girl: 8\n- 1 boy: 8\n- 1 girl: 8\n- 1 boy: 8\n- 1 girl: 8\n- 1 boy: 8\n- 1 girl: 8\n- 1 boy: 8\n- 1 girl: 8\n- 1 boy: 8\n- 1 girl: 8\n- 1 boy: 8\n- 1 girl: 8\n- 1 boy: 8\n- 1 girl: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.0, "ram_available_mb": 44222.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18617.1, "ram_available_mb": 44223.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.813, "power_cpu_cv_mean_watts": 2.067, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 67.493}, "timestamp": "2026-01-30T20:42:29.605397"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4582.37, "latencies_ms": [4582.37], "images_per_second": 0.218, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The main objects in the image are the children, who are positioned in the foreground. The children are arranged in a semi-circular formation, with some sitting on the ground and others standing. The background consists of a stone wall, providing a solid and stable backdrop for the children.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18617.1, "ram_available_mb": 44223.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18616.7, "ram_available_mb": 44224.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.941, "power_cpu_cv_mean_watts": 1.814, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 70.632}, "timestamp": "2026-01-30T20:42:36.244289"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5783.584, "latencies_ms": [5783.584], "images_per_second": 0.173, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The image depicts a group of children, likely in a school setting, posing for a group photo. The children are dressed in various school uniforms, and they are arranged in a semi-circular formation, with some sitting on the ground and others standing. The setting appears to be outdoors, possibly in a schoolyard or a park, with a stone wall in the background.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18616.7, "ram_available_mb": 44224.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.888, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 69.208}, "timestamp": "2026-01-30T20:42:44.069523"}
{"image_index": 27, "image_name": "000000002299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002299.jpg", "image_width": 500, "image_height": 302, "image_resolution": "500x302", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6050.316, "latencies_ms": [6050.316], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 81, "n_tiles": 6, "output_text": "The black and white photograph features a group of children in a school setting, with notable visual attributes such as the use of black and white photography, a classic and timeless look, and a soft, diffused lighting that highlights the children's features without creating harsh shadows. The children are dressed in various school uniforms, with some wearing dresses and others in suits, indicating a formal or semi-formal occasion.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18617.0, "ram_available_mb": 44223.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.877, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 69.1}, "timestamp": "2026-01-30T20:42:52.131996"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4826.659, "latencies_ms": [4826.659], "images_per_second": 0.207, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image shows a plate of bread with a slice of grilled bread on it, accompanied by a small bowl of sauce, a wine glass, and a napkin.", "error": null, "sys_before": {"cpu_percent": 32.3, "ram_used_mb": 18616.0, "ram_available_mb": 44224.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18617.1, "ram_available_mb": 44223.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.78, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 8.769, "gpu_utilization_percent_mean": 87.325}, "timestamp": "2026-01-30T20:42:59.142253"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4433.381, "latencies_ms": [4433.381], "images_per_second": 0.226, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 12, "output_text": "bread: 2\nbowl: 1\nglass: 1\ntable: 1\nspoon: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18617.1, "ram_available_mb": 44223.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18616.8, "ram_available_mb": 44224.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.434, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.77, "gpu_utilization_percent_mean": 90.333}, "timestamp": "2026-01-30T20:43:05.592825"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7370.896, "latencies_ms": [7370.896], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The main objects in the image are a plate of bread, a glass of red wine, and a white bowl. The plate of bread is in the foreground, with the glass of red wine and the white bowl placed behind it. The glass of red wine is positioned slightly to the right of the plate, and the white bowl is placed to the left of the plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.8, "ram_available_mb": 44224.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18618.1, "ram_available_mb": 44222.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.895, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 84.355}, "timestamp": "2026-01-30T20:43:14.993922"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6144.101, "latencies_ms": [6144.101], "images_per_second": 0.163, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image depicts a rustic dining setting with a focus on a plate of grilled bread and a glass of red wine. The scene is set in a cozy, possibly outdoor or semi-outdoor environment, with a wooden table and a blurred background suggesting a relaxed atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18618.1, "ram_available_mb": 44222.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18617.5, "ram_available_mb": 44223.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.604, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 86.431}, "timestamp": "2026-01-30T20:43:23.174523"}
{"image_index": 28, "image_name": "000000002431.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002431.jpg", "image_width": 457, "image_height": 640, "image_resolution": "457x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6895.299, "latencies_ms": [6895.299], "images_per_second": 0.145, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image features a rustic wooden table with a white plate containing grilled bread slices. The lighting is warm and natural, casting a soft glow on the scene. The bread has a golden-brown crust, indicating it has been grilled, and the plate is placed on a white cloth, adding a touch of elegance to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18617.5, "ram_available_mb": 44223.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18618.1, "ram_available_mb": 44222.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.083, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.768, "gpu_utilization_percent_mean": 85.069}, "timestamp": "2026-01-30T20:43:32.104275"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2893.393, "latencies_ms": [2893.393], "images_per_second": 0.346, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "A snowboarder is performing a jump in a snowy mountainous area, surrounded by snow-covered trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 28.2, "ram_used_mb": 18618.1, "ram_available_mb": 44222.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.417, "power_cpu_cv_mean_watts": 1.411, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 75.609}, "timestamp": "2026-01-30T20:43:37.107021"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3638.359, "latencies_ms": [3638.359], "images_per_second": 0.275, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "1. Person skiing\n2. Person standing\n3. Person standing\n4. Person standing\n5. Person standing\n6. Person standing\n7. Person standing\n8. Person standing", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18618.9, "ram_available_mb": 44222.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.916, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 72.233}, "timestamp": "2026-01-30T20:43:42.798827"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5129.734, "latencies_ms": [5129.734], "images_per_second": 0.195, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The main objects in the image are a skier in mid-air, a snowboarder standing on the snow, and a group of people standing on the snowy slope. The skier is in the foreground, the snowboarder is in the background, and the group of people is near the bottom of the slope.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.9, "ram_available_mb": 44222.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18620.0, "ram_available_mb": 44220.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.49, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.69}, "timestamp": "2026-01-30T20:43:49.943967"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3866.772, "latencies_ms": [3866.772], "images_per_second": 0.259, "prompt_tokens": 24, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image depicts a snowy mountainous landscape under a clear blue sky. A skier is captured mid-air, performing a jump, while two other individuals are standing on the snowy slope, observing the action.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18620.0, "ram_available_mb": 44220.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.508, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 71.406}, "timestamp": "2026-01-30T20:43:55.825704"}
{"image_index": 29, "image_name": "000000002473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4155.272, "latencies_ms": [4155.272], "images_per_second": 0.241, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a snowy landscape with a clear blue sky. The snow is pristine and untouched, indicating a recent snowfall. The scene is illuminated by the bright sunlight, casting shadows and highlighting the texture of the snow.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.375, "power_cpu_cv_mean_watts": 1.744, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 71.382}, "timestamp": "2026-01-30T20:44:01.995137"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4406.363, "latencies_ms": [4406.363], "images_per_second": 0.227, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "A person is skiing down a snowy mountain slope, with their skis cutting through the snow and their poles guiding their movement.", "error": null, "sys_before": {"cpu_percent": 34.1, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18618.0, "ram_available_mb": 44222.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.543, "power_cpu_cv_mean_watts": 1.179, "power_sys_5v0_mean_watts": 8.854, "gpu_utilization_percent_mean": 89.222}, "timestamp": "2026-01-30T20:44:08.568734"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5236.899, "latencies_ms": [5236.899], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "1. Skier\n2. Snow\n3. Ski poles\n4. Snowboard\n5. Snow\n6. Snowboard tracks\n7. Snowboard\n8. Snowboard tracks", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.0, "ram_available_mb": 44222.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18616.7, "ram_available_mb": 44224.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.322, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 8.765, "gpu_utilization_percent_mean": 88.279}, "timestamp": "2026-01-30T20:44:15.823740"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6268.385, "latencies_ms": [6268.385], "images_per_second": 0.16, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The main objects in the image are a person skiing and a snowy landscape. The person is positioned in the foreground, standing on a ski trail, while the snowy landscape stretches out in the background. The person is near the foreground, and the landscape is further away.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18616.7, "ram_available_mb": 44224.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18617.9, "ram_available_mb": 44223.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.601, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 85.635}, "timestamp": "2026-01-30T20:44:24.115601"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7155.271, "latencies_ms": [7155.271], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a snowy landscape with a person standing on skis, holding ski poles. The individual is dressed in winter attire, including a green top and black pants, and is surrounded by snow-covered terrain with a few trees and rocks visible. The sky is partly cloudy, and the overall scene suggests a serene winter setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18617.9, "ram_available_mb": 44223.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18617.6, "ram_available_mb": 44223.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.026, "power_cpu_cv_mean_watts": 1.669, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 85.267}, "timestamp": "2026-01-30T20:44:33.283849"}
{"image_index": 30, "image_name": "000000002532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002532.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5012.286, "latencies_ms": [5012.286], "images_per_second": 0.2, "prompt_tokens": 22, "response_tokens_est": 37, "n_tiles": 12, "output_text": "The image depicts a snowy landscape under a clear blue sky with scattered white clouds. The scene is illuminated by natural sunlight, casting shadows on the snow-covered ground.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18617.6, "ram_available_mb": 44223.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18619.3, "ram_available_mb": 44221.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.669, "power_cpu_cv_mean_watts": 1.326, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 88.595}, "timestamp": "2026-01-30T20:44:40.316052"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4589.046, "latencies_ms": [4589.046], "images_per_second": 0.218, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The image shows a close-up of a brown, round object with a glossy surface, which appears to be a chocolate bar or a similar treat.", "error": null, "sys_before": {"cpu_percent": 26.2, "ram_used_mb": 18619.1, "ram_available_mb": 44221.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18621.7, "ram_available_mb": 44219.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.245, "power_cpu_cv_mean_watts": 1.276, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 88.974}, "timestamp": "2026-01-30T20:44:47.068339"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3458.548, "latencies_ms": [3458.548], "images_per_second": 0.289, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 12, "output_text": "apple: 1\nbanana: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18621.7, "ram_available_mb": 44219.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 18621.3, "ram_available_mb": 44219.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.793, "power_cpu_cv_mean_watts": 0.844, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 94.75}, "timestamp": "2026-01-30T20:44:52.563283"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5839.954, "latencies_ms": [5839.954], "images_per_second": 0.171, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The main object in the image is a banana, which is positioned in the foreground. The banana is placed on a dark surface, likely a table or countertop. The background is slightly blurred, indicating that the focus is on the banana.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18621.3, "ram_available_mb": 44219.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18621.3, "ram_available_mb": 44219.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.999, "power_cpu_cv_mean_watts": 1.461, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 86.792}, "timestamp": "2026-01-30T20:45:00.420799"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5159.854, "latencies_ms": [5159.854], "images_per_second": 0.194, "prompt_tokens": 24, "response_tokens_est": 39, "n_tiles": 12, "output_text": "The image shows a close-up of a chocolate-covered banana placed on a dark surface. The lighting is dim, and the focus is on the banana, making the background indistinct.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18621.3, "ram_available_mb": 44219.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18619.8, "ram_available_mb": 44221.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.408, "power_cpu_cv_mean_watts": 1.36, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 88.326}, "timestamp": "2026-01-30T20:45:07.615212"}
{"image_index": 31, "image_name": "000000002587.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002587.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5417.569, "latencies_ms": [5417.569], "images_per_second": 0.185, "prompt_tokens": 22, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image features a close-up of a chocolate-covered banana with a glossy, smooth surface. The lighting is dim, casting a warm, golden hue over the scene, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.8, "ram_available_mb": 44221.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.187, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 87.2}, "timestamp": "2026-01-30T20:45:15.069749"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3031.616, "latencies_ms": [3031.616], "images_per_second": 0.33, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image shows a white mug with a black skull and crossbones design, and a black knife with a silver blade lying on a textured surface.", "error": null, "sys_before": {"cpu_percent": 31.2, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18619.8, "ram_available_mb": 44221.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.13, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 73.32}, "timestamp": "2026-01-30T20:45:20.229903"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3564.398, "latencies_ms": [3564.398], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "1. Skull and crossed bones on mug\n2. Knife\n3. Mug\n4. Knife\n5. Mug\n6. Knife\n7. Mug\n8. Knife", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.8, "ram_available_mb": 44221.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18618.5, "ram_available_mb": 44222.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.26, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 72.862}, "timestamp": "2026-01-30T20:45:25.826007"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5499.794, "latencies_ms": [5499.794], "images_per_second": 0.182, "prompt_tokens": 30, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The main objects in the image are a white mug with a skull and crossed bones design, and a black knife with a serrated edge. The white mug is positioned in the foreground, while the black knife is located in the background. The mug is placed on a surface with a striped pattern, and the knife is lying parallel to the mug.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18618.5, "ram_available_mb": 44222.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18618.8, "ram_available_mb": 44222.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.18, "power_cpu_cv_mean_watts": 1.926, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.574}, "timestamp": "2026-01-30T20:45:33.346492"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5029.904, "latencies_ms": [5029.904], "images_per_second": 0.199, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image shows a white mug with a black skull and crossbones design on it, placed on a surface with a striped pattern. To the right of the mug, there is a black knife with a silver blade lying on the same surface. The mug and knife are the only objects visible in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.8, "ram_available_mb": 44222.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18620.1, "ram_available_mb": 44220.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.317, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 69.929}, "timestamp": "2026-01-30T20:45:40.399093"}
{"image_index": 32, "image_name": "000000002592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002592.jpg", "image_width": 640, "image_height": 366, "image_resolution": "640x366", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4764.107, "latencies_ms": [4764.107], "images_per_second": 0.21, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image features a white mug with a black skull and crossbones design, and a black knife with a silver blade. The mug and knife are placed on a textured surface, possibly a tablecloth, and the lighting is soft and diffused, creating a calm and neutral atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18620.1, "ram_available_mb": 44220.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18618.4, "ram_available_mb": 44222.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.694, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.564}, "timestamp": "2026-01-30T20:45:47.181488"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2399.852, "latencies_ms": [2399.852], "images_per_second": 0.417, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 1, "output_text": "A group of people is gathered around a bar counter, with one person in a gray suit and glasses standing at the counter, seemingly engaged in conversation with the others.", "error": null, "sys_before": {"cpu_percent": 14.5, "ram_used_mb": 18618.4, "ram_available_mb": 44222.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18619.1, "ram_available_mb": 44221.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.274, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 6.869, "gpu_utilization_percent_mean": 70.75}, "timestamp": "2026-01-30T20:45:51.644896"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8202.508, "latencies_ms": [8202.508], "images_per_second": 0.122, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 1, "output_text": "- man: 3\n- woman: 2\n- man: 2\n- woman: 2\n- man: 1\n- woman: 1\n- man: 1\n- woman: 1\n- man: 1\n- woman: 1\n- man: 1\n- woman: 1\n- man: 1\n- woman: 1\n- man: 1\n- woman: 1\n- man: 1\n- woman: 1\n- man: 1\n- woman: 1\n- man: 1\n- woman", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18618.5, "ram_available_mb": 44222.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18618.2, "ram_available_mb": 44222.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.65, "power_cpu_cv_mean_watts": 2.256, "power_sys_5v0_mean_watts": 7.225, "gpu_utilization_percent_mean": 64.859}, "timestamp": "2026-01-30T20:46:01.895190"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6162.571, "latencies_ms": [6162.571], "images_per_second": 0.162, "prompt_tokens": 30, "response_tokens_est": 95, "n_tiles": 1, "output_text": "In the image, the main objects are the people and the wine display. The people are positioned in the foreground, with the man in the light blue shirt and the woman in the black top standing near the wine display. The wine bottles are arranged on the counter, and the display case is located to the left of the counter. The background features a wooden counter and shelves with various items, while the far right side shows a person standing near a counter with a laptop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18618.2, "ram_available_mb": 44222.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18619.7, "ram_available_mb": 44221.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.819, "power_cpu_cv_mean_watts": 2.222, "power_sys_5v0_mean_watts": 7.151, "gpu_utilization_percent_mean": 65.094}, "timestamp": "2026-01-30T20:46:10.095422"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5187.41, "latencies_ms": [5187.41], "images_per_second": 0.193, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 1, "output_text": "The scene depicts a lively indoor setting, likely a wine tasting room or a bar, where a group of people is engaged in a social interaction. The room is filled with various wine bottles displayed on shelves and a wooden counter where a person in a gray suit is interacting with a customer. The atmosphere appears to be convivial and relaxed, with people mingling and enjoying the wine.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.7, "ram_available_mb": 44221.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.755, "power_cpu_cv_mean_watts": 2.152, "power_sys_5v0_mean_watts": 7.105, "gpu_utilization_percent_mean": 65.372}, "timestamp": "2026-01-30T20:46:17.300562"}
{"image_index": 33, "image_name": "000000002685.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002685.jpg", "image_width": 640, "image_height": 555, "image_resolution": "640x555", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3075.578, "latencies_ms": [3075.578], "images_per_second": 0.325, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The room is painted in a soft teal color, with a warm, ambient lighting that creates a cozy atmosphere. The wooden counter and bar stools are made of light-colored wood, complementing the overall color scheme.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18618.2, "ram_available_mb": 44222.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.582, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 6.951, "gpu_utilization_percent_mean": 67.24}, "timestamp": "2026-01-30T20:46:22.407957"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4498.48, "latencies_ms": [4498.48], "images_per_second": 0.222, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "A large flock of white birds is flying in the sky above a calm body of water, with a dock and boats visible in the background.", "error": null, "sys_before": {"cpu_percent": 33.2, "ram_used_mb": 18618.2, "ram_available_mb": 44222.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18619.0, "ram_available_mb": 44221.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.46, "power_cpu_cv_mean_watts": 1.223, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 88.703}, "timestamp": "2026-01-30T20:46:29.115569"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4412.7, "latencies_ms": [4412.7], "images_per_second": 0.227, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 12, "output_text": "bird: 1\nboat: 1\nbuilding: 1\ntower: 1\ntube: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.0, "ram_available_mb": 44221.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18618.9, "ram_available_mb": 44222.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.44, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 8.781, "gpu_utilization_percent_mean": 90.324}, "timestamp": "2026-01-30T20:46:35.569787"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6832.857, "latencies_ms": [6832.857], "images_per_second": 0.146, "prompt_tokens": 30, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The main objects in the image are a large field of tall grass, a white bird in flight, and a docked boat in the background. The docked boat is near the dock, while the white bird is in the foreground. The field of tall grass is in the background, and the docked boat is further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.9, "ram_available_mb": 44222.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18620.0, "ram_available_mb": 44220.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.401, "power_cpu_cv_mean_watts": 1.63, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 85.5}, "timestamp": "2026-01-30T20:46:44.436554"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7220.679, "latencies_ms": [7220.679], "images_per_second": 0.138, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The image depicts a serene coastal scene with a large expanse of green grass in the foreground, likely a marsh or wetland area. In the background, there is a dock with various boats and fishing equipment, and a cloudy sky above. A white bird is seen flying in the distance, adding a dynamic element to the tranquil setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18620.0, "ram_available_mb": 44220.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18618.4, "ram_available_mb": 44222.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.075, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 84.933}, "timestamp": "2026-01-30T20:46:53.667863"}
{"image_index": 34, "image_name": "000000002923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000002923.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6329.048, "latencies_ms": [6329.048], "images_per_second": 0.158, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a serene coastal scene with a mix of green and brown hues, indicating a mix of vegetation and sandy terrain. The sky is partly cloudy, with patches of blue peeking through the grey clouds, suggesting a partly cloudy day with ample sunlight.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18618.4, "ram_available_mb": 44222.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18618.5, "ram_available_mb": 44222.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.459, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 85.981}, "timestamp": "2026-01-30T20:47:02.009586"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2626.466, "latencies_ms": [2626.466], "images_per_second": 0.381, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A young man is sitting on the toilet, wearing a dark shirt and jeans, with his hands resting on the seat.", "error": null, "sys_before": {"cpu_percent": 23.3, "ram_used_mb": 18618.5, "ram_available_mb": 44222.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18617.7, "ram_available_mb": 44223.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.084, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 74.714}, "timestamp": "2026-01-30T20:47:06.731598"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3279.868, "latencies_ms": [3279.868], "images_per_second": 0.305, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 6, "output_text": "1. Man\n2. Toilet\n3. Clothes\n4. Shoes\n5. Floor\n6. Wall\n7. Sink\n8. Ceiling", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18617.7, "ram_available_mb": 44223.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18620.1, "ram_available_mb": 44220.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.429, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 72.963}, "timestamp": "2026-01-30T20:47:12.025016"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4841.828, "latencies_ms": [4841.828], "images_per_second": 0.207, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The main object in the foreground is a man sitting on the toilet. He is wearing a dark-colored shirt and jeans, with his legs crossed. The toilet is positioned to the right of him. In the background, there is a wall with a checkered pattern and a sink visible to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18620.1, "ram_available_mb": 44220.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18621.1, "ram_available_mb": 44219.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.691, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 70.512}, "timestamp": "2026-01-30T20:47:18.914290"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5098.101, "latencies_ms": [5098.101], "images_per_second": 0.196, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The image depicts a young man sitting on the toilet in a bathroom. He is wearing a dark-colored shirt and jeans, and his legs are crossed. The setting is a bathroom with a black and white checkered tile wall, a white toilet, and a black and white checkered towel or mat on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18621.1, "ram_available_mb": 44219.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18621.1, "ram_available_mb": 44219.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.281, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 69.279}, "timestamp": "2026-01-30T20:47:26.052911"}
{"image_index": 35, "image_name": "000000003156.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003156.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4058.031, "latencies_ms": [4058.031], "images_per_second": 0.246, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image is a black and white photograph featuring a young man sitting on the toilet. The man is wearing a dark-colored shirt, jeans, and sneakers. The lighting is soft and even, creating a monochromatic effect.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18621.1, "ram_available_mb": 44219.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18620.7, "ram_available_mb": 44220.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.389, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 71.618}, "timestamp": "2026-01-30T20:47:32.122883"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2209.96, "latencies_ms": [2209.96], "images_per_second": 0.452, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 2, "output_text": "A group of people is standing on a snowy mountain slope, with tracks in the snow leading up to them, indicating recent human activity.", "error": null, "sys_before": {"cpu_percent": 20.3, "ram_used_mb": 18620.7, "ram_available_mb": 44220.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18621.1, "ram_available_mb": 44219.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.733, "power_cpu_cv_mean_watts": 1.692, "power_sys_5v0_mean_watts": 7.061, "gpu_utilization_percent_mean": 64.056}, "timestamp": "2026-01-30T20:47:36.418506"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2269.961, "latencies_ms": [2269.961], "images_per_second": 0.441, "prompt_tokens": 26, "response_tokens_est": 30, "n_tiles": 2, "output_text": "- Snow\n- Mountain\n- People\n- Tracks\n- Hills\n- Slopes\n- Rocks\n- Snowdrifts", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18621.1, "ram_available_mb": 44219.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18619.9, "ram_available_mb": 44221.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.845, "power_cpu_cv_mean_watts": 1.625, "power_sys_5v0_mean_watts": 7.096, "gpu_utilization_percent_mean": 64.556}, "timestamp": "2026-01-30T20:47:40.711738"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4658.452, "latencies_ms": [4658.452], "images_per_second": 0.215, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 2, "output_text": "The main objects in the image are a group of people and a snowy mountain landscape. The people are located in the foreground, near the center of the image, while the snowy mountain and its rocky peaks are in the background. The tracks in the snow indicate that the people are near the mountain, possibly hiking or exploring the area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.9, "ram_available_mb": 44221.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18620.6, "ram_available_mb": 44220.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.958, "power_cpu_cv_mean_watts": 2.077, "power_sys_5v0_mean_watts": 7.292, "gpu_utilization_percent_mean": 61.211}, "timestamp": "2026-01-30T20:47:47.396296"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3198.005, "latencies_ms": [3198.005], "images_per_second": 0.313, "prompt_tokens": 24, "response_tokens_est": 45, "n_tiles": 2, "output_text": "The image depicts a snowy mountainous landscape with a group of people gathered on the slopes. The clear blue sky and the tracks in the snow suggest recent human activity, possibly indicating a hiking or skiing expedition.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18620.6, "ram_available_mb": 44220.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18621.4, "ram_available_mb": 44219.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.288, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 7.19, "gpu_utilization_percent_mean": 62.556}, "timestamp": "2026-01-30T20:47:52.632135"}
{"image_index": 36, "image_name": "000000003255.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003255.jpg", "image_width": 640, "image_height": 363, "image_resolution": "640x363", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4790.581, "latencies_ms": [4790.581], "images_per_second": 0.209, "prompt_tokens": 22, "response_tokens_est": 71, "n_tiles": 2, "output_text": "The image showcases a snowy mountain landscape under a clear blue sky. The snow-covered slopes are illuminated by the sunlight, creating a striking contrast between the white snow and the blue sky. The lighting highlights the texture of the snow and the rugged terrain, while the clear weather adds to the serene and pristine atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18621.4, "ram_available_mb": 44219.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18620.5, "ram_available_mb": 44220.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.872, "power_cpu_cv_mean_watts": 2.103, "power_sys_5v0_mean_watts": 7.283, "gpu_utilization_percent_mean": 62.35}, "timestamp": "2026-01-30T20:47:59.485336"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2466.938, "latencies_ms": [2466.938], "images_per_second": 0.405, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The image shows a bowl of food consisting of white rice, a portion of broccoli, and a portion of a red sauce, all placed on a wooden surface.", "error": null, "sys_before": {"cpu_percent": 10.4, "ram_used_mb": 18620.5, "ram_available_mb": 44220.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.274, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 6.874, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-30T20:48:04.020914"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8269.526, "latencies_ms": [8269.526], "images_per_second": 0.121, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 1, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.752, "power_cpu_cv_mean_watts": 2.245, "power_sys_5v0_mean_watts": 7.196, "gpu_utilization_percent_mean": 65.0}, "timestamp": "2026-01-30T20:48:14.311881"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4123.458, "latencies_ms": [4123.458], "images_per_second": 0.243, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The main objects in the image are a bowl of food and a bowl of broccoli. The bowl of food is placed in the foreground, while the bowl of broccoli is positioned in the background. The food is placed on a wooden surface, and the bowl of broccoli is slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18619.0, "ram_available_mb": 44221.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.745, "power_cpu_cv_mean_watts": 2.097, "power_sys_5v0_mean_watts": 7.097, "gpu_utilization_percent_mean": 66.765}, "timestamp": "2026-01-30T20:48:20.500568"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3848.116, "latencies_ms": [3848.116], "images_per_second": 0.26, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The image shows a simple yet appetizing meal consisting of a bowl of white rice, a portion of broccoli, and a serving of red-orange stew. The meal is presented on a white plate, and the setting appears to be a dining table with a dark wooden surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.0, "ram_available_mb": 44221.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18619.1, "ram_available_mb": 44221.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.551, "power_cpu_cv_mean_watts": 2.067, "power_sys_5v0_mean_watts": 7.056, "gpu_utilization_percent_mean": 68.032}, "timestamp": "2026-01-30T20:48:26.365363"}
{"image_index": 37, "image_name": "000000003501.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003501.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3486.349, "latencies_ms": [3486.349], "images_per_second": 0.287, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 1, "output_text": "The image features a white bowl containing a meal consisting of broccoli, white rice, and a red-orange sauce. The bowl is placed on a wooden surface, and the lighting is soft and even, highlighting the colors and textures of the food.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18619.1, "ram_available_mb": 44221.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.457, "power_cpu_cv_mean_watts": 2.017, "power_sys_5v0_mean_watts": 6.98, "gpu_utilization_percent_mean": 68.857}, "timestamp": "2026-01-30T20:48:31.865170"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4025.014, "latencies_ms": [4025.014], "images_per_second": 0.248, "prompt_tokens": 12, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image shows a person's lower legs and feet, wearing black shoes with white soles, standing on a skateboard with a checkered pattern on the deck, positioned on a wooden surface with grass and a bench in the background.", "error": null, "sys_before": {"cpu_percent": 25.6, "ram_used_mb": 18618.4, "ram_available_mb": 44222.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.849, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 70.455}, "timestamp": "2026-01-30T20:48:38.036258"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4470.257, "latencies_ms": [4470.257], "images_per_second": 0.224, "prompt_tokens": 26, "response_tokens_est": 55, "n_tiles": 6, "output_text": "skateboard: 1\nskateboard wheels: 1\nskateboard deck: 1\nskateboard handle: 1\nskateboard footwear: 1\nskateboard strap: 1\nskateboard: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18620.7, "ram_available_mb": 44220.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.014, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 70.811}, "timestamp": "2026-01-30T20:48:44.563661"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4890.529, "latencies_ms": [4890.529], "images_per_second": 0.204, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The main object in the foreground is a skateboard with a checkered pattern on the deck. The skateboard is positioned on a wooden surface, likely a bench or a ledge. In the background, there is a wooden plank and a grassy area, indicating that the scene is set outdoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18620.7, "ram_available_mb": 44220.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18622.6, "ram_available_mb": 44218.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.593, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 69.927}, "timestamp": "2026-01-30T20:48:51.475117"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4345.753, "latencies_ms": [4345.753], "images_per_second": 0.23, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The image depicts a skateboard resting on a wooden surface, likely a deck or a bench, with a grassy background. The skateboard has a checkered pattern on its wheels, and the person wearing the skateboard is not visible in the frame.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18622.6, "ram_available_mb": 44218.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18621.0, "ram_available_mb": 44219.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.156, "power_cpu_cv_mean_watts": 1.77, "power_sys_5v0_mean_watts": 7.976, "gpu_utilization_percent_mean": 71.25}, "timestamp": "2026-01-30T20:48:57.868158"}
{"image_index": 38, "image_name": "000000003553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003553.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3916.996, "latencies_ms": [3916.996], "images_per_second": 0.255, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The notable visual attributes of the image include a skateboard with a checkered pattern on the front, resting on a wooden surface. The lighting is bright, casting shadows on the ground, and the weather appears to be sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18621.0, "ram_available_mb": 44219.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18622.2, "ram_available_mb": 44218.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.774, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 71.906}, "timestamp": "2026-01-30T20:49:03.807172"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3272.324, "latencies_ms": [3272.324], "images_per_second": 0.306, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 6, "output_text": "The image shows a bunch of bananas with one of them slightly bent, resting on a wooden surface, with a blurred background featuring a computer monitor and a blue cup.", "error": null, "sys_before": {"cpu_percent": 35.2, "ram_used_mb": 18622.2, "ram_available_mb": 44218.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18621.2, "ram_available_mb": 44219.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.768, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 70.222}, "timestamp": "2026-01-30T20:49:09.213990"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3092.214, "latencies_ms": [3092.214], "images_per_second": 0.323, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "- Banana: 3\n- Mango: 1\n- Cup: 1\n- Table: 1\n- Computer: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18621.2, "ram_available_mb": 44219.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18619.7, "ram_available_mb": 44221.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.929, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 7.94, "gpu_utilization_percent_mean": 73.84}, "timestamp": "2026-01-30T20:49:14.329137"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5549.109, "latencies_ms": [5549.109], "images_per_second": 0.18, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The main object in the foreground is a bunch of bananas, which are positioned on a wooden surface. The bananas are slightly out of focus, indicating that they are not the main subject of the image. In the background, there is a blurred object that appears to be a computer monitor, suggesting that the setting might be an office or a workspace.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18619.7, "ram_available_mb": 44221.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.279, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 69.935}, "timestamp": "2026-01-30T20:49:21.922808"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6589.797, "latencies_ms": [6589.797], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 90, "n_tiles": 6, "output_text": "The image depicts a close-up view of a bunch of bananas placed on a wooden surface, likely a table or countertop. The bananas are yellow with some brown spots, and one of them is slightly bent, giving the impression that it is about to fall. In the background, there is a blurred image of a computer monitor and a blue cup, suggesting that the setting is an indoor environment, possibly a home or office.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18617.6, "ram_available_mb": 44223.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.574, "power_cpu_cv_mean_watts": 1.96, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 68.291}, "timestamp": "2026-01-30T20:49:30.548210"}
{"image_index": 39, "image_name": "000000003661.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003661.jpg", "image_width": 640, "image_height": 384, "image_resolution": "640x384", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5073.374, "latencies_ms": [5073.374], "images_per_second": 0.197, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The image features a bunch of ripe bananas with a yellowish-green hue, indicating ripeness. The lighting is soft and natural, casting gentle shadows on the wooden surface. The bananas are placed on a table, and there is a blurred background with a blue object and a cup, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18617.6, "ram_available_mb": 44223.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18620.0, "ram_available_mb": 44220.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.513, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 69.976}, "timestamp": "2026-01-30T20:49:37.658619"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4924.797, "latencies_ms": [4924.797], "images_per_second": 0.203, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 12, "output_text": "The image shows a plate of food consisting of stir-fried chicken, broccoli, carrots, and rice, all served on a colorful plate with a red and white pattern.", "error": null, "sys_before": {"cpu_percent": 32.5, "ram_used_mb": 18620.0, "ram_available_mb": 44220.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18618.8, "ram_available_mb": 44222.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.76, "power_cpu_cv_mean_watts": 1.29, "power_sys_5v0_mean_watts": 8.781, "gpu_utilization_percent_mean": 86.951}, "timestamp": "2026-01-30T20:49:44.748988"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5024.215, "latencies_ms": [5024.215], "images_per_second": 0.199, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 12, "output_text": "chicken: 2\nrice: 1\ncarrots: 2\nbroccoli: 1\npeppers: 1\nsauce: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.8, "ram_available_mb": 44222.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18619.7, "ram_available_mb": 44221.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.72, "power_cpu_cv_mean_watts": 1.326, "power_sys_5v0_mean_watts": 8.779, "gpu_utilization_percent_mean": 88.167}, "timestamp": "2026-01-30T20:49:51.798589"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6116.934, "latencies_ms": [6116.934], "images_per_second": 0.163, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The main objects in the image are a plate of food and a glass of water. The plate of food is placed in the foreground, with the glass of water positioned in the background. The food is positioned near the glass, and the glass is placed on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.7, "ram_available_mb": 44221.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18620.2, "ram_available_mb": 44220.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.833, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 86.137}, "timestamp": "2026-01-30T20:49:59.942568"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6473.815, "latencies_ms": [6473.815], "images_per_second": 0.154, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image depicts a plate of food on a wooden table, likely in a dining setting. The plate contains a variety of dishes, including rice, broccoli, carrots, and chicken, all garnished with a sauce. The setting suggests a casual meal, possibly at home or in a restaurant.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18620.2, "ram_available_mb": 44220.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18619.2, "ram_available_mb": 44221.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.571, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.473}, "timestamp": "2026-01-30T20:50:08.448376"}
{"image_index": 40, "image_name": "000000003845.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003845.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6295.145, "latencies_ms": [6295.145], "images_per_second": 0.159, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image features a plate of food with a vibrant and colorful design. The plate is adorned with a mix of red, orange, and green hues, creating a visually appealing contrast. The lighting is warm and natural, casting a soft glow on the food and enhancing the colors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.2, "ram_available_mb": 44221.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18619.4, "ram_available_mb": 44221.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.62, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.797, "gpu_utilization_percent_mean": 86.264}, "timestamp": "2026-01-30T20:50:16.786421"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4242.274, "latencies_ms": [4242.274], "images_per_second": 0.236, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 12, "output_text": "A young girl is playing a video game on a couch in a cozy living room, surrounded by family members and friends.", "error": null, "sys_before": {"cpu_percent": 28.9, "ram_used_mb": 18619.4, "ram_available_mb": 44221.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.676, "power_cpu_cv_mean_watts": 1.179, "power_sys_5v0_mean_watts": 8.862, "gpu_utilization_percent_mean": 88.0}, "timestamp": "2026-01-30T20:50:23.175692"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10513.204, "latencies_ms": [10513.204], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- girl: 1\n- woman: 2\n- man: 1\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman: 2\n- woman", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.238, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 82.477}, "timestamp": "2026-01-30T20:50:35.720902"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6698.973, "latencies_ms": [6698.973], "images_per_second": 0.149, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The main objects in the image are a young girl, a man, and a woman. The girl is in the foreground, standing on a grey rug, while the man and woman are in the background, near a couch. The man is standing near a bar, and the woman is standing near a staircase.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18618.8, "ram_available_mb": 44222.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.288, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.766, "gpu_utilization_percent_mean": 85.286}, "timestamp": "2026-01-30T20:50:44.442597"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6173.04, "latencies_ms": [6173.04], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The scene is set in a cozy living room with a gray sofa, a red patterned cushion, and a gray rug. A group of people, including a young girl in a colorful dress, are gathered around a coffee table, with one person holding a remote control.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18618.8, "ram_available_mb": 44222.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18618.9, "ram_available_mb": 44222.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.538, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.74, "gpu_utilization_percent_mean": 86.0}, "timestamp": "2026-01-30T20:50:52.639326"}
{"image_index": 41, "image_name": "000000003934.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000003934.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5461.72, "latencies_ms": [5461.72], "images_per_second": 0.183, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The room is well-lit with warm, ambient lighting, creating a cozy atmosphere. The wooden floor and light-colored walls provide a neutral backdrop, while the gray and white patterned rug adds a touch of texture.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18618.9, "ram_available_mb": 44222.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18622.5, "ram_available_mb": 44218.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.132, "power_cpu_cv_mean_watts": 1.42, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 87.043}, "timestamp": "2026-01-30T20:51:00.134260"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3554.514, "latencies_ms": [3554.514], "images_per_second": 0.281, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 6, "output_text": "A man in a dark suit and striped tie is shaking hands with another man in a light-colored shirt and tie, while a group of people are gathered around tables in a formal event setting.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18622.5, "ram_available_mb": 44218.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18621.4, "ram_available_mb": 44219.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.109, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 72.414}, "timestamp": "2026-01-30T20:51:05.791671"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4047.391, "latencies_ms": [4047.391], "images_per_second": 0.247, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 6, "output_text": "1. Man in suit\n2. Man in suit\n3. Man in suit\n4. Man in suit\n5. Man in suit\n6. Man in suit\n7. Man in suit\n8. Man in suit", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18621.4, "ram_available_mb": 44219.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18621.3, "ram_available_mb": 44219.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.553, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 71.606}, "timestamp": "2026-01-30T20:51:11.850132"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4419.106, "latencies_ms": [4419.106], "images_per_second": 0.226, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The main object in the foreground is a man in a dark suit and yellow tie, shaking hands with another man in a light blue shirt and dark jacket. The background features a crowded room with tables set for a formal event, where other attendees are engaged in conversations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18621.3, "ram_available_mb": 44219.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18620.6, "ram_available_mb": 44220.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.013, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 70.486}, "timestamp": "2026-01-30T20:51:18.291956"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6400.292, "latencies_ms": [6400.292], "images_per_second": 0.156, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 6, "output_text": "The image depicts a formal event, likely a conference or banquet, taking place in a spacious, well-lit room with elegant decor. Several attendees are engaged in conversations, while others are seated at tables covered with white tablecloths, some with plates and glasses. The central focus is on two men shaking hands, one in a dark suit and the other in a striped suit, indicating a formal interaction or greeting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18620.6, "ram_available_mb": 44220.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18624.1, "ram_available_mb": 44216.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.649, "power_cpu_cv_mean_watts": 1.935, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 68.925}, "timestamp": "2026-01-30T20:51:26.711985"}
{"image_index": 42, "image_name": "000000004134.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004134.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4389.011, "latencies_ms": [4389.011], "images_per_second": 0.228, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The image features a man in a dark suit and striped tie, holding a white folder. The background is filled with other attendees in formal attire, some in suits and others in more casual clothing. The lighting is warm and ambient, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18624.1, "ram_available_mb": 44216.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18622.3, "ram_available_mb": 44218.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.165, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 71.472}, "timestamp": "2026-01-30T20:51:33.141899"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2631.361, "latencies_ms": [2631.361], "images_per_second": 0.38, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "The image shows a man wearing a white shirt and a striped tie, standing indoors with a slightly blurred background.", "error": null, "sys_before": {"cpu_percent": 30.7, "ram_used_mb": 18622.3, "ram_available_mb": 44218.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18623.9, "ram_available_mb": 44217.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.909, "power_cpu_cv_mean_watts": 1.278, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 77.048}, "timestamp": "2026-01-30T20:51:37.893368"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3208.632, "latencies_ms": [3208.632], "images_per_second": 0.312, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 6, "output_text": "1. Man\n2. Shirt\n3. Tie\n4. Background\n5. Light\n6. Person\n7. Hand\n8. Cigarette", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18623.9, "ram_available_mb": 44217.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18623.1, "ram_available_mb": 44217.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.802, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 73.654}, "timestamp": "2026-01-30T20:51:43.139121"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4836.804, "latencies_ms": [4836.804], "images_per_second": 0.207, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The main object in the foreground is a person wearing a white shirt and a striped tie. The person's face is slightly turned to the right, and their hand is holding a cigarette. The background is blurred, but it appears to be an indoor setting with indistinct shapes and lights.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18623.1, "ram_available_mb": 44217.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18623.8, "ram_available_mb": 44217.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.66, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 70.275}, "timestamp": "2026-01-30T20:51:50.007465"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5389.441, "latencies_ms": [5389.441], "images_per_second": 0.186, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The image depicts a man in a professional setting, likely an office or a similar environment. He is dressed in a white shirt and a striped tie, and appears to be in a moment of contemplation or deep thought. The background is dimly lit, with indistinct shapes and colors, suggesting an indoor setting with artificial lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18623.8, "ram_available_mb": 44217.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18623.3, "ram_available_mb": 44217.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.193, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T20:51:57.413003"}
{"image_index": 43, "image_name": "000000004395.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004395.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4281.154, "latencies_ms": [4281.154], "images_per_second": 0.234, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The notable visual attributes in the image include a person wearing a white shirt and a striped tie, with a dark background. The lighting is dim, and the person's face is illuminated by a soft light source, creating a warm and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18623.3, "ram_available_mb": 44217.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18624.5, "ram_available_mb": 44216.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.351, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 70.829}, "timestamp": "2026-01-30T20:52:03.727167"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4499.915, "latencies_ms": [4499.915], "images_per_second": 0.222, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "The image shows a cozy living room with a television on a stand, a plaid-patterned couch, and a small wooden chair.", "error": null, "sys_before": {"cpu_percent": 31.7, "ram_used_mb": 18624.5, "ram_available_mb": 44216.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18625.3, "ram_available_mb": 44215.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.251, "power_cpu_cv_mean_watts": 1.191, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 88.27}, "timestamp": "2026-01-30T20:52:10.370350"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4878.243, "latencies_ms": [4878.243], "images_per_second": 0.205, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "chair: 1\ntv stand: 1\ntv: 1\nwallpaper: 1\ncouch: 2\nblanket: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18625.3, "ram_available_mb": 44215.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18625.8, "ram_available_mb": 44215.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.73, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 8.769, "gpu_utilization_percent_mean": 88.5}, "timestamp": "2026-01-30T20:52:17.274615"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6797.479, "latencies_ms": [6797.479], "images_per_second": 0.147, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The main objects in the image are a television, a couch, and a chair. The television is positioned in the background, slightly to the right, while the couch and chair are in the foreground, closer to the viewer. The couch is placed near the television, and the chair is positioned to the left of the couch.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18625.8, "ram_available_mb": 44215.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.364, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 85.263}, "timestamp": "2026-01-30T20:52:26.119687"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7157.756, "latencies_ms": [7157.756], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a television set on a wooden stand against a yellow wall. The room is furnished with a plaid-patterned couch, a red chair, and a blue and red striped blanket draped over a chair. The setting appears to be a home, possibly in a living room or a casual sitting area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.105, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 84.7}, "timestamp": "2026-01-30T20:52:35.299773"}
{"image_index": 44, "image_name": "000000004495.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004495.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5645.941, "latencies_ms": [5645.941], "images_per_second": 0.177, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The room is dimly lit, with a warm and cozy ambiance. The walls are painted in a light yellow color, and the furniture includes a plaid-patterned armchair and a blue and red checkered sofa.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.098, "power_cpu_cv_mean_watts": 1.44, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 87.128}, "timestamp": "2026-01-30T20:52:43.005048"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1514.8, "latencies_ms": [1514.8], "images_per_second": 0.66, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 1, "output_text": "A surfer is riding a wave in the ocean, wearing a yellow shirt and red shorts.", "error": null, "sys_before": {"cpu_percent": 17.6, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18626.5, "ram_available_mb": 44214.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.58, "power_cpu_cv_mean_watts": 1.569, "power_sys_5v0_mean_watts": 6.61, "gpu_utilization_percent_mean": 72.417}, "timestamp": "2026-01-30T20:52:46.580665"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2816.979, "latencies_ms": [2816.979], "images_per_second": 0.355, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 1, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18626.5, "ram_available_mb": 44214.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.341, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 6.913, "gpu_utilization_percent_mean": 70.091}, "timestamp": "2026-01-30T20:52:51.417186"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3526.204, "latencies_ms": [3526.204], "images_per_second": 0.284, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The main object, a surfer, is positioned in the foreground, riding a wave. The wave is in the background, creating a dynamic scene. The surfer is near the water's edge, with the wave's crest and foam clearly visible.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18628.5, "ram_available_mb": 44212.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.573, "power_cpu_cv_mean_watts": 1.989, "power_sys_5v0_mean_watts": 7.0, "gpu_utilization_percent_mean": 67.379}, "timestamp": "2026-01-30T20:52:57.001202"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5016.164, "latencies_ms": [5016.164], "images_per_second": 0.199, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 1, "output_text": "The scene captures a surfer riding a wave in the ocean. The surfer, dressed in a yellow shirt and red shorts, is skillfully maneuvering a surfboard amidst the frothy white waves. The setting is a dynamic and energetic environment typical of a surfing session, with the surfer's focused posture and the swirling water indicating the intensity of the ride.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18628.5, "ram_available_mb": 44212.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18627.9, "ram_available_mb": 44213.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.703, "power_cpu_cv_mean_watts": 2.09, "power_sys_5v0_mean_watts": 7.119, "gpu_utilization_percent_mean": 66.61}, "timestamp": "2026-01-30T20:53:04.041437"}
{"image_index": 45, "image_name": "000000004765.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004765.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2306.255, "latencies_ms": [2306.255], "images_per_second": 0.434, "prompt_tokens": 22, "response_tokens_est": 32, "n_tiles": 1, "output_text": "The surfer is wearing a yellow shirt and red shorts, which stand out against the blue-green water. The lighting is bright, indicating it is daytime.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 18627.9, "ram_available_mb": 44213.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18626.7, "ram_available_mb": 44214.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.414, "power_cpu_cv_mean_watts": 1.736, "power_sys_5v0_mean_watts": 6.804, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T20:53:08.362001"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4173.808, "latencies_ms": [4173.808], "images_per_second": 0.24, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "The image shows a cat sitting on a desk with a laptop, a phone, and a keyboard in the background.", "error": null, "sys_before": {"cpu_percent": 31.3, "ram_used_mb": 18626.5, "ram_available_mb": 44214.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18628.2, "ram_available_mb": 44212.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.982, "power_cpu_cv_mean_watts": 1.131, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 89.765}, "timestamp": "2026-01-30T20:53:14.695861"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6119.825, "latencies_ms": [6119.825], "images_per_second": 0.163, "prompt_tokens": 26, "response_tokens_est": 55, "n_tiles": 12, "output_text": "- Laptop: 1\n- Keyboard: 1\n- Phone: 1\n- Computer mouse: 1\n- Computer monitor: 1\n- Computer mouse pad: 1\n- Computer mouse: 1\n- Computer mouse pad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18628.2, "ram_available_mb": 44212.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.883, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 85.941}, "timestamp": "2026-01-30T20:53:22.828320"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6857.833, "latencies_ms": [6857.833], "images_per_second": 0.146, "prompt_tokens": 30, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The main objects in the image are a laptop, a cat, and a phone. The laptop is positioned in the foreground, with the cat resting on it. The phone is placed to the right of the laptop, and the cat is near the phone. The background is out of focus, emphasizing the laptop and the cat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18626.6, "ram_available_mb": 44214.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.253, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 84.579}, "timestamp": "2026-01-30T20:53:31.717929"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5702.79, "latencies_ms": [5702.79], "images_per_second": 0.175, "prompt_tokens": 24, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The image depicts a cluttered office workspace with a laptop, a phone, and a cat. The cat is resting on the laptop, and the office environment includes various items such as a keyboard, a mouse, and a phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.6, "ram_available_mb": 44214.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18629.8, "ram_available_mb": 44211.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.014, "power_cpu_cv_mean_watts": 1.44, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 85.532}, "timestamp": "2026-01-30T20:53:39.461506"}
{"image_index": 46, "image_name": "000000004795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000004795.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5761.215, "latencies_ms": [5761.215], "images_per_second": 0.174, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image features a laptop with a white keyboard and a black mouse. The laptop is placed on a wooden desk, and the background includes a computer monitor displaying a webpage. The lighting is bright, and the overall setting appears to be indoors.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18629.8, "ram_available_mb": 44211.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18629.7, "ram_available_mb": 44211.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.982, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 86.708}, "timestamp": "2026-01-30T20:53:47.268513"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4683.931, "latencies_ms": [4683.931], "images_per_second": 0.213, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "A group of people, including a man in a suit, are gathered around a young girl who is holding a pair of scissors, cutting a ribbon.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18629.7, "ram_available_mb": 44211.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18629.4, "ram_available_mb": 44211.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.912, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 89.282}, "timestamp": "2026-01-30T20:53:54.135894"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5237.205, "latencies_ms": [5237.205], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18629.4, "ram_available_mb": 44211.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18629.9, "ram_available_mb": 44211.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.342, "power_cpu_cv_mean_watts": 1.348, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 87.659}, "timestamp": "2026-01-30T20:54:01.414023"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6422.836, "latencies_ms": [6422.836], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 60, "n_tiles": 12, "output_text": "In the image, the main objects are a group of people gathered around a table, with a child holding a ribbon. The child is positioned near the table, while the other individuals are standing in the background. The ribbon is held by the child, and the table is situated in the foreground.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18629.9, "ram_available_mb": 44211.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18630.0, "ram_available_mb": 44210.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.512, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 85.963}, "timestamp": "2026-01-30T20:54:09.877951"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7278.463, "latencies_ms": [7278.463], "images_per_second": 0.137, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The scene depicts a group of people gathered outside a building, likely at a ribbon-cutting ceremony. The setting appears to be a public space, possibly a street or a plaza, with a blue balloon and a red ribbon being the focal points of the event. The individuals are dressed in casual attire, and some are holding cameras, capturing the moment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18630.0, "ram_available_mb": 44210.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18628.9, "ram_available_mb": 44211.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.019, "power_cpu_cv_mean_watts": 1.68, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 84.597}, "timestamp": "2026-01-30T20:54:19.184849"}
{"image_index": 47, "image_name": "000000005001.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005001.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5867.772, "latencies_ms": [5867.772], "images_per_second": 0.17, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The image depicts a group of people gathered around a table, with a blue balloon and a red ribbon being held by a child. The scene is well-lit, with a mix of natural and artificial light, creating a vibrant and lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18628.9, "ram_available_mb": 44211.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18629.8, "ram_available_mb": 44211.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.814, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 86.52}, "timestamp": "2026-01-30T20:54:27.075161"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2866.33, "latencies_ms": [2866.33], "images_per_second": 0.349, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "A bus with the destination \"First Group\" is parked on a street, with a sign indicating it is free to use Wi-Fi onboard.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18629.8, "ram_available_mb": 44211.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18629.7, "ram_available_mb": 44211.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.347, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 75.292}, "timestamp": "2026-01-30T20:54:32.064593"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3627.792, "latencies_ms": [3627.792], "images_per_second": 0.276, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18629.7, "ram_available_mb": 44211.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18629.4, "ram_available_mb": 44211.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.684, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 71.867}, "timestamp": "2026-01-30T20:54:37.708910"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6022.071, "latencies_ms": [6022.071], "images_per_second": 0.166, "prompt_tokens": 30, "response_tokens_est": 81, "n_tiles": 6, "output_text": "The main object in the foreground is a bus, which is positioned on the right side of the image. The bus is facing the left side of the frame, indicating that it is moving towards the viewer. In the background, there are buildings and a street, which are further away from the bus. The bus is parked on the street, and there are other vehicles and people visible in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18629.4, "ram_available_mb": 44211.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18629.2, "ram_available_mb": 44211.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.882, "power_cpu_cv_mean_watts": 1.963, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 68.706}, "timestamp": "2026-01-30T20:54:45.757802"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4813.859, "latencies_ms": [4813.859], "images_per_second": 0.208, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a modern city bus on a city street, with a clear sky overhead. The bus is white with purple and pink accents, and it has a digital display showing the route number \"1st Group.\" The bus is parked on a street with other vehicles and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18629.2, "ram_available_mb": 44211.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18629.0, "ram_available_mb": 44211.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.709, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 70.55}, "timestamp": "2026-01-30T20:54:52.612690"}
{"image_index": 48, "image_name": "000000005037.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005037.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3025.0, "latencies_ms": [3025.0], "images_per_second": 0.331, "prompt_tokens": 22, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The bus in the image is predominantly white with purple and pink accents. The lighting is bright, indicating daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18629.0, "ram_available_mb": 44211.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18628.3, "ram_available_mb": 44212.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.002, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 73.76}, "timestamp": "2026-01-30T20:54:57.685730"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3973.675, "latencies_ms": [3973.675], "images_per_second": 0.252, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 12, "output_text": "A man is sitting on the floor in a room, taking a selfie with his smartphone.", "error": null, "sys_before": {"cpu_percent": 32.9, "ram_used_mb": 18628.3, "ram_available_mb": 44212.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18628.3, "ram_available_mb": 44212.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.13, "power_cpu_cv_mean_watts": 1.014, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 88.938}, "timestamp": "2026-01-30T20:55:03.816855"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4751.874, "latencies_ms": [4751.874], "images_per_second": 0.21, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Mirror\n2. Man\n3. Floor\n4. Wood\n5. Wall\n6. Floor\n7. Rug\n8. Rug", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18628.3, "ram_available_mb": 44212.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18628.4, "ram_available_mb": 44212.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.912, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.769, "gpu_utilization_percent_mean": 89.077}, "timestamp": "2026-01-30T20:55:10.586228"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6787.676, "latencies_ms": [6787.676], "images_per_second": 0.147, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The main object in the foreground is a man taking a selfie with a smartphone. He is sitting on the floor, with his legs crossed and his arms resting on his knees. The background features a wooden door frame and a mirror reflecting the room. The man is positioned near the mirror, which is positioned on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18628.4, "ram_available_mb": 44212.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18627.3, "ram_available_mb": 44213.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.286, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 84.603}, "timestamp": "2026-01-30T20:55:19.434150"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5394.078, "latencies_ms": [5394.078], "images_per_second": 0.185, "prompt_tokens": 24, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image depicts a man sitting on the floor in a room with wooden flooring and a wooden wall. He is taking a selfie with a smartphone, which is placed in front of him on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18627.3, "ram_available_mb": 44213.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18627.2, "ram_available_mb": 44213.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.296, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 87.067}, "timestamp": "2026-01-30T20:55:26.864503"}
{"image_index": 49, "image_name": "000000005060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005060.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5481.089, "latencies_ms": [5481.089], "images_per_second": 0.182, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The image features a wooden-framed mirror with a warm, natural finish, placed on a light wooden floor. The room is well-lit with natural light streaming in through a window, creating a bright and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18627.2, "ram_available_mb": 44213.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.284, "power_cpu_cv_mean_watts": 1.446, "power_sys_5v0_mean_watts": 8.848, "gpu_utilization_percent_mean": 87.304}, "timestamp": "2026-01-30T20:55:34.383071"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2817.242, "latencies_ms": [2817.242], "images_per_second": 0.355, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 6, "output_text": "A group of young men are posing with surfboards, with one holding a surfboard and another holding a surfboard with a logo.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18626.2, "ram_available_mb": 44214.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.52, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 75.652}, "timestamp": "2026-01-30T20:55:39.308565"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3369.051, "latencies_ms": [3369.051], "images_per_second": 0.297, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 6, "output_text": "1. Surfboards\n2. People\n3. Water bottles\n4. Air conditioner\n5. Bottle\n6. Bottle\n7. Bottle\n8. Bottle", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18626.2, "ram_available_mb": 44214.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18624.7, "ram_available_mb": 44216.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.621, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 73.036}, "timestamp": "2026-01-30T20:55:44.710890"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4570.388, "latencies_ms": [4570.388], "images_per_second": 0.219, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The main objects in the image are a group of young men and a woman, with the surfboards being held by the men. The surfboards are positioned in the foreground, with the men standing in the middle ground. The woman is in the background, slightly to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18624.7, "ram_available_mb": 44216.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.968, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 70.816}, "timestamp": "2026-01-30T20:55:51.326091"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5299.621, "latencies_ms": [5299.621], "images_per_second": 0.189, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The scene depicts a group of young men in a casual indoor setting, likely a garage or a room with a concrete floor. They are gathered around a surfboard, with one of them holding a surfboard and another holding a surfboard. The atmosphere appears relaxed and informal, with the men seemingly engaged in a casual conversation or activity.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18624.5, "ram_available_mb": 44216.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.329, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 70.068}, "timestamp": "2026-01-30T20:55:58.679493"}
{"image_index": 50, "image_name": "000000005193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005193.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5548.415, "latencies_ms": [5548.415], "images_per_second": 0.18, "prompt_tokens": 22, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The image depicts a group of young men holding surfboards, with one man in the foreground holding a surfboard with a vibrant yellow and red design. The lighting is dim, suggesting an indoor setting, possibly a garage or a storage area. The surfboards appear to be made of wood or a similar material, and the overall atmosphere is casual and relaxed.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18624.5, "ram_available_mb": 44216.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18624.0, "ram_available_mb": 44216.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.069, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.283}, "timestamp": "2026-01-30T20:56:06.253709"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2715.155, "latencies_ms": [2715.155], "images_per_second": 0.368, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 2, "output_text": "The image features a large, yellow airplane with the word \"LOT\" written on its fuselage, parked on a tarmac with a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18624.0, "ram_available_mb": 44216.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18623.9, "ram_available_mb": 44217.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.527, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 7.134, "gpu_utilization_percent_mean": 64.318}, "timestamp": "2026-01-30T20:56:11.051345"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3369.907, "latencies_ms": [3369.907], "images_per_second": 0.297, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 2, "output_text": "- airplane: 1\n- plane: 1\n- aircraft: 1\n- aircraft: 1\n- airplane: 1\n- plane: 1\n- airplane: 1\n- plane: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18623.9, "ram_available_mb": 44217.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18624.4, "ram_available_mb": 44216.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.117, "power_cpu_cv_mean_watts": 1.917, "power_sys_5v0_mean_watts": 7.225, "gpu_utilization_percent_mean": 63.786}, "timestamp": "2026-01-30T20:56:16.460027"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4978.57, "latencies_ms": [4978.57], "images_per_second": 0.201, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 2, "output_text": "The main object in the image is a yellow airplane with the word \"LOT\" written on its fuselage. The airplane is positioned in the foreground, slightly to the right. In the background, there are other airplanes, including a red and white one, which are further away. The sky is partly cloudy, providing a backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18624.4, "ram_available_mb": 44216.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.665, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 7.298, "gpu_utilization_percent_mean": 62.643}, "timestamp": "2026-01-30T20:56:23.480416"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5380.599, "latencies_ms": [5380.599], "images_per_second": 0.186, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 2, "output_text": "The image depicts a large, yellow commercial airplane parked on a tarmac, with a cloudy sky in the background. The airplane is adorned with the logo and name \"LOT\" on its fuselage, and the word \"POLSKIE LINE\" is visible on the tail. The scene suggests that the airplane is either preparing for departure or has just arrived at the airport.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.635, "power_cpu_cv_mean_watts": 2.109, "power_sys_5v0_mean_watts": 7.316, "gpu_utilization_percent_mean": 62.533}, "timestamp": "2026-01-30T20:56:30.878063"}
{"image_index": 51, "image_name": "000000005477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005477.jpg", "image_width": 640, "image_height": 349, "image_resolution": "640x349", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3906.131, "latencies_ms": [3906.131], "images_per_second": 0.256, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 2, "output_text": "The notable visual attributes of the airplane in the image include its golden color, which stands out against the cloudy sky. The lighting is bright, casting shadows on the runway, indicating it is daytime. The weather appears to be partly cloudy, with patches of blue sky visible.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.143, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.251, "gpu_utilization_percent_mean": 63.094}, "timestamp": "2026-01-30T20:56:36.796614"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2047.861, "latencies_ms": [2047.861], "images_per_second": 0.488, "prompt_tokens": 12, "response_tokens_est": 15, "n_tiles": 6, "output_text": "A person is holding a toilet seat in a black and white photo.", "error": null, "sys_before": {"cpu_percent": 36.6, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18625.5, "ram_available_mb": 44215.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.886, "power_cpu_cv_mean_watts": 1.026, "power_sys_5v0_mean_watts": 8.1, "gpu_utilization_percent_mean": 74.375}, "timestamp": "2026-01-30T20:56:40.959650"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4097.925, "latencies_ms": [4097.925], "images_per_second": 0.244, "prompt_tokens": 26, "response_tokens_est": 49, "n_tiles": 6, "output_text": "1. Toilet\n2. Hand\n3. Toilet paper\n4. Toilet brush\n5. Toilet seat\n6. Toilet paper roll\n7. Toilet paper holder\n8. Toilet paper dispenser", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18625.5, "ram_available_mb": 44215.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18624.4, "ram_available_mb": 44216.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.43, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 7.957, "gpu_utilization_percent_mean": 71.441}, "timestamp": "2026-01-30T20:56:47.110058"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4162.776, "latencies_ms": [4162.776], "images_per_second": 0.24, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The main object in the foreground is a toilet with a seat and lid. The person's legs are visible, suggesting the person is standing near the toilet. The background is not clearly visible, but the person's hand is holding the toilet seat.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18624.4, "ram_available_mb": 44216.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.442, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 71.912}, "timestamp": "2026-01-30T20:56:53.289112"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3776.924, "latencies_ms": [3776.924], "images_per_second": 0.265, "prompt_tokens": 24, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The image depicts a black and white scene of a toilet with a person's legs visible, holding the toilet seat. The setting appears to be a bathroom, and the person is likely preparing to use the toilet.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.859, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 72.094}, "timestamp": "2026-01-30T20:56:59.109545"}
{"image_index": 52, "image_name": "000000005503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005503.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3674.579, "latencies_ms": [3674.579], "images_per_second": 0.272, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 6, "output_text": "The image is in black and white, with a focus on a toilet seat and a person's hand holding it. The lighting is dim, and the materials appear to be a combination of metal and fabric.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.046, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 72.833}, "timestamp": "2026-01-30T20:57:04.808461"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3182.578, "latencies_ms": [3182.578], "images_per_second": 0.314, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 6, "output_text": "A skier is navigating through a snowy landscape, wearing a blue jacket and a helmet, with ski poles in hand, as they carve through the snow.", "error": null, "sys_before": {"cpu_percent": 34.7, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18625.1, "ram_available_mb": 44215.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.848, "power_cpu_cv_mean_watts": 1.51, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 74.577}, "timestamp": "2026-01-30T20:57:10.138957"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3492.444, "latencies_ms": [3492.444], "images_per_second": 0.286, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 6, "output_text": "1. Person\n2. Ski poles\n3. Ski\n4. Snow\n5. Snowboard\n6. Snowboarder\n7. Snowboard\n8. Snowboarder", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18625.1, "ram_available_mb": 44215.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18625.3, "ram_available_mb": 44215.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.291, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 72.966}, "timestamp": "2026-01-30T20:57:15.659198"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7305.568, "latencies_ms": [7305.568], "images_per_second": 0.137, "prompt_tokens": 30, "response_tokens_est": 102, "n_tiles": 6, "output_text": "The main objects in the image are two skiers. The skier on the left is in the foreground, wearing a blue jacket and a white helmet, and is actively skiing. The skier on the right is further back, also in a blue jacket and a white helmet, and is also skiing. The skiers are positioned in the snowy environment, with the skier on the left appearing to be closer to the camera and the skier on the right appearing to be further away.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18625.3, "ram_available_mb": 44215.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18625.2, "ram_available_mb": 44215.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.347, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.361}, "timestamp": "2026-01-30T20:57:25.000151"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5981.047, "latencies_ms": [5981.047], "images_per_second": 0.167, "prompt_tokens": 24, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image depicts a snowy mountainous landscape with a person skiing down a snow-covered slope. The individual is wearing a blue jacket, black pants, and a helmet, and is using ski poles to navigate the snowy terrain. The scene is set in a winter environment, with snow-covered trees and a clear sky, creating a picturesque and serene winter sports setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18625.2, "ram_available_mb": 44215.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18624.6, "ram_available_mb": 44216.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.815, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 69.66}, "timestamp": "2026-01-30T20:57:32.996846"}
{"image_index": 53, "image_name": "000000005529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005529.jpg", "image_width": 444, "image_height": 640, "image_resolution": "444x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4534.086, "latencies_ms": [4534.086], "images_per_second": 0.221, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 6, "output_text": "The image depicts a snowy landscape with a person skiing. The individual is wearing a blue jacket and a white helmet, and is using yellow ski poles. The snow is white and powdery, and the trees are covered in snow, indicating a winter setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18624.6, "ram_available_mb": 44216.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18623.9, "ram_available_mb": 44217.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.886, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 70.5}, "timestamp": "2026-01-30T20:57:39.568811"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4131.855, "latencies_ms": [4131.855], "images_per_second": 0.242, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A tennis player is preparing to serve on a blue court, with a crowd of spectators in the background.", "error": null, "sys_before": {"cpu_percent": 35.7, "ram_used_mb": 18623.9, "ram_available_mb": 44217.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18623.5, "ram_available_mb": 44217.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.842, "power_cpu_cv_mean_watts": 1.084, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 88.559}, "timestamp": "2026-01-30T20:57:45.847817"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5215.192, "latencies_ms": [5215.192], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis court\n4. Spectator\n5. Advertisements\n6. Stadium\n7. Ball\n8. Ball return", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18623.5, "ram_available_mb": 44217.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18623.1, "ram_available_mb": 44217.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.421, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 88.114}, "timestamp": "2026-01-30T20:57:53.101225"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8051.874, "latencies_ms": [8051.874], "images_per_second": 0.124, "prompt_tokens": 30, "response_tokens_est": 87, "n_tiles": 12, "output_text": "The main object in the foreground is a tennis player, wearing a yellow shirt and black shorts, holding a tennis racket. The player is positioned on the left side of the image. In the background, there is a blue tennis court with a white boundary line, and a scoreboard displaying the word \"KIA\" and other advertisements. The scoreboard is located near the center of the image, slightly behind the tennis player.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18623.1, "ram_available_mb": 44217.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18624.8, "ram_available_mb": 44216.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.774, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 83.551}, "timestamp": "2026-01-30T20:58:03.174209"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5515.75, "latencies_ms": [5515.75], "images_per_second": 0.181, "prompt_tokens": 24, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The image depicts a scene from a tennis match taking place on a blue court with a crowd of spectators in the background. The player in the foreground is preparing to serve, while another player is observing the action.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18624.8, "ram_available_mb": 44216.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18624.1, "ram_available_mb": 44216.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.17, "power_cpu_cv_mean_watts": 1.411, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 86.913}, "timestamp": "2026-01-30T20:58:10.711772"}
{"image_index": 54, "image_name": "000000005586.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005586.jpg", "image_width": 320, "image_height": 240, "image_resolution": "320x240", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4582.007, "latencies_ms": [4582.007], "images_per_second": 0.218, "prompt_tokens": 22, "response_tokens_est": 30, "n_tiles": 12, "output_text": "The image shows a blue tennis court with white boundary lines and a blue surface. The lighting is bright, indicating an outdoor setting with clear weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18624.1, "ram_available_mb": 44216.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18625.0, "ram_available_mb": 44215.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.293, "power_cpu_cv_mean_watts": 1.223, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 89.658}, "timestamp": "2026-01-30T20:58:17.316876"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3902.462, "latencies_ms": [3902.462], "images_per_second": 0.256, "prompt_tokens": 12, "response_tokens_est": 57, "n_tiles": 2, "output_text": "The image shows a plate with a bowl of sweet, round, orange fruits, likely apricots, placed on a napkin, accompanied by a small bowl of a dark, chunky stew or curry, likely containing meat or vegetables, on a table with a dark cloth.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18625.0, "ram_available_mb": 44215.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18625.0, "ram_available_mb": 44215.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.005, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 7.218, "gpu_utilization_percent_mean": 62.788}, "timestamp": "2026-01-30T20:58:23.296827"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3733.394, "latencies_ms": [3733.394], "images_per_second": 0.268, "prompt_tokens": 26, "response_tokens_est": 54, "n_tiles": 2, "output_text": "- plate: 1\n- bowl: 2\n- spoon: 1\n- plate: 1\n- bowl: 1\n- bowl: 1\n- bowl: 1\n- bowl: 1\n- bowl: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18625.0, "ram_available_mb": 44215.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.134, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.313, "gpu_utilization_percent_mean": 63.774}, "timestamp": "2026-01-30T20:58:29.078976"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4963.593, "latencies_ms": [4963.593], "images_per_second": 0.201, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 2, "output_text": "The main objects in the image are a plate with a bowl of food and a small bowl of fruit. The plate is placed in the foreground, while the bowl of food and the small bowl of fruit are in the background. The plate is near the center of the image, with the bowl of food and the small bowl of fruit positioned on either side of it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18625.2, "ram_available_mb": 44215.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18625.5, "ram_available_mb": 44215.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.655, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 7.327, "gpu_utilization_percent_mean": 63.119}, "timestamp": "2026-01-30T20:58:36.074361"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5063.003, "latencies_ms": [5063.003], "images_per_second": 0.198, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 2, "output_text": "The image depicts a dining setting with a focus on a plate of food. The plate contains a variety of items, including a bowl of meat, a bowl of peaches, and a bowl of what appears to be a sweet dish. The setting is likely a restaurant or a dining area, and the food items are being served on a table covered with a dark cloth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18625.5, "ram_available_mb": 44215.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18625.0, "ram_available_mb": 44215.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.915, "power_cpu_cv_mean_watts": 2.133, "power_sys_5v0_mean_watts": 7.337, "gpu_utilization_percent_mean": 61.977}, "timestamp": "2026-01-30T20:58:43.155179"}
{"image_index": 55, "image_name": "000000005600.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005600.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3888.221, "latencies_ms": [3888.221], "images_per_second": 0.257, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 2, "output_text": "The image features a plate with a dark blue rim and a white center, containing a bowl of red-orange meat and a bowl of pale orange fruits. The plate is placed on a table with a dark cloth, and the lighting is warm and soft, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18625.0, "ram_available_mb": 44215.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18624.8, "ram_available_mb": 44216.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.151, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 7.245, "gpu_utilization_percent_mean": 62.212}, "timestamp": "2026-01-30T20:58:49.065792"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2526.111, "latencies_ms": [2526.111], "images_per_second": 0.396, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 6, "output_text": "A group of sheep are standing in a field, with one sheep in the foreground looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 21.6, "ram_used_mb": 18623.9, "ram_available_mb": 44217.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18624.2, "ram_available_mb": 44216.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.697, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 74.8}, "timestamp": "2026-01-30T20:58:53.721807"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3555.66, "latencies_ms": [3555.66], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "1. Sheep\n2. Sheep\n3. Sheep\n4. Sheep\n5. Sheep\n6. Sheep\n7. Sheep\n8. Sheep", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18624.2, "ram_available_mb": 44216.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18624.2, "ram_available_mb": 44216.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.193, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 72.767}, "timestamp": "2026-01-30T20:58:59.326932"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4362.085, "latencies_ms": [4362.085], "images_per_second": 0.229, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The main objects in the image are sheep, with the closest sheep in the foreground and the other sheep in the background. The sheep in the foreground are standing on a grassy area, while the sheep in the background are located further away, behind a fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18624.2, "ram_available_mb": 44216.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18624.7, "ram_available_mb": 44216.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.163, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 71.361}, "timestamp": "2026-01-30T20:59:05.734642"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5359.39, "latencies_ms": [5359.39], "images_per_second": 0.187, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The image depicts a group of sheep in a pastoral setting, likely a farm or a rural area. The sheep are standing on a grassy field, with some of them looking directly at the camera. In the background, there is a brick wall and a playground structure, suggesting a mix of natural and man-made elements in the environment.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18624.7, "ram_available_mb": 44216.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18624.6, "ram_available_mb": 44216.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.292, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 69.311}, "timestamp": "2026-01-30T20:59:13.140603"}
{"image_index": 56, "image_name": "000000005992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000005992.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4910.019, "latencies_ms": [4910.019], "images_per_second": 0.204, "prompt_tokens": 22, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The sheep in the image have a thick, woolly coat that appears to be a mix of brown and gray hues. The lighting is bright and natural, suggesting it is daytime with ample sunlight. The weather seems to be clear and sunny, as the sheep are comfortably standing in a grassy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18624.6, "ram_available_mb": 44216.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18623.7, "ram_available_mb": 44217.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.522, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 70.293}, "timestamp": "2026-01-30T20:59:20.084975"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4401.921, "latencies_ms": [4401.921], "images_per_second": 0.227, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "The image features a bunch of ripe bananas and a red apple, both resting on a fabric surface with a blue and white pattern.", "error": null, "sys_before": {"cpu_percent": 26.6, "ram_used_mb": 18623.7, "ram_available_mb": 44217.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18623.2, "ram_available_mb": 44217.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.664, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 89.611}, "timestamp": "2026-01-30T20:59:26.631452"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5185.615, "latencies_ms": [5185.615], "images_per_second": 0.193, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 12, "output_text": "1. Banana\n2. Apple\n3. Banana\n4. Banana\n5. Banana\n6. Banana\n7. Banana\n8. Banana", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18623.2, "ram_available_mb": 44217.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18622.5, "ram_available_mb": 44218.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.478, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 8.749, "gpu_utilization_percent_mean": 87.977}, "timestamp": "2026-01-30T20:59:33.831594"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5737.297, "latencies_ms": [5737.297], "images_per_second": 0.174, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The main objects in the image are a bunch of bananas and a red apple. The bananas are positioned in the foreground, with one partially cut and lying on the surface. The apple is in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18622.5, "ram_available_mb": 44218.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18625.6, "ram_available_mb": 44215.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.202, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 87.479}, "timestamp": "2026-01-30T20:59:41.600060"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7151.021, "latencies_ms": [7151.021], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image features a bunch of ripe bananas and a red apple resting on a patterned blue fabric surface. The bananas are green with some brown spots, while the apple has a vibrant red and yellow color. The setting appears to be indoors, possibly in a kitchen or dining area, as the fabric is likely a tablecloth or placemat.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18625.6, "ram_available_mb": 44215.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18625.5, "ram_available_mb": 44215.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.105, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 84.803}, "timestamp": "2026-01-30T20:59:50.809873"}
{"image_index": 57, "image_name": "000000006012.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006012.jpg", "image_width": 640, "image_height": 531, "image_resolution": "640x531", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5368.025, "latencies_ms": [5368.025], "images_per_second": 0.186, "prompt_tokens": 22, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image features a bunch of bananas and a red apple, both resting on a fabric surface with a blue floral pattern. The lighting is natural, casting soft shadows and highlighting the vibrant colors of the fruits.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18625.4, "ram_available_mb": 44215.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18625.6, "ram_available_mb": 44215.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.303, "power_cpu_cv_mean_watts": 1.407, "power_sys_5v0_mean_watts": 8.797, "gpu_utilization_percent_mean": 86.178}, "timestamp": "2026-01-30T20:59:58.199689"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2625.128, "latencies_ms": [2625.128], "images_per_second": 0.381, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 2, "output_text": "A modern tram, painted in blue and white, is moving along a track in a city, with the number 2 visible on its front, and passengers inside the vehicle.", "error": null, "sys_before": {"cpu_percent": 24.1, "ram_used_mb": 18625.6, "ram_available_mb": 44215.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18625.6, "ram_available_mb": 44215.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.418, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.18, "gpu_utilization_percent_mean": 63.591}, "timestamp": "2026-01-30T21:00:02.894956"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2524.863, "latencies_ms": [2524.863], "images_per_second": 0.396, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 2, "output_text": "1. Train\n2. Tracks\n3. Electric wires\n4. Street\n5. Trees\n6. Building\n7. Car\n8. Person", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18625.6, "ram_available_mb": 44215.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18625.8, "ram_available_mb": 44215.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.639, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.127, "gpu_utilization_percent_mean": 65.25}, "timestamp": "2026-01-30T21:00:07.451548"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6667.785, "latencies_ms": [6667.785], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 102, "n_tiles": 2, "output_text": "The main object in the image is a blue and white tram, which is positioned in the foreground on the right side of the frame. The tram is moving along the tracks, indicating its role as a mode of public transportation. In the background, there is a parked vehicle, possibly a van, and some trees, suggesting the tram is in an urban or suburban setting. The clear blue sky and the absence of other significant objects in the immediate vicinity further emphasize the tram as the central focus of the image.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18625.8, "ram_available_mb": 44215.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18625.8, "ram_available_mb": 44215.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.755, "power_cpu_cv_mean_watts": 2.174, "power_sys_5v0_mean_watts": 7.373, "gpu_utilization_percent_mean": 62.232}, "timestamp": "2026-01-30T21:00:16.164828"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4141.171, "latencies_ms": [4141.171], "images_per_second": 0.241, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 2, "output_text": "The image depicts a modern tram in motion on a city street, with clear blue skies overhead. The tram is numbered 2 and is painted in a combination of white and blue colors. The tram is moving along a set of tracks, and there are other vehicles and trees visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18625.8, "ram_available_mb": 44215.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.167, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 7.292, "gpu_utilization_percent_mean": 62.943}, "timestamp": "2026-01-30T21:00:22.322616"}
{"image_index": 58, "image_name": "000000006040.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006040.jpg", "image_width": 640, "image_height": 351, "image_resolution": "640x351", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3511.477, "latencies_ms": [3511.477], "images_per_second": 0.285, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 2, "output_text": "The notable visual attributes of the tram include its predominantly blue and white color scheme, sleek and modern design, and the use of glass for the windows. The lighting is bright and natural, indicating daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18626.3, "ram_available_mb": 44214.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.294, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 7.233, "gpu_utilization_percent_mean": 62.172}, "timestamp": "2026-01-30T21:00:27.873992"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3184.506, "latencies_ms": [3184.506], "images_per_second": 0.314, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 6, "output_text": "The image shows a well-lit bathroom with a wooden vanity, a white bathtub, a red patterned curtain, and a large mirror with gold fixtures.", "error": null, "sys_before": {"cpu_percent": 25.4, "ram_used_mb": 18626.3, "ram_available_mb": 44214.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18625.7, "ram_available_mb": 44215.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.306, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 72.28}, "timestamp": "2026-01-30T21:00:33.179107"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3564.961, "latencies_ms": [3564.961], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18625.7, "ram_available_mb": 44215.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.138, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 72.69}, "timestamp": "2026-01-30T21:00:38.775566"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6670.375, "latencies_ms": [6670.375], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 92, "n_tiles": 6, "output_text": "The main objects in the image are a wooden vanity with a sink, a white bathtub, and a red patterned curtain. The vanity is positioned in the foreground, with the sink and faucet on the right side. The bathtub is located to the left of the vanity, and the red curtain is partially covering the bathtub. The vanity is situated near the bathtub, and the curtain is near the bathtub.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18624.9, "ram_available_mb": 44216.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18624.6, "ram_available_mb": 44216.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.637, "power_cpu_cv_mean_watts": 1.96, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 68.768}, "timestamp": "2026-01-30T21:00:47.499996"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6570.019, "latencies_ms": [6570.019], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 90, "n_tiles": 6, "output_text": "The image depicts a well-lit bathroom with a modern and elegant design. The room features a wooden vanity with a white countertop, two sinks with gold faucets, and a red patterned shower curtain. The walls are painted in a light beige color, and there is a white bathtub with a towel draped over it. The bathroom appears to be clean and tidy, with a focus on a classic and luxurious aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18624.6, "ram_available_mb": 44216.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18624.5, "ram_available_mb": 44216.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.583, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 68.364}, "timestamp": "2026-01-30T21:00:56.096136"}
{"image_index": 59, "image_name": "000000006213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006213.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4828.623, "latencies_ms": [4828.623], "images_per_second": 0.207, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The bathroom features a warm, neutral color palette with beige walls and a white bathtub. The lighting is soft and ambient, with recessed ceiling lights providing a gentle glow. The materials used include wood for the vanity and a red patterned curtain, and the faucets are gold-colored.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18624.5, "ram_available_mb": 44216.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18624.5, "ram_available_mb": 44216.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.639, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 70.2}, "timestamp": "2026-01-30T21:01:02.942088"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2179.862, "latencies_ms": [2179.862], "images_per_second": 0.459, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 6, "output_text": "A surfer is performing a trick on a wave, captured in black and white.", "error": null, "sys_before": {"cpu_percent": 23.8, "ram_used_mb": 18624.5, "ram_available_mb": 44216.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18622.8, "ram_available_mb": 44218.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.483, "power_cpu_cv_mean_watts": 1.037, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 79.353}, "timestamp": "2026-01-30T21:01:07.227958"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3545.606, "latencies_ms": [3545.606], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18622.8, "ram_available_mb": 44218.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18622.6, "ram_available_mb": 44218.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.415, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 72.931}, "timestamp": "2026-01-30T21:01:12.817759"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5541.5, "latencies_ms": [5541.5], "images_per_second": 0.18, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The main object in the foreground is a surfer performing a trick on a wave. The surfer is positioned near the center of the image, slightly to the left. The background features the ocean, with waves crashing towards the right side of the image. The surfer is in the middle of the wave, which is the most prominent feature in the scene.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18622.6, "ram_available_mb": 44218.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18622.3, "ram_available_mb": 44218.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.266, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 70.217}, "timestamp": "2026-01-30T21:01:20.403522"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5550.511, "latencies_ms": [5550.511], "images_per_second": 0.18, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The image captures a dynamic scene of a surfer riding a large wave in the ocean. The surfer is in mid-air, performing a trick, with the wave's crest reaching up to their waist. The ocean is rough, with white foam and splashes, and the surfer is dressed in a wetsuit, indicating the cold water conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18622.3, "ram_available_mb": 44218.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18621.7, "ram_available_mb": 44219.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.169, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 69.217}, "timestamp": "2026-01-30T21:01:27.995539"}
{"image_index": 60, "image_name": "000000006460.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006460.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5303.038, "latencies_ms": [5303.038], "images_per_second": 0.189, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image is a black and white photograph capturing a surfer in mid-action on a large wave. The surfer is wearing a wetsuit, and the wave is crashing with a significant amount of foam. The lighting is natural, likely from the sun, casting shadows and highlighting the texture of the water and the surfer's form.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18621.7, "ram_available_mb": 44219.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18620.9, "ram_available_mb": 44220.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.366, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 69.932}, "timestamp": "2026-01-30T21:01:35.321185"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3354.141, "latencies_ms": [3354.141], "images_per_second": 0.298, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "A baseball player in a white uniform with the number 10 is preparing to swing at a pitch, while a catcher and umpire are positioned behind him on the field.", "error": null, "sys_before": {"cpu_percent": 26.8, "ram_used_mb": 18620.8, "ram_available_mb": 44220.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18620.4, "ram_available_mb": 44220.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.423, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.967, "gpu_utilization_percent_mean": 72.821}, "timestamp": "2026-01-30T21:01:40.791141"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3741.502, "latencies_ms": [3741.502], "images_per_second": 0.267, "prompt_tokens": 26, "response_tokens_est": 43, "n_tiles": 6, "output_text": "baseball player: 1\ncatcher: 1\numpire: 1\nhome plate: 1\npitcher: 1\nbatter: 1\numpire: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18620.4, "ram_available_mb": 44220.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.839, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 72.452}, "timestamp": "2026-01-30T21:01:46.593983"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8466.048, "latencies_ms": [8466.048], "images_per_second": 0.118, "prompt_tokens": 30, "response_tokens_est": 121, "n_tiles": 6, "output_text": "The main objects in the image are a baseball player, a catcher, and an umpire. The baseball player is positioned in the foreground, wearing a white uniform with the number 10, holding a bat, and standing ready to bat. The catcher is crouched behind the home plate, wearing a black uniform with red and white accents, and is holding a mitt. The umpire is standing to the left of the catcher, wearing a blue shirt and gray pants, observing the play. The background features a blue wall and a few spectators seated on benches.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.915, "power_cpu_cv_mean_watts": 2.048, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 67.479}, "timestamp": "2026-01-30T21:01:57.076822"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5178.123, "latencies_ms": [5178.123], "images_per_second": 0.193, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image captures a moment during a baseball game, with a batter in a white uniform preparing to swing at a pitch. The scene takes place on a well-maintained baseball field, with a catcher crouched behind home plate, ready to catch the ball, and a umpire standing nearby, observing the play.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18620.6, "ram_available_mb": 44220.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.492, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 70.116}, "timestamp": "2026-01-30T21:02:04.296226"}
{"image_index": 61, "image_name": "000000006471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006471.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4696.116, "latencies_ms": [4696.116], "images_per_second": 0.213, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The baseball player is wearing a white uniform with black and orange accents, and he is holding a bat. The catcher is wearing a black uniform with red and white accents, and he is crouched behind home plate. The lighting is bright, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18620.6, "ram_available_mb": 44220.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.822, "power_cpu_cv_mean_watts": 1.767, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 70.846}, "timestamp": "2026-01-30T21:02:11.046801"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4799.624, "latencies_ms": [4799.624], "images_per_second": 0.208, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image depicts a collection of various fruits, including apples, pears, and possibly peaches, arranged in a somewhat haphazard manner on a surface.", "error": null, "sys_before": {"cpu_percent": 33.1, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18620.6, "ram_available_mb": 44220.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.767, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 87.1}, "timestamp": "2026-01-30T21:02:17.991885"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10556.854, "latencies_ms": [10556.854], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "apple: 1\npear: 1\npeach: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi: 1\nkiwi:", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18620.6, "ram_available_mb": 44220.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18620.4, "ram_available_mb": 44220.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.165, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 81.795}, "timestamp": "2026-01-30T21:02:30.567000"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5340.342, "latencies_ms": [5340.342], "images_per_second": 0.187, "prompt_tokens": 30, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The main objects in the image are a cluster of peanuts and a single apple. The peanuts are scattered in the foreground, while the apple is positioned slightly to the right in the background.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18620.4, "ram_available_mb": 44220.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.44, "power_cpu_cv_mean_watts": 1.348, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 87.364}, "timestamp": "2026-01-30T21:02:37.922044"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6374.218, "latencies_ms": [6374.218], "images_per_second": 0.157, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The image depicts a collection of peanuts scattered on a surface, with a few peanuts partially buried in the ground. The setting appears to be outdoors, possibly in a garden or a field, as the peanuts are scattered and some are partially buried in the soil.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18619.9, "ram_available_mb": 44221.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.535, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 8.767, "gpu_utilization_percent_mean": 85.887}, "timestamp": "2026-01-30T21:02:46.325832"}
{"image_index": 62, "image_name": "000000006614.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006614.jpg", "image_width": 500, "image_height": 396, "image_resolution": "500x396", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6258.935, "latencies_ms": [6258.935], "images_per_second": 0.16, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The image depicts a black and white photograph of a cluster of apples and peaches. The apples and peaches are depicted with a high level of detail, showcasing their textures and shapes. The lighting is soft and even, highlighting the natural colors and textures of the fruits.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18619.8, "ram_available_mb": 44221.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.572, "power_cpu_cv_mean_watts": 1.51, "power_sys_5v0_mean_watts": 8.772, "gpu_utilization_percent_mean": 86.173}, "timestamp": "2026-01-30T21:02:54.622596"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3176.679, "latencies_ms": [3176.679], "images_per_second": 0.315, "prompt_tokens": 12, "response_tokens_est": 45, "n_tiles": 2, "output_text": "The image depicts a modern urban street scene with a curved road, a sidewalk, and a row of multi-story buildings on one side, while the other side features a green area with some trees and a bus stop.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18620.3, "ram_available_mb": 44220.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18619.6, "ram_available_mb": 44221.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.176, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 7.172, "gpu_utilization_percent_mean": 63.423}, "timestamp": "2026-01-30T21:02:59.905129"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2270.555, "latencies_ms": [2270.555], "images_per_second": 0.44, "prompt_tokens": 26, "response_tokens_est": 30, "n_tiles": 2, "output_text": "- Street\n- Car\n- Bus\n- Pedestrian\n- Building\n- Street light\n- Greenery\n- Sidewalk", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18619.6, "ram_available_mb": 44221.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.885, "power_cpu_cv_mean_watts": 1.624, "power_sys_5v0_mean_watts": 7.056, "gpu_utilization_percent_mean": 62.889}, "timestamp": "2026-01-30T21:03:04.217034"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4843.434, "latencies_ms": [4843.434], "images_per_second": 0.206, "prompt_tokens": 30, "response_tokens_est": 72, "n_tiles": 2, "output_text": "The main objects in the image are a road, a sidewalk, and a building. The road is on the left side of the image, with a sidewalk running parallel to it on the right. The building is located on the right side of the image, near the sidewalk. The road curves gently to the right, and the sidewalk curves to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.928, "power_cpu_cv_mean_watts": 2.063, "power_sys_5v0_mean_watts": 7.29, "gpu_utilization_percent_mean": 62.325}, "timestamp": "2026-01-30T21:03:11.124637"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4823.109, "latencies_ms": [4823.109], "images_per_second": 0.207, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 2, "output_text": "The image depicts a modern urban street scene with a mix of residential and commercial buildings lining the street. The road is a two-way street with a curved path on the right side, and there are parked cars and a bus visible. The sky is partly cloudy, and the area appears to be well-maintained with greenery and sidewalks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18619.3, "ram_available_mb": 44221.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.868, "power_cpu_cv_mean_watts": 2.053, "power_sys_5v0_mean_watts": 7.29, "gpu_utilization_percent_mean": 61.9}, "timestamp": "2026-01-30T21:03:17.985815"}
{"image_index": 63, "image_name": "000000006723.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006723.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4055.221, "latencies_ms": [4055.221], "images_per_second": 0.247, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 2, "output_text": "The image depicts a city street scene with a mix of modern and older buildings. The street is lined with a mix of concrete and brick structures, and there are greenery and trees on the right side. The sky is partly cloudy, providing a mix of natural and artificial lighting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18619.3, "ram_available_mb": 44221.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.033, "power_cpu_cv_mean_watts": 1.991, "power_sys_5v0_mean_watts": 7.254, "gpu_utilization_percent_mean": 63.152}, "timestamp": "2026-01-30T21:03:24.084238"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4779.93, "latencies_ms": [4779.93], "images_per_second": 0.209, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image depicts a group of three individuals seated at a table in what appears to be a restaurant, with one person holding a smartphone and another person wearing glasses.", "error": null, "sys_before": {"cpu_percent": 33.2, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18619.0, "ram_available_mb": 44221.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.198, "power_cpu_cv_mean_watts": 1.284, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 87.821}, "timestamp": "2026-01-30T21:03:31.020077"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10557.225, "latencies_ms": [10557.225], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- television: 1\n- television set: 1\n- man: 1\n- woman: 1\n- camera: 1\n- camera: 1\n- table: 1\n- table: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n- wall: 1\n-", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18619.0, "ram_available_mb": 44221.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18619.0, "ram_available_mb": 44221.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.216, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 82.652}, "timestamp": "2026-01-30T21:03:43.604340"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5780.93, "latencies_ms": [5780.93], "images_per_second": 0.173, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The main objects in the image are a man and a woman. The man is in the foreground, while the woman is slightly behind him. The man is holding a phone in his right hand, and the woman is standing close to him.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.0, "ram_available_mb": 44221.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.953, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 86.583}, "timestamp": "2026-01-30T21:03:51.420316"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8041.64, "latencies_ms": [8041.64], "images_per_second": 0.124, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 12, "output_text": "The image depicts a cozy indoor setting, likely a restaurant or bar, with a warm and inviting ambiance. The scene includes a man and a woman posing for a photo, both smiling and looking directly at the camera. The man is wearing glasses and a blue shirt, while the woman is dressed in a white top. The background features a television screen displaying a scene, and there are framed pictures and posters on the walls.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18619.7, "ram_available_mb": 44221.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.832, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 84.544}, "timestamp": "2026-01-30T21:04:01.519601"}
{"image_index": 64, "image_name": "000000006763.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006763.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6296.168, "latencies_ms": [6296.168], "images_per_second": 0.159, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image features a man and a woman seated at a table, both smiling and posing for the camera. The man is wearing a blue shirt, and the woman is in a white top. The lighting is warm, and the background includes framed pictures and a television screen displaying a scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18619.7, "ram_available_mb": 44221.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18619.2, "ram_available_mb": 44221.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.608, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 85.096}, "timestamp": "2026-01-30T21:04:09.857435"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2339.626, "latencies_ms": [2339.626], "images_per_second": 0.427, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 6, "output_text": "A woman in a costume is talking on her phone while surrounded by other people at an event.", "error": null, "sys_before": {"cpu_percent": 28.9, "ram_used_mb": 18619.2, "ram_available_mb": 44221.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18618.6, "ram_available_mb": 44222.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.684, "power_cpu_cv_mean_watts": 1.181, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 78.0}, "timestamp": "2026-01-30T21:04:14.331152"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4526.176, "latencies_ms": [4526.176], "images_per_second": 0.221, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 6, "output_text": "1. Woman: 1\n2. Man: 2\n3. Woman: 1\n4. Man: 1\n5. Woman: 1\n6. Man: 1\n7. Woman: 1\n8. Man: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18618.5, "ram_available_mb": 44222.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.04, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 71.054}, "timestamp": "2026-01-30T21:04:20.869422"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6222.565, "latencies_ms": [6222.565], "images_per_second": 0.161, "prompt_tokens": 30, "response_tokens_est": 84, "n_tiles": 6, "output_text": "The main object in the foreground is a woman wearing a costume with gold accents and a helmet. She is holding a phone to her ear and appears to be engaged in a conversation. In the background, there are other people, including a man wearing a white cap and another individual with a beard. The setting seems to be outdoors, possibly at a festival or event, with a blurred cityscape in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18617.8, "ram_available_mb": 44223.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.819, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 68.731}, "timestamp": "2026-01-30T21:04:29.120594"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5747.054, "latencies_ms": [5747.054], "images_per_second": 0.174, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The image depicts a lively outdoor gathering, likely a festival or convention, with a diverse crowd of people. The setting appears to be in a public area with buildings in the background, and the atmosphere is bustling with activity. The focus is on a woman in the foreground who is engaged in a phone conversation, while others in the background are also interacting with each other.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18617.8, "ram_available_mb": 44223.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18617.1, "ram_available_mb": 44223.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.036, "power_cpu_cv_mean_watts": 1.911, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.667}, "timestamp": "2026-01-30T21:04:36.909430"}
{"image_index": 65, "image_name": "000000006771.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006771.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3236.761, "latencies_ms": [3236.761], "images_per_second": 0.309, "prompt_tokens": 22, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The woman in the image is wearing a black and gold costume with intricate designs and accessories. The lighting is bright, and the scene appears to be outdoors during the daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18617.1, "ram_available_mb": 44223.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18617.2, "ram_available_mb": 44223.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.899, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 73.808}, "timestamp": "2026-01-30T21:04:42.159482"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3835.253, "latencies_ms": [3835.253], "images_per_second": 0.261, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The image shows a small, white tiled bathroom with a toilet, a green bucket, and a red bucket on the floor, along with a white toilet paper holder and a white shower head mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.459, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 71.75}, "timestamp": "2026-01-30T21:04:48.098224"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3673.818, "latencies_ms": [3673.818], "images_per_second": 0.272, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 6, "output_text": "1. Toilet\n2. Water heater\n3. Showerhead\n4. Tiled floor\n5. Tiled walls\n6. Green bucket\n7. Red bucket\n8. White pipe", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.123, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 72.333}, "timestamp": "2026-01-30T21:04:53.792330"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5931.897, "latencies_ms": [5931.897], "images_per_second": 0.169, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The main objects in the image are a toilet, a green bucket, and a red bucket. The toilet is located in the foreground, with the green bucket and red bucket positioned near it. The toilet is situated on the left side of the image, while the green and red buckets are on the right side. The white pipes and the white tiled walls are also visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.952, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 69.122}, "timestamp": "2026-01-30T21:05:01.748501"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6033.291, "latencies_ms": [6033.291], "images_per_second": 0.166, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 6, "output_text": "The image depicts a small, utilitarian bathroom with white tiled walls and floor. The room features a white toilet with a black circular opening, a green bucket, and a red bucket on the floor. There is a white shower head mounted on the wall, and a white toilet paper holder is visible. The setting appears to be a public restroom, possibly in a residential or commercial building.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.901, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 69.06}, "timestamp": "2026-01-30T21:05:09.825509"}
{"image_index": 66, "image_name": "000000006818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006818.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3433.456, "latencies_ms": [3433.456], "images_per_second": 0.291, "prompt_tokens": 22, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The image depicts a small, white tiled bathroom with a single white toilet and a green bucket. The lighting is dim, and the walls and floor are tiled in white.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.544, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 73.821}, "timestamp": "2026-01-30T21:05:15.295579"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3508.787, "latencies_ms": [3508.787], "images_per_second": 0.285, "prompt_tokens": 12, "response_tokens_est": 13, "n_tiles": 12, "output_text": "A man is laughing while holding the ear of an elephant.", "error": null, "sys_before": {"cpu_percent": 26.0, "ram_used_mb": 18614.7, "ram_available_mb": 44226.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 18615.6, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.787, "power_cpu_cv_mean_watts": 0.911, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 90.207}, "timestamp": "2026-01-30T21:05:20.949036"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4918.92, "latencies_ms": [4918.92], "images_per_second": 0.203, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 12, "output_text": "1. Elephant\n2. Man\n3. Glasses\n4. T-shirt\n5. Ear\n6. Neck\n7. Face\n8. Hair", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.6, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.666, "power_cpu_cv_mean_watts": 1.27, "power_sys_5v0_mean_watts": 8.777, "gpu_utilization_percent_mean": 88.561}, "timestamp": "2026-01-30T21:05:27.878573"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5570.642, "latencies_ms": [5570.642], "images_per_second": 0.18, "prompt_tokens": 30, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The main object in the foreground is a person wearing a gray t-shirt. The person is interacting with an elephant, which is positioned in the background. The elephant is partially obscured by the person, indicating a close proximity.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.172, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 87.261}, "timestamp": "2026-01-30T21:05:35.482371"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6855.49, "latencies_ms": [6855.49], "images_per_second": 0.146, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a man in a natural setting, likely a zoo or wildlife sanctuary, interacting with a group of elephants. The man is wearing a light-colored shirt and is seen laughing or smiling broadly, suggesting a joyful and relaxed atmosphere. The background features lush greenery and hills, indicating a serene and peaceful environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.198, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 85.224}, "timestamp": "2026-01-30T21:05:44.377873"}
{"image_index": 67, "image_name": "000000006894.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006894.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5230.841, "latencies_ms": [5230.841], "images_per_second": 0.191, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The image features a man wearing glasses and a light-colored t-shirt. The man is smiling and appears to be in a sunny outdoor setting, with the background showing lush greenery and a hill.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.272, "power_cpu_cv_mean_watts": 1.351, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 88.395}, "timestamp": "2026-01-30T21:05:51.635556"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5152.562, "latencies_ms": [5152.562], "images_per_second": 0.194, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The image depicts a group of four children sitting on the grass, each holding a white frisbee, with one child in the foreground holding a frisbee with a logo on it.", "error": null, "sys_before": {"cpu_percent": 29.4, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18615.5, "ram_available_mb": 44225.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.535, "power_cpu_cv_mean_watts": 1.36, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 87.023}, "timestamp": "2026-01-30T21:05:58.942459"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5010.72, "latencies_ms": [5010.72], "images_per_second": 0.2, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 12, "output_text": "1. Frisbee: 2\n2. Children: 3\n3. Grass: 1\n4. Tree: 1\n5. Background: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.5, "ram_available_mb": 44225.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.621, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 87.738}, "timestamp": "2026-01-30T21:06:06.004434"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7238.501, "latencies_ms": [7238.501], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The main objects in the image are three children sitting on the grass. The child on the left is holding a frisbee, the child in the middle is also holding a frisbee, and the child on the right is holding a frisbee as well. The background consists of trees and foliage, indicating that the scene takes place outdoors.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.067, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 84.787}, "timestamp": "2026-01-30T21:06:15.280175"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6430.98, "latencies_ms": [6430.98], "images_per_second": 0.155, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The scene depicts a group of children playing outdoors on a grassy field. They are holding white frisbees and appear to be enjoying their time together. The setting is a natural, grassy area with trees and foliage in the background, suggesting a park or a backyard.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18615.3, "ram_available_mb": 44225.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.482, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 85.852}, "timestamp": "2026-01-30T21:06:23.731331"}
{"image_index": 68, "image_name": "000000006954.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000006954.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5590.849, "latencies_ms": [5590.849], "images_per_second": 0.179, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image depicts a group of children playing outdoors on a sunny day. The children are wearing casual clothing, and the grass is green and lush. The lighting is bright and natural, indicating a clear day with ample sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.3, "ram_available_mb": 44225.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.979, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 87.234}, "timestamp": "2026-01-30T21:06:31.360473"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4161.541, "latencies_ms": [4161.541], "images_per_second": 0.24, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A young child is holding a black umbrella with a pattern, standing on a wet sidewalk next to a hedge.", "error": null, "sys_before": {"cpu_percent": 27.9, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.646, "power_cpu_cv_mean_watts": 1.06, "power_sys_5v0_mean_watts": 8.781, "gpu_utilization_percent_mean": 89.441}, "timestamp": "2026-01-30T21:06:37.671785"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5352.531, "latencies_ms": [5352.531], "images_per_second": 0.187, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 12, "output_text": "umbrella: 1\nchild: 1\ncoat: 1\nsweater: 1\nsocks: 1\nshoe: 1\nglove: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.255, "power_cpu_cv_mean_watts": 1.398, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 87.311}, "timestamp": "2026-01-30T21:06:45.056102"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6142.326, "latencies_ms": [6142.326], "images_per_second": 0.163, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The main object in the foreground is a young child holding a black umbrella with a pattern. The child is standing on a wet sidewalk, with a bush and a parked car visible in the background. The child is near the bush, and the car is parked further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.562, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 85.904}, "timestamp": "2026-01-30T21:06:53.248353"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6479.285, "latencies_ms": [6479.285], "images_per_second": 0.154, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image depicts a young child standing under a black umbrella in a residential area during a rainy day. The child is dressed in a red coat and blue jeans, holding the umbrella with both hands. The background shows a wet sidewalk, a parked car, and a house with a gray roof.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.574, "power_cpu_cv_mean_watts": 1.536, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 85.648}, "timestamp": "2026-01-30T21:07:01.752863"}
{"image_index": 69, "image_name": "000000007088.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007088.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6804.422, "latencies_ms": [6804.422], "images_per_second": 0.147, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a young child holding a black umbrella with a pink pattern, standing on a wet sidewalk. The child is wearing a red coat and dark pants, and the umbrella provides some protection from the rain. The lighting is soft and diffused, suggesting an overcast day, and the wet ground reflects the surroundings.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.281, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 85.211}, "timestamp": "2026-01-30T21:07:10.614754"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3561.136, "latencies_ms": [3561.136], "images_per_second": 0.281, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The image captures a group of elephants in a dusty, outdoor environment, with one elephant prominently in the foreground, its trunk raised as if it is either greeting or communicating with the others.", "error": null, "sys_before": {"cpu_percent": 34.4, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18615.3, "ram_available_mb": 44225.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.024, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 72.621}, "timestamp": "2026-01-30T21:07:16.287657"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2179.059, "latencies_ms": [2179.059], "images_per_second": 0.459, "prompt_tokens": 26, "response_tokens_est": 17, "n_tiles": 6, "output_text": "elephant: 2\nwater: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.3, "ram_available_mb": 44225.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.012, "power_cpu_cv_mean_watts": 0.966, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 79.765}, "timestamp": "2026-01-30T21:07:20.485986"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4923.259, "latencies_ms": [4923.259], "images_per_second": 0.203, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The main object in the foreground is an elephant, which is positioned near the center of the image. The background features another elephant, slightly out of focus, indicating that the primary focus is on the elephant in the foreground. The elephant in the background is further away, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18614.7, "ram_available_mb": 44226.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.736, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.512}, "timestamp": "2026-01-30T21:07:27.442846"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6154.476, "latencies_ms": [6154.476], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 83, "n_tiles": 6, "output_text": "The image captures a group of elephants in a natural, outdoor setting. The elephants are standing on a dusty, reddish-brown ground, with one elephant in the foreground appearing to be in motion, possibly walking or running. The background features more elephants, some of which are partially obscured by the dust. The scene suggests a wild, natural environment, likely in a savanna or similar habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.7, "ram_available_mb": 44226.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.783, "power_cpu_cv_mean_watts": 1.964, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 69.269}, "timestamp": "2026-01-30T21:07:35.630221"}
{"image_index": 70, "image_name": "000000007108.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007108.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4709.408, "latencies_ms": [4709.408], "images_per_second": 0.212, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image features a group of elephants in a dusty, reddish-brown environment. The elephants have rough, wrinkled skin, and their tusks are visible. The lighting is natural, with a soft, diffused quality, suggesting it might be early morning or late afternoon.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18614.9, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.899, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 70.667}, "timestamp": "2026-01-30T21:07:42.372077"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3973.75, "latencies_ms": [3973.75], "images_per_second": 0.252, "prompt_tokens": 12, "response_tokens_est": 21, "n_tiles": 12, "output_text": "A surfer is riding a wave in the ocean, wearing a red and black wetsuit.", "error": null, "sys_before": {"cpu_percent": 27.6, "ram_used_mb": 18614.9, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.067, "power_cpu_cv_mean_watts": 1.056, "power_sys_5v0_mean_watts": 8.873, "gpu_utilization_percent_mean": 90.636}, "timestamp": "2026-01-30T21:07:48.486344"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5225.143, "latencies_ms": [5225.143], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.413, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 87.5}, "timestamp": "2026-01-30T21:07:55.772641"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4928.956, "latencies_ms": [4928.956], "images_per_second": 0.203, "prompt_tokens": 30, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The main object in the foreground is a surfer riding a wave. The wave is in the background, and the surfer is positioned near the center of the image.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.694, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 88.293}, "timestamp": "2026-01-30T21:08:02.737380"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7030.589, "latencies_ms": [7030.589], "images_per_second": 0.142, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The image captures a surfer skillfully riding a wave in the ocean. The surfer is wearing a red and black wetsuit, and the wave is breaking to the right, creating a spray of water around the surfer. The setting is a dynamic and powerful ocean environment, with the surfer navigating the wave with precision and skill.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.22, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.322}, "timestamp": "2026-01-30T21:08:11.801721"}
{"image_index": 71, "image_name": "000000007278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007278.jpg", "image_width": 640, "image_height": 482, "image_resolution": "640x482", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6963.558, "latencies_ms": [6963.558], "images_per_second": 0.144, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image captures a surfer skillfully riding a wave, with the surfer dressed in a red and black wetsuit. The wave is a vibrant green, and the surfer is in mid-action, leaning into the wave. The lighting is bright and clear, highlighting the dynamic movement of the surfer and the splashing water.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.307, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 85.103}, "timestamp": "2026-01-30T21:08:20.793420"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2060.352, "latencies_ms": [2060.352], "images_per_second": 0.485, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 2, "output_text": "Two people are riding horses on a sandy beach, with one person holding a stick, while the other is holding a flag.", "error": null, "sys_before": {"cpu_percent": 29.0, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.747, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 7.092, "gpu_utilization_percent_mean": 65.471}, "timestamp": "2026-01-30T21:08:24.948648"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4103.459, "latencies_ms": [4103.459], "images_per_second": 0.244, "prompt_tokens": 26, "response_tokens_est": 60, "n_tiles": 2, "output_text": "1. Horse: 1\n2. Rider: 2\n3. Horseback rider: 1\n4. Horse: 1\n5. Horseback rider: 1\n6. Horse: 1\n7. Horse: 1\n8. Horse: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18616.0, "ram_available_mb": 44224.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.864, "power_cpu_cv_mean_watts": 1.967, "power_sys_5v0_mean_watts": 7.213, "gpu_utilization_percent_mean": 61.088}, "timestamp": "2026-01-30T21:08:31.089638"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7164.374, "latencies_ms": [7164.374], "images_per_second": 0.14, "prompt_tokens": 30, "response_tokens_est": 110, "n_tiles": 2, "output_text": "In the image, the main objects are two people riding horses on a sandy beach. The person on the left is wearing a white shirt and a hat, while the person on the right is wearing a white shirt and a hat as well. The horses are in the foreground, with the person on the left riding a white horse and the person on the right riding a brown horse. The background features the ocean and a few people enjoying the beach. The sandy beach is the primary foreground, while the ocean and people are in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18616.0, "ram_available_mb": 44224.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.411, "power_cpu_cv_mean_watts": 2.169, "power_sys_5v0_mean_watts": 7.34, "gpu_utilization_percent_mean": 61.667}, "timestamp": "2026-01-30T21:08:40.308835"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4891.922, "latencies_ms": [4891.922], "images_per_second": 0.204, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 2, "output_text": "The image depicts a lively beach scene with two individuals riding horses. One person is on a white horse, while the other is on a brown horse. They are both wearing traditional attire, and the white horse is adorned with a red ribbon. The background shows a sandy beach with people enjoying the water, and the sky is partly cloudy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.647, "power_cpu_cv_mean_watts": 2.051, "power_sys_5v0_mean_watts": 7.307, "gpu_utilization_percent_mean": 61.854}, "timestamp": "2026-01-30T21:08:47.229232"}
{"image_index": 72, "image_name": "000000007281.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007281.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2861.177, "latencies_ms": [2861.177], "images_per_second": 0.35, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 2, "output_text": "The image depicts a sunny beach scene with clear blue skies and scattered clouds. The sandy beach is populated with people, a horse, and a rider, all bathed in bright sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.435, "power_cpu_cv_mean_watts": 1.759, "power_sys_5v0_mean_watts": 7.161, "gpu_utilization_percent_mean": 63.043}, "timestamp": "2026-01-30T21:08:52.116090"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3061.243, "latencies_ms": [3061.243], "images_per_second": 0.327, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "A small dog is standing near a red tractor with a black seat, which is parked on a gravel surface in front of a building with a bicycle rack.", "error": null, "sys_before": {"cpu_percent": 21.7, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.078, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 74.52}, "timestamp": "2026-01-30T21:08:57.326067"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3608.901, "latencies_ms": [3608.901], "images_per_second": 0.277, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "1. Motorcycle\n2. Lawn mower\n3. Dog\n4. Bicycle\n5. Car\n6. Tire\n7. Wheel\n8. Lawn mower", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18615.5, "ram_available_mb": 44225.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.162, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 72.467}, "timestamp": "2026-01-30T21:09:02.963319"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5391.92, "latencies_ms": [5391.92], "images_per_second": 0.185, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The main object in the foreground is a red tractor with a black seat. The tractor is positioned on a gravel surface, with a small dog standing near it. In the background, there is a parked silver car and a blue tarp covering part of the car. The tractor is situated near the car, and the dog is near the tractor.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18615.5, "ram_available_mb": 44225.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.238, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 69.4}, "timestamp": "2026-01-30T21:09:10.408219"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3559.857, "latencies_ms": [3559.857], "images_per_second": 0.281, "prompt_tokens": 24, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The image depicts a rustic outdoor scene with a red tractor and a small dog standing beside it. The setting appears to be a rural area with greenery and a clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.245, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 72.31}, "timestamp": "2026-01-30T21:09:15.992157"}
{"image_index": 73, "image_name": "000000007386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007386.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4334.494, "latencies_ms": [4334.494], "images_per_second": 0.231, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The image features a red tractor with a black seat, situated on a gravel surface. The tractor is equipped with a metal ladder, and there is a bicycle parked nearby. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18615.6, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.139, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 70.944}, "timestamp": "2026-01-30T21:09:22.369479"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4615.697, "latencies_ms": [4615.697], "images_per_second": 0.217, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "A man is standing on a sandy beach, holding a kite in his hands, with a few people around him, enjoying the sunny day.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 18615.6, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.807, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.771, "gpu_utilization_percent_mean": 88.026}, "timestamp": "2026-01-30T21:09:29.175122"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5218.831, "latencies_ms": [5218.831], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.373, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 8.796, "gpu_utilization_percent_mean": 88.372}, "timestamp": "2026-01-30T21:09:36.408241"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7357.126, "latencies_ms": [7357.126], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The main object in the foreground is a person standing on the sandy beach, with their back to the camera. The person is wearing a black shirt and blue jeans. In the background, there is a large body of water, a few trees, and a few people scattered around. The person in the foreground is near the water, while the background is more distant.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.993, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 84.721}, "timestamp": "2026-01-30T21:09:45.785199"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5564.977, "latencies_ms": [5564.977], "images_per_second": 0.18, "prompt_tokens": 24, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image depicts a sunny beach scene with a man standing on the sand, holding a kite in his hands. The beach is populated with people, some walking and others sitting on the sand, enjoying the pleasant weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.141, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.795, "gpu_utilization_percent_mean": 85.957}, "timestamp": "2026-01-30T21:09:53.393729"}
{"image_index": 74, "image_name": "000000007511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007511.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5239.137, "latencies_ms": [5239.137], "images_per_second": 0.191, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The image depicts a sunny day at a beach with a clear blue sky and scattered clouds. The sandy beach is populated with people, some walking and others sitting, enjoying the pleasant weather.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.238, "power_cpu_cv_mean_watts": 1.329, "power_sys_5v0_mean_watts": 8.77, "gpu_utilization_percent_mean": 87.25}, "timestamp": "2026-01-30T21:10:00.666777"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5017.494, "latencies_ms": [5017.494], "images_per_second": 0.199, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image depicts a cluttered kitchen counter with various items scattered around, including a green bottle, a red gift, a blue bottle, a yellow notebook, and a silver knife.", "error": null, "sys_before": {"cpu_percent": 27.5, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.666, "power_cpu_cv_mean_watts": 1.344, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 87.333}, "timestamp": "2026-01-30T21:10:07.847995"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10528.564, "latencies_ms": [10528.564], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.224, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 83.101}, "timestamp": "2026-01-30T21:10:20.419714"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7861.439, "latencies_ms": [7861.439], "images_per_second": 0.127, "prompt_tokens": 30, "response_tokens_est": 84, "n_tiles": 12, "output_text": "The main objects in the image are located in the kitchen, with the sink and countertop in the foreground, and various kitchen items and appliances in the background. The sink is positioned near the countertop, with a green bottle of dish soap and a red gift plate on the countertop. The kitchen cabinets are in the background, with a white bowl on the top shelf and a black microwave oven above the cabinets.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.951, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 84.636}, "timestamp": "2026-01-30T21:10:30.317452"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6593.556, "latencies_ms": [6593.556], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a cluttered kitchen counter with various items scattered around. The counter is cluttered with kitchen utensils, containers, and a green bottle, while the surrounding cabinets and countertops are visible. The setting appears to be a kitchen with a mix of modern and somewhat dated appliances and decor.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.499, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 86.091}, "timestamp": "2026-01-30T21:10:38.933250"}
{"image_index": 75, "image_name": "000000007574.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007574.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4661.006, "latencies_ms": [4661.006], "images_per_second": 0.215, "prompt_tokens": 22, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The kitchen is well-lit with natural light streaming in from a window. The cabinets are made of light wood, and the countertops are black.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.921, "power_cpu_cv_mean_watts": 1.243, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 89.436}, "timestamp": "2026-01-30T21:10:45.624215"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3933.264, "latencies_ms": [3933.264], "images_per_second": 0.254, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 12, "output_text": "A kite with a red and white color scheme is flying high in the clear blue sky.", "error": null, "sys_before": {"cpu_percent": 27.1, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.231, "power_cpu_cv_mean_watts": 1.014, "power_sys_5v0_mean_watts": 8.867, "gpu_utilization_percent_mean": 91.281}, "timestamp": "2026-01-30T21:10:51.711388"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5221.966, "latencies_ms": [5221.966], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.29, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 88.14}, "timestamp": "2026-01-30T21:10:58.970158"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6720.944, "latencies_ms": [6720.944], "images_per_second": 0.149, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The main object in the image is a kite, which is prominently positioned in the foreground. The kite is flying high in the sky, with its tail extending towards the right side of the image. The background features a clear blue sky, providing a contrasting backdrop to the vibrant colors of the kite.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.46, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.852, "gpu_utilization_percent_mean": 85.964}, "timestamp": "2026-01-30T21:11:07.714363"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7571.782, "latencies_ms": [7571.782], "images_per_second": 0.132, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The image depicts a vibrant scene of a kite flying in the clear blue sky. The kite, with its striking red and white color scheme, is captured in mid-flight, with its tail and tail fin visible against the backdrop of the sky. The scene suggests a sunny day, with the kite's design and the clear blue sky indicating a pleasant and enjoyable outdoor activity.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.034, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 84.46}, "timestamp": "2026-01-30T21:11:17.303084"}
{"image_index": 76, "image_name": "000000007784.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007784.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4987.055, "latencies_ms": [4987.055], "images_per_second": 0.201, "prompt_tokens": 22, "response_tokens_est": 36, "n_tiles": 12, "output_text": "The kite in the image is predominantly white with a striking red and black design. It is set against a clear blue sky, indicating a sunny day with good weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.477, "power_cpu_cv_mean_watts": 1.297, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 87.905}, "timestamp": "2026-01-30T21:11:24.327480"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4029.702, "latencies_ms": [4029.702], "images_per_second": 0.248, "prompt_tokens": 12, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image shows a well-lit, modern bedroom with a large window that offers a view of trees outside, a bed with white and black pillows, a nightstand with a lamp, and a door that leads to another room.", "error": null, "sys_before": {"cpu_percent": 23.2, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.358, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 71.706}, "timestamp": "2026-01-30T21:11:30.489759"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3926.009, "latencies_ms": [3926.009], "images_per_second": 0.255, "prompt_tokens": 26, "response_tokens_est": 46, "n_tiles": 6, "output_text": "bed: 2\npillows: 4\npillow covers: 2\nnightstand: 1\ntable lamp: 1\nwindow: 1\ndoor: 1\nwall art: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.644, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 72.25}, "timestamp": "2026-01-30T21:11:36.431724"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5511.158, "latencies_ms": [5511.158], "images_per_second": 0.181, "prompt_tokens": 30, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The main objects in the image are a bed and a nightstand. The bed is positioned in the foreground, with a dark-colored headboard and a white bedspread. The nightstand is located to the left of the bed, holding a lamp with a white shade. The background features a window with blinds, allowing natural light to enter the room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.027, "power_cpu_cv_mean_watts": 1.854, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 69.283}, "timestamp": "2026-01-30T21:11:43.978587"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3949.932, "latencies_ms": [3949.932], "images_per_second": 0.253, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image depicts a well-lit, modern bedroom with a large window that offers a view of trees outside. The room is furnished with a bed, a nightstand, and a lamp, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.744, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 72.121}, "timestamp": "2026-01-30T21:11:49.968161"}
{"image_index": 77, "image_name": "000000007795.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007795.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3862.456, "latencies_ms": [3862.456], "images_per_second": 0.259, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The room features a warm, yellowish-green wall color, complemented by a wooden ceiling with a metal grid. The lighting is soft and ambient, with a warm glow from a bedside lamp casting a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18616.0, "ram_available_mb": 44224.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.741, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 72.312}, "timestamp": "2026-01-30T21:11:55.861979"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3597.798, "latencies_ms": [3597.798], "images_per_second": 0.278, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 6, "output_text": "A motorcyclist wearing a white helmet and a white and green jacket is riding a white motorcycle with black accents, while a group of people stands behind a fence on the side of a road.", "error": null, "sys_before": {"cpu_percent": 28.0, "ram_used_mb": 18616.0, "ram_available_mb": 44224.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.988, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 73.033}, "timestamp": "2026-01-30T21:12:01.601884"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3435.116, "latencies_ms": [3435.116], "images_per_second": 0.291, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 6, "output_text": "1. Motorcycle\n2. Rider\n3. Helmet\n4. Gloves\n5. Motorcycle\n6. Rider\n7. Helmet\n8. Gloves", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.312, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 72.966}, "timestamp": "2026-01-30T21:12:07.079262"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5116.204, "latencies_ms": [5116.204], "images_per_second": 0.195, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The main object in the foreground is a white motorcycle with black and green accents, positioned on the right side of the road. The background features a group of people standing behind a wooden fence, with a person lying on the grass to the left. The road curves to the left, and the fence runs parallel to the road.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.554, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.953}, "timestamp": "2026-01-30T21:12:14.207026"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4705.162, "latencies_ms": [4705.162], "images_per_second": 0.213, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image captures a dynamic scene of a motorcyclist in full gear, including a helmet, riding a white and green motorcycle on a road. The background shows a group of people standing and watching the rider, with a fence and greenery visible, suggesting a rural or park setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.864, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 70.359}, "timestamp": "2026-01-30T21:12:20.932514"}
{"image_index": 78, "image_name": "000000007816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007816.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3726.307, "latencies_ms": [3726.307], "images_per_second": 0.268, "prompt_tokens": 22, "response_tokens_est": 43, "n_tiles": 6, "output_text": "The motorcycle in the image is predominantly white with black accents, featuring a sleek design and a visible logo on the side. The lighting is natural, suggesting daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18616.6, "ram_available_mb": 44224.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.92, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 72.419}, "timestamp": "2026-01-30T21:12:26.702381"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3045.086, "latencies_ms": [3045.086], "images_per_second": 0.328, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image shows a well-lit dining table with a clear glass vase containing white flowers, surrounded by elegant tableware and a dimly lit background.", "error": null, "sys_before": {"cpu_percent": 32.2, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.03, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 74.68}, "timestamp": "2026-01-30T21:12:31.848330"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3629.119, "latencies_ms": [3629.119], "images_per_second": 0.276, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "table: 1\ntablecloth: 1\nglass: 1\nvase: 1\nflowers: 1\ntableware: 1\nnapkin: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.016, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 72.4}, "timestamp": "2026-01-30T21:12:37.505816"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5331.49, "latencies_ms": [5331.49], "images_per_second": 0.188, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main objects in the image are a table and a vase with flowers. The table is in the foreground, with a white tablecloth covering it. The vase with the flowers is placed near the center of the table, slightly to the left. In the background, there are other tables and chairs, suggesting a dining area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.147, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 69.289}, "timestamp": "2026-01-30T21:12:44.861644"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5492.225, "latencies_ms": [5492.225], "images_per_second": 0.182, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts a dimly lit dining area with a table set for a meal. The table is adorned with white tablecloths, and there are several clear glassware pieces, including wine glasses and a vase with white flowers. The setting suggests a formal or semi-formal dining experience, possibly in a restaurant or a private event space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18614.4, "ram_available_mb": 44226.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.133, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 69.935}, "timestamp": "2026-01-30T21:12:52.385215"}
{"image_index": 79, "image_name": "000000007818.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007818.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5856.874, "latencies_ms": [5856.874], "images_per_second": 0.171, "prompt_tokens": 22, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The image depicts a dimly lit dining table with a white tablecloth, illuminated by soft, warm lighting. The table is adorned with elegant glassware, including a clear vase with white flowers and a smaller glass bowl. The overall atmosphere is serene and sophisticated, with a focus on the delicate beauty of the flowers and the refined simplicity of the table setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18614.4, "ram_available_mb": 44226.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18614.6, "ram_available_mb": 44226.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.926, "power_cpu_cv_mean_watts": 1.921, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 69.327}, "timestamp": "2026-01-30T21:13:00.301732"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2810.582, "latencies_ms": [2810.582], "images_per_second": 0.356, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 4, "output_text": "The image features a black and white photograph of a classic street clock mounted on a pole, with a blurred background of a grassy field and a clear sky.", "error": null, "sys_before": {"cpu_percent": 20.8, "ram_used_mb": 18614.3, "ram_available_mb": 44226.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18614.6, "ram_available_mb": 44226.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5451.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.007, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.617, "gpu_utilization_percent_mean": 66.174}, "timestamp": "2026-01-30T21:13:05.190605"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2891.405, "latencies_ms": [2891.405], "images_per_second": 0.346, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 4, "output_text": "1. Clock\n2. Clock face\n3. Clock tower\n4. Grass\n5. Sky\n6. Street light\n7. Person\n8. Bird", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.6, "ram_available_mb": 44226.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5463.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.868, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.584, "gpu_utilization_percent_mean": 67.261}, "timestamp": "2026-01-30T21:13:10.096155"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4165.311, "latencies_ms": [4165.311], "images_per_second": 0.24, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 4, "output_text": "The main object in the image is a clock, which is positioned in the foreground. The clock is mounted on a pole, and its face is visible, showing the time. The background features a blurred natural landscape, suggesting that the clock is placed in an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5465.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.206, "power_cpu_cv_mean_watts": 1.854, "power_sys_5v0_mean_watts": 7.634, "gpu_utilization_percent_mean": 66.0}, "timestamp": "2026-01-30T21:13:16.308094"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4423.185, "latencies_ms": [4423.185], "images_per_second": 0.226, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 4, "output_text": "The image depicts a black and white photograph of a classic street clock mounted on a pole. The clock face is visible, showing the time as approximately 10:10. The background is blurred, but it appears to be an outdoor setting with a grassy field and a clear sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5460.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.991, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 7.635, "gpu_utilization_percent_mean": 65.892}, "timestamp": "2026-01-30T21:13:22.779617"}
{"image_index": 80, "image_name": "000000007888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007888.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4355.65, "latencies_ms": [4355.65], "images_per_second": 0.23, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 4, "output_text": "The image is a black and white photograph featuring a vintage-style clock mounted on a pole. The clock has a rectangular face with Roman numerals and a decorative border. The background is a blurred natural scene, possibly a field, with a soft, diffuse light that enhances the vintage aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18614.4, "ram_available_mb": 44226.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5459.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.112, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.652, "gpu_utilization_percent_mean": 65.0}, "timestamp": "2026-01-30T21:13:29.172160"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2665.871, "latencies_ms": [2665.871], "images_per_second": 0.375, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A young man is performing a trick on a skateboard in an outdoor setting with trees and a clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 26.2, "ram_used_mb": 18614.3, "ram_available_mb": 44226.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18613.4, "ram_available_mb": 44227.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.941, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 76.455}, "timestamp": "2026-01-30T21:13:33.963659"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3989.023, "latencies_ms": [3989.023], "images_per_second": 0.251, "prompt_tokens": 26, "response_tokens_est": 47, "n_tiles": 6, "output_text": "1. Skateboard\n2. Person\n3. Skateboarder\n4. Skateboard\n5. Skateboard\n6. Skateboard\n7. Skateboard\n8. Skateboard", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18613.4, "ram_available_mb": 44227.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18613.3, "ram_available_mb": 44227.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.479, "power_cpu_cv_mean_watts": 1.65, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 71.273}, "timestamp": "2026-01-30T21:13:39.983690"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5742.124, "latencies_ms": [5742.124], "images_per_second": 0.174, "prompt_tokens": 30, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The main object in the foreground is a young man skateboarding. He is positioned on the left side of the image, with his body slightly turned to the right. The background features a tree and a few other people, indicating that the skateboarder is in an outdoor setting. The skateboard is also visible, placed on the ground in front of the skateboarder.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18613.3, "ram_available_mb": 44227.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18611.5, "ram_available_mb": 44229.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.029, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T21:13:47.739709"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5245.314, "latencies_ms": [5245.314], "images_per_second": 0.191, "prompt_tokens": 24, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The image depicts a young man skateboarding in an outdoor urban setting. He is captured mid-action, performing a trick on a skateboard. The skateboarder is wearing a dark-colored t-shirt, light-colored pants, and sneakers, and is positioned on a concrete surface with a tree and some greenery in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.5, "ram_available_mb": 44229.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18611.6, "ram_available_mb": 44229.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.4, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 69.864}, "timestamp": "2026-01-30T21:13:55.040153"}
{"image_index": 81, "image_name": "000000007977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007977.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5472.984, "latencies_ms": [5472.984], "images_per_second": 0.183, "prompt_tokens": 22, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts a young man skateboarding in an outdoor setting. The skateboarder is wearing a dark-colored t-shirt, light-colored pants, and a baseball cap. The scene is well-lit, with natural daylight illuminating the surroundings. The ground appears to be made of concrete, and there are trees and a clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18611.6, "ram_available_mb": 44229.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.336, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.533}, "timestamp": "2026-01-30T21:14:02.556234"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2125.104, "latencies_ms": [2125.104], "images_per_second": 0.471, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 2, "output_text": "The image shows a white plate filled with orange carrots, green peas, and purple beets, all arranged on a kitchen countertop.", "error": null, "sys_before": {"cpu_percent": 22.4, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.982, "power_cpu_cv_mean_watts": 1.579, "power_sys_5v0_mean_watts": 7.05, "gpu_utilization_percent_mean": 66.824}, "timestamp": "2026-01-30T21:14:06.766828"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2275.993, "latencies_ms": [2275.993], "images_per_second": 0.439, "prompt_tokens": 26, "response_tokens_est": 30, "n_tiles": 2, "output_text": "carrot: 8\npea: 1\npotato: 1\nknife: 1\ncutting board: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18610.7, "ram_available_mb": 44230.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.04, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 7.162, "gpu_utilization_percent_mean": 64.944}, "timestamp": "2026-01-30T21:14:11.082681"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5207.539, "latencies_ms": [5207.539], "images_per_second": 0.192, "prompt_tokens": 30, "response_tokens_est": 78, "n_tiles": 2, "output_text": "The main objects in the image are a white plate filled with orange carrots, a blue knife, and a bunch of green beans. The plate is placed on a countertop, with the green beans and the knife positioned near the plate. The background includes a white container and a white cup, while the foreground features a bunch of green beans and a bunch of purple and red beets.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.7, "ram_available_mb": 44230.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.999, "power_cpu_cv_mean_watts": 2.096, "power_sys_5v0_mean_watts": 7.304, "gpu_utilization_percent_mean": 62.256}, "timestamp": "2026-01-30T21:14:18.304786"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5118.478, "latencies_ms": [5118.478], "images_per_second": 0.195, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 2, "output_text": "The image depicts a kitchen countertop with a white plate containing a mix of cooked carrots and green beans. To the right of the plate, there is a blue knife and a bunch of fresh vegetables, including a bunch of purple beets and a bunch of green beans. The setting appears to be a kitchen, and the focus is on the food items on the countertop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18610.5, "ram_available_mb": 44230.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.738, "power_cpu_cv_mean_watts": 2.058, "power_sys_5v0_mean_watts": 7.281, "gpu_utilization_percent_mean": 61.953}, "timestamp": "2026-01-30T21:14:25.434047"}
{"image_index": 82, "image_name": "000000007991.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000007991.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4067.878, "latencies_ms": [4067.878], "images_per_second": 0.246, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 2, "output_text": "The image features a white plate filled with orange carrots, green peas, and purple beets. The carrots are brightly colored, contrasting with the muted tones of the other vegetables and the countertop. The lighting is soft and natural, casting gentle shadows and highlighting the textures of the vegetables.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18610.0, "ram_available_mb": 44230.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.1, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 7.21, "gpu_utilization_percent_mean": 63.5}, "timestamp": "2026-01-30T21:14:31.531814"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4168.006, "latencies_ms": [4168.006], "images_per_second": 0.24, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "A man is standing on a stage, speaking to an audience, with a large screen behind him displaying his image.", "error": null, "sys_before": {"cpu_percent": 33.8, "ram_used_mb": 18610.0, "ram_available_mb": 44230.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.912, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 90.529}, "timestamp": "2026-01-30T21:14:37.893889"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4845.391, "latencies_ms": [4845.391], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Man\n2. Suits\n3. Background\n4. Speaker\n5. Table\n6. Water bottles\n7. Table\n8. Speaker", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.839, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.761, "gpu_utilization_percent_mean": 89.15}, "timestamp": "2026-01-30T21:14:44.765590"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6181.241, "latencies_ms": [6181.241], "images_per_second": 0.162, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The main object in the foreground is a person with red hair, who is facing away from the camera. The person is standing in front of a large screen displaying a man in a suit. The screen is positioned in the background, with the man's image slightly blurred.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.808, "power_cpu_cv_mean_watts": 1.51, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 86.058}, "timestamp": "2026-01-30T21:14:52.996746"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5586.225, "latencies_ms": [5586.225], "images_per_second": 0.179, "prompt_tokens": 24, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image depicts a man standing on a stage, delivering a speech or presentation. The background features a large screen displaying a projected image of the same man, suggesting that the presentation is being delivered in front of an audience.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.167, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.771, "gpu_utilization_percent_mean": 87.0}, "timestamp": "2026-01-30T21:15:00.605486"}
{"image_index": 83, "image_name": "000000008021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008021.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4726.05, "latencies_ms": [4726.05], "images_per_second": 0.212, "prompt_tokens": 22, "response_tokens_est": 32, "n_tiles": 12, "output_text": "The image features a man standing on a stage with a large screen behind him displaying a colorful geometric pattern. The lighting is warm, creating a vibrant atmosphere.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18610.4, "ram_available_mb": 44230.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.951, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.781, "gpu_utilization_percent_mean": 88.718}, "timestamp": "2026-01-30T21:15:07.352100"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3821.175, "latencies_ms": [3821.175], "images_per_second": 0.262, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 12, "output_text": "Two workers in blue uniforms are conversing near a scooter parked on the sidewalk.", "error": null, "sys_before": {"cpu_percent": 31.5, "ram_used_mb": 18610.4, "ram_available_mb": 44230.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.273, "power_cpu_cv_mean_watts": 0.943, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 90.258}, "timestamp": "2026-01-30T21:15:13.353047"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5228.434, "latencies_ms": [5228.434], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.476, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.775, "gpu_utilization_percent_mean": 88.0}, "timestamp": "2026-01-30T21:15:20.622658"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8193.443, "latencies_ms": [8193.443], "images_per_second": 0.122, "prompt_tokens": 30, "response_tokens_est": 89, "n_tiles": 12, "output_text": "In the image, there is a scooter parked on the left side of the frame, near the curb. The scooter is facing the right side of the frame. In the background, there is a building with a sign that reads \"\u4e0a\u6d77\u5efa\u5de5\u96c6\u56e2\" (Shanghai Construction Group). The sign is mounted on a pole and is positioned near the building. The ground is paved, and there is a small trash can nearby.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18610.3, "ram_available_mb": 44230.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.674, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 83.754}, "timestamp": "2026-01-30T21:15:30.831156"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7521.424, "latencies_ms": [7521.424], "images_per_second": 0.133, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The image depicts a scene in an urban setting, likely a street or a parking area, with a concrete sidewalk and a paved road. Two individuals, one in a blue uniform and the other in casual attire, are standing near a scooter. The background features a building with a blue and white sign, a blue and white advertisement, and a blue and red banner.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18610.3, "ram_available_mb": 44230.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18610.1, "ram_available_mb": 44230.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.977, "power_cpu_cv_mean_watts": 1.659, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 84.857}, "timestamp": "2026-01-30T21:15:40.368368"}
{"image_index": 84, "image_name": "000000008211.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008211.jpg", "image_width": 640, "image_height": 459, "image_resolution": "640x459", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5855.438, "latencies_ms": [5855.438], "images_per_second": 0.171, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The image depicts a scene with a blue and white sign on a building, featuring Chinese characters. The sign is mounted on a gray pillar. The pavement is wet, indicating recent rain. The lighting is natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.1, "ram_available_mb": 44230.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.835, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.778, "gpu_utilization_percent_mean": 86.714}, "timestamp": "2026-01-30T21:15:48.245564"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2781.39, "latencies_ms": [2781.39], "images_per_second": 0.36, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The image shows a plate of food, which includes a black, square-shaped dish containing a green, creamy soup and a portion of shredded chicken, all placed on a white, round plate.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.301, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 6.92, "gpu_utilization_percent_mean": 69.913}, "timestamp": "2026-01-30T21:15:53.119245"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8222.379, "latencies_ms": [8222.379], "images_per_second": 0.122, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 1, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.661, "power_cpu_cv_mean_watts": 2.226, "power_sys_5v0_mean_watts": 7.208, "gpu_utilization_percent_mean": 65.271}, "timestamp": "2026-01-30T21:16:03.377074"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4148.469, "latencies_ms": [4148.469], "images_per_second": 0.241, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 1, "output_text": "The main objects in the image are a black rectangular baking dish filled with a green and yellow vegetable soup, and a white plate holding shredded chicken. The dish is placed on the left side of the plate, while the shredded chicken is in the foreground, and the plate itself is in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.697, "power_cpu_cv_mean_watts": 2.061, "power_sys_5v0_mean_watts": 7.07, "gpu_utilization_percent_mean": 67.353}, "timestamp": "2026-01-30T21:16:09.555405"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3291.753, "latencies_ms": [3291.753], "images_per_second": 0.304, "prompt_tokens": 24, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The image shows a white plate with a black, square-shaped dish containing a green, creamy soup and chunks of chicken. The dish is placed on a beige carpeted floor, and there is a silver fork resting on the plate.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.659, "power_cpu_cv_mean_watts": 1.988, "power_sys_5v0_mean_watts": 6.988, "gpu_utilization_percent_mean": 65.296}, "timestamp": "2026-01-30T21:16:14.863417"}
{"image_index": 85, "image_name": "000000008277.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008277.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3103.419, "latencies_ms": [3103.419], "images_per_second": 0.322, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 1, "output_text": "The image features a white plate with a black rectangular baking dish containing a green and yellow vegetable stew. The plate is placed on a beige carpeted floor, and the lighting is soft and natural, casting gentle shadows.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.551, "power_cpu_cv_mean_watts": 1.971, "power_sys_5v0_mean_watts": 6.979, "gpu_utilization_percent_mean": 68.88}, "timestamp": "2026-01-30T21:16:19.995944"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3312.365, "latencies_ms": [3312.365], "images_per_second": 0.302, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 6, "output_text": "The image features a man wearing a light blue shirt, a red tie, and a plaid flat cap, standing outdoors with a building and a clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 30.5, "ram_used_mb": 18610.2, "ram_available_mb": 44230.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18610.7, "ram_available_mb": 44230.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.722, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 73.704}, "timestamp": "2026-01-30T21:16:25.437155"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3534.558, "latencies_ms": [3534.558], "images_per_second": 0.283, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18610.7, "ram_available_mb": 44230.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.398, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 73.31}, "timestamp": "2026-01-30T21:16:31.003277"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4828.137, "latencies_ms": [4828.137], "images_per_second": 0.207, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The main object in the foreground is a man wearing a blue shirt and a red tie. He is positioned slightly to the right of the center of the image. The background features a building with a green roof and a window. The man is in the foreground, and the building is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.631, "power_cpu_cv_mean_watts": 1.798, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.122}, "timestamp": "2026-01-30T21:16:37.865302"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4700.901, "latencies_ms": [4700.901], "images_per_second": 0.213, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image shows a man wearing a light blue shirt, a red tie, and a plaid flat cap. He is outdoors, likely in a park or garden, with a blurred background featuring greenery and a building. The man appears to be smiling and looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.81, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.436}, "timestamp": "2026-01-30T21:16:44.608813"}
{"image_index": 86, "image_name": "000000008532.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008532.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3620.741, "latencies_ms": [3620.741], "images_per_second": 0.276, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The man in the image is wearing a light blue shirt, a red tie, and a plaid flat cap. The lighting is bright, and the background is blurred, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.005, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 72.633}, "timestamp": "2026-01-30T21:16:50.286329"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2577.841, "latencies_ms": [2577.841], "images_per_second": 0.388, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 4, "output_text": "The image is a collage of four photographs showing various slices of pizza, each with different toppings and appearances, all placed on white plates.", "error": null, "sys_before": {"cpu_percent": 22.8, "ram_used_mb": 18610.7, "ram_available_mb": 44230.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5451.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.429, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 7.56, "gpu_utilization_percent_mean": 68.286}, "timestamp": "2026-01-30T21:16:54.987713"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2688.666, "latencies_ms": [2688.666], "images_per_second": 0.372, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 4, "output_text": "1. Pizza\n2. Pizza\n3. Pizza\n4. Pizza\n5. Pizza\n6. Pizza\n7. Pizza\n8. Pizza", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18611.2, "ram_available_mb": 44229.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5463.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.57, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 7.641, "gpu_utilization_percent_mean": 66.045}, "timestamp": "2026-01-30T21:16:59.718990"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7677.294, "latencies_ms": [7677.294], "images_per_second": 0.13, "prompt_tokens": 30, "response_tokens_est": 114, "n_tiles": 4, "output_text": "The main objects in the image are pizzas, and they are arranged in a way that showcases their spatial relationships. The pizzas are positioned in the center of the image, with the leftmost pizza being the closest to the viewer, while the rightmost pizza is the furthest away. The foreground pizza is the most prominent, with its toppings and crust clearly visible. The background pizza is slightly out of focus, indicating that it is further away. The pizzas are placed on white plates, which help to highlight their colors and textures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.2, "ram_available_mb": 44229.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18610.3, "ram_available_mb": 44230.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5465.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.718, "power_cpu_cv_mean_watts": 2.12, "power_sys_5v0_mean_watts": 7.661, "gpu_utilization_percent_mean": 64.631}, "timestamp": "2026-01-30T21:17:09.422575"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4347.681, "latencies_ms": [4347.681], "images_per_second": 0.23, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 4, "output_text": "The image is a collage of four photographs depicting various slices of pizza. The pizza appears to be on a white plate, and the slices are being cut and eaten by someone. The overall setting suggests a casual dining environment, possibly at a restaurant or a home with a pizza-making setup.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18610.3, "ram_available_mb": 44230.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18609.3, "ram_available_mb": 44231.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5460.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.201, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 7.632, "gpu_utilization_percent_mean": 66.694}, "timestamp": "2026-01-30T21:17:15.799306"}
{"image_index": 87, "image_name": "000000008629.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008629.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4408.368, "latencies_ms": [4408.368], "images_per_second": 0.227, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 4, "output_text": "The image showcases a collage of four photographs featuring a pizza with various toppings. The pizza crust appears golden-brown, and the toppings are visible, including melted cheese, red tomato pieces, and green herbs. The lighting is bright, highlighting the textures and colors of the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.3, "ram_available_mb": 44231.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18609.4, "ram_available_mb": 44231.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5459.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.079, "power_cpu_cv_mean_watts": 1.873, "power_sys_5v0_mean_watts": 7.598, "gpu_utilization_percent_mean": 65.676}, "timestamp": "2026-01-30T21:17:22.230440"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4669.029, "latencies_ms": [4669.029], "images_per_second": 0.214, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "Two young girls are standing in front of a fence, with one of them holding a black goat's head, while the other girl is holding a hand.", "error": null, "sys_before": {"cpu_percent": 30.7, "ram_used_mb": 18609.4, "ram_available_mb": 44231.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18609.6, "ram_available_mb": 44231.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.221, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 86.769}, "timestamp": "2026-01-30T21:17:29.048946"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5309.594, "latencies_ms": [5309.594], "images_per_second": 0.188, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 12, "output_text": "- goat: 2\n- girl: 2\n- woman: 1\n- dog: 1\n- fence: 1\n- child: 1\n- pet: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18609.6, "ram_available_mb": 44231.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18609.2, "ram_available_mb": 44231.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.413, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.777, "gpu_utilization_percent_mean": 87.511}, "timestamp": "2026-01-30T21:17:36.372286"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7631.554, "latencies_ms": [7631.554], "images_per_second": 0.131, "prompt_tokens": 30, "response_tokens_est": 80, "n_tiles": 12, "output_text": "In the image, the main objects are a black goat and a young girl. The goat is in the foreground, while the girl is positioned slightly behind it. The girl is holding the goat's head, indicating a close interaction between them. The goat is also in the foreground, while the girl is in the background. The background features a fence and a house, providing context to the setting.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18609.2, "ram_available_mb": 44231.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18609.3, "ram_available_mb": 44231.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.094, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 85.156}, "timestamp": "2026-01-30T21:17:46.033997"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7686.647, "latencies_ms": [7686.647], "images_per_second": 0.13, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 12, "output_text": "The image depicts a scene in a petting zoo or a similar animal enclosure. A young girl and a young boy are interacting with a black goat, which is lying down. The girl is gently petting the goat, while the boy stands behind her, observing the interaction. The setting is outdoors, with a fence and greenery visible in the background, indicating a controlled environment for the animals.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.3, "ram_available_mb": 44231.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18609.5, "ram_available_mb": 44231.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.086, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 84.538}, "timestamp": "2026-01-30T21:17:55.760994"}
{"image_index": 88, "image_name": "000000008690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008690.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5873.77, "latencies_ms": [5873.77], "images_per_second": 0.17, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The image features a bright, sunny day with clear blue skies. The lighting is natural, casting soft shadows on the ground. The scene includes a white goat with black patches, a black and white dog, and a girl in a colorful floral dress.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.5, "ram_available_mb": 44231.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18609.9, "ram_available_mb": 44231.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.855, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 86.26}, "timestamp": "2026-01-30T21:18:03.673104"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3328.032, "latencies_ms": [3328.032], "images_per_second": 0.3, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "The image depicts a nighttime scene of a roadway with traffic lights, illuminated signs, and a dark sky, with a hint of a mountain range in the background.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18609.7, "ram_available_mb": 44231.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18609.5, "ram_available_mb": 44231.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.676, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 72.852}, "timestamp": "2026-01-30T21:18:09.102298"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3608.656, "latencies_ms": [3608.656], "images_per_second": 0.277, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "- Traffic light: 2\n- Street light: 1\n- Road: 1\n- Buildings: 3\n- Power lines: 2\n- Road sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.5, "ram_available_mb": 44231.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18609.6, "ram_available_mb": 44231.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.192, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 72.233}, "timestamp": "2026-01-30T21:18:14.740602"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5358.764, "latencies_ms": [5358.764], "images_per_second": 0.187, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The main objects in the image are the traffic lights and the road. The traffic lights are positioned in the foreground, with the green light illuminated, indicating that vehicles can proceed. The road is in the background, extending into the distance with other traffic lights and signs visible. The distant mountains and buildings provide a sense of depth to the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18609.6, "ram_available_mb": 44231.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18609.0, "ram_available_mb": 44231.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.361, "power_cpu_cv_mean_watts": 1.833, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 70.178}, "timestamp": "2026-01-30T21:18:22.132525"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4825.257, "latencies_ms": [4825.257], "images_per_second": 0.207, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a nighttime scene of a highway intersection during twilight. The sky is dark, and the streetlights are on, illuminating the scene. The traffic lights are green, indicating that vehicles can proceed. The road is empty, and there are no visible pedestrians or other vehicles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.0, "ram_available_mb": 44231.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18608.9, "ram_available_mb": 44232.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.76, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 70.2}, "timestamp": "2026-01-30T21:18:28.980905"}
{"image_index": 89, "image_name": "000000008762.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008762.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4840.099, "latencies_ms": [4840.099], "images_per_second": 0.207, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a nighttime scene with a clear sky and a few scattered lights from vehicles and streetlights. The traffic lights are illuminated green, indicating that vehicles can proceed. The overall lighting is dim, with the main source of light being the streetlights and the illuminated traffic lights.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18608.9, "ram_available_mb": 44232.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18608.9, "ram_available_mb": 44232.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.532, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 69.976}, "timestamp": "2026-01-30T21:18:35.836255"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2122.908, "latencies_ms": [2122.908], "images_per_second": 0.471, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 6, "output_text": "A smiling woman is standing in front of a table filled with ripe bananas.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18608.9, "ram_available_mb": 44232.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 18609.9, "ram_available_mb": 44231.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.366, "power_cpu_cv_mean_watts": 1.037, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 77.176}, "timestamp": "2026-01-30T21:18:40.085110"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2095.78, "latencies_ms": [2095.78], "images_per_second": 0.477, "prompt_tokens": 26, "response_tokens_est": 16, "n_tiles": 6, "output_text": "bananas: 20\nwoman: 1\nshirt: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.9, "ram_available_mb": 44231.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 18609.5, "ram_available_mb": 44231.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.249, "power_cpu_cv_mean_watts": 0.966, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 80.059}, "timestamp": "2026-01-30T21:18:44.198148"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3819.258, "latencies_ms": [3819.258], "images_per_second": 0.262, "prompt_tokens": 30, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The main objects in the image are bananas and a woman. The bananas are in the foreground, with a bunch of them in the center. The woman is in the background, standing near the bananas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.5, "ram_available_mb": 44231.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18609.6, "ram_available_mb": 44231.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.833, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.942, "gpu_utilization_percent_mean": 71.71}, "timestamp": "2026-01-30T21:18:50.040312"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5007.27, "latencies_ms": [5007.27], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a woman standing in front of a market stall, surrounded by a variety of bananas. She is smiling and appears to be enjoying her time at the market. The setting is an outdoor market, with the woman standing in front of a stall that is filled with fresh produce, including bananas.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18609.6, "ram_available_mb": 44231.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18610.3, "ram_available_mb": 44230.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.514, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 70.476}, "timestamp": "2026-01-30T21:18:57.077572"}
{"image_index": 90, "image_name": "000000008844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008844.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3610.896, "latencies_ms": [3610.896], "images_per_second": 0.277, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The image features a woman with a warm smile, wearing a colorful, patterned shirt. The background includes a rustic wooden table with a bunch of ripe bananas, suggesting a warm, sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.3, "ram_available_mb": 44230.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18610.0, "ram_available_mb": 44230.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.086, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 72.2}, "timestamp": "2026-01-30T21:19:02.719483"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4887.461, "latencies_ms": [4887.461], "images_per_second": 0.205, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image depicts a street scene featuring a red brick building with a green metal fire escape, a closed shuttered shop, and a graffiti-covered metal shutter.", "error": null, "sys_before": {"cpu_percent": 28.6, "ram_used_mb": 18610.0, "ram_available_mb": 44230.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18609.8, "ram_available_mb": 44231.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.851, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.779, "gpu_utilization_percent_mean": 87.8}, "timestamp": "2026-01-30T21:19:09.764361"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5061.968, "latencies_ms": [5061.968], "images_per_second": 0.198, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 12, "output_text": "fire hydrant: 1\nbicycle: 1\nbuilding: 1\nwindow: 2\ngarage door: 2\ngraffiti: 5", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18609.8, "ram_available_mb": 44231.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18609.1, "ram_available_mb": 44231.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.469, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.762, "gpu_utilization_percent_mean": 88.19}, "timestamp": "2026-01-30T21:19:16.884066"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7470.712, "latencies_ms": [7470.712], "images_per_second": 0.134, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The main objects in the image are a red brick building with a green metal fire escape, a closed metal shutter door, and a green door with graffiti. The fire escape is attached to the building, and the green door is located near the fire hydrant. The graffiti on the door and shutter is in the foreground, while the fire hydrant is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18609.1, "ram_available_mb": 44231.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18609.2, "ram_available_mb": 44231.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.907, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 84.381}, "timestamp": "2026-01-30T21:19:26.379631"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6967.942, "latencies_ms": [6967.942], "images_per_second": 0.144, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts an urban alleyway with a red brick building on the left and a green metal shuttered shop on the right. The shop has various graffiti tags on its shutters, and a fire hydrant is visible in the foreground. The scene suggests a quiet, possibly neglected area with a mix of commercial and residential structures.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.2, "ram_available_mb": 44231.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18610.4, "ram_available_mb": 44230.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.231, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 85.552}, "timestamp": "2026-01-30T21:19:35.380501"}
{"image_index": 91, "image_name": "000000008899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000008899.jpg", "image_width": 640, "image_height": 539, "image_resolution": "640x539", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6858.481, "latencies_ms": [6858.481], "images_per_second": 0.146, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a weathered, urban scene with a red brick building featuring a green metal fire escape. The building has a weathered look with visible signs of wear and tear. The fire escape is green, and the building has a red brick facade. The scene is illuminated by natural daylight, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.4, "ram_available_mb": 44230.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18611.1, "ram_available_mb": 44229.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.21, "power_cpu_cv_mean_watts": 1.637, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 85.293}, "timestamp": "2026-01-30T21:19:44.291072"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3170.132, "latencies_ms": [3170.132], "images_per_second": 0.315, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 6, "output_text": "A man is in the process of throwing a bright yellow frisbee, with his eyes wide open and mouth open, indicating he is fully engaged in the activity.", "error": null, "sys_before": {"cpu_percent": 25.3, "ram_used_mb": 18610.9, "ram_available_mb": 44230.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18611.4, "ram_available_mb": 44229.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.818, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 73.154}, "timestamp": "2026-01-30T21:19:49.591411"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3271.632, "latencies_ms": [3271.632], "images_per_second": 0.306, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 6, "output_text": "frisbee: 1\nman: 1\nhat: 1\nshirt: 1\nclothes: 1\nsunglasses: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.4, "ram_available_mb": 44229.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18611.4, "ram_available_mb": 44229.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.542, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 73.148}, "timestamp": "2026-01-30T21:19:54.926817"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5436.597, "latencies_ms": [5436.597], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The main object in the foreground is a man holding a bright green frisbee. He is positioned slightly to the left and in the foreground. The background is dimly lit and out of focus, with indistinct shapes and people. The man appears to be in the center of the image, with the frisbee being the focal point.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18611.4, "ram_available_mb": 44229.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18610.3, "ram_available_mb": 44230.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.16, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 69.457}, "timestamp": "2026-01-30T21:20:02.392950"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5044.605, "latencies_ms": [5044.605], "images_per_second": 0.198, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The image depicts a man in a black sleeveless top and a blue and white checkered beanie, holding a bright yellow frisbee in his right hand. He appears to be in a dimly lit indoor setting, possibly a recreational area or a sports facility, with a crowd of people in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.3, "ram_available_mb": 44230.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.396, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 70.163}, "timestamp": "2026-01-30T21:20:09.484800"}
{"image_index": 92, "image_name": "000000009378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009378.jpg", "image_width": 600, "image_height": 400, "image_resolution": "600x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3220.8, "latencies_ms": [3220.8], "images_per_second": 0.31, "prompt_tokens": 22, "response_tokens_est": 34, "n_tiles": 6, "output_text": "The man in the image is wearing a black sleeveless top and a blue and white checkered beanie. The lighting is dim, creating a moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18611.5, "ram_available_mb": 44229.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.788, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-30T21:20:14.724869"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5256.064, "latencies_ms": [5256.064], "images_per_second": 0.19, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image depicts a group of people sitting around a table, each engrossed in their own computer screens, with a variety of laptops and computers scattered around, indicating a busy and collaborative work environment.", "error": null, "sys_before": {"cpu_percent": 28.4, "ram_used_mb": 18611.5, "ram_available_mb": 44229.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.664, "power_cpu_cv_mean_watts": 1.369, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 86.767}, "timestamp": "2026-01-30T21:20:22.123193"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4731.868, "latencies_ms": [4731.868], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Laptop\n2. Laptop\n3. Laptop\n4. Laptop\n5. Laptop\n6. Laptop\n7. Laptop\n8. Laptop", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.964, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 89.205}, "timestamp": "2026-01-30T21:20:28.868853"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6670.046, "latencies_ms": [6670.046], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The main objects in the image are a laptop, a keyboard, and a mouse. The laptop is positioned in the foreground, with the keyboard and mouse placed in front of it. The laptop screen is turned on, displaying some content. The keyboard and mouse are in the foreground, with the laptop in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18612.6, "ram_available_mb": 44228.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.46, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 85.536}, "timestamp": "2026-01-30T21:20:37.593258"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7089.694, "latencies_ms": [7089.694], "images_per_second": 0.141, "prompt_tokens": 24, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The image depicts a dimly lit room filled with people engaged in various activities. The setting appears to be a casual gathering or meeting place, possibly a bar or a small restaurant, with a table cluttered with laptops, drinks, and other personal items. The individuals are focused on their screens, suggesting they are either working or browsing through content.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18612.6, "ram_available_mb": 44228.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18613.7, "ram_available_mb": 44227.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.171, "power_cpu_cv_mean_watts": 1.662, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 84.65}, "timestamp": "2026-01-30T21:20:46.727024"}
{"image_index": 93, "image_name": "000000009400.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009400.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5662.432, "latencies_ms": [5662.432], "images_per_second": 0.177, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The image depicts a dimly lit room with a warm, yellowish glow from a lamp. The lighting creates a cozy atmosphere, highlighting the cluttered desk with various electronic devices, including laptops, a keyboard, and a mouse.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18613.7, "ram_available_mb": 44227.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.088, "power_cpu_cv_mean_watts": 1.485, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 87.438}, "timestamp": "2026-01-30T21:20:54.443750"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3943.394, "latencies_ms": [3943.394], "images_per_second": 0.254, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 12, "output_text": "A young girl with blonde hair is holding a blue umbrella and a brown bottle in her hand.", "error": null, "sys_before": {"cpu_percent": 32.4, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.213, "power_cpu_cv_mean_watts": 1.001, "power_sys_5v0_mean_watts": 8.853, "gpu_utilization_percent_mean": 89.031}, "timestamp": "2026-01-30T21:21:00.558294"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5153.384, "latencies_ms": [5153.384], "images_per_second": 0.194, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 12, "output_text": "1. Girl\n2. Blue umbrella\n3. Blue umbrella\n4. Blue umbrella\n5. Blue umbrella\n6. Blue umbrella\n7. Blue umbrella\n8. Blue umbrella", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.439, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 88.07}, "timestamp": "2026-01-30T21:21:07.764684"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4676.26, "latencies_ms": [4676.26], "images_per_second": 0.214, "prompt_tokens": 30, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The main object in the foreground is a young girl holding a blue umbrella. The background features a blue umbrella, and the ground is covered with gravel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.891, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 88.462}, "timestamp": "2026-01-30T21:21:14.499489"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6359.248, "latencies_ms": [6359.248], "images_per_second": 0.157, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The image depicts a young child standing under a large blue umbrella, holding a brown object in their right hand. The child is wearing a pink jacket and blue jeans, and the ground appears to be a gravel surface. The setting suggests a casual outdoor environment, possibly during a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.577, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 86.057}, "timestamp": "2026-01-30T21:21:22.886253"}
{"image_index": 94, "image_name": "000000009448.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009448.jpg", "image_width": 551, "image_height": 640, "image_resolution": "551x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5511.437, "latencies_ms": [5511.437], "images_per_second": 0.181, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The notable visual attributes of the image include a young girl with light blonde hair, wearing a pink jacket and a colorful scarf. The background features a blue umbrella, and the lighting suggests it is daytime with natural sunlight.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18615.1, "ram_available_mb": 44225.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.116, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 87.674}, "timestamp": "2026-01-30T21:21:30.426742"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4371.336, "latencies_ms": [4371.336], "images_per_second": 0.229, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 12, "output_text": "The image shows a man standing in an office with a computer setup on a desk, including a monitor, keyboard, and mouse.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18614.7, "ram_available_mb": 44226.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.408, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 88.694}, "timestamp": "2026-01-30T21:21:36.946544"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4985.057, "latencies_ms": [4985.057], "images_per_second": 0.201, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 12, "output_text": "1. Computer monitor\n2. Computer mouse\n3. Keyboard\n4. Printer\n5. Desk\n6. Chair\n7. Cables\n8. Power outlet", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.654, "power_cpu_cv_mean_watts": 1.28, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 88.366}, "timestamp": "2026-01-30T21:21:43.957493"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5767.418, "latencies_ms": [5767.418], "images_per_second": 0.173, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The main objects in the image are a man in a suit and a computer setup. The man is positioned in the foreground, standing near the computer setup. The computer setup is located in the background, slightly to the right of the man.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.064, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 87.229}, "timestamp": "2026-01-30T21:21:51.736472"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7023.144, "latencies_ms": [7023.144], "images_per_second": 0.142, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The image depicts a man standing in an office or workspace, with a computer setup in front of him. The room appears to be well-lit, with a window providing natural light. The man is dressed in a dark suit and tie, and he seems to be engaged in a task, possibly working on a computer or using a device.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.228, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 85.136}, "timestamp": "2026-01-30T21:22:00.796746"}
{"image_index": 95, "image_name": "000000009483.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009483.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5349.701, "latencies_ms": [5349.701], "images_per_second": 0.187, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image depicts a well-lit office environment with a white wall and a window with a partially drawn curtain. The desk is equipped with a computer monitor, keyboard, mouse, and various electronic devices.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18616.2, "ram_available_mb": 44224.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.19, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 87.067}, "timestamp": "2026-01-30T21:22:08.183427"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4214.325, "latencies_ms": [4214.325], "images_per_second": 0.237, "prompt_tokens": 12, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image depicts a group of four men sitting around a wooden dining table, engaged in a casual conversation, with various items on the table, including a coffee cup, a bottle, and a bowl of food, suggesting a relaxed and informal gathering.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.12, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 71.086}, "timestamp": "2026-01-30T21:22:14.512657"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3129.893, "latencies_ms": [3129.893], "images_per_second": 0.319, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 6, "output_text": "1. Table\n2. People\n3. Coffee\n4. Cups\n5. Bowl\n6. Bottle\n7. Glass\n8. Plate", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18616.4, "ram_available_mb": 44224.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.722, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 73.538}, "timestamp": "2026-01-30T21:22:19.702014"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7720.928, "latencies_ms": [7720.928], "images_per_second": 0.13, "prompt_tokens": 30, "response_tokens_est": 109, "n_tiles": 6, "output_text": "The main objects in the image are a group of people sitting around a wooden dining table. The table is the central focus, with various items placed on it, including a white mug, a blue plate, a bottle, and a glass. The people are positioned in the background, with the leftmost person facing the camera, the middle person partially obscured, and the rightmost person facing away from the camera. The foreground is occupied by the table and the people's legs, while the background features the ceiling and a window with curtains.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18615.7, "ram_available_mb": 44225.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.13, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 67.667}, "timestamp": "2026-01-30T21:22:29.444632"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4580.52, "latencies_ms": [4580.52], "images_per_second": 0.218, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a cozy indoor setting where four men are gathered around a wooden dining table. They appear to be enjoying a meal, with some of them holding cups and plates. The room has a warm ambiance, with natural light streaming in through large windows covered with curtains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.903, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 70.816}, "timestamp": "2026-01-30T21:22:36.060776"}
{"image_index": 96, "image_name": "000000009590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009590.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4646.268, "latencies_ms": [4646.268], "images_per_second": 0.215, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The image depicts a cozy indoor setting with a warm, natural light streaming in through large windows covered with light-colored curtains. The room features wooden furniture, including a wooden table and chairs, and a wooden ceiling. The lighting is soft and natural, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.9, "ram_available_mb": 44225.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.745, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 70.421}, "timestamp": "2026-01-30T21:22:42.720493"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4154.569, "latencies_ms": [4154.569], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "A red pickup truck is parked on a snowy street, with a snow-covered roof and a person nearby.", "error": null, "sys_before": {"cpu_percent": 29.5, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.971, "power_cpu_cv_mean_watts": 1.084, "power_sys_5v0_mean_watts": 8.877, "gpu_utilization_percent_mean": 90.588}, "timestamp": "2026-01-30T21:22:49.057979"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6002.704, "latencies_ms": [6002.704], "images_per_second": 0.167, "prompt_tokens": 26, "response_tokens_est": 53, "n_tiles": 12, "output_text": "1. Snow\n2. Snow-covered truck\n3. Snow-covered house\n4. Snow-covered trees\n5. Snow-covered driveway\n6. Snow-covered sidewalk\n7. Snow-covered car\n8. Snow-covered vehicle", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.862, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 86.52}, "timestamp": "2026-01-30T21:22:57.103413"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7274.622, "latencies_ms": [7274.622], "images_per_second": 0.137, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The main objects in the image are a red pickup truck and a snow-covered residential area. The truck is parked on the right side of the image, with its front facing the viewer. The residential area is in the background, with houses and trees visible. The truck is positioned near the snow-covered sidewalk, and the houses are further back in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18615.8, "ram_available_mb": 44225.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.165, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 84.623}, "timestamp": "2026-01-30T21:23:06.438067"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6761.165, "latencies_ms": [6761.165], "images_per_second": 0.148, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a snowy residential area with a red pickup truck parked on the side of a snow-covered street. A person is seen clearing snow from the truck's bed, indicating recent snowfall. The scene is set in a quiet neighborhood with houses and trees covered in snow, creating a serene winter atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18615.2, "ram_available_mb": 44225.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.392, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 85.351}, "timestamp": "2026-01-30T21:23:15.246776"}
{"image_index": 97, "image_name": "000000009769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7166.916, "latencies_ms": [7166.916], "images_per_second": 0.14, "prompt_tokens": 22, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a snowy residential area with a red pickup truck parked on the side of a snow-covered street. The truck is covered in snow, and the surrounding area is blanketed in white snow, indicating a winter scene. The lighting is subdued, with a grayish tone, and the overall atmosphere is quiet and serene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.148, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 84.583}, "timestamp": "2026-01-30T21:23:24.444804"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4321.19, "latencies_ms": [4321.19], "images_per_second": 0.231, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "A man is taking a photo of himself in a bathroom with a mirror, while a white towel is hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 31.3, "ram_used_mb": 18615.6, "ram_available_mb": 44225.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.326, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 88.889}, "timestamp": "2026-01-30T21:23:30.948156"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5208.93, "latencies_ms": [5208.93], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.493, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 87.837}, "timestamp": "2026-01-30T21:23:38.183597"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7715.231, "latencies_ms": [7715.231], "images_per_second": 0.13, "prompt_tokens": 30, "response_tokens_est": 81, "n_tiles": 12, "output_text": "The main objects in the image are located in the foreground, with the bathroom sink and mirror being the most prominent features. The sink is situated on the left side of the image, while the mirror is positioned in the center. The bathroom is also partially visible in the background, with a doorway leading to another room. The towels are hanging on the left side of the sink, near the mirror.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.965, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 84.308}, "timestamp": "2026-01-30T21:23:47.930311"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4936.369, "latencies_ms": [4936.369], "images_per_second": 0.203, "prompt_tokens": 24, "response_tokens_est": 36, "n_tiles": 12, "output_text": "The image depicts a luxurious bathroom with a marble countertop and a large mirror. A man is taking a selfie in the mirror, capturing the bathroom's elegance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18616.3, "ram_available_mb": 44224.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.78, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 89.146}, "timestamp": "2026-01-30T21:23:54.889723"}
{"image_index": 98, "image_name": "000000009772.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009772.jpg", "image_width": 550, "image_height": 640, "image_resolution": "550x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4720.756, "latencies_ms": [4720.756], "images_per_second": 0.212, "prompt_tokens": 22, "response_tokens_est": 32, "n_tiles": 12, "output_text": "The bathroom features a warm, inviting ambiance with beige walls and a marble countertop. The lighting is soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18616.1, "ram_available_mb": 44224.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18616.0, "ram_available_mb": 44224.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.928, "power_cpu_cv_mean_watts": 1.242, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 88.769}, "timestamp": "2026-01-30T21:24:01.634123"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3768.558, "latencies_ms": [3768.558], "images_per_second": 0.265, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 12, "output_text": "A group of people are seen loading luggage into a white SUV at an airport.", "error": null, "sys_before": {"cpu_percent": 23.0, "ram_used_mb": 18616.0, "ram_available_mb": 44224.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.196, "power_cpu_cv_mean_watts": 0.995, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 90.161}, "timestamp": "2026-01-30T21:24:07.544589"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4737.26, "latencies_ms": [4737.26], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Car\n2. Car\n3. Car\n4. Car\n5. Car\n6. Car\n7. Car\n8. Car", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18615.4, "ram_available_mb": 44225.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.921, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 89.128}, "timestamp": "2026-01-30T21:24:14.308764"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7028.959, "latencies_ms": [7028.959], "images_per_second": 0.142, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 12, "output_text": "In the image, the main objects are a luggage cart, a man, and a white SUV. The luggage cart is positioned near the foreground, with its handle and wheels visible. The man is standing to the right of the luggage cart, facing the SUV. The white SUV is parked in the background, slightly to the right of the man.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18615.0, "ram_available_mb": 44225.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.299, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 85.373}, "timestamp": "2026-01-30T21:24:23.370306"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7463.441, "latencies_ms": [7463.441], "images_per_second": 0.134, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The image depicts a scene inside a car dealership, likely a parking lot or garage, where a group of people is gathered around a white SUV. The individuals appear to be engaged in a discussion or transaction, with one person handling luggage and another assisting. The setting is indoors, with a high ceiling and artificial lighting, and there are various signs and advertisements visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18614.8, "ram_available_mb": 44226.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18614.2, "ram_available_mb": 44226.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.031, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 84.823}, "timestamp": "2026-01-30T21:24:32.846350"}
{"image_index": 99, "image_name": "000000009891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009891.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6304.589, "latencies_ms": [6304.589], "images_per_second": 0.159, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a scene inside a car dealership, with a white SUV parked in the background. The lighting is bright, illuminating the interior and the vehicles. The materials used in the scene include metal for the car and luggage, and the flooring appears to be made of concrete.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18614.2, "ram_available_mb": 44226.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18613.3, "ram_available_mb": 44227.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.634, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 85.846}, "timestamp": "2026-01-30T21:24:41.168193"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4851.001, "latencies_ms": [4851.001], "images_per_second": 0.206, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image shows a plate of food consisting of a grilled chicken sandwich with sesame seeds on top, accompanied by a side of French fries and a small bowl of sauce.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 18613.3, "ram_available_mb": 44227.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18613.8, "ram_available_mb": 44227.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.836, "power_cpu_cv_mean_watts": 1.271, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 87.4}, "timestamp": "2026-01-30T21:24:48.160821"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5500.238, "latencies_ms": [5500.238], "images_per_second": 0.182, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 12, "output_text": "1. Bun\n2. Potato chips\n3. Cheese\n4. Sausage\n5. Sausage\n6. Sausage\n7. Sausage\n8. Sausage", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18613.8, "ram_available_mb": 44227.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18612.9, "ram_available_mb": 44228.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.249, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 87.609}, "timestamp": "2026-01-30T21:24:55.703500"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7288.024, "latencies_ms": [7288.024], "images_per_second": 0.137, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The main objects in the image are a hamburger and a side of fries. The hamburger is positioned in the foreground, with a sesame seed bun and a grilled patty. The fries are in the background, slightly out of focus. The hamburger is placed on a white plate, and there is a small blue bowl containing a sauce next to it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18612.9, "ram_available_mb": 44228.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18612.8, "ram_available_mb": 44228.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.097, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 84.672}, "timestamp": "2026-01-30T21:25:05.017422"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5884.639, "latencies_ms": [5884.639], "images_per_second": 0.17, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The image depicts a plate of food, specifically a hamburger and fries, accompanied by a side of ketchup. The setting appears to be a casual dining environment, possibly a fast-food restaurant, with a focus on the food items.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18612.8, "ram_available_mb": 44228.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18612.8, "ram_available_mb": 44228.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.966, "power_cpu_cv_mean_watts": 1.496, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 86.694}, "timestamp": "2026-01-30T21:25:12.960015"}
{"image_index": 100, "image_name": "000000009914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000009914.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6548.518, "latencies_ms": [6548.518], "images_per_second": 0.153, "prompt_tokens": 22, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The image features a plate of food, including a grilled chicken sandwich with sesame seeds on the bun, a side of fries, and a small bowl of sauce. The lighting is bright, and the colors are vibrant, with the golden-brown fries contrasting against the white plate and the dark sauce.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18612.8, "ram_available_mb": 44228.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18613.0, "ram_available_mb": 44227.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.489, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 86.073}, "timestamp": "2026-01-30T21:25:21.569569"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4145.166, "latencies_ms": [4145.166], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a cozy, well-lit room with a large bed covered in a green mosquito net, a small wooden table with a candle, and a wooden chair, all set against a backdrop of yellow walls and large windows with curtains.", "error": null, "sys_before": {"cpu_percent": 26.2, "ram_used_mb": 18613.0, "ram_available_mb": 44227.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18613.5, "ram_available_mb": 44227.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.186, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 71.314}, "timestamp": "2026-01-30T21:25:27.850812"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3795.198, "latencies_ms": [3795.198], "images_per_second": 0.263, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 6, "output_text": "bed: 1\ntable: 1\nchair: 1\ntable lamp: 1\nwindow: 2\ncurtain: 2\nwall art: 2\nfloor lamp: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18613.5, "ram_available_mb": 44227.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18614.3, "ram_available_mb": 44226.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.754, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 71.844}, "timestamp": "2026-01-30T21:25:33.663534"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6322.534, "latencies_ms": [6322.534], "images_per_second": 0.158, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 6, "output_text": "The main object in the foreground is a bed with a green canopy, which is positioned near the center of the image. The bed is surrounded by a wooden frame and is partially covered by a green sheet. In the background, there is a wooden table with a lamp on it, and a framed picture hangs on the wall. The room has a tiled floor and large windows with curtains, allowing natural light to enter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.3, "ram_available_mb": 44226.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.818, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 68.698}, "timestamp": "2026-01-30T21:25:42.005534"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4999.53, "latencies_ms": [4999.53], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a cozy, well-lit room with a large bed covered by a green mosquito net. The room features wooden furniture, including a table and chairs, and is decorated with paintings and curtains. The setting appears to be a bedroom or a guest room, with natural light streaming in through large windows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.495, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T21:25:49.022344"}
{"image_index": 101, "image_name": "000000010092.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010092.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3796.914, "latencies_ms": [3796.914], "images_per_second": 0.263, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The room is brightly lit with natural light streaming through large windows adorned with sheer curtains. The walls are painted in a warm, earthy tone, complemented by wooden furniture and a green canopy bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18614.5, "ram_available_mb": 44226.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18614.2, "ram_available_mb": 44226.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.908, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 71.968}, "timestamp": "2026-01-30T21:25:54.840909"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1823.293, "latencies_ms": [1823.293], "images_per_second": 0.548, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 2, "output_text": "A gray and white cat is perched on the hood of a black car, seemingly curious about the surroundings.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 18614.2, "ram_available_mb": 44226.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18613.3, "ram_available_mb": 44227.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.474, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 6.999, "gpu_utilization_percent_mean": 66.286}, "timestamp": "2026-01-30T21:25:58.720412"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2582.295, "latencies_ms": [2582.295], "images_per_second": 0.387, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 2, "output_text": "1. Cat\n2. Car\n3. Lamp\n4. Floor\n5. Floor mat\n6. Floor lamp\n7. Table\n8. Table lamp", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18613.3, "ram_available_mb": 44227.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18613.2, "ram_available_mb": 44227.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.598, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 7.197, "gpu_utilization_percent_mean": 63.8}, "timestamp": "2026-01-30T21:26:03.330059"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6404.711, "latencies_ms": [6404.711], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 98, "n_tiles": 2, "output_text": "In the image, there is a black car parked in the foreground, with a cat standing on its roof. The cat is positioned near the front of the car, near the windshield. In the background, there is a cluttered kitchen counter with various items, including a lamp, a box, and a bicycle. The kitchen counter is situated near the car, creating a spatial relationship where the car is the main focus in the foreground, while the kitchen counter is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18613.2, "ram_available_mb": 44227.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18613.5, "ram_available_mb": 44227.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.573, "power_cpu_cv_mean_watts": 2.173, "power_sys_5v0_mean_watts": 7.353, "gpu_utilization_percent_mean": 62.5}, "timestamp": "2026-01-30T21:26:11.754697"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2930.732, "latencies_ms": [2930.732], "images_per_second": 0.341, "prompt_tokens": 24, "response_tokens_est": 41, "n_tiles": 2, "output_text": "The image depicts a cozy, cluttered kitchen with various items on the countertops and shelves. A tabby cat is perched on the hood of a black car, looking around with curiosity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18613.5, "ram_available_mb": 44227.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18612.8, "ram_available_mb": 44228.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.333, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 7.186, "gpu_utilization_percent_mean": 65.0}, "timestamp": "2026-01-30T21:26:16.731861"}
{"image_index": 102, "image_name": "000000010363.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010363.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3311.38, "latencies_ms": [3311.38], "images_per_second": 0.302, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 2, "output_text": "The image features a black car with a reflective surface, and a gray and white striped cat is perched on the roof. The lighting is bright, and the scene appears to be indoors, possibly in a garage or workshop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.8, "ram_available_mb": 44228.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.202, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 7.304, "gpu_utilization_percent_mean": 63.5}, "timestamp": "2026-01-30T21:26:22.057375"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3010.494, "latencies_ms": [3010.494], "images_per_second": 0.332, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The image shows a plate of food, which includes a hearty meat dish topped with a layer of mashed potatoes and a generous amount of gravy, garnished with chopped herbs and a slice of roasted tomato.", "error": null, "sys_before": {"cpu_percent": 20.3, "ram_used_mb": 18611.6, "ram_available_mb": 44229.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.502, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 7.003, "gpu_utilization_percent_mean": 68.36}, "timestamp": "2026-01-30T21:26:27.136214"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8240.782, "latencies_ms": [8240.782], "images_per_second": 0.121, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 1, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.81, "power_cpu_cv_mean_watts": 2.222, "power_sys_5v0_mean_watts": 7.222, "gpu_utilization_percent_mean": 64.986}, "timestamp": "2026-01-30T21:26:37.423002"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4958.974, "latencies_ms": [4958.974], "images_per_second": 0.202, "prompt_tokens": 30, "response_tokens_est": 75, "n_tiles": 1, "output_text": "The main object in the foreground is a plate of food, which includes a beef dish topped with a creamy sauce and garnished with herbs. The plate is placed on a metal table, and there is a small portion of food in the background on a different plate. The background plate is partially visible, and there is a utensil on the table near the plate.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.681, "power_cpu_cv_mean_watts": 2.119, "power_sys_5v0_mean_watts": 7.139, "gpu_utilization_percent_mean": 65.78}, "timestamp": "2026-01-30T21:26:44.396196"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4988.574, "latencies_ms": [4988.574], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 1, "output_text": "The image depicts a plate of food, specifically a savory dish consisting of a meatloaf topped with a layer of mashed potatoes and a generous amount of gravy. The plate is placed on a metal table, and there is a side of fries visible in the background. The setting appears to be a casual dining environment, possibly a restaurant or a home kitchen.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.786, "power_cpu_cv_mean_watts": 2.126, "power_sys_5v0_mean_watts": 7.149, "gpu_utilization_percent_mean": 65.548}, "timestamp": "2026-01-30T21:26:51.402871"}
{"image_index": 103, "image_name": "000000010583.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010583.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2352.856, "latencies_ms": [2352.856], "images_per_second": 0.425, "prompt_tokens": 22, "response_tokens_est": 33, "n_tiles": 1, "output_text": "The plate is white, with a dark brown sauce and a golden-brown meat topping. The lighting is bright, highlighting the textures and colors of the food.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.2, "ram_available_mb": 44228.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18611.5, "ram_available_mb": 44229.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.57, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 6.886, "gpu_utilization_percent_mean": 69.368}, "timestamp": "2026-01-30T21:26:55.786927"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5313.594, "latencies_ms": [5313.594], "images_per_second": 0.188, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image depicts a group of people gathered around a table in a cozy living room, with a man in a white t-shirt holding a controller and another man in a blue t-shirt playing a video game.", "error": null, "sys_before": {"cpu_percent": 33.5, "ram_used_mb": 18611.5, "ram_available_mb": 44229.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.463, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 85.956}, "timestamp": "2026-01-30T21:27:03.276876"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4845.356, "latencies_ms": [4845.356], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Couch\n2. Table\n3. People\n4. Laptop\n5. Bottle\n6. Beverage\n7. Bottle\n8. Beverage", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.838, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.774, "gpu_utilization_percent_mean": 88.65}, "timestamp": "2026-01-30T21:27:10.163787"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7339.65, "latencies_ms": [7339.65], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The main objects in the image are a group of people and various items on a table. The people are seated on a couch, with one person holding a bottle. The table is located in the foreground, with various items such as cans, a remote control, and a bottle of beer. The couch is in the background, and there is a red cushion on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.175, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 84.705}, "timestamp": "2026-01-30T21:27:19.517021"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6540.973, "latencies_ms": [6540.973], "images_per_second": 0.153, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The image depicts a cozy living room scene with a group of people gathered around a table. The room is warmly lit, and there is a red couch and a red cushion visible in the background. The group appears to be engaged in a casual, social gathering, possibly enjoying drinks and snacks together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.546, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 85.691}, "timestamp": "2026-01-30T21:27:28.072435"}
{"image_index": 104, "image_name": "000000010707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010707.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5874.424, "latencies_ms": [5874.424], "images_per_second": 0.17, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The image depicts a cozy living room with warm lighting, primarily from a lamp on the right side. The room is filled with various items such as a red couch, a pink table, and a red cushion, creating a vibrant and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18611.9, "ram_available_mb": 44229.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.946, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 86.918}, "timestamp": "2026-01-30T21:27:35.988872"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2180.818, "latencies_ms": [2180.818], "images_per_second": 0.459, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 6, "output_text": "A baseball player is crouched on the field, ready to catch a ball.", "error": null, "sys_before": {"cpu_percent": 29.3, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18612.1, "ram_available_mb": 44228.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.166, "power_cpu_cv_mean_watts": 1.113, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 78.333}, "timestamp": "2026-01-30T21:27:40.293476"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4672.779, "latencies_ms": [4672.779], "images_per_second": 0.214, "prompt_tokens": 26, "response_tokens_est": 58, "n_tiles": 6, "output_text": "baseball player: 1\ncatcher's gear: 1\nbaseball bat: 1\nbaseball glove: 1\nbaseball uniform: 1\nbaseball helmet: 1\nbaseball cleats: 1\nbaseball bat: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.1, "ram_available_mb": 44228.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.658, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 70.718}, "timestamp": "2026-01-30T21:27:46.994301"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4709.308, "latencies_ms": [4709.308], "images_per_second": 0.212, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The main object in the foreground is a baseball player crouched near the home plate. The player is wearing a black and white uniform, and his gloves are positioned near his hands. The background features a well-maintained green field, with a white chalk line marking the home plate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.808, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 70.225}, "timestamp": "2026-01-30T21:27:53.753477"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6137.923, "latencies_ms": [6137.923], "images_per_second": 0.163, "prompt_tokens": 24, "response_tokens_est": 83, "n_tiles": 6, "output_text": "The image captures a baseball player in a white and black uniform crouched on the dirt infield of a baseball field. The player is wearing a protective helmet, gloves, and cleats, indicating that he is either preparing to catch a ball or has just completed a play. The field is well-maintained with white lines marking the bases, and the grass surrounding the infield is lush and green.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.803, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 69.431}, "timestamp": "2026-01-30T21:28:01.914079"}
{"image_index": 105, "image_name": "000000010764.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010764.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4264.832, "latencies_ms": [4264.832], "images_per_second": 0.234, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The baseball player is wearing a black and white uniform, complete with a helmet, chest protector, and batting gloves. The field is well-maintained with white chalk lines marking the playing area, and the lighting suggests it is daytime with clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.487, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 71.171}, "timestamp": "2026-01-30T21:28:08.196189"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5257.995, "latencies_ms": [5257.995], "images_per_second": 0.19, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image shows a bathroom with a wooden vanity, a white toilet, a pink tiled wall, a white towel hanging on the wall, a glass shower door, and a green mat on the floor.", "error": null, "sys_before": {"cpu_percent": 32.5, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.4, "power_cpu_cv_mean_watts": 1.374, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 86.636}, "timestamp": "2026-01-30T21:28:15.621147"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5207.913, "latencies_ms": [5207.913], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.4, "ram_available_mb": 44228.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18612.3, "ram_available_mb": 44228.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.42, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 87.795}, "timestamp": "2026-01-30T21:28:22.871340"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6480.5, "latencies_ms": [6480.5], "images_per_second": 0.154, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The main objects in the image are a toilet and a bathtub. The toilet is located in the foreground, while the bathtub is situated in the background. The bathtub is partially visible through a glass door, and the toilet is positioned to the right of the bathtub.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18612.3, "ram_available_mb": 44228.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.475, "power_cpu_cv_mean_watts": 1.587, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 85.836}, "timestamp": "2026-01-30T21:28:31.379185"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4678.978, "latencies_ms": [4678.978], "images_per_second": 0.214, "prompt_tokens": 24, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The image shows a bathroom with a wooden vanity and a white toilet. The room is well-lit, and there is a shower door partially open.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18611.7, "ram_available_mb": 44229.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18611.8, "ram_available_mb": 44229.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.898, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.774, "gpu_utilization_percent_mean": 89.0}, "timestamp": "2026-01-30T21:28:38.112022"}
{"image_index": 106, "image_name": "000000010977.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010977.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6104.853, "latencies_ms": [6104.853], "images_per_second": 0.164, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The bathroom features a pinkish-purple tiled wall, a white bathtub, a wooden vanity with a white sink, a white toilet, and a white towel hanging on the wall. The lighting is bright, and the overall color scheme is warm and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.8, "ram_available_mb": 44229.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.776, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 86.392}, "timestamp": "2026-01-30T21:28:46.248209"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4028.447, "latencies_ms": [4028.447], "images_per_second": 0.248, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "The image shows a room with a window, a bed with a plaid bedspread, and curtains.", "error": null, "sys_before": {"cpu_percent": 26.2, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18611.3, "ram_available_mb": 44229.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.144, "power_cpu_cv_mean_watts": 1.08, "power_sys_5v0_mean_watts": 8.873, "gpu_utilization_percent_mean": 90.091}, "timestamp": "2026-01-30T21:28:52.409825"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4448.145, "latencies_ms": [4448.145], "images_per_second": 0.225, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 12, "output_text": "bed: 1\ncurtain: 1\nlamp: 1\nwindow: 1\nwall: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18610.7, "ram_available_mb": 44230.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.26, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 87.784}, "timestamp": "2026-01-30T21:28:58.904403"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6972.087, "latencies_ms": [6972.087], "images_per_second": 0.143, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image shows a room with a window on the left side, through which daylight is entering. The window is framed by a dark curtain. The main focus of the image is a plaid bed with a yellow and green pattern, positioned in the foreground. The bed is positioned near the window, allowing natural light to illuminate the room.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.238, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 85.288}, "timestamp": "2026-01-30T21:29:07.900269"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6234.774, "latencies_ms": [6234.774], "images_per_second": 0.16, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The image depicts a dimly lit bedroom with a single bed in the center. The bed is covered with a plaid bedspread, and the room is illuminated by a small window with curtains. The overall scene suggests a quiet, possibly early morning or late evening setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.612, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 85.623}, "timestamp": "2026-01-30T21:29:16.172844"}
{"image_index": 107, "image_name": "000000010995.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000010995.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5692.929, "latencies_ms": [5692.929], "images_per_second": 0.176, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The image shows a plaid bedspread with a yellow and green color scheme, set against a dark wall. The room is dimly lit, with a single light source coming from a window, casting a soft glow on the bed.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.976, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 86.833}, "timestamp": "2026-01-30T21:29:23.880079"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5103.283, "latencies_ms": [5103.283], "images_per_second": 0.196, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 12, "output_text": "A young couple is posing for a photo at a formal event, with the man in a black suit and the woman in a black dress with a sparkling top and a beige belt.", "error": null, "sys_before": {"cpu_percent": 25.8, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.447, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 86.674}, "timestamp": "2026-01-30T21:29:31.157844"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4851.923, "latencies_ms": [4851.923], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Woman\n2. Man\n3. Rose\n4. Necklace\n5. Dress\n6. Bangle\n7. Ring\n8. Background", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18609.9, "ram_available_mb": 44231.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.728, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 88.049}, "timestamp": "2026-01-30T21:29:38.030722"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5801.686, "latencies_ms": [5801.686], "images_per_second": 0.172, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The main objects in the image are a man and a woman. The man is in the foreground, while the woman is slightly behind him. The man is holding a rose, and the woman is wearing a black dress with a light-colored belt.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18609.9, "ram_available_mb": 44231.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18609.8, "ram_available_mb": 44231.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.973, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 87.224}, "timestamp": "2026-01-30T21:29:45.867362"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8064.254, "latencies_ms": [8064.254], "images_per_second": 0.124, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 12, "output_text": "The image depicts a young couple dressed in formal attire, likely at a wedding or a similar event. The man is wearing a black suit and tie, while the woman is dressed in a black dress with a sequined top and a beige belt. They are both smiling and appear to be enjoying the moment, with the man holding a white rose. The background is softly lit, suggesting an indoor setting with warm lighting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18609.8, "ram_available_mb": 44231.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18609.8, "ram_available_mb": 44231.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.68, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 8.844, "gpu_utilization_percent_mean": 83.696}, "timestamp": "2026-01-30T21:29:55.951256"}
{"image_index": 108, "image_name": "000000011051.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011051.jpg", "image_width": 640, "image_height": 536, "image_resolution": "640x536", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6182.115, "latencies_ms": [6182.115], "images_per_second": 0.162, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image features a young woman with dark hair styled in a bun, wearing a black dress with a sequined top and a beige belt. The lighting is warm, casting a soft glow on her face, and the background is neutral, ensuring the focus remains on her.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18609.8, "ram_available_mb": 44231.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18610.1, "ram_available_mb": 44230.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.637, "power_cpu_cv_mean_watts": 1.54, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 86.135}, "timestamp": "2026-01-30T21:30:04.170941"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5079.796, "latencies_ms": [5079.796], "images_per_second": 0.197, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image shows a chain-link fence enclosing a grassy area with a stop sign attached to it, and behind the fence, there are palm trees and a building with balconies.", "error": null, "sys_before": {"cpu_percent": 29.5, "ram_used_mb": 18610.0, "ram_available_mb": 44230.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.533, "power_cpu_cv_mean_watts": 1.344, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 86.881}, "timestamp": "2026-01-30T21:30:11.428786"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5658.075, "latencies_ms": [5658.075], "images_per_second": 0.177, "prompt_tokens": 26, "response_tokens_est": 47, "n_tiles": 12, "output_text": "- Stop sign: 1\n- Fence: 1\n- Bushes: 1\n- Greenery: 1\n- House: 1\n- Palm trees: 1\n- Building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18611.0, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18610.9, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.029, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 86.532}, "timestamp": "2026-01-30T21:30:19.148091"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7101.032, "latencies_ms": [7101.032], "images_per_second": 0.141, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main objects in the image are a chain-link fence, a stop sign, and a bush. The stop sign is positioned in the foreground, near the bottom of the image, while the bush is located to the right of the fence. The background features a building and palm trees, indicating that the scene is set in an urban or suburban area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18610.9, "ram_available_mb": 44229.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.278, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 85.305}, "timestamp": "2026-01-30T21:30:28.288856"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8014.986, "latencies_ms": [8014.986], "images_per_second": 0.125, "prompt_tokens": 24, "response_tokens_est": 86, "n_tiles": 12, "output_text": "The image depicts a scene of an outdoor area with a chain-link fence in the foreground. The fence is enclosing a grassy area with a few scattered objects, including a blue plastic bag and a white plastic bottle. Beyond the fence, there are palm trees and a building with balconies, suggesting a residential or commercial area. The setting appears to be a park or a public space with some litter and debris visible.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18610.6, "ram_available_mb": 44230.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18610.4, "ram_available_mb": 44230.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.766, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 84.103}, "timestamp": "2026-01-30T21:30:38.321469"}
{"image_index": 109, "image_name": "000000011122.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011122.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5999.226, "latencies_ms": [5999.226], "images_per_second": 0.167, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image shows a chain-link fence with a red stop sign attached to it. The stop sign is prominently displayed in the foreground, surrounded by a green metal fence. The lighting is bright, indicating it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.4, "ram_available_mb": 44230.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18611.1, "ram_available_mb": 44229.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.819, "power_cpu_cv_mean_watts": 1.539, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 86.098}, "timestamp": "2026-01-30T21:30:46.365175"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4743.734, "latencies_ms": [4743.734], "images_per_second": 0.211, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 12, "output_text": "A man wearing a gray t-shirt and brown shorts is standing next to a bicycle with a basket, while another man in a black jacket is riding a motorcycle.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.004, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 87.897}, "timestamp": "2026-01-30T21:30:53.244841"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5212.33, "latencies_ms": [5212.33], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "1. Bicycle\n2. Helmet\n3. Bicycle\n4. Bicycle\n5. Bicycle\n6. Bicycle\n7. Bicycle\n8. Bicycle", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18610.8, "ram_available_mb": 44230.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18612.3, "ram_available_mb": 44228.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.41, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 87.341}, "timestamp": "2026-01-30T21:31:00.485520"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6262.24, "latencies_ms": [6262.24], "images_per_second": 0.16, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The main objects in the image are a motorcycle and a bicycle. The motorcycle is positioned in the foreground, while the bicycle is in the background. The bicycle is parked near the motorcycle, indicating a spatial relationship where the motorcycle is closer to the foreground and the bicycle is further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18612.3, "ram_available_mb": 44228.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18614.0, "ram_available_mb": 44226.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.722, "power_cpu_cv_mean_watts": 1.54, "power_sys_5v0_mean_watts": 8.846, "gpu_utilization_percent_mean": 86.115}, "timestamp": "2026-01-30T21:31:08.780085"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6581.297, "latencies_ms": [6581.297], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The scene depicts a serene outdoor setting with a man standing beside a bicycle, which is parked on a paved path surrounded by lush greenery. The man is wearing a light-colored t-shirt, dark shorts, and sneakers, and appears to be engaged in conversation or simply observing the surroundings.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18614.0, "ram_available_mb": 44226.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 10.0, "ram_used_mb": 18618.5, "ram_available_mb": 44222.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.445, "power_cpu_cv_mean_watts": 1.915, "power_sys_5v0_mean_watts": 8.868, "gpu_utilization_percent_mean": 85.473}, "timestamp": "2026-01-30T21:31:17.398665"}
{"image_index": 110, "image_name": "000000011149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011149.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5083.636, "latencies_ms": [5083.636], "images_per_second": 0.197, "prompt_tokens": 22, "response_tokens_est": 37, "n_tiles": 12, "output_text": "The image features a person wearing a black jacket and a helmet, standing next to a yellow bicycle. The scene is well-lit with natural sunlight, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 12.1, "ram_used_mb": 18618.5, "ram_available_mb": 44222.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 12.9, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.506, "power_cpu_cv_mean_watts": 2.508, "power_sys_5v0_mean_watts": 8.936, "gpu_utilization_percent_mean": 88.69}, "timestamp": "2026-01-30T21:31:24.555037"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2849.825, "latencies_ms": [2849.825], "images_per_second": 0.351, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "A man in a blue shirt is standing on a sidewalk next to a black street lamp, while a red car is driving on the street.", "error": null, "sys_before": {"cpu_percent": 40.9, "ram_used_mb": 18618.7, "ram_available_mb": 44222.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 12.6, "ram_used_mb": 18619.1, "ram_available_mb": 44221.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.581, "power_cpu_cv_mean_watts": 2.653, "power_sys_5v0_mean_watts": 8.244, "gpu_utilization_percent_mean": 75.375}, "timestamp": "2026-01-30T21:31:29.540578"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5650.444, "latencies_ms": [5650.444], "images_per_second": 0.177, "prompt_tokens": 26, "response_tokens_est": 74, "n_tiles": 6, "output_text": "- Pedestrian: 1\n- Car: 1\n- Street light: 1\n- Building: 1\n- Traffic sign: 2\n- Street sign: 2\n- Bicycle: 1\n- Person: 1\n- Street: 1\n- Car: 1\n- Pedestrian: 1", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18619.1, "ram_available_mb": 44221.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 14.1, "ram_used_mb": 18619.6, "ram_available_mb": 44221.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.034, "power_cpu_cv_mean_watts": 2.871, "power_sys_5v0_mean_watts": 8.202, "gpu_utilization_percent_mean": 68.667}, "timestamp": "2026-01-30T21:31:37.236180"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4756.609, "latencies_ms": [4756.609], "images_per_second": 0.21, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The main objects in the image are a black street lamp, a red car, and a person standing near the sidewalk. The street lamp is positioned in the foreground, while the red car is in the background. The person is standing near the sidewalk, which is located in the middle ground.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18619.6, "ram_available_mb": 44221.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 13.9, "ram_used_mb": 18619.9, "ram_available_mb": 44221.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.648, "power_cpu_cv_mean_watts": 2.814, "power_sys_5v0_mean_watts": 8.179, "gpu_utilization_percent_mean": 70.3}, "timestamp": "2026-01-30T21:31:44.025869"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5999.483, "latencies_ms": [5999.483], "images_per_second": 0.167, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image depicts an urban street scene with a pedestrian crossing sign and a traffic light in the foreground. A man in a blue shirt is standing near the crossing sign, while a woman in a gray top is walking on the sidewalk. The street is lined with buildings, trees, and a red car is visible in the background. The setting appears to be a city street during the daytime.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18619.9, "ram_available_mb": 44221.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 14.6, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.67, "power_cpu_cv_mean_watts": 2.883, "power_sys_5v0_mean_watts": 8.198, "gpu_utilization_percent_mean": 68.137}, "timestamp": "2026-01-30T21:31:52.045441"}
{"image_index": 111, "image_name": "000000011197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011197.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4778.872, "latencies_ms": [4778.872], "images_per_second": 0.209, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image depicts a city street scene with a mix of urban and natural elements. The street is paved with red bricks, and there is a black metal lamppost in the foreground. The lighting is natural, likely from the overcast sky, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18619.5, "ram_available_mb": 44221.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 9.1, "ram_used_mb": 18627.0, "ram_available_mb": 44213.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.761, "power_cpu_cv_mean_watts": 2.574, "power_sys_5v0_mean_watts": 8.139, "gpu_utilization_percent_mean": 70.275}, "timestamp": "2026-01-30T21:31:58.839601"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4155.123, "latencies_ms": [4155.123], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "The image shows a bronze statue of two women sitting on a bench, with one of them holding a bag.", "error": null, "sys_before": {"cpu_percent": 37.7, "ram_used_mb": 18627.0, "ram_available_mb": 44213.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18626.8, "ram_available_mb": 44214.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.581, "power_cpu_cv_mean_watts": 1.084, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 89.588}, "timestamp": "2026-01-30T21:32:05.161241"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4873.081, "latencies_ms": [4873.081], "images_per_second": 0.205, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Statue\n2. Woman\n3. Man\n4. Woman\n5. Woman\n6. Woman\n7. Woman\n8. Statue", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.8, "ram_available_mb": 44214.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18626.7, "ram_available_mb": 44214.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.705, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.777, "gpu_utilization_percent_mean": 88.7}, "timestamp": "2026-01-30T21:32:12.073935"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7533.945, "latencies_ms": [7533.945], "images_per_second": 0.133, "prompt_tokens": 30, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The main object in the foreground is a bronze statue of a woman sitting on a bench. The statue is positioned near the center of the image, with a concrete bench and a metal trash can nearby. In the background, there are other people standing and a closed garage door. The statue is the focal point of the image, with the people and the garage door providing context and depth.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18626.7, "ram_available_mb": 44214.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18627.0, "ram_available_mb": 44213.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.016, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 84.762}, "timestamp": "2026-01-30T21:32:21.637291"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7458.213, "latencies_ms": [7458.213], "images_per_second": 0.134, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The image depicts a scene in an outdoor urban setting, possibly a public square or plaza, with a large, weathered bronze statue of two women seated on a bench. The ground is paved with bricks, and there is a metal trash can nearby. The lighting suggests it is daytime, and the shadows indicate the sun is shining from the right side of the frame.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18627.0, "ram_available_mb": 44213.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18627.1, "ram_available_mb": 44213.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.057, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 84.548}, "timestamp": "2026-01-30T21:32:31.117122"}
{"image_index": 112, "image_name": "000000011511.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011511.jpg", "image_width": 640, "image_height": 464, "image_resolution": "640x464", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5404.6, "latencies_ms": [5404.6], "images_per_second": 0.185, "prompt_tokens": 22, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The bronze statue of two women is notable for its weathered appearance, with visible signs of wear and tear. The lighting in the image is natural, casting shadows on the ground, indicating that it is daytime.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18627.1, "ram_available_mb": 44213.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.252, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 87.622}, "timestamp": "2026-01-30T21:32:38.553598"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5379.883, "latencies_ms": [5379.883], "images_per_second": 0.186, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image shows a set of road signs, including a blue directional arrow indicating a left turn, a yellow bus icon, and a green directional arrow indicating a right turn, all mounted on a metal pole.", "error": null, "sys_before": {"cpu_percent": 31.4, "ram_used_mb": 18626.7, "ram_available_mb": 44214.2, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18627.1, "ram_available_mb": 44213.8, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.296, "power_cpu_cv_mean_watts": 1.424, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 85.444}, "timestamp": "2026-01-30T21:32:46.126893"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6082.239, "latencies_ms": [6082.239], "images_per_second": 0.164, "prompt_tokens": 26, "response_tokens_est": 54, "n_tiles": 12, "output_text": "- Airplane: 1\n- Bus: 1\n- Car: 1\n- Parking sign: 1\n- Traffic sign: 1\n- Traffic light: 1\n- Road sign: 1\n- Street sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18627.1, "ram_available_mb": 44213.8, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18626.8, "ram_available_mb": 44214.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.716, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 85.784}, "timestamp": "2026-01-30T21:32:54.269916"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8551.995, "latencies_ms": [8551.995], "images_per_second": 0.117, "prompt_tokens": 30, "response_tokens_est": 92, "n_tiles": 12, "output_text": "The main objects in the image are a series of road signs. The signs are arranged in a way that the \"P\" sign is positioned in the foreground, while the \"Im Sional\" sign is in the background. The \"Im Sional\" sign is closer to the camera, making it appear larger and more prominent. The \"P\" sign is positioned near the \"Im Sional\" sign, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.8, "ram_available_mb": 44214.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18626.8, "ram_available_mb": 44214.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.658, "power_cpu_cv_mean_watts": 1.769, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 83.625}, "timestamp": "2026-01-30T21:33:04.839870"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5889.023, "latencies_ms": [5889.023], "images_per_second": 0.17, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The image depicts a collection of road signs, including directional arrows and parking signs, against a backdrop of trees and a cloudy sky. The signs are mounted on a pole and are in various colors and shapes, indicating different directions and destinations.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.8, "ram_available_mb": 44214.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18626.8, "ram_available_mb": 44214.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.826, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 86.776}, "timestamp": "2026-01-30T21:33:12.769246"}
{"image_index": 113, "image_name": "000000011615.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011615.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8474.856, "latencies_ms": [8474.856], "images_per_second": 0.118, "prompt_tokens": 22, "response_tokens_est": 94, "n_tiles": 12, "output_text": "The image features a collection of road signs, including a blue and white sign with an airplane icon, a green and white sign with a bus icon, and a white sign with a parking sign. The signs are mounted on a brown pole and are illuminated by natural daylight, suggesting a clear and sunny day. The colors are vibrant, with the blue and white sign contrasting against the green and white sign, and the white sign standing out against the brown pole.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.8, "ram_available_mb": 44214.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18626.7, "ram_available_mb": 44214.2, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.753, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.85, "gpu_utilization_percent_mean": 84.0}, "timestamp": "2026-01-30T21:33:23.257770"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3958.693, "latencies_ms": [3958.693], "images_per_second": 0.253, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 12, "output_text": "A woman and a young girl are standing next to a suitcase, both wearing backpacks.", "error": null, "sys_before": {"cpu_percent": 25.5, "ram_used_mb": 18626.2, "ram_available_mb": 44214.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.882, "power_cpu_cv_mean_watts": 1.007, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 89.939}, "timestamp": "2026-01-30T21:33:29.360052"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4864.889, "latencies_ms": [4864.889], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 12, "output_text": "1. Woman\n2. Girl\n3. Bag\n4. Suitcase\n5. Bag\n6. Woman\n7. Bag\n8. Bag", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18627.2, "ram_available_mb": 44213.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.768, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 88.525}, "timestamp": "2026-01-30T21:33:36.257060"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8821.886, "latencies_ms": [8821.886], "images_per_second": 0.113, "prompt_tokens": 30, "response_tokens_est": 99, "n_tiles": 12, "output_text": "The main objects in the image are a woman and a young girl standing next to a suitcase. The woman is wearing a red shirt and has a black backpack, while the girl is wearing a light blue shirt and has a colorful backpack. The suitcase is positioned in the foreground, with the woman and girl standing near it. The background features a platform with a yellow tactile paving strip, and there is a man in a white shirt and a colorful bag visible in the background.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18627.2, "ram_available_mb": 44213.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18627.2, "ram_available_mb": 44213.7, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.522, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 8.848, "gpu_utilization_percent_mean": 83.392}, "timestamp": "2026-01-30T21:33:47.115900"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 9047.345, "latencies_ms": [9047.345], "images_per_second": 0.111, "prompt_tokens": 24, "response_tokens_est": 103, "n_tiles": 12, "output_text": "The image depicts a scene inside a subway station, where a woman and a young girl are standing next to a black suitcase. The woman is wearing a red shirt and has a black shoulder bag, while the girl is dressed in a light blue shirt and has a colorful backpack. They appear to be waiting for their train, with the woman holding a ticket and the girl making a peace sign with her hand. The setting is a modern subway station with a yellow tactile paving strip on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18627.2, "ram_available_mb": 44213.7, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18626.5, "ram_available_mb": 44214.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.469, "power_cpu_cv_mean_watts": 1.786, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 83.368}, "timestamp": "2026-01-30T21:33:58.202295"}
{"image_index": 114, "image_name": "000000011699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011699.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7182.961, "latencies_ms": [7182.961], "images_per_second": 0.139, "prompt_tokens": 22, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The image features a woman and a young girl standing next to a black suitcase. The woman is wearing a red shirt, and the girl is dressed in a light blue shirt. The scene is well-lit, with natural light illuminating the surroundings. The suitcase is made of black material, and the ground is covered with yellow tactile paving.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.5, "ram_available_mb": 44214.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18626.4, "ram_available_mb": 44214.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.251, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.855, "gpu_utilization_percent_mean": 85.098}, "timestamp": "2026-01-30T21:34:07.430858"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2991.077, "latencies_ms": [2991.077], "images_per_second": 0.334, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The image depicts a zebra standing in a natural environment with trees and bushes in the background, showcasing its distinctive black and white stripes.", "error": null, "sys_before": {"cpu_percent": 27.2, "ram_used_mb": 18626.4, "ram_available_mb": 44214.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18626.4, "ram_available_mb": 44214.5, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.141, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 74.92}, "timestamp": "2026-01-30T21:34:12.547163"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2785.172, "latencies_ms": [2785.172], "images_per_second": 0.359, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 6, "output_text": "zebra: 2\ntree: 1\nbush: 1\nlog: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18626.4, "ram_available_mb": 44214.5, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.36, "power_cpu_cv_mean_watts": 1.288, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T21:34:17.389732"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4932.422, "latencies_ms": [4932.422], "images_per_second": 0.203, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The main objects in the image are two zebras. The foreground features a zebra with a prominent black and white striped pattern, while the background shows another zebra with a similar pattern. The zebra in the foreground is closer to the camera, while the one in the background is further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.0, "ram_available_mb": 44214.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18626.6, "ram_available_mb": 44214.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.745, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 8.11, "gpu_utilization_percent_mean": 70.39}, "timestamp": "2026-01-30T21:34:24.349461"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6400.902, "latencies_ms": [6400.902], "images_per_second": 0.156, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 6, "output_text": "The image depicts a scene in a natural habitat, likely a savanna or grassland, where two zebras are present. The zebras are standing on a dirt path surrounded by trees and shrubs, with one zebra facing the camera and the other slightly turned away. The setting suggests a peaceful and serene environment, typical of a wildlife reserve or a protected area where zebras can roam freely.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18626.6, "ram_available_mb": 44214.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18626.6, "ram_available_mb": 44214.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.634, "power_cpu_cv_mean_watts": 1.951, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 69.13}, "timestamp": "2026-01-30T21:34:32.794791"}
{"image_index": 115, "image_name": "000000011760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011760.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4698.354, "latencies_ms": [4698.354], "images_per_second": 0.213, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image features two zebras standing in a natural environment. The zebras have distinctive black and white stripes on their bodies, and their fur appears to be a mix of brown and white. The lighting is natural, suggesting it is daytime, and the ground is covered in dirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18626.6, "ram_available_mb": 44214.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.844, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 70.59}, "timestamp": "2026-01-30T21:34:39.529785"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3065.636, "latencies_ms": [3065.636], "images_per_second": 0.326, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image shows a professional video camera mounted on a tripod, with a laptop placed on a folding chair nearby, indicating a setup for filming or recording.", "error": null, "sys_before": {"cpu_percent": 34.4, "ram_used_mb": 18626.9, "ram_available_mb": 44214.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18627.8, "ram_available_mb": 44213.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.015, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 75.28}, "timestamp": "2026-01-30T21:34:44.744477"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3206.034, "latencies_ms": [3206.034], "images_per_second": 0.312, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 6, "output_text": "1. Laptop\n2. Chair\n3. Tripod\n4. Camera\n5. Microphone\n6. Wall\n7. Floor\n8. Table", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18627.8, "ram_available_mb": 44213.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18627.6, "ram_available_mb": 44213.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.724, "power_cpu_cv_mean_watts": 1.433, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 73.846}, "timestamp": "2026-01-30T21:34:49.985707"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3866.643, "latencies_ms": [3866.643], "images_per_second": 0.259, "prompt_tokens": 30, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The main objects in the image are a laptop and a tripod. The laptop is positioned on a folding chair, which is located in the foreground. The tripod is positioned in the background, slightly to the right.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 18627.6, "ram_available_mb": 44213.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18627.6, "ram_available_mb": 44213.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.579, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 72.031}, "timestamp": "2026-01-30T21:34:55.892141"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4157.709, "latencies_ms": [4157.709], "images_per_second": 0.241, "prompt_tokens": 24, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a professional video production setup in a well-lit room. A camera is mounted on a tripod, and a laptop is placed on a folding chair, indicating that the scene is likely set up for filming or recording purposes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18627.6, "ram_available_mb": 44213.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18627.8, "ram_available_mb": 44213.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.212, "power_cpu_cv_mean_watts": 1.671, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 71.114}, "timestamp": "2026-01-30T21:35:02.111228"}
{"image_index": 116, "image_name": "000000011813.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000011813.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3488.624, "latencies_ms": [3488.624], "images_per_second": 0.287, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image features a well-lit indoor setting with a white wall and a black laptop on a folding chair. The lighting is bright, casting clear shadows and highlighting the objects in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18627.8, "ram_available_mb": 44213.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18628.3, "ram_available_mb": 44212.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.316, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 73.655}, "timestamp": "2026-01-30T21:35:07.652214"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2372.175, "latencies_ms": [2372.175], "images_per_second": 0.422, "prompt_tokens": 12, "response_tokens_est": 21, "n_tiles": 6, "output_text": "A flock of sheep is being kept in a metal pen, with some wool scattered around the pen.", "error": null, "sys_before": {"cpu_percent": 26.5, "ram_used_mb": 18628.3, "ram_available_mb": 44212.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18628.3, "ram_available_mb": 44212.6, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.695, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 78.526}, "timestamp": "2026-01-30T21:35:12.143344"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3568.34, "latencies_ms": [3568.34], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "1. Sheep\n2. Sheep\n3. Sheep\n4. Sheep\n5. Sheep\n6. Sheep\n7. Sheep\n8. Sheep", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18628.3, "ram_available_mb": 44212.6, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18628.5, "ram_available_mb": 44212.4, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.146, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 73.207}, "timestamp": "2026-01-30T21:35:17.747358"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5118.2, "latencies_ms": [5118.2], "images_per_second": 0.195, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The main objects in the image are sheep, which are located in the foreground. The sheep are surrounded by a metal wire fence, and there is a pile of sheep's wool in the foreground. The background features a paved surface and a small, white object, possibly a ball, which is not part of the sheep.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18628.5, "ram_available_mb": 44212.4, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18628.8, "ram_available_mb": 44212.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.535, "power_cpu_cv_mean_watts": 1.816, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 70.116}, "timestamp": "2026-01-30T21:35:24.922077"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4688.492, "latencies_ms": [4688.492], "images_per_second": 0.213, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a sheep in a pen, surrounded by a variety of sheep's wool. The sheep are in a fenced area, likely a sheep farm, with a concrete floor and metal bars. The sheep appear to be resting or grazing, with some wool scattered around them.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18628.8, "ram_available_mb": 44212.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18628.8, "ram_available_mb": 44212.1, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.882, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 70.667}, "timestamp": "2026-01-30T21:35:31.659418"}
{"image_index": 117, "image_name": "000000012062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012062.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4820.499, "latencies_ms": [4820.499], "images_per_second": 0.207, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image shows a sheep in a wire pen, with a light-colored wool coat. The sheep is surrounded by a mix of wool and dirt, indicating a natural, outdoor setting. The lighting is soft and diffused, likely due to overcast weather, which casts a gentle glow on the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18628.8, "ram_available_mb": 44212.1, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18629.0, "ram_available_mb": 44211.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.675, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 70.05}, "timestamp": "2026-01-30T21:35:38.507651"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3487.123, "latencies_ms": [3487.123], "images_per_second": 0.287, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 6, "output_text": "A female tennis player in a purple outfit is preparing to hit a tennis ball on a blue court, while a man in a red shirt and another in a blue shirt are recording the game.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18629.0, "ram_available_mb": 44211.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18630.0, "ram_available_mb": 44210.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.075, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 8.128, "gpu_utilization_percent_mean": 72.931}, "timestamp": "2026-01-30T21:35:44.115627"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3908.553, "latencies_ms": [3908.553], "images_per_second": 0.256, "prompt_tokens": 26, "response_tokens_est": 46, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Blue tennis court\n5. Blue net\n6. Blue advertising boards\n7. Blue seating area\n8. Blue spectator seats", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18630.0, "ram_available_mb": 44210.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18630.9, "ram_available_mb": 44209.9, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.804, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 72.219}, "timestamp": "2026-01-30T21:35:50.037171"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6518.611, "latencies_ms": [6518.611], "images_per_second": 0.153, "prompt_tokens": 30, "response_tokens_est": 89, "n_tiles": 6, "output_text": "The main object in the foreground is a tennis player in a purple outfit, preparing to hit a tennis ball. The player is positioned near the net, which is the central focus of the image. In the background, there is a scoreboard displaying the names of the players and the score, with a crowd of spectators seated in the stands. The net is prominently placed between the two players, dividing the court into two halves.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18630.9, "ram_available_mb": 44209.9, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18630.9, "ram_available_mb": 44210.0, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.486, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 68.727}, "timestamp": "2026-01-30T21:35:58.602615"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5110.884, "latencies_ms": [5110.884], "images_per_second": 0.196, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The image depicts a professional tennis match taking place on a blue hard court. The court is surrounded by a blue net, and there are several people in the background, including a referee and a cameraman. The match is being broadcasted, as indicated by the presence of a Sony Ericsson logo on the court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18630.9, "ram_available_mb": 44210.0, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18630.6, "ram_available_mb": 44210.3, "ram_percent": 29.6}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.535, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 70.186}, "timestamp": "2026-01-30T21:36:05.763637"}
{"image_index": 118, "image_name": "000000012120.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012120.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3664.842, "latencies_ms": [3664.842], "images_per_second": 0.273, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 6, "output_text": "The image depicts a brightly lit blue tennis court with a vibrant blue surface. The court is surrounded by a blue net, and the lighting is even and bright, highlighting the players and the court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18630.6, "ram_available_mb": 44210.3, "ram_percent": 29.6}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18634.2, "ram_available_mb": 44206.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.972, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 72.419}, "timestamp": "2026-01-30T21:36:11.446780"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4080.872, "latencies_ms": [4080.872], "images_per_second": 0.245, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A man is walking with a suitcase, carrying it on his shoulder, while a woman is standing nearby.", "error": null, "sys_before": {"cpu_percent": 28.7, "ram_used_mb": 18634.2, "ram_available_mb": 44206.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18634.9, "ram_available_mb": 44206.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.973, "power_cpu_cv_mean_watts": 1.119, "power_sys_5v0_mean_watts": 8.861, "gpu_utilization_percent_mean": 89.618}, "timestamp": "2026-01-30T21:36:17.660963"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10513.907, "latencies_ms": [10513.907], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit sign: 1\n- Exit", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18634.9, "ram_available_mb": 44206.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18634.9, "ram_available_mb": 44206.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.156, "power_cpu_cv_mean_watts": 1.901, "power_sys_5v0_mean_watts": 8.877, "gpu_utilization_percent_mean": 82.923}, "timestamp": "2026-01-30T21:36:30.198977"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6530.737, "latencies_ms": [6530.737], "images_per_second": 0.153, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The main objects in the image are a man in a suit carrying a suitcase and a glass door. The man is positioned in the foreground, while the glass door is located in the background. The suitcase is near the man, indicating that he is likely about to enter or exit through the door.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18634.9, "ram_available_mb": 44206.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18634.8, "ram_available_mb": 44206.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.635, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.852, "gpu_utilization_percent_mean": 85.527}, "timestamp": "2026-01-30T21:36:38.762117"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5627.767, "latencies_ms": [5627.767], "images_per_second": 0.178, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The image depicts an airport terminal with a modern, clean design. A man is seen walking towards the terminal, carrying a suitcase. The terminal features a glass door, a staircase, and various signs and information boards.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18634.8, "ram_available_mb": 44206.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18634.8, "ram_available_mb": 44206.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.019, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 86.708}, "timestamp": "2026-01-30T21:36:46.438289"}
{"image_index": 119, "image_name": "000000012280.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012280.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5742.739, "latencies_ms": [5742.739], "images_per_second": 0.174, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image depicts a modern, well-lit indoor setting with a sleek, metallic staircase and a glass door. The floor is made of polished concrete, and the overall lighting is bright and even, creating a clean and contemporary atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18634.8, "ram_available_mb": 44206.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18635.3, "ram_available_mb": 44205.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.094, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 86.958}, "timestamp": "2026-01-30T21:36:54.218735"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5098.764, "latencies_ms": [5098.764], "images_per_second": 0.196, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 12, "output_text": "The image shows a table with a pizza box, a glass of water, a glass of red wine, and a plate of pizza, all set on a colorful checkered tablecloth.", "error": null, "sys_before": {"cpu_percent": 34.6, "ram_used_mb": 18634.8, "ram_available_mb": 44206.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18634.1, "ram_available_mb": 44206.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.551, "power_cpu_cv_mean_watts": 1.344, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 86.976}, "timestamp": "2026-01-30T21:37:01.501130"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10543.147, "latencies_ms": [10543.147], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18634.1, "ram_available_mb": 44206.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18633.8, "ram_available_mb": 44207.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.083, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 82.341}, "timestamp": "2026-01-30T21:37:14.069954"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6843.459, "latencies_ms": [6843.459], "images_per_second": 0.146, "prompt_tokens": 30, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The main objects in the image are a pizza and a glass of water. The pizza is placed on a pizza box, while the glass of water is placed on a tablecloth. The pizza box is positioned in the background, slightly out of focus, while the glass of water is in the foreground, closer to the viewer.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18633.8, "ram_available_mb": 44207.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18634.2, "ram_available_mb": 44206.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.354, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.808, "gpu_utilization_percent_mean": 85.19}, "timestamp": "2026-01-30T21:37:22.938060"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6858.001, "latencies_ms": [6858.001], "images_per_second": 0.146, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a dining scene with a table set for two people. The table is covered with a colorful checkered tablecloth, and there are two pizza boxes, one with a slice of pizza and the other empty. The setting appears to be a home kitchen or dining area, with a television visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18634.2, "ram_available_mb": 44206.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18634.4, "ram_available_mb": 44206.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.263, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 84.69}, "timestamp": "2026-01-30T21:37:31.834352"}
{"image_index": 120, "image_name": "000000012576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012576.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6586.972, "latencies_ms": [6586.972], "images_per_second": 0.152, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a dining table with a pizza and a glass of water. The pizza has a golden-brown crust and a red tomato sauce, while the glass of water is clear and has the word \"PIZZA\" printed on it. The lighting is soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18634.4, "ram_available_mb": 44206.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.507, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.866, "gpu_utilization_percent_mean": 85.455}, "timestamp": "2026-01-30T21:37:40.444944"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4403.915, "latencies_ms": [4403.915], "images_per_second": 0.227, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "A young boy is crouched down, wearing a protective helmet and a red shirt, preparing to catch a baseball with his mitt.", "error": null, "sys_before": {"cpu_percent": 26.0, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18634.5, "ram_available_mb": 44206.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.626, "power_cpu_cv_mean_watts": 1.19, "power_sys_5v0_mean_watts": 8.885, "gpu_utilization_percent_mean": 89.222}, "timestamp": "2026-01-30T21:37:46.976793"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10537.894, "latencies_ms": [10537.894], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "baseball bat: 1\nbaseball glove: 1\ncatcher's mask: 1\ncatcher's uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1\nbaseball uniform: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18634.5, "ram_available_mb": 44206.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.182, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 8.87, "gpu_utilization_percent_mean": 82.73}, "timestamp": "2026-01-30T21:37:59.574564"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8236.463, "latencies_ms": [8236.463], "images_per_second": 0.121, "prompt_tokens": 30, "response_tokens_est": 90, "n_tiles": 12, "output_text": "In the image, the baseball player is positioned in the foreground, crouched down near the dirt area. The baseball bat is held by the player, and the catcher is positioned behind him, wearing a protective helmet and mitt. The background features a group of people sitting on the grass, with a few standing and watching the game. The setting is a park with trees and a clear sky, providing a serene atmosphere for the game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.779, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 8.859, "gpu_utilization_percent_mean": 83.829}, "timestamp": "2026-01-30T21:38:09.837954"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6130.59, "latencies_ms": [6130.59], "images_per_second": 0.163, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image depicts a sunny day at a park where a group of people is gathered to watch a baseball game. A young boy, wearing a protective helmet and a baseball uniform, is preparing to bat, while others are seated on the grass, some watching the game.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18635.0, "ram_available_mb": 44205.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.709, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 86.255}, "timestamp": "2026-01-30T21:38:17.990139"}
{"image_index": 121, "image_name": "000000012639.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012639.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6077.215, "latencies_ms": [6077.215], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image depicts a sunny day at a park where a group of people is gathered. The scene is characterized by vibrant green grass, a clear blue sky, and a few trees providing shade. The lighting is bright and natural, casting soft shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18635.0, "ram_available_mb": 44205.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18635.3, "ram_available_mb": 44205.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.693, "power_cpu_cv_mean_watts": 1.492, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 86.275}, "timestamp": "2026-01-30T21:38:26.101716"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4556.448, "latencies_ms": [4556.448], "images_per_second": 0.219, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 12, "output_text": "The image shows a black telephone with a banana placed on top of it, along with a calculator and a piece of paper with handwritten notes.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 18635.3, "ram_available_mb": 44205.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18636.3, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.208, "power_cpu_cv_mean_watts": 1.244, "power_sys_5v0_mean_watts": 8.856, "gpu_utilization_percent_mean": 87.421}, "timestamp": "2026-01-30T21:38:32.842908"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4173.914, "latencies_ms": [4173.914], "images_per_second": 0.24, "prompt_tokens": 26, "response_tokens_est": 23, "n_tiles": 12, "output_text": "- Phone\n- Banana\n- Calculator\n- Notebook\n- Cable\n- Keyboard\n- Paper", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.3, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18636.1, "ram_available_mb": 44204.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.627, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 90.829}, "timestamp": "2026-01-30T21:38:39.066882"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7791.094, "latencies_ms": [7791.094], "images_per_second": 0.128, "prompt_tokens": 30, "response_tokens_est": 83, "n_tiles": 12, "output_text": "The main objects in the image are a black telephone, a banana, and a calculator. The telephone is positioned in the foreground, slightly to the left, with its cord extending towards the right side of the image. The banana is placed to the right of the telephone, leaning against the calculator. The calculator is in the background, slightly to the right, with its screen facing the left side of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18636.1, "ram_available_mb": 44204.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.056, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.871, "gpu_utilization_percent_mean": 84.742}, "timestamp": "2026-01-30T21:38:48.871607"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7770.998, "latencies_ms": [7770.998], "images_per_second": 0.129, "prompt_tokens": 24, "response_tokens_est": 82, "n_tiles": 12, "output_text": "The image depicts a cluttered desk with various items scattered around. The desk surface is white, and there are several objects present, including a black telephone with a cord, a black calculator, a yellow banana, and a piece of paper with handwritten text. The setting appears to be a workspace or study area, with the objects suggesting that someone might be engaged in some form of work or study.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.853, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 83.939}, "timestamp": "2026-01-30T21:38:58.671250"}
{"image_index": 122, "image_name": "000000012667.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012667.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5454.259, "latencies_ms": [5454.259], "images_per_second": 0.183, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image features a white desk with a yellow banana placed on it. The lighting is bright, casting soft shadows on the desk. The banana's vibrant color contrasts with the white surface, making it stand out.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.184, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 87.087}, "timestamp": "2026-01-30T21:39:06.171602"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3772.298, "latencies_ms": [3772.298], "images_per_second": 0.265, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The image depicts a bustling crowd of people, with a focus on a group of young women and girls gathered closely together, some holding stuffed animals, while others are engaged in conversation or looking at their phones.", "error": null, "sys_before": {"cpu_percent": 24.8, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.906, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.082, "gpu_utilization_percent_mean": 72.323}, "timestamp": "2026-01-30T21:39:12.079586"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2002.203, "latencies_ms": [2002.203], "images_per_second": 0.499, "prompt_tokens": 26, "response_tokens_est": 14, "n_tiles": 6, "output_text": "- teddy bear: 2\n- people: 20", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.333, "power_cpu_cv_mean_watts": 0.901, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 81.188}, "timestamp": "2026-01-30T21:39:16.139788"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5019.978, "latencies_ms": [5019.978], "images_per_second": 0.199, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main objects in the image are a group of people, with the foreground and background objects being more distant from the camera. The foreground includes a group of young women, while the background features a crowd of people. The people in the foreground are closer to the camera, while those in the background are further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18634.9, "ram_available_mb": 44206.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.476, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 69.643}, "timestamp": "2026-01-30T21:39:23.196226"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6580.788, "latencies_ms": [6580.788], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 90, "n_tiles": 6, "output_text": "The image depicts a bustling outdoor scene with a large crowd of people gathered in what appears to be a public square or park. The setting is likely during the daytime, as indicated by the natural light and shadows. The crowd consists of various individuals, some of whom are engaged in conversation, while others are looking around or holding items such as books or papers. The atmosphere seems lively and dynamic, with people moving and interacting with one another.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18634.9, "ram_available_mb": 44206.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18634.8, "ram_available_mb": 44206.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.58, "power_cpu_cv_mean_watts": 1.973, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 68.855}, "timestamp": "2026-01-30T21:39:31.837596"}
{"image_index": 123, "image_name": "000000012670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012670.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5660.412, "latencies_ms": [5660.412], "images_per_second": 0.177, "prompt_tokens": 22, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The image depicts a bustling outdoor scene with a diverse crowd of people. Notable visual attributes include the vibrant colors of the clothing worn by the individuals, such as red, blue, and green, which stand out against the overcast sky. The lighting is soft and diffused, likely due to the cloudy weather, casting a gentle glow over the scene.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18634.8, "ram_available_mb": 44206.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18634.2, "ram_available_mb": 44206.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.108, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 69.745}, "timestamp": "2026-01-30T21:39:39.545520"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3918.62, "latencies_ms": [3918.62], "images_per_second": 0.255, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 12, "output_text": "A man is holding a baby while standing next to a horse, both looking at each other.", "error": null, "sys_before": {"cpu_percent": 26.5, "ram_used_mb": 18634.2, "ram_available_mb": 44206.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.216, "power_cpu_cv_mean_watts": 1.051, "power_sys_5v0_mean_watts": 8.866, "gpu_utilization_percent_mean": 90.75}, "timestamp": "2026-01-30T21:39:45.614587"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4732.166, "latencies_ms": [4732.166], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Man\n2. Baby\n3. Horse\n4. Building\n5. Door\n6. Window\n7. Floor\n8. Chain", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18634.0, "ram_available_mb": 44206.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.898, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 88.538}, "timestamp": "2026-01-30T21:39:52.371682"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7514.84, "latencies_ms": [7514.84], "images_per_second": 0.133, "prompt_tokens": 30, "response_tokens_est": 78, "n_tiles": 12, "output_text": "In the image, the man is holding a baby close to his chest, with the baby's head resting on his shoulder. The baby is positioned in the foreground, while the man is in the background. The man is standing near a horse, which is in the left side of the image. The horse is partially visible, and the man is holding the baby close to his chest.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18634.0, "ram_available_mb": 44206.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.087, "power_cpu_cv_mean_watts": 1.697, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 84.952}, "timestamp": "2026-01-30T21:40:01.926867"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6012.717, "latencies_ms": [6012.717], "images_per_second": 0.166, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image depicts a man and a young child standing in an outdoor setting, likely a stable or barn, with a horse visible in the background. The man is holding the child, and both are smiling, suggesting a moment of joy and connection between them.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18634.3, "ram_available_mb": 44206.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.796, "power_cpu_cv_mean_watts": 1.514, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 86.6}, "timestamp": "2026-01-30T21:40:09.964788"}
{"image_index": 124, "image_name": "000000012748.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000012748.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6135.173, "latencies_ms": [6135.173], "images_per_second": 0.163, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image features a man and a baby in a rustic, stone-walled enclosure. The man is wearing a red shirt, and the baby is dressed in a light blue shirt. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.746, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 86.294}, "timestamp": "2026-01-30T21:40:18.119218"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4073.321, "latencies_ms": [4073.321], "images_per_second": 0.245, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "The image shows a white plate with a small, round, and slightly translucent banana placed on it.", "error": null, "sys_before": {"cpu_percent": 31.2, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.883, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 89.758}, "timestamp": "2026-01-30T21:40:24.325308"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4740.724, "latencies_ms": [4740.724], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. plate\n2. banana\n3. bowl\n4. bowl\n5. bowl\n6. bowl\n7. bowl\n8. bowl", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 12.5, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.102, "power_cpu_cv_mean_watts": 2.249, "power_sys_5v0_mean_watts": 8.95, "gpu_utilization_percent_mean": 88.949}, "timestamp": "2026-01-30T21:40:31.101510"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5848.82, "latencies_ms": [5848.82], "images_per_second": 0.171, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The main object in the image is a white plate with a banana on it. The banana is placed on the plate, which is positioned on a wooden surface. The banana is the closest object to the viewer, while the plate is further away.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 13.4, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.949, "power_cpu_cv_mean_watts": 2.616, "power_sys_5v0_mean_watts": 9.044, "gpu_utilization_percent_mean": 86.204}, "timestamp": "2026-01-30T21:40:38.988510"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4906.592, "latencies_ms": [4906.592], "images_per_second": 0.204, "prompt_tokens": 24, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image shows a white plate with a banana on it, placed on a wooden table. The banana appears to be fresh and ripe, with a slightly curved shape.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.595, "power_cpu_cv_mean_watts": 2.472, "power_sys_5v0_mean_watts": 8.925, "gpu_utilization_percent_mean": 87.805}, "timestamp": "2026-01-30T21:40:45.907378"}
{"image_index": 125, "image_name": "000000013004.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013004.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4917.812, "latencies_ms": [4917.812], "images_per_second": 0.203, "prompt_tokens": 22, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image features a white plate with a light brown rim, placed on a wooden table. The lighting is soft and natural, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 12.8, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.654, "power_cpu_cv_mean_watts": 2.452, "power_sys_5v0_mean_watts": 8.935, "gpu_utilization_percent_mean": 87.366}, "timestamp": "2026-01-30T21:40:52.865310"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2698.125, "latencies_ms": [2698.125], "images_per_second": 0.371, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A man is kneeling on the ground, working on a metal wheel with a spoke wrench, while another person stands nearby.", "error": null, "sys_before": {"cpu_percent": 37.6, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 12.6, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.762, "power_cpu_cv_mean_watts": 2.549, "power_sys_5v0_mean_watts": 8.204, "gpu_utilization_percent_mean": 76.318}, "timestamp": "2026-01-30T21:40:57.702532"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3104.118, "latencies_ms": [3104.118], "images_per_second": 0.322, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Wheel\n2. Wheel\n3. Wheel\n4. Wheel\n5. Wheel\n6. Wheel\n7. Wheel\n8. Wheel", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 7.9, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.801, "power_cpu_cv_mean_watts": 2.419, "power_sys_5v0_mean_watts": 8.118, "gpu_utilization_percent_mean": 72.615}, "timestamp": "2026-01-30T21:41:02.845383"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6720.537, "latencies_ms": [6720.537], "images_per_second": 0.149, "prompt_tokens": 30, "response_tokens_est": 92, "n_tiles": 6, "output_text": "The main object in the foreground is a man wearing glasses and a green shirt, who is crouched down and working on a metal wheel. The wheel is placed on a flat surface, possibly a workshop floor. In the background, there is a motorcycle with a blue and red design, and a bicycle with a silver frame and black seat. The motorcycle and bicycle are positioned further back, with the man in the foreground being the closest to the camera.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.393, "power_cpu_cv_mean_watts": 1.967, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 68.368}, "timestamp": "2026-01-30T21:41:11.612371"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4827.944, "latencies_ms": [4827.944], "images_per_second": 0.207, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a man working on a motorcycle in a workshop or garage setting. He is focused on cleaning or repairing the motorcycle's wheels, with a metal wheel and a brush in his hands. The workshop is cluttered with various tools and parts, and the man is wearing casual clothing.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.598, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 70.195}, "timestamp": "2026-01-30T21:41:18.496417"}
{"image_index": 126, "image_name": "000000013177.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013177.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5564.382, "latencies_ms": [5564.382], "images_per_second": 0.18, "prompt_tokens": 22, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The image features a man wearing a green shirt and dark pants, crouched down in a workshop or garage. He is working on a metal wheel with a circular pattern, surrounded by various tools and machinery. The lighting is dim, with a subdued ambiance, and the man is wearing sandals, suggesting a warm, possibly humid environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.049, "power_cpu_cv_mean_watts": 1.892, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 69.255}, "timestamp": "2026-01-30T21:41:26.072675"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2642.918, "latencies_ms": [2642.918], "images_per_second": 0.378, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A skateboarder is performing a trick on a ramp in a park, with trees and a fence in the background.", "error": null, "sys_before": {"cpu_percent": 32.2, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.891, "power_cpu_cv_mean_watts": 1.22, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 76.667}, "timestamp": "2026-01-30T21:41:30.842970"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4640.868, "latencies_ms": [4640.868], "images_per_second": 0.215, "prompt_tokens": 26, "response_tokens_est": 58, "n_tiles": 6, "output_text": "skateboard: 1\nskateboarder: 1\nskateboard: 1\nskateboarder: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.956, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 70.842}, "timestamp": "2026-01-30T21:41:37.497972"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5006.641, "latencies_ms": [5006.641], "images_per_second": 0.2, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main subject, a skateboarder, is in the foreground, performing a trick on a ramp. The skateboarder is positioned near the center of the image, with the ramp and the background elements slightly out of focus. The background features a fence and a building, providing context to the skateboarding scene.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.532, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 69.881}, "timestamp": "2026-01-30T21:41:44.528636"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5547.403, "latencies_ms": [5547.403], "images_per_second": 0.18, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The image captures a dynamic moment of a skateboarder performing a trick on a concrete ramp in an outdoor setting. The skateboarder, dressed in a black t-shirt and black pants, is captured mid-air, with their body angled towards the ground and their arms extended. The background features a fence and greenery, suggesting a park or recreational area.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.118, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 69.553}, "timestamp": "2026-01-30T21:41:52.096569"}
{"image_index": 127, "image_name": "000000013201.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013201.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3982.513, "latencies_ms": [3982.513], "images_per_second": 0.251, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The notable visual attributes of the image include the vibrant green grass, the clear blue sky, and the bright sunlight. The lighting is natural, casting a warm glow on the scene, and the weather appears to be sunny and clear.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.465, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 71.879}, "timestamp": "2026-01-30T21:41:58.114364"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3048.7, "latencies_ms": [3048.7], "images_per_second": 0.328, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image depicts a group of people playing a game of frisbee outdoors during sunset, with the sky painted in hues of blue and orange.", "error": null, "sys_before": {"cpu_percent": 37.6, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.998, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 73.88}, "timestamp": "2026-01-30T21:42:03.316635"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4046.099, "latencies_ms": [4046.099], "images_per_second": 0.247, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 6, "output_text": "frisbee: 3\npeople: 4\nshorts: 2\nsocks: 2\nshoes: 2\nt-shirt: 2\nglasses: 1\ntrunks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.406, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 71.324}, "timestamp": "2026-01-30T21:42:09.395738"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5238.007, "latencies_ms": [5238.007], "images_per_second": 0.191, "prompt_tokens": 30, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The main objects in the image are a group of people and a frisbee. The people are positioned in the foreground, with two men and a woman kneeling on the grass. The frisbee is held by the man in the center, who is kneeling. The background features a clear sky and a distant tree line.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.391, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 70.25}, "timestamp": "2026-01-30T21:42:16.673515"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4220.294, "latencies_ms": [4220.294], "images_per_second": 0.237, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The scene is set in a grassy field during twilight, with a group of people gathered around a white frisbee. They are engaged in a playful game, with some individuals kneeling and others standing, all holding the frisbee.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.268, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 71.057}, "timestamp": "2026-01-30T21:42:22.927622"}
{"image_index": 128, "image_name": "000000013291.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013291.jpg", "image_width": 500, "image_height": 335, "image_resolution": "500x335", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4936.17, "latencies_ms": [4936.17], "images_per_second": 0.203, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The image depicts a group of people playing frisbee outdoors during sunset. The sky is clear with a gradient of blue, and the lighting is warm, casting a golden hue over the scene. The individuals are dressed in casual attire, with some wearing shorts and t-shirts, and others in pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18639.2, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.677, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 70.585}, "timestamp": "2026-01-30T21:42:29.881773"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3348.757, "latencies_ms": [3348.757], "images_per_second": 0.299, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "The image shows a large, white airplane with red accents parked on a tarmac, with various ground support vehicles and personnel nearby, indicating that it is likely at an airport.", "error": null, "sys_before": {"cpu_percent": 24.8, "ram_used_mb": 18639.2, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.616, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 73.889}, "timestamp": "2026-01-30T21:42:35.327726"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8854.94, "latencies_ms": [8854.94], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.822, "power_cpu_cv_mean_watts": 2.073, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 67.77}, "timestamp": "2026-01-30T21:42:46.201045"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6392.306, "latencies_ms": [6392.306], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 85, "n_tiles": 6, "output_text": "The main object in the foreground is a large airplane with the \"Japan Endless Discovery\" logo on its fuselage. The airplane is parked on the tarmac, with its landing gear extended. In the background, there are other aircraft and ground support vehicles, indicating that this is an airport setting. The airplane is positioned near the tarmac, with other planes and ground equipment visible in the distance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.293, "power_cpu_cv_mean_watts": 1.928, "power_sys_5v0_mean_watts": 7.944, "gpu_utilization_percent_mean": 68.093}, "timestamp": "2026-01-30T21:42:54.631835"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4887.646, "latencies_ms": [4887.646], "images_per_second": 0.205, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image depicts a large commercial airplane parked on a tarmac at an airport. The scene is set under a partly cloudy sky, with a few palm trees visible in the background. Several ground crew members are present, working on the aircraft, and there are various airport equipment and vehicles nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.619, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.098}, "timestamp": "2026-01-30T21:43:01.568358"}
{"image_index": 129, "image_name": "000000013348.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013348.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4024.99, "latencies_ms": [4024.99], "images_per_second": 0.248, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The notable visual attributes of the image include a large, white airplane with red accents on its tail and a red logo on the fuselage. The sky is partly cloudy with blue patches, indicating a partly cloudy day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18639.7, "ram_available_mb": 44201.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.559, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 71.647}, "timestamp": "2026-01-30T21:43:07.618467"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2873.188, "latencies_ms": [2873.188], "images_per_second": 0.348, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "A young person is performing a skateboard trick on a concrete ledge in a park, surrounded by green grass and a few benches.", "error": null, "sys_before": {"cpu_percent": 25.2, "ram_used_mb": 18639.7, "ram_available_mb": 44201.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18639.7, "ram_available_mb": 44201.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.587, "power_cpu_cv_mean_watts": 1.376, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 76.174}, "timestamp": "2026-01-30T21:43:12.582578"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4034.497, "latencies_ms": [4034.497], "images_per_second": 0.248, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 6, "output_text": "1. Skateboarder\n2. Park bench\n3. Sidewalk\n4. Concrete wall\n5. Green metal fence\n6. Green metal structure\n7. Green metal bench\n8. Green metal trash can", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.443, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 71.647}, "timestamp": "2026-01-30T21:43:18.665413"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7021.742, "latencies_ms": [7021.742], "images_per_second": 0.142, "prompt_tokens": 30, "response_tokens_est": 97, "n_tiles": 6, "output_text": "In the image, the main subject is a young person skateboarding on a concrete ledge. The skateboarder is positioned near the foreground, with their body leaning forward and arms outstretched for balance. The concrete ledge is located in the middle ground, and the background features a park setting with green grass, a wooden fence, and a bench. The skateboarder is near the fence, and there is a trash can and a street sign visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.373, "power_cpu_cv_mean_watts": 1.996, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 68.085}, "timestamp": "2026-01-30T21:43:27.728741"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4992.459, "latencies_ms": [4992.459], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a young person skateboarding in a park-like setting. The skateboarder is performing a trick on a concrete ledge, surrounded by green grass and a few benches. The scene is set in a public area with a sidewalk, a paved road, and a fence in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.647, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.293}, "timestamp": "2026-01-30T21:43:34.744542"}
{"image_index": 130, "image_name": "000000013546.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013546.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6085.468, "latencies_ms": [6085.468], "images_per_second": 0.164, "prompt_tokens": 22, "response_tokens_est": 82, "n_tiles": 6, "output_text": "The image depicts a young person skateboarding on a concrete ramp in a park. The skateboarder is wearing a yellow t-shirt, black pants, and a black cap, and is captured mid-action, with their body leaning forward and arms outstretched for balance. The scene is bathed in natural sunlight, casting long shadows on the ground, indicating it is likely a bright, sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.874, "power_cpu_cv_mean_watts": 1.948, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 68.941}, "timestamp": "2026-01-30T21:43:42.849090"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2706.149, "latencies_ms": [2706.149], "images_per_second": 0.37, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "The image shows a close-up of a chocolate cake with a dollop of cream on a plate adorned with floral patterns.", "error": null, "sys_before": {"cpu_percent": 26.7, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.648, "power_cpu_cv_mean_watts": 1.293, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 75.364}, "timestamp": "2026-01-30T21:43:47.678500"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3547.987, "latencies_ms": [3547.987], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.259, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 73.138}, "timestamp": "2026-01-30T21:43:53.265349"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5744.52, "latencies_ms": [5744.52], "images_per_second": 0.174, "prompt_tokens": 30, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The main object in the foreground is a chocolate cake with a glossy, chocolate glaze on top. The cake is placed on a white plate with a floral pattern. In the background, there is another plate with a similar floral pattern, but it is out of focus. The cake is positioned near the center of the image, with the other plate slightly to the right.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.971, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 69.104}, "timestamp": "2026-01-30T21:44:01.060404"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4642.053, "latencies_ms": [4642.053], "images_per_second": 0.215, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The image depicts a close-up view of a chocolate cake with a dollop of cream on a white plate adorned with gold floral patterns. The cake is being cut with a knife, and the cream is being poured onto the cake, creating a visually appealing and appetizing scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.835, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 70.41}, "timestamp": "2026-01-30T21:44:07.723155"}
{"image_index": 131, "image_name": "000000013597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013597.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4456.169, "latencies_ms": [4456.169], "images_per_second": 0.224, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The image features a chocolate cake with a glossy, smooth chocolate glaze and a golden-brown frosting. The cake is placed on a white plate with a floral pattern, and the lighting is warm and soft, highlighting the rich colors and textures of the cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.03, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 70.892}, "timestamp": "2026-01-30T21:44:14.213848"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5344.445, "latencies_ms": [5344.445], "images_per_second": 0.187, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image depicts a cluttered office space with various items scattered across the floor and tables, including a man working on a laptop, a person sitting at a desk, and a person standing near a computer.", "error": null, "sys_before": {"cpu_percent": 27.6, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.357, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 85.295}, "timestamp": "2026-01-30T21:44:21.720354"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4794.068, "latencies_ms": [4794.068], "images_per_second": 0.209, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 12, "output_text": "1. Laptop\n2. Computer monitor\n3. Paper\n4. Chair\n5. Box\n6. Box\n7. Box\n8. Box", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.859, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 8.776, "gpu_utilization_percent_mean": 88.925}, "timestamp": "2026-01-30T21:44:28.566574"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8560.974, "latencies_ms": [8560.974], "images_per_second": 0.117, "prompt_tokens": 30, "response_tokens_est": 95, "n_tiles": 12, "output_text": "In the image, the main objects are arranged in a somewhat cluttered workspace. The foreground features a man sitting at a table, working on a laptop. To his left, there is a red chair and a black bag. In the background, there are several other individuals engaged in various activities. The table is cluttered with various items, including a red box, a computer monitor, and a red cup. The overall spatial relationships suggest a busy and active work environment.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.599, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 83.694}, "timestamp": "2026-01-30T21:44:39.163023"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7155.125, "latencies_ms": [7155.125], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a cluttered office or workshop environment with various items scattered across the floor and tables. A group of people is engaged in work, with some seated at desks and others standing. The setting appears to be a workspace, possibly a home office or a small workshop, with a mix of electronic devices, papers, and personal belongings.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.138, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 85.033}, "timestamp": "2026-01-30T21:44:48.378224"}
{"image_index": 132, "image_name": "000000013659.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013659.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4811.764, "latencies_ms": [4811.764], "images_per_second": 0.208, "prompt_tokens": 22, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The image depicts a cluttered office space with a yellowish floor and walls. The lighting is dim, with a mix of natural and artificial light sources.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.72, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 88.525}, "timestamp": "2026-01-30T21:44:55.245155"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4863.494, "latencies_ms": [4863.494], "images_per_second": 0.206, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image depicts a group of people playing a video game in a cozy living room, with a woman in the foreground holding a controller and two men standing behind her.", "error": null, "sys_before": {"cpu_percent": 30.6, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.77, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 87.725}, "timestamp": "2026-01-30T21:45:02.257226"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5773.272, "latencies_ms": [5773.272], "images_per_second": 0.173, "prompt_tokens": 26, "response_tokens_est": 49, "n_tiles": 12, "output_text": "- woman: 1\n- man: 3\n- game controller: 1\n- couch: 1\n- table: 1\n- chair: 1\n- floor: 1\n- wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.905, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 86.5}, "timestamp": "2026-01-30T21:45:10.059217"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8421.269, "latencies_ms": [8421.269], "images_per_second": 0.119, "prompt_tokens": 30, "response_tokens_est": 93, "n_tiles": 12, "output_text": "The main objects in the image are a group of people playing a video game in a living room. The foreground features a woman standing on the left side, holding a controller, while the man in the background is also holding a controller. The room has a couch, a wooden table, and various items on the table, including a bottle and a basket. The background includes a window with blinds, a framed picture, and a framed photo on the wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.719, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 83.732}, "timestamp": "2026-01-30T21:45:20.518460"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8675.023, "latencies_ms": [8675.023], "images_per_second": 0.115, "prompt_tokens": 24, "response_tokens_est": 97, "n_tiles": 12, "output_text": "The image depicts a casual indoor scene where three individuals are engaged in a video game. The setting appears to be a living room with a carpeted floor, a couch, a wooden table, and various personal items scattered around. The individuals are casually dressed, with one person in a white tank top and shorts, another in a striped shirt and shorts, and the third in a green shirt and shorts. They are all barefoot, suggesting a relaxed and informal atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.568, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 83.575}, "timestamp": "2026-01-30T21:45:31.236762"}
{"image_index": 133, "image_name": "000000013729.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013729.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6205.136, "latencies_ms": [6205.136], "images_per_second": 0.161, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a beige carpeted floor. The room is well-lit, with a warm and inviting ambiance. The walls are painted in a light color, and there is a wooden table with a basket and some items on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.599, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.865}, "timestamp": "2026-01-30T21:45:39.500366"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3884.295, "latencies_ms": [3884.295], "images_per_second": 0.257, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 12, "output_text": "A lone person stands on a snowy beach, watching the sun set over the ocean.", "error": null, "sys_before": {"cpu_percent": 31.5, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.001, "power_cpu_cv_mean_watts": 1.039, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 89.719}, "timestamp": "2026-01-30T21:45:45.549589"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5223.871, "latencies_ms": [5223.871], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.429, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 87.349}, "timestamp": "2026-01-30T21:45:52.815481"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6013.244, "latencies_ms": [6013.244], "images_per_second": 0.166, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The main objects in the image are the sun, the person, and the beach. The person is standing near the water's edge, with the sun positioned in the background. The beach is the foreground, with the person and the sun being the main subjects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18638.0, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.806, "power_cpu_cv_mean_watts": 1.506, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 86.68}, "timestamp": "2026-01-30T21:46:00.880534"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6061.53, "latencies_ms": [6061.53], "images_per_second": 0.165, "prompt_tokens": 24, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image captures a serene beach scene during sunset, with the sun low on the horizon casting a warm glow over the water and the sand. A lone person is standing on the shore, gazing at the sun, while the waves gently lap at the shore.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.0, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.716, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 86.706}, "timestamp": "2026-01-30T21:46:08.974256"}
{"image_index": 134, "image_name": "000000013774.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013774.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7743.816, "latencies_ms": [7743.816], "images_per_second": 0.129, "prompt_tokens": 22, "response_tokens_est": 82, "n_tiles": 12, "output_text": "The image captures a serene beach scene during sunset, with the sun low on the horizon casting a warm, golden glow across the sky and reflecting off the water. The sky is a gradient of warm colors, transitioning from a deep blue to a soft orange near the horizon. The beach is covered in a thin layer of snow, and the water is calm with gentle waves lapping at the shore.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18637.6, "ram_available_mb": 44203.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18637.3, "ram_available_mb": 44203.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.991, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 84.815}, "timestamp": "2026-01-30T21:46:18.740444"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6066.168, "latencies_ms": [6066.168], "images_per_second": 0.165, "prompt_tokens": 12, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image depicts a cozy living room with a modern and stylish interior design, featuring a white sofa adorned with colorful pillows, a round coffee table with a vase of flowers, and a red chair. The room is well-lit by natural light coming through large windows, and the walls are decorated with various wall art pieces, including a circular wall clock and abstract wall hangings.", "error": null, "sys_before": {"cpu_percent": 30.2, "ram_used_mb": 18637.3, "ram_available_mb": 44203.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.489, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.902}, "timestamp": "2026-01-30T21:46:26.908420"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3435.073, "latencies_ms": [3435.073], "images_per_second": 0.291, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 6, "output_text": "1. Living room\n2. Sofa\n3. Coffee table\n4. Rug\n5. Chairs\n6. TV stand\n7. Decorative plates\n8. Plants", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18637.6, "ram_available_mb": 44203.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.404, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 72.607}, "timestamp": "2026-01-30T21:46:32.366571"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7238.451, "latencies_ms": [7238.451], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 101, "n_tiles": 6, "output_text": "The main objects in the image are a living room and a dining area. The living room features a white sofa with yellow and striped pillows, a black and white patterned rug, a small round coffee table, and a television on a stand. The dining area includes a white round table with a red chair, a vase with a green plant, and a small side table with a red chair. The living room is positioned in the background, while the dining area is in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18637.6, "ram_available_mb": 44203.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.323, "power_cpu_cv_mean_watts": 2.016, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 68.475}, "timestamp": "2026-01-30T21:46:41.616656"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6873.768, "latencies_ms": [6873.768], "images_per_second": 0.145, "prompt_tokens": 24, "response_tokens_est": 95, "n_tiles": 6, "output_text": "The image depicts a cozy, well-lit living room with a modern and stylish decor. The room features a white sofa adorned with colorful pillows, a black and white patterned rug, and a round white coffee table with a vase of flowers. The space is furnished with red chairs and a television on a stand. The room is well-lit, with natural light streaming in through large windows, and the walls are decorated with various wall art pieces.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18637.9, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.42, "power_cpu_cv_mean_watts": 1.996, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 68.293}, "timestamp": "2026-01-30T21:46:50.540762"}
{"image_index": 135, "image_name": "000000013923.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000013923.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5602.903, "latencies_ms": [5602.903], "images_per_second": 0.178, "prompt_tokens": 22, "response_tokens_est": 74, "n_tiles": 6, "output_text": "The room features a warm and inviting ambiance with a combination of natural and artificial lighting. The walls are painted in a light, neutral color, and the furniture includes a white sofa, red chairs, and a black and white patterned rug. The room is well-lit, with natural light streaming in through the large windows and a modern television on the wall.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18637.9, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18637.5, "ram_available_mb": 44203.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.067, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 69.617}, "timestamp": "2026-01-30T21:46:58.165438"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1980.471, "latencies_ms": [1980.471], "images_per_second": 0.505, "prompt_tokens": 12, "response_tokens_est": 14, "n_tiles": 6, "output_text": "A cat is sitting on top of a refrigerator, looking around.", "error": null, "sys_before": {"cpu_percent": 32.5, "ram_used_mb": 18637.5, "ram_available_mb": 44203.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.257, "power_cpu_cv_mean_watts": 0.876, "power_sys_5v0_mean_watts": 7.948, "gpu_utilization_percent_mean": 80.688}, "timestamp": "2026-01-30T21:47:02.288841"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3552.632, "latencies_ms": [3552.632], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "1. Cat\n2. Refrigerator\n3. Toy\n4. Toy box\n5. Toy car\n6. Toy blocks\n7. Toy blocks\n8. Toy blocks", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.301, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 73.103}, "timestamp": "2026-01-30T21:47:07.876104"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3928.408, "latencies_ms": [3928.408], "images_per_second": 0.255, "prompt_tokens": 30, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The main object in the foreground is a cat sitting on top of a refrigerator. The refrigerator is located to the right of the cat. The background includes a wall and a ceiling, which are not directly visible in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.528, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 71.455}, "timestamp": "2026-01-30T21:47:13.856382"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4622.551, "latencies_ms": [4622.551], "images_per_second": 0.216, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The image depicts a domestic scene featuring a cat sitting on top of a refrigerator. The cat is wearing a blue collar and appears to be looking towards the camera. The setting is a kitchen, as evidenced by the presence of a refrigerator and various kitchen items on top of it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.814, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 70.641}, "timestamp": "2026-01-30T21:47:20.521460"}
{"image_index": 136, "image_name": "000000014007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014007.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4997.698, "latencies_ms": [4997.698], "images_per_second": 0.2, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image features a cat sitting on top of a refrigerator, which is painted in a deep blue color. The lighting in the room is soft and warm, casting a gentle glow on the cat and the refrigerator. The background is neutral, with a beige wall and a ceiling that has a subtle, rounded design.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.58, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 69.714}, "timestamp": "2026-01-30T21:47:27.531563"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3845.529, "latencies_ms": [3845.529], "images_per_second": 0.26, "prompt_tokens": 12, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image depicts a cozy, well-organized living room with a yellow balloon floating in the air, a blue balloon on the refrigerator, and a yellow balloon on a table, all contributing to a festive atmosphere.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.583, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 72.062}, "timestamp": "2026-01-30T21:47:33.500153"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4219.626, "latencies_ms": [4219.626], "images_per_second": 0.237, "prompt_tokens": 26, "response_tokens_est": 51, "n_tiles": 6, "output_text": "- refrigerator: 1\n- microwave: 1\n- table: 1\n- chair: 1\n- bookshelf: 1\n- lamp: 1\n- wall art: 1\n- balloons: 3", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.287, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 71.167}, "timestamp": "2026-01-30T21:47:39.747310"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6133.345, "latencies_ms": [6133.345], "images_per_second": 0.163, "prompt_tokens": 30, "response_tokens_est": 83, "n_tiles": 6, "output_text": "The main objects in the image are a refrigerator, a bed, and a desk. The refrigerator is located on the left side of the image, near the foreground. The bed is in the background, slightly to the right. The desk is located in the middle of the image, near the right side. The yellow balloons are placed on the desk and the bed, adding a playful touch to the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.883, "power_cpu_cv_mean_watts": 1.956, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 69.385}, "timestamp": "2026-01-30T21:47:47.914819"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5955.756, "latencies_ms": [5955.756], "images_per_second": 0.168, "prompt_tokens": 24, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image depicts a cozy, well-organized living room with a mix of personal and decorative items. The room is furnished with a wooden coffee table, a bed with a yellow balloon, a white refrigerator, and various decorative items like books and framed pictures on the walls. The atmosphere suggests a casual, lived-in space with a touch of festivity, possibly for a birthday or celebration.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.956, "power_cpu_cv_mean_watts": 1.947, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 69.26}, "timestamp": "2026-01-30T21:47:55.889165"}
{"image_index": 137, "image_name": "000000014038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014038.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4591.077, "latencies_ms": [4591.077], "images_per_second": 0.218, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The room is brightly lit with a modern chandelier hanging from the ceiling. The walls are painted in a light color, and there are various decorations, including balloons in yellow and blue. The floor is wooden, and there are shelves filled with books and other items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18637.6, "ram_available_mb": 44203.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.02, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 70.816}, "timestamp": "2026-01-30T21:48:02.505215"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3987.864, "latencies_ms": [3987.864], "images_per_second": 0.251, "prompt_tokens": 12, "response_tokens_est": 21, "n_tiles": 12, "output_text": "A man is sitting in a train, using a laptop on a table, with a focused expression.", "error": null, "sys_before": {"cpu_percent": 25.2, "ram_used_mb": 18637.6, "ram_available_mb": 44203.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.114, "power_cpu_cv_mean_watts": 1.044, "power_sys_5v0_mean_watts": 8.873, "gpu_utilization_percent_mean": 90.121}, "timestamp": "2026-01-30T21:48:08.658927"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4766.224, "latencies_ms": [4766.224], "images_per_second": 0.21, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 12, "output_text": "1. Laptop\n2. Man\n3. Headphones\n4. Window\n5. Chair\n6. Table\n7. Keyboard\n8. Mouse", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.045, "power_cpu_cv_mean_watts": 1.242, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 89.487}, "timestamp": "2026-01-30T21:48:15.435998"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5945.173, "latencies_ms": [5945.173], "images_per_second": 0.168, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The main object in the foreground is a man sitting on a train seat, holding a laptop. The laptop is placed on a small table or bench near the man. The background features blurred train tracks and a window, indicating the train is in motion.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18636.6, "ram_available_mb": 44204.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.798, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 8.808, "gpu_utilization_percent_mean": 86.64}, "timestamp": "2026-01-30T21:48:23.426267"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5454.437, "latencies_ms": [5454.437], "images_per_second": 0.183, "prompt_tokens": 24, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image depicts a man sitting in a train carriage, engrossed in using a laptop. The setting is inside a train, with a window providing natural light and a cushioned seat visible in the background.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18636.6, "ram_available_mb": 44204.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.217, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 87.467}, "timestamp": "2026-01-30T21:48:30.919065"}
{"image_index": 138, "image_name": "000000014226.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014226.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7458.951, "latencies_ms": [7458.951], "images_per_second": 0.134, "prompt_tokens": 22, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The image features a man sitting in a train, holding a laptop. The laptop is silver and has an Apple logo on it. The man is wearing a dark jacket and has red hair. The train interior has a beige and brown color scheme, with a window showing a blurry view outside. The lighting is dim, with a warm tone, possibly from the interior lighting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.984, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 84.619}, "timestamp": "2026-01-30T21:48:40.425672"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3595.37, "latencies_ms": [3595.37], "images_per_second": 0.278, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The image depicts a modern train station with multiple tracks and a sleek, silver train moving along them, set against a backdrop of a cloudy sky and a cityscape with buildings in the distance.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.231, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 72.517}, "timestamp": "2026-01-30T21:48:46.126934"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3576.64, "latencies_ms": [3576.64], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.119, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 72.655}, "timestamp": "2026-01-30T21:48:51.734556"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5335.701, "latencies_ms": [5335.701], "images_per_second": 0.187, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main objects in the image are a train and a bridge. The train is positioned in the foreground, with its front end closer to the viewer. The bridge is in the background, spanning across the image and connecting the two sides. The train is on the tracks, while the bridge is supported by metal beams and spans over the tracks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.283, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T21:48:59.081074"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3564.997, "latencies_ms": [3564.997], "images_per_second": 0.281, "prompt_tokens": 24, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The image depicts a modern train station with a sleek, silver train moving along the tracks. The station is surrounded by a series of metal structures and platforms, with a clear blue sky overhead.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.2, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.147, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 72.724}, "timestamp": "2026-01-30T21:49:04.677239"}
{"image_index": 139, "image_name": "000000014380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5318.715, "latencies_ms": [5318.715], "images_per_second": 0.188, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image showcases a modern train station with a sleek, silver train in motion on the tracks. The station is surrounded by a clear blue sky with scattered white clouds, indicating a bright and sunny day. The station's infrastructure, including the metal beams and platforms, is well-lit by natural sunlight, creating a vibrant and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.2, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.293, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 69.568}, "timestamp": "2026-01-30T21:49:12.007710"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2982.298, "latencies_ms": [2982.298], "images_per_second": 0.335, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "A group of people are gathered in a park, with a colorful kite being flown by a woman and a child, while others sit and watch.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.314, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 75.708}, "timestamp": "2026-01-30T21:49:17.089252"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4581.467, "latencies_ms": [4581.467], "images_per_second": 0.218, "prompt_tokens": 26, "response_tokens_est": 57, "n_tiles": 6, "output_text": "1. Kite: 1\n2. Person: 3\n3. Person: 2\n4. Person: 1\n5. Person: 1\n6. Person: 1\n7. Person: 1\n8. Person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.934, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 70.974}, "timestamp": "2026-01-30T21:49:23.685209"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6088.521, "latencies_ms": [6088.521], "images_per_second": 0.164, "prompt_tokens": 30, "response_tokens_est": 82, "n_tiles": 6, "output_text": "In the image, the main object, a colorful kite, is prominently positioned in the foreground. The kite is being flown by a person standing to the right of the frame. In the background, there are several people scattered across the grassy field, some of whom are walking or standing. The kite is the central focus, with the people and the field serving as the background elements.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.868, "power_cpu_cv_mean_watts": 1.955, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 69.216}, "timestamp": "2026-01-30T21:49:31.798513"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6830.367, "latencies_ms": [6830.367], "images_per_second": 0.146, "prompt_tokens": 24, "response_tokens_est": 94, "n_tiles": 6, "output_text": "The image depicts a vibrant outdoor scene in a park where a group of people is gathered to fly a colorful kite. The kite, with its vivid colors and intricate patterns, is being held aloft by a person in the foreground. In the background, other individuals are scattered around the grassy field, some sitting on chairs, while others are standing or walking. The setting is a sunny day, and the overall atmosphere is one of leisure and enjoyment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.385, "power_cpu_cv_mean_watts": 1.989, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 68.207}, "timestamp": "2026-01-30T21:49:40.648757"}
{"image_index": 140, "image_name": "000000014439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014439.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4713.673, "latencies_ms": [4713.673], "images_per_second": 0.212, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The kite in the image is vibrant and colorful, featuring a combination of blue, purple, yellow, and orange hues. It is being flown by a person in a light-colored shirt, and the kite is illuminated by the sunlight, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.712, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 70.282}, "timestamp": "2026-01-30T21:49:47.398585"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2577.261, "latencies_ms": [2577.261], "images_per_second": 0.388, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "A model of a red and black train is seen on tracks with several workers in orange uniforms working on the tracks.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.009, "power_cpu_cv_mean_watts": 1.183, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 76.571}, "timestamp": "2026-01-30T21:49:52.103291"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3569.286, "latencies_ms": [3569.286], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.058, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 72.233}, "timestamp": "2026-01-30T21:49:57.718151"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4595.637, "latencies_ms": [4595.637], "images_per_second": 0.218, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The main objects in the image are a model train and a group of railway workers. The model train is positioned in the foreground, while the railway workers are in the background. The workers are near the tracks, working on the ground, while the model train is on the tracks.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.806, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.282}, "timestamp": "2026-01-30T21:50:04.339578"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4362.258, "latencies_ms": [4362.258], "images_per_second": 0.229, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The image depicts a miniature model of a train and railway track, with a group of railway workers in orange uniforms working on the tracks. The scene is set in a rural or semi-rural area, with greenery and a fence visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.98, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 70.432}, "timestamp": "2026-01-30T21:50:10.730238"}
{"image_index": 141, "image_name": "000000014473.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014473.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3863.061, "latencies_ms": [3863.061], "images_per_second": 0.259, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image features a red and black train with the Virgin logo on its side, moving on tracks surrounded by greenery. The scene is well-lit, with natural sunlight casting shadows on the train and the surrounding landscape.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.76, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 71.969}, "timestamp": "2026-01-30T21:50:16.635123"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4329.656, "latencies_ms": [4329.656], "images_per_second": 0.231, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "The image shows a close-up of a cat's fur, which appears to be a mix of light brown and white colors.", "error": null, "sys_before": {"cpu_percent": 26.1, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.343, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.798, "gpu_utilization_percent_mean": 88.639}, "timestamp": "2026-01-30T21:50:23.106209"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3460.206, "latencies_ms": [3460.206], "images_per_second": 0.289, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 12, "output_text": "cat: 1\nblanket: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.86, "power_cpu_cv_mean_watts": 0.815, "power_sys_5v0_mean_watts": 8.777, "gpu_utilization_percent_mean": 93.75}, "timestamp": "2026-01-30T21:50:28.592136"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5958.551, "latencies_ms": [5958.551], "images_per_second": 0.168, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The main object in the image is a cat's fur, which occupies the foreground. The fur is primarily light brown with some white areas. The background is a textured fabric, possibly a couch or a blanket, which is slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.827, "power_cpu_cv_mean_watts": 1.48, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 86.633}, "timestamp": "2026-01-30T21:50:36.563508"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6061.858, "latencies_ms": [6061.858], "images_per_second": 0.165, "prompt_tokens": 24, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image shows a close-up of a cat's fur, which appears to be a mix of light brown and white colors. The cat is lying down on a textured surface, possibly a bed or a soft fabric, with its head turned slightly to the side.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.817, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 86.46}, "timestamp": "2026-01-30T21:50:44.640107"}
{"image_index": 142, "image_name": "000000014831.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014831.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6414.524, "latencies_ms": [6414.524], "images_per_second": 0.156, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image shows a close-up of a cat's fur with a mix of light brown and white colors. The lighting is soft and diffused, creating gentle shadows and highlights on the fur. The background appears to be a textured fabric, possibly a blanket or a piece of clothing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.218, "power_cpu_cv_mean_watts": 1.552, "power_sys_5v0_mean_watts": 8.762, "gpu_utilization_percent_mean": 84.364}, "timestamp": "2026-01-30T21:50:53.098950"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4835.604, "latencies_ms": [4835.604], "images_per_second": 0.207, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image shows a close-up of a black and white cow's head, with a red and white feeding tube attached to its mouth, indicating that it is being fed.", "error": null, "sys_before": {"cpu_percent": 24.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.964, "power_cpu_cv_mean_watts": 1.302, "power_sys_5v0_mean_watts": 8.855, "gpu_utilization_percent_mean": 86.75}, "timestamp": "2026-01-30T21:51:00.067543"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5751.412, "latencies_ms": [5751.412], "images_per_second": 0.174, "prompt_tokens": 26, "response_tokens_est": 49, "n_tiles": 12, "output_text": "1. Dog\n2. Dog's ear\n3. Dog's paw\n4. Dog's nose\n5. Dog's mouth\n6. Dog's tail\n7. Dog's paw\n8. Dog's paw", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.042, "power_cpu_cv_mean_watts": 1.444, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 87.292}, "timestamp": "2026-01-30T21:51:07.834117"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7893.573, "latencies_ms": [7893.573], "images_per_second": 0.127, "prompt_tokens": 30, "response_tokens_est": 84, "n_tiles": 12, "output_text": "The main object in the foreground is a black and white cow, which is positioned near the center of the image. The cow is interacting with a red and white plastic bottle, which is placed to the right of the cow. The bottle is partially buried in the dirt, indicating that it has been used for feeding the cow. The background is out of focus, emphasizing the cow and the bottle in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.833, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 84.269}, "timestamp": "2026-01-30T21:51:17.780558"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8019.603, "latencies_ms": [8019.603], "images_per_second": 0.125, "prompt_tokens": 24, "response_tokens_est": 86, "n_tiles": 12, "output_text": "The image depicts a close-up view of a black and white cow's head, with its mouth slightly open, revealing its tongue. The cow is standing on a concrete surface, surrounded by various objects and debris, including a black container with a red lid, a yellow label, and a metal pipe. The setting appears to be a farm or livestock area, with the cow likely being part of a herd or being fed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.697, "power_cpu_cv_mean_watts": 1.738, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 83.912}, "timestamp": "2026-01-30T21:51:27.821186"}
{"image_index": 143, "image_name": "000000014888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000014888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5160.394, "latencies_ms": [5160.394], "images_per_second": 0.194, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 12, "output_text": "The image shows a black and white cow with a shiny, wet coat, indicating recent rain. The lighting is dim, with a soft, natural light source illuminating the cow's fur.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.525, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 88.07}, "timestamp": "2026-01-30T21:51:35.011618"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3268.851, "latencies_ms": [3268.851], "images_per_second": 0.306, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 6, "output_text": "The image shows a plate of savory sandwiches with a side of pickles, placed on a patterned tablecloth, and a knife is partially visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 31.6, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.767, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 8.068, "gpu_utilization_percent_mean": 73.889}, "timestamp": "2026-01-30T21:51:40.386334"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2595.483, "latencies_ms": [2595.483], "images_per_second": 0.385, "prompt_tokens": 26, "response_tokens_est": 24, "n_tiles": 6, "output_text": "- plate: 1\n- sandwich: 1\n- knife: 1\n- fork: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.103, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 77.048}, "timestamp": "2026-01-30T21:51:45.029160"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4043.799, "latencies_ms": [4043.799], "images_per_second": 0.247, "prompt_tokens": 30, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The main object in the foreground is a plate with a sandwich and a knife. The sandwich is placed on the plate, and the knife is positioned near the plate. The background is dark, which makes the plate and sandwich stand out.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.455, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 71.412}, "timestamp": "2026-01-30T21:51:51.088515"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5318.482, "latencies_ms": [5318.482], "images_per_second": 0.188, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image depicts a plate of sandwiches, which are placed on a patterned tablecloth. The sandwiches are cut in half, revealing their contents, and a knife with a black handle is resting on the table, ready for use. The overall setting suggests a cozy, intimate dining environment, possibly in a home or a small restaurant.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.22, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T21:51:58.433551"}
{"image_index": 144, "image_name": "000000015079.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015079.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4048.827, "latencies_ms": [4048.827], "images_per_second": 0.247, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image features a plate of food with a light-colored bread and a dark, possibly red or purple filling. The plate is adorned with a decorative pattern, and the lighting is warm and soft, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.496, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 71.455}, "timestamp": "2026-01-30T21:52:04.511342"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4108.478, "latencies_ms": [4108.478], "images_per_second": 0.243, "prompt_tokens": 12, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image shows a colorful assortment of food items arranged in various colored containers, including a red container with spaghetti and meatballs, a green container with carrots, a blue container with grapes, and a purple container with a salad.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.271, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 71.618}, "timestamp": "2026-01-30T21:52:10.759527"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3032.878, "latencies_ms": [3032.878], "images_per_second": 0.33, "prompt_tokens": 26, "response_tokens_est": 31, "n_tiles": 6, "output_text": "- pasta: 1\n- meat: 1\n- cheese: 1\n- vegetables: 3\n- grapes: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.067, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 74.28}, "timestamp": "2026-01-30T21:52:15.828324"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7490.357, "latencies_ms": [7490.357], "images_per_second": 0.134, "prompt_tokens": 30, "response_tokens_est": 105, "n_tiles": 6, "output_text": "The main objects in the image are arranged in a visually appealing manner. The left side of the image features a purple container with a red pasta dish, while the right side has a green container with a green vegetable salad. In the foreground, there is a blue container with a green vegetable salad. The background is filled with other containers, but they are not the focus of the image. The arrangement creates a sense of balance and organization, with the pasta dish and salad in the foreground and the other containers in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.203, "power_cpu_cv_mean_watts": 2.01, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 68.302}, "timestamp": "2026-01-30T21:52:25.362911"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5122.203, "latencies_ms": [5122.203], "images_per_second": 0.195, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The image shows a colorful assortment of food items arranged neatly in various colored trays. The scene appears to be set in a kitchen or dining area, with the food items including pasta, vegetables, and grapes. The setting suggests a meal or snack time, with the food items being prepared and ready to be eaten.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.455, "power_cpu_cv_mean_watts": 1.845, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.953}, "timestamp": "2026-01-30T21:52:32.511586"}
{"image_index": 145, "image_name": "000000015254.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015254.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5677.192, "latencies_ms": [5677.192], "images_per_second": 0.176, "prompt_tokens": 22, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The image features a colorful assortment of food items arranged in various colored trays. The vibrant colors of the food, such as the red sauce in the orange tray, the green grapes in the blue tray, and the green vegetables in the purple tray, stand out against the dark background. The lighting is bright and even, highlighting the textures and colors of the food.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.01, "power_cpu_cv_mean_watts": 1.875, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 69.723}, "timestamp": "2026-01-30T21:52:40.201512"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3783.009, "latencies_ms": [3783.009], "images_per_second": 0.264, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The image captures a vibrant scene of cherry blossoms in full bloom, with the blossoms forming a dense canopy that partially obscures the view of a nearby building, creating a picturesque and serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 24.8, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.805, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 71.969}, "timestamp": "2026-01-30T21:52:46.110647"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3558.765, "latencies_ms": [3558.765], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.149, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 72.567}, "timestamp": "2026-01-30T21:52:51.706058"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5236.142, "latencies_ms": [5236.142], "images_per_second": 0.191, "prompt_tokens": 30, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The main objects in the image are the cherry blossoms in full bloom, which are in the foreground. The background features a traffic light, which is slightly out of focus. The cherry blossoms are densely packed, creating a lush and vibrant foreground, while the traffic light is positioned in the middle ground, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.464, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 69.705}, "timestamp": "2026-01-30T21:52:58.962502"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4009.661, "latencies_ms": [4009.661], "images_per_second": 0.249, "prompt_tokens": 24, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image captures a vibrant scene of cherry blossoms in full bloom, with their delicate pink petals swaying gently in the wind. The blossoms are densely packed on a tree, creating a picturesque and serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.62, "power_cpu_cv_mean_watts": 1.708, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 71.559}, "timestamp": "2026-01-30T21:53:05.019702"}
{"image_index": 146, "image_name": "000000015272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015272.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3839.231, "latencies_ms": [3839.231], "images_per_second": 0.26, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image showcases a tree in full bloom, with its branches adorned with delicate pink flowers. The lighting is soft and diffused, likely due to an overcast sky, creating a gentle and serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.854, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 72.281}, "timestamp": "2026-01-30T21:53:10.915660"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4385.7, "latencies_ms": [4385.7], "images_per_second": 0.228, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 12, "output_text": "The image shows a plate of broccoli and other vegetables, including pieces of potato, with a piece of grilled salmon on top.", "error": null, "sys_before": {"cpu_percent": 24.7, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.45, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 87.111}, "timestamp": "2026-01-30T21:53:17.438341"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4906.879, "latencies_ms": [4906.879], "images_per_second": 0.204, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 12, "output_text": "broccoli: 10\nonion: 1\ngarlic: 1\nchili: 1\npepper: 1\nrice: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.831, "power_cpu_cv_mean_watts": 1.299, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 88.317}, "timestamp": "2026-01-30T21:53:24.371425"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7262.164, "latencies_ms": [7262.164], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The main object in the foreground is a plate of broccoli and other vegetables. The broccoli is the most prominent vegetable, occupying the center of the plate. The other vegetables, such as carrots and possibly other greens, are scattered around the broccoli. The background is slightly blurred, indicating that the focus is on the broccoli and the other vegetables.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.13, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 84.532}, "timestamp": "2026-01-30T21:53:33.667839"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5126.934, "latencies_ms": [5126.934], "images_per_second": 0.195, "prompt_tokens": 24, "response_tokens_est": 39, "n_tiles": 12, "output_text": "The image depicts a plate of broccoli and other vegetables, likely prepared for a meal. The setting appears to be a dining table, with the focus on the colorful and healthy meal.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.653, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 88.651}, "timestamp": "2026-01-30T21:53:40.846888"}
{"image_index": 147, "image_name": "000000015278.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015278.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6889.153, "latencies_ms": [6889.153], "images_per_second": 0.145, "prompt_tokens": 22, "response_tokens_est": 68, "n_tiles": 12, "output_text": "The image showcases a plate of broccoli and other vegetables, with the broccoli being the most prominent color due to its vibrant green hue. The lighting is bright and even, highlighting the textures and colors of the food. The plate itself is white, providing a clean and neutral background that makes the colors of the food stand out.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.314, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.866, "gpu_utilization_percent_mean": 85.172}, "timestamp": "2026-01-30T21:53:49.774824"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5247.576, "latencies_ms": [5247.576], "images_per_second": 0.191, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image depicts a dimly lit indoor setting with a group of people seated around a table, some of whom are engaged in conversation, while others appear to be focused on their phones or other devices.", "error": null, "sys_before": {"cpu_percent": 30.3, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.567, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.887, "gpu_utilization_percent_mean": 86.136}, "timestamp": "2026-01-30T21:53:57.197096"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4704.85, "latencies_ms": [4704.85], "images_per_second": 0.213, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Person\n2. Person\n3. Person\n4. Person\n5. Person\n6. Person\n7. Person\n8. Person", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.148, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 89.538}, "timestamp": "2026-01-30T21:54:03.927517"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6170.957, "latencies_ms": [6170.957], "images_per_second": 0.162, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The main objects in the image are a group of people sitting at a table. The person in the foreground is a young boy eating, while the other people are seated in the background. The table is located in the middle of the image, with the people sitting around it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.777, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 86.385}, "timestamp": "2026-01-30T21:54:12.123779"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6319.51, "latencies_ms": [6319.51], "images_per_second": 0.158, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a dimly lit indoor setting, likely a restaurant or bar, with patrons seated at tables. The atmosphere is cozy and intimate, with warm lighting creating a relaxed ambiance. The focus is on a young boy eating, while other patrons are visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.593, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 85.415}, "timestamp": "2026-01-30T21:54:20.481517"}
{"image_index": 148, "image_name": "000000015335.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015335.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4792.423, "latencies_ms": [4792.423], "images_per_second": 0.209, "prompt_tokens": 22, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The image depicts a dimly lit indoor setting with warm, orange lighting. The individuals are seated, and the background features a wrought iron railing.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.739, "power_cpu_cv_mean_watts": 1.252, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 88.85}, "timestamp": "2026-01-30T21:54:27.298018"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2580.345, "latencies_ms": [2580.345], "images_per_second": 0.388, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "A yellow bus is parked on the side of a street, with a white van and a building in the background.", "error": null, "sys_before": {"cpu_percent": 23.8, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.003, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 76.143}, "timestamp": "2026-01-30T21:54:31.993381"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3064.509, "latencies_ms": [3064.509], "images_per_second": 0.326, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Bus\n2. Bus\n3. Bus\n4. Bus\n5. Bus\n6. Bus\n7. Bus\n8. Bus", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.079, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 74.16}, "timestamp": "2026-01-30T21:54:37.104722"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4170.488, "latencies_ms": [4170.488], "images_per_second": 0.24, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The main objects in the image are a bus and a building. The bus is located in the foreground, near the sidewalk, while the building is in the background. The bus is positioned closer to the foreground, while the building is further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.478, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 71.529}, "timestamp": "2026-01-30T21:54:43.307143"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4892.848, "latencies_ms": [4892.848], "images_per_second": 0.204, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image depicts a city street scene with a yellow bus in the foreground, moving along a curved road. The setting appears to be a modern urban area with a mix of buildings, trees, and a sidewalk. The bus is the main focus, and the scene is captured during daylight with clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.669, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 70.325}, "timestamp": "2026-01-30T21:54:50.215537"}
{"image_index": 149, "image_name": "000000015338.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015338.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4960.537, "latencies_ms": [4960.537], "images_per_second": 0.202, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The image depicts a sunny day with clear blue skies. The scene is characterized by the bright yellow bus in the foreground, contrasting sharply with the gray and beige buildings in the background. The lighting is natural, with shadows cast by the trees and buildings, indicating the sun is high in the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.601, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 69.854}, "timestamp": "2026-01-30T21:54:57.188681"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3251.627, "latencies_ms": [3251.627], "images_per_second": 0.308, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The image depicts a stop sign mounted on a metal pole, with a blue car visible in the background, and a clear, sunny sky casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 31.3, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.543, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 8.068, "gpu_utilization_percent_mean": 73.148}, "timestamp": "2026-01-30T21:55:02.568901"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3544.325, "latencies_ms": [3544.325], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.296, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 73.483}, "timestamp": "2026-01-30T21:55:08.164947"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5422.577, "latencies_ms": [5422.577], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The main objects in the image are a stop sign and a metal fence. The stop sign is positioned in the foreground, near the bottom left corner of the image. The metal fence is situated in the background, to the right of the stop sign. The fence is partially obscured by the stop sign, creating a sense of depth in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.37, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.6}, "timestamp": "2026-01-30T21:55:15.616853"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5841.131, "latencies_ms": [5841.131], "images_per_second": 0.171, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The image depicts a scene in an urban setting during what appears to be either sunrise or sunset, given the warm, golden light bathing the surroundings. A stop sign is prominently displayed on a metal pole, with a blue car visible in the background. The sign and the car are situated on a paved area, bordered by a metal fence and some greenery.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.992, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 69.245}, "timestamp": "2026-01-30T21:55:23.493377"}
{"image_index": 150, "image_name": "000000015440.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015440.jpg", "image_width": 404, "image_height": 640, "image_resolution": "404x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6206.863, "latencies_ms": [6206.863], "images_per_second": 0.161, "prompt_tokens": 22, "response_tokens_est": 84, "n_tiles": 6, "output_text": "The image features a stop sign with a red octagonal shape and white lettering, mounted on a metal pole. The sign is illuminated by the warm, golden light of a setting or rising sun, casting long shadows and creating a serene atmosphere. The surrounding area includes a paved road, a metal fence with arches, and some greenery, all bathed in the soft glow of the sun.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.788, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 69.135}, "timestamp": "2026-01-30T21:55:31.749187"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4068.793, "latencies_ms": [4068.793], "images_per_second": 0.246, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "A cat is lying on a black surface, with its paws wrapped around a white and black cord.", "error": null, "sys_before": {"cpu_percent": 29.3, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.734, "power_cpu_cv_mean_watts": 1.084, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 89.588}, "timestamp": "2026-01-30T21:55:37.971557"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3697.997, "latencies_ms": [3697.997], "images_per_second": 0.27, "prompt_tokens": 26, "response_tokens_est": 15, "n_tiles": 12, "output_text": "cat: 1\nmouse: 1\ncord: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.427, "power_cpu_cv_mean_watts": 0.894, "power_sys_5v0_mean_watts": 8.771, "gpu_utilization_percent_mean": 93.267}, "timestamp": "2026-01-30T21:55:43.681776"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6130.15, "latencies_ms": [6130.15], "images_per_second": 0.163, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The main object in the foreground is a white cat with black stripes, which is lying on a black surface. The cat's paws are holding a white cord. In the background, there is a black object, possibly a piece of furniture or clothing, partially visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.718, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 86.431}, "timestamp": "2026-01-30T21:55:51.843081"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6499.322, "latencies_ms": [6499.322], "images_per_second": 0.154, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image depicts a domestic cat lying on a dark surface, possibly a bed or couch, with its paws resting on a white mouse. The cat's eyes are open, and it appears to be looking directly at the camera. The setting is indoors, and the cat seems relaxed and comfortable.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.482, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.797, "gpu_utilization_percent_mean": 85.685}, "timestamp": "2026-01-30T21:56:00.374696"}
{"image_index": 151, "image_name": "000000015497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015497.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6411.445, "latencies_ms": [6411.445], "images_per_second": 0.156, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The image features a cat with a white and brown tabby coat, sitting on a dark surface. The lighting is dim, casting a soft glow on the cat's fur. The cat's eyes are a striking green, adding a vibrant contrast to the overall dark and muted tones of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.571, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 85.926}, "timestamp": "2026-01-30T21:56:08.820320"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4582.921, "latencies_ms": [4582.921], "images_per_second": 0.218, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The image depicts a bustling urban scene with a variety of buses and vehicles navigating through a busy city street, surrounded by modern buildings and infrastructure.", "error": null, "sys_before": {"cpu_percent": 26.4, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.282, "power_cpu_cv_mean_watts": 1.233, "power_sys_5v0_mean_watts": 8.867, "gpu_utilization_percent_mean": 88.868}, "timestamp": "2026-01-30T21:56:15.548180"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4099.812, "latencies_ms": [4099.812], "images_per_second": 0.244, "prompt_tokens": 26, "response_tokens_est": 21, "n_tiles": 12, "output_text": "bus: 5\nbuilding: 1\ntrees: 1\nsign: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.594, "power_cpu_cv_mean_watts": 1.013, "power_sys_5v0_mean_watts": 8.763, "gpu_utilization_percent_mean": 90.5}, "timestamp": "2026-01-30T21:56:21.695493"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7221.521, "latencies_ms": [7221.521], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The main objects in the image are a bus and a cityscape. The bus is in the foreground, near the bottom left corner, while the cityscape is in the background, stretching across the entire image. The bus is parked on the side of the road, and the cityscape features various buildings, including a tall tower with a red and white antenna.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.067, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 84.689}, "timestamp": "2026-01-30T21:56:30.957789"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6239.577, "latencies_ms": [6239.577], "images_per_second": 0.16, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The image depicts a bustling urban scene with a busy street filled with various buses and vehicles. The setting appears to be a city with modern buildings and infrastructure, including a bridge and overhead power lines. The weather is overcast, and the overall atmosphere is busy and dynamic.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.583, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 85.811}, "timestamp": "2026-01-30T21:56:39.212113"}
{"image_index": 152, "image_name": "000000015517.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015517.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6565.427, "latencies_ms": [6565.427], "images_per_second": 0.152, "prompt_tokens": 22, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The image depicts a bustling urban scene with a mix of modern and traditional architectural styles. The sky is partly cloudy, providing a soft, diffused light that enhances the colors and textures of the scene. The buses, with their varied colors and designs, add vibrancy to the urban landscape.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.427, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 85.436}, "timestamp": "2026-01-30T21:56:47.800165"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2621.149, "latencies_ms": [2621.149], "images_per_second": 0.382, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A young man is performing a skateboard trick on a ramp, with a large tent and other equipment in the background.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.078, "power_cpu_cv_mean_watts": 1.297, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 74.19}, "timestamp": "2026-01-30T21:56:52.531590"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4600.05, "latencies_ms": [4600.05], "images_per_second": 0.217, "prompt_tokens": 26, "response_tokens_est": 57, "n_tiles": 6, "output_text": "skateboard: 1\nskateboarder: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.84, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 70.395}, "timestamp": "2026-01-30T21:56:59.166245"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6420.686, "latencies_ms": [6420.686], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 87, "n_tiles": 6, "output_text": "The main object in the foreground is a skateboarder performing a trick on a ramp. The skateboarder is positioned near the center of the image, with their skateboard and feet clearly visible. The background features a series of large, open tents, suggesting a temporary or outdoor setting. The skateboarder's shadow is cast on the ground, indicating that the light source is coming from the right side of the image.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.575, "power_cpu_cv_mean_watts": 1.943, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 68.389}, "timestamp": "2026-01-30T21:57:07.647011"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5508.06, "latencies_ms": [5508.06], "images_per_second": 0.182, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts a skateboarder performing a trick on a ramp at an outdoor skate park. The skate park is surrounded by large, tarp-covered structures, and there are other skateboards and bicycles scattered around. The setting appears to be a sunny day, and the skateboarder is wearing a hat and shorts, indicating warm weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.046, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 69.348}, "timestamp": "2026-01-30T21:57:15.195164"}
{"image_index": 153, "image_name": "000000015597.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015597.jpg", "image_width": 433, "image_height": 640, "image_resolution": "433x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5324.328, "latencies_ms": [5324.328], "images_per_second": 0.188, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image depicts a skateboarder performing a trick on a concrete ramp, with a clear blue sky overhead. The skateboarder is wearing a white hat and black shorts, and the ramp is covered in a light-colored material. The lighting is bright and natural, casting shadows of the skateboarder and the ramp onto the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.127, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 69.682}, "timestamp": "2026-01-30T21:57:22.534150"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2309.874, "latencies_ms": [2309.874], "images_per_second": 0.433, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 2, "output_text": "A person is windsurfing on the ocean, holding onto a board with a sail, while other windsurfers are also seen in the distance.", "error": null, "sys_before": {"cpu_percent": 23.6, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.733, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 7.13, "gpu_utilization_percent_mean": 64.421}, "timestamp": "2026-01-30T21:57:26.922468"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2838.635, "latencies_ms": [2838.635], "images_per_second": 0.352, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 2, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.922, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 7.288, "gpu_utilization_percent_mean": 62.13}, "timestamp": "2026-01-30T21:57:31.804913"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4624.148, "latencies_ms": [4624.148], "images_per_second": 0.216, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 2, "output_text": "The main objects in the image are a person kiteboarding and several kites flying in the sky. The person is positioned in the foreground, on a kiteboard, while the kites are in the background, flying high above the water. The kites are near the person, indicating that the person is actively kiteboarding.", "error": null, "sys_before": {"cpu_percent": 11.8, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.915, "power_cpu_cv_mean_watts": 2.074, "power_sys_5v0_mean_watts": 7.317, "gpu_utilization_percent_mean": 62.59}, "timestamp": "2026-01-30T21:57:38.466674"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4896.561, "latencies_ms": [4896.561], "images_per_second": 0.204, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 2, "output_text": "The image captures a serene beach scene with a person windsurfing in the ocean. The person is wearing a wetsuit and is holding onto a windsurf board, which is partially submerged in the water. The ocean is calm with gentle waves, and several kites are flying in the sky, adding to the picturesque atmosphere of the beach.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.861, "power_cpu_cv_mean_watts": 2.061, "power_sys_5v0_mean_watts": 7.306, "gpu_utilization_percent_mean": 62.634}, "timestamp": "2026-01-30T21:57:45.399503"}
{"image_index": 154, "image_name": "000000015660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015660.jpg", "image_width": 640, "image_height": 348, "image_resolution": "640x348", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2733.812, "latencies_ms": [2733.812], "images_per_second": 0.366, "prompt_tokens": 22, "response_tokens_est": 38, "n_tiles": 2, "output_text": "The image depicts a vibrant scene at the beach with clear blue skies and a few scattered clouds. The ocean waves are gently crashing onto the shore, creating a dynamic and lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.505, "power_cpu_cv_mean_watts": 1.828, "power_sys_5v0_mean_watts": 7.2, "gpu_utilization_percent_mean": 63.261}, "timestamp": "2026-01-30T21:57:50.182846"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3160.933, "latencies_ms": [3160.933], "images_per_second": 0.316, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 6, "output_text": "The image shows a vibrant red fire hydrant situated in a lush green grassy area, with a backdrop of a residential building and a variety of trees and flowers.", "error": null, "sys_before": {"cpu_percent": 32.6, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.893, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 73.808}, "timestamp": "2026-01-30T21:57:55.489416"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3565.331, "latencies_ms": [3565.331], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.34, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 72.552}, "timestamp": "2026-01-30T21:58:01.073504"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5291.421, "latencies_ms": [5291.421], "images_per_second": 0.189, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main object in the foreground is a red fire hydrant, which is situated on the grass. The hydrant is positioned near the center of the image, slightly to the left. In the background, there is a house with a white exterior and a window with purple flowers. The house is slightly to the right of the hydrant.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.491, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 70.159}, "timestamp": "2026-01-30T21:58:08.414831"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4708.965, "latencies_ms": [4708.965], "images_per_second": 0.212, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a vibrant red fire hydrant situated in a lush, green grassy area with a backdrop of a residential building and trees. The hydrant appears weathered, with some rust and wear visible on its surface, indicating it has been exposed to the elements for some time.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.853, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 70.308}, "timestamp": "2026-01-30T21:58:15.170450"}
{"image_index": 155, "image_name": "000000015746.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015746.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4418.477, "latencies_ms": [4418.477], "images_per_second": 0.226, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The notable visual attributes of the image include a vivid red fire hydrant with a black cap and a black hose attachment, set against a lush green grassy background. The lighting is natural, suggesting it is daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.017, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 70.944}, "timestamp": "2026-01-30T21:58:21.617380"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3003.175, "latencies_ms": [3003.175], "images_per_second": 0.333, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The image depicts a close-up view of a blue wooden surface with a few birds perched on it, including a bird in mid-flight.", "error": null, "sys_before": {"cpu_percent": 37.9, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.246, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 75.333}, "timestamp": "2026-01-30T21:58:26.743681"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4043.219, "latencies_ms": [4043.219], "images_per_second": 0.247, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 6, "output_text": "birds: 3\nbirds: 2\nbirds: 1\nbirds: 1\nbirds: 1\nbirds: 1\nbirds: 1\nbirds: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.501, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 70.735}, "timestamp": "2026-01-30T21:58:32.804378"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4770.319, "latencies_ms": [4770.319], "images_per_second": 0.21, "prompt_tokens": 30, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The main objects in the image are a pair of birds and a piece of wood. The birds are positioned near the bottom left corner of the image, while the wood is in the background. The birds are in close proximity to the wood, suggesting they may be perched or resting on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.769, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 70.45}, "timestamp": "2026-01-30T21:58:39.613527"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5541.611, "latencies_ms": [5541.611], "images_per_second": 0.18, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The image depicts a close-up view of a weathered wooden surface with a blue paint finish. Birds are perched on the surface, with one bird in the foreground appearing to be in the process of eating or catching something. The setting suggests an outdoor or rustic environment, possibly a park or a backyard, with the birds engaging in typical avian behavior.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.125, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 69.617}, "timestamp": "2026-01-30T21:58:47.216388"}
{"image_index": 156, "image_name": "000000015751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015751.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3546.739, "latencies_ms": [3546.739], "images_per_second": 0.282, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The image features a weathered, teal-colored wooden surface with visible signs of wear and age. The lighting is soft and diffused, casting gentle shadows and highlighting the texture of the wood.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.256, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 73.138}, "timestamp": "2026-01-30T21:58:52.783589"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3733.679, "latencies_ms": [3733.679], "images_per_second": 0.268, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 12, "output_text": "A woman is walking through a rustic barn with a brown horse in the background.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.629, "power_cpu_cv_mean_watts": 0.969, "power_sys_5v0_mean_watts": 8.853, "gpu_utilization_percent_mean": 91.484}, "timestamp": "2026-01-30T21:58:58.688008"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4835.176, "latencies_ms": [4835.176], "images_per_second": 0.207, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Horse\n2. Barn\n3. Horses\n4. Woman\n5. Horse\n6. Horses\n7. Horse\n8. Horse", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.79, "power_cpu_cv_mean_watts": 1.28, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 88.61}, "timestamp": "2026-01-30T21:59:05.579679"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6256.524, "latencies_ms": [6256.524], "images_per_second": 0.16, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The main object in the foreground is a woman wearing blue jeans and white shoes, standing near the dirt ground. The background features a horse in a stable with a wooden wall and a red door. The stable has various items like a bucket, a ladder, and a wooden bench.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.584, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 86.077}, "timestamp": "2026-01-30T21:59:13.849167"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5475.329, "latencies_ms": [5475.329], "images_per_second": 0.183, "prompt_tokens": 24, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image depicts a rustic, rural setting with a brown horse in a stable. A woman is walking through the stable, and the environment is filled with various tools and equipment, indicating a working farm or ranch.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.088, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 86.935}, "timestamp": "2026-01-30T21:59:21.374234"}
{"image_index": 157, "image_name": "000000015956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000015956.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4996.765, "latencies_ms": [4996.765], "images_per_second": 0.2, "prompt_tokens": 22, "response_tokens_est": 36, "n_tiles": 12, "output_text": "The image depicts a rustic barn with a dirt floor and wooden walls. The lighting is natural, with sunlight streaming in through a window, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.663, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.769, "gpu_utilization_percent_mean": 88.122}, "timestamp": "2026-01-30T21:59:28.387247"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5197.747, "latencies_ms": [5197.747], "images_per_second": 0.192, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image depicts a serene and lush green meadow with a variety of wildlife, including a zebra grazing and a herd of elephants and rhinos peacefully coexisting in the background.", "error": null, "sys_before": {"cpu_percent": 23.6, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.6, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.625, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 8.85, "gpu_utilization_percent_mean": 86.93}, "timestamp": "2026-01-30T21:59:35.715533"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6671.378, "latencies_ms": [6671.378], "images_per_second": 0.15, "prompt_tokens": 26, "response_tokens_est": 64, "n_tiles": 12, "output_text": "1. Rhino: 1\n2. Elephant: 1\n3. Zebra: 1\n4. Buffalo: 1\n5. Giraffe: 1\n6. Antelope: 1\n7. Deer: 1\n8. Cattle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.38, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 85.339}, "timestamp": "2026-01-30T21:59:44.443690"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6991.113, "latencies_ms": [6991.113], "images_per_second": 0.143, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The main objects in the image are a herd of zebras and a group of rhinos. The zebras are in the foreground, grazing on the green grass, while the rhinos are in the background, standing on the hill. The trees and rocks are in the midground, providing a natural backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.15, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 84.61}, "timestamp": "2026-01-30T21:59:53.458305"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6169.672, "latencies_ms": [6169.672], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a serene and lush green meadow with a variety of wildlife, including a herd of zebras grazing peacefully. The meadow is bordered by a stone wall and is surrounded by tall trees, creating a tranquil and natural environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.705, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 86.173}, "timestamp": "2026-01-30T22:00:01.661030"}
{"image_index": 158, "image_name": "000000016010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016010.jpg", "image_width": 640, "image_height": 471, "image_resolution": "640x471", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4921.11, "latencies_ms": [4921.11], "images_per_second": 0.203, "prompt_tokens": 22, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image depicts a lush, green meadow with a variety of trees in the background. The sky is partly cloudy, providing a mix of sunlight and shade.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.639, "power_cpu_cv_mean_watts": 1.279, "power_sys_5v0_mean_watts": 8.779, "gpu_utilization_percent_mean": 88.341}, "timestamp": "2026-01-30T22:00:08.597275"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2617.831, "latencies_ms": [2617.831], "images_per_second": 0.382, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A white horse is being pulled by a carriage on a street, with people walking around and a park in the background.", "error": null, "sys_before": {"cpu_percent": 32.3, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.137, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 77.667}, "timestamp": "2026-01-30T22:00:13.343238"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3545.567, "latencies_ms": [3545.567], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 2\nobject: 3\nobject: 4\nobject: 5\nobject: 6\nobject: 7\nobject: 8", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.327, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 72.793}, "timestamp": "2026-01-30T22:00:18.931891"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6441.047, "latencies_ms": [6441.047], "images_per_second": 0.155, "prompt_tokens": 30, "response_tokens_est": 88, "n_tiles": 6, "output_text": "The main object in the foreground is a white horse being pulled by a carriage. The carriage is decorated with green and gold colors and has the word \"Disneyland\" on it. In the background, there is a crowd of people and a trolley. The trolley is moving along the street, and there is a yellow and white umbrella nearby. The scene appears to be set in a park or a public area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.701, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 68.556}, "timestamp": "2026-01-30T22:00:27.384350"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6277.084, "latencies_ms": [6277.084], "images_per_second": 0.159, "prompt_tokens": 24, "response_tokens_est": 85, "n_tiles": 6, "output_text": "The image depicts a scene from a parade or public event, likely in a park or open area, with a white horse being pulled by a carriage. The carriage is adorned with the Disneyland logo and the number 1, and it is being led by a person dressed in formal attire. The setting is lively with people walking and enjoying the event, and there are trees and greenery in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.701, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 68.736}, "timestamp": "2026-01-30T22:00:35.711561"}
{"image_index": 159, "image_name": "000000016228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016228.jpg", "image_width": 640, "image_height": 440, "image_resolution": "640x440", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4929.774, "latencies_ms": [4929.774], "images_per_second": 0.203, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The image depicts a vintage scene with a horse-drawn carriage, a white horse, and a crowd of people. The carriage is adorned with green and red colors, and the horse is wearing a harness. The scene is well-lit by natural sunlight, creating a bright and cheerful atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.569, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 70.293}, "timestamp": "2026-01-30T22:00:42.689151"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4386.568, "latencies_ms": [4386.568], "images_per_second": 0.228, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 12, "output_text": "The image depicts a group of elderly men sitting on benches in a public square, each engrossed in reading newspapers.", "error": null, "sys_before": {"cpu_percent": 34.7, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.283, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 89.278}, "timestamp": "2026-01-30T22:00:49.222285"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6158.639, "latencies_ms": [6158.639], "images_per_second": 0.162, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 12, "output_text": "1. Man: 2\n2. Man: 2\n3. Man: 2\n4. Man: 2\n5. Man: 2\n6. Man: 2\n7. Man: 2\n8. Man: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.808, "power_cpu_cv_mean_watts": 1.517, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 86.423}, "timestamp": "2026-01-30T22:00:57.434144"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6358.755, "latencies_ms": [6358.755], "images_per_second": 0.157, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The main objects in the image are a group of elderly men sitting on benches. The benches are positioned in the foreground, with the men sitting near the center of the image. The background features a building with a large sign, and a few other people are visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.721, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 86.415}, "timestamp": "2026-01-30T22:01:05.817823"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6734.144, "latencies_ms": [6734.144], "images_per_second": 0.148, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The scene depicts an outdoor setting with several elderly individuals seated on benches. They are engaged in reading newspapers, with some holding their papers and others looking at them. The setting appears to be a public area, possibly a park or a square, with a clear sky overhead and a few other people in the background.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.388, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 85.75}, "timestamp": "2026-01-30T22:01:14.574928"}
{"image_index": 160, "image_name": "000000016249.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016249.jpg", "image_width": 500, "image_height": 365, "image_resolution": "500x365", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6629.616, "latencies_ms": [6629.616], "images_per_second": 0.151, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a sunny day with clear blue skies and bright sunlight. The scene is characterized by the vibrant colors of the buildings, the green metal benches, and the red and white signage. The lighting is natural, casting shadows on the ground, and the weather appears to be pleasant and warm.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.325, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.808, "gpu_utilization_percent_mean": 85.545}, "timestamp": "2026-01-30T22:01:23.246097"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4929.547, "latencies_ms": [4929.547], "images_per_second": 0.203, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 12, "output_text": "The image shows a well-organized desk with a laptop, a glass of orange juice, a phone, and a lamp, all set against a warmly lit background.", "error": null, "sys_before": {"cpu_percent": 28.1, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.644, "power_cpu_cv_mean_watts": 1.27, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 88.049}, "timestamp": "2026-01-30T22:01:30.334087"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5766.235, "latencies_ms": [5766.235], "images_per_second": 0.173, "prompt_tokens": 26, "response_tokens_est": 49, "n_tiles": 12, "output_text": "- Laptop: 1\n- Phone: 1\n- Glass: 1\n- Lamp: 1\n- Desk: 1\n- Magazine: 1\n- Book: 1\n- Candle: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.939, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 86.667}, "timestamp": "2026-01-30T22:01:38.118487"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7285.328, "latencies_ms": [7285.328], "images_per_second": 0.137, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The main objects in the image are a desk, a laptop, a lamp, and a cup of orange juice. The desk is positioned in the foreground, with the laptop and the lamp placed on top of it. The cup of orange juice is placed on the desk, near the lamp. The lamp is positioned in the background, providing light to the desk area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18640.5, "ram_available_mb": 44200.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.114, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 84.77}, "timestamp": "2026-01-30T22:01:47.434218"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7211.421, "latencies_ms": [7211.421], "images_per_second": 0.139, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The image depicts a well-organized workspace with a desk featuring a laptop, a phone, and a glass of orange juice. The desk is set against a warmly lit wall, and there is a decorative lamp with a classic design on the desk. The overall scene suggests a calm and productive environment, possibly in a home office or a study room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.5, "ram_available_mb": 44200.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.109, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 85.467}, "timestamp": "2026-01-30T22:01:56.658793"}
{"image_index": 161, "image_name": "000000016439.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016439.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7102.126, "latencies_ms": [7102.126], "images_per_second": 0.141, "prompt_tokens": 22, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The image depicts a well-lit, cozy office desk with a warm yellowish light illuminating the scene. The desk features a black laptop, a glass of orange juice, a phone, and various papers, with a classic lamp on the right side. The desk's materials include wood and metal, and the overall atmosphere is inviting and comfortable.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.231, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 84.797}, "timestamp": "2026-01-30T22:02:05.791221"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3013.066, "latencies_ms": [3013.066], "images_per_second": 0.332, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The image depicts a beach scene with various beach equipment and accessories spread out on the sand, including a striped beach towel, a blue surfboard, a red bag, and a green and white beach umbrella.", "error": null, "sys_before": {"cpu_percent": 8.5, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.579, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 6.983, "gpu_utilization_percent_mean": 67.44}, "timestamp": "2026-01-30T22:02:10.879766"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8252.338, "latencies_ms": [8252.338], "images_per_second": 0.121, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 1, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.51, "power_cpu_cv_mean_watts": 2.24, "power_sys_5v0_mean_watts": 7.231, "gpu_utilization_percent_mean": 65.217}, "timestamp": "2026-01-30T22:02:21.171838"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5667.069, "latencies_ms": [5667.069], "images_per_second": 0.176, "prompt_tokens": 30, "response_tokens_est": 87, "n_tiles": 1, "output_text": "The main objects in the image are located in the foreground, with the beach towel, surfboards, and bags positioned near the sandy shore. The surfboards are placed on the sand, while the beach towel is spread out on the sand. In the background, there is a beach umbrella and a person standing near the water. The ocean is visible in the distance, and a person can be seen further out on the water.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.631, "power_cpu_cv_mean_watts": 2.147, "power_sys_5v0_mean_watts": 7.148, "gpu_utilization_percent_mean": 64.702}, "timestamp": "2026-01-30T22:02:28.854475"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4943.367, "latencies_ms": [4943.367], "images_per_second": 0.202, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 1, "output_text": "The image depicts a serene beach scene with a clear blue sky overhead. The sandy beach is dotted with various beach gear, including a striped beach towel, a blue surfboard, a red bag, and a green and white beach umbrella. In the background, the ocean is calm with gentle waves, and a few people can be seen enjoying the beach.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.517, "power_cpu_cv_mean_watts": 2.12, "power_sys_5v0_mean_watts": 7.092, "gpu_utilization_percent_mean": 66.22}, "timestamp": "2026-01-30T22:02:35.821164"}
{"image_index": 162, "image_name": "000000016451.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016451.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4611.819, "latencies_ms": [4611.819], "images_per_second": 0.217, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 1, "output_text": "The image depicts a sunny beach scene with clear blue skies and calm ocean waters. The sandy beach is adorned with various beach gear, including a striped beach towel, a blue surfboard, a red bag, and a green and white umbrella. The lighting is bright and natural, indicating a clear day with minimal cloud cover.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.583, "power_cpu_cv_mean_watts": 2.076, "power_sys_5v0_mean_watts": 7.117, "gpu_utilization_percent_mean": 67.026}, "timestamp": "2026-01-30T22:02:42.445734"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3843.395, "latencies_ms": [3843.395], "images_per_second": 0.26, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 12, "output_text": "A sheep stands on a rocky outcrop with a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 32.0, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.3, "power_cpu_cv_mean_watts": 0.982, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 89.903}, "timestamp": "2026-01-30T22:02:48.459210"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5227.462, "latencies_ms": [5227.462], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.402, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 87.93}, "timestamp": "2026-01-30T22:02:55.725642"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7110.543, "latencies_ms": [7110.543], "images_per_second": 0.141, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main objects in the image are a sheep and a rocky landscape. The sheep is positioned on the left side of the image, standing on a small mound of grass. The rocky landscape is in the foreground, with large, dark rocks and patches of green grass. The sheep is near the rocks, and the sky is visible in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.118, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 84.8}, "timestamp": "2026-01-30T22:03:04.888971"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5825.773, "latencies_ms": [5825.773], "images_per_second": 0.172, "prompt_tokens": 24, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The image depicts a serene landscape featuring a sheep standing on a rocky outcrop under a clear blue sky. The sheep appears to be grazing on the grassy area, surrounded by large, rugged rocks and a lush green meadow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.801, "power_cpu_cv_mean_watts": 1.447, "power_sys_5v0_mean_watts": 8.766, "gpu_utilization_percent_mean": 86.429}, "timestamp": "2026-01-30T22:03:12.731236"}
{"image_index": 163, "image_name": "000000016502.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016502.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6187.645, "latencies_ms": [6187.645], "images_per_second": 0.162, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image features a serene landscape with a clear blue sky adorned with fluffy white clouds. The ground is covered in lush green grass, and the rocky terrain is rugged and textured. The lighting is bright and natural, suggesting a sunny day with minimal cloud cover.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.654, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 86.385}, "timestamp": "2026-01-30T22:03:20.959310"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4140.71, "latencies_ms": [4140.71], "images_per_second": 0.242, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "The image shows a person with blue hair and a blue shirt, holding a smartphone and taking a selfie.", "error": null, "sys_before": {"cpu_percent": 27.2, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.664, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 89.706}, "timestamp": "2026-01-30T22:03:27.246944"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4849.253, "latencies_ms": [4849.253], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Woman\n2. Blue hair\n3. Blue shirt\n4. Phone\n5. Ring\n6. Wall\n7. Background\n8. Reflection", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.839, "power_cpu_cv_mean_watts": 1.271, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 89.25}, "timestamp": "2026-01-30T22:03:34.130617"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5832.478, "latencies_ms": [5832.478], "images_per_second": 0.171, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The main object in the image is a person holding a smartphone. The person is positioned in the foreground, with the smartphone held up to their face. The background is out of focus, indicating that the focus is on the person and the smartphone.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.882, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 86.755}, "timestamp": "2026-01-30T22:03:41.991825"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4928.469, "latencies_ms": [4928.469], "images_per_second": 0.203, "prompt_tokens": 24, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image depicts a person with blue hair and a blue shirt standing in front of a light-colored wall. The person is holding a smartphone and taking a selfie.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.584, "power_cpu_cv_mean_watts": 1.299, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 88.22}, "timestamp": "2026-01-30T22:03:48.936580"}
{"image_index": 164, "image_name": "000000016598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016598.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6487.73, "latencies_ms": [6487.73], "images_per_second": 0.154, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The notable visual attributes of the image include the striking blue hair of the person, which stands out against the neutral background. The lighting is soft and diffused, creating a gentle ambiance. The person is wearing a blue shirt, and the image has a watermark indicating copyright by Janie Henderson.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.543, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 85.593}, "timestamp": "2026-01-30T22:03:57.461548"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4297.437, "latencies_ms": [4297.437], "images_per_second": 0.233, "prompt_tokens": 12, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The image depicts a classic, well-appointed room with a large, ornate fireplace, a wooden cabinet, a wooden table with a book, and several antique chairs, all set against a backdrop of a framed painting and a decorative mantelpiece.", "error": null, "sys_before": {"cpu_percent": 20.4, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.383, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 70.771}, "timestamp": "2026-01-30T22:04:03.852340"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3574.952, "latencies_ms": [3574.952], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.19, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 72.897}, "timestamp": "2026-01-30T22:04:09.445292"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5786.481, "latencies_ms": [5786.481], "images_per_second": 0.173, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The main objects in the image are a fireplace, a wooden cabinet, a chair, and a small round table. The fireplace is positioned in the foreground, with a chair and a small round table placed near it. The wooden cabinet is situated in the background, and the chair is positioned to the right of the fireplace. The small round table is placed in front of the cabinet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.069, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 69.583}, "timestamp": "2026-01-30T22:04:17.253234"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6803.716, "latencies_ms": [6803.716], "images_per_second": 0.147, "prompt_tokens": 24, "response_tokens_est": 94, "n_tiles": 6, "output_text": "The image depicts a classic, well-appointed room with a traditional fireplace, a wooden cabinet, and a patterned carpet. The room appears to be a study or a living room with antique furniture, including a leather armchair and a wooden table with a book on it. The walls are adorned with framed pictures, and there is a small, ornate vase on the mantelpiece. The overall ambiance suggests a cozy, historical setting.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.525, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 69.14}, "timestamp": "2026-01-30T22:04:26.103927"}
{"image_index": 165, "image_name": "000000016958.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000016958.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4042.911, "latencies_ms": [4042.911], "images_per_second": 0.247, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image depicts a classic, well-appointed room with a dark wooden fireplace, a dark wooden cabinet, and a patterned carpet. The room is illuminated by soft, warm lighting, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.55, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 71.455}, "timestamp": "2026-01-30T22:04:32.169298"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3416.522, "latencies_ms": [3416.522], "images_per_second": 0.293, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 4, "output_text": "A brown dog is energetically jumping in the air, attempting to catch a red frisbee with its mouth wide open, while a black car is parked in the background on a well-maintained lawn.", "error": null, "sys_before": {"cpu_percent": 24.7, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5451.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.068, "power_cpu_cv_mean_watts": 1.731, "power_sys_5v0_mean_watts": 7.637, "gpu_utilization_percent_mean": 63.429}, "timestamp": "2026-01-30T22:04:37.712084"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3140.911, "latencies_ms": [3140.911], "images_per_second": 0.318, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 4, "output_text": "dog: 1\nfrisbee: 1\ncar: 1\ntree: 1\ngrass: 1\nbushes: 1\nhouse: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5463.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.316, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 7.618, "gpu_utilization_percent_mean": 66.269}, "timestamp": "2026-01-30T22:04:42.877871"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6928.515, "latencies_ms": [6928.515], "images_per_second": 0.144, "prompt_tokens": 30, "response_tokens_est": 101, "n_tiles": 4, "output_text": "In the image, the main object is a dog in the foreground, positioned near the center of the frame. The dog is facing to the right, with its body slightly turned towards the camera. In the background, there is a black car parked on the left side of the image, slightly behind the dog. The car is closer to the background, while the dog is closer to the foreground. The dog is also near a tree trunk, which is partially visible on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5465.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.773, "power_cpu_cv_mean_watts": 2.072, "power_sys_5v0_mean_watts": 7.699, "gpu_utilization_percent_mean": 64.897}, "timestamp": "2026-01-30T22:04:51.823324"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4340.071, "latencies_ms": [4340.071], "images_per_second": 0.23, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 4, "output_text": "The image captures a lively scene in a well-maintained backyard, featuring a brown dog mid-leap, seemingly in the midst of a playful game of fetch with a red frisbee. The lush green lawn and the presence of a black car in the background suggest a suburban setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.6, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5460.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.123, "power_cpu_cv_mean_watts": 1.847, "power_sys_5v0_mean_watts": 7.651, "gpu_utilization_percent_mean": 65.694}, "timestamp": "2026-01-30T22:04:58.204834"}
{"image_index": 166, "image_name": "000000017029.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017029.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4264.773, "latencies_ms": [4264.773], "images_per_second": 0.234, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 4, "output_text": "The image features a black car parked on a well-maintained lawn, with a dog in mid-air, seemingly caught in the motion of a game of fetch. The dog has a dark coat, and the scene is bathed in natural daylight, creating a vibrant and lively atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5459.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.278, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 7.676, "gpu_utilization_percent_mean": 65.167}, "timestamp": "2026-01-30T22:05:04.512063"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3364.054, "latencies_ms": [3364.054], "images_per_second": 0.297, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "The image features a close-up of a giraffe's face, with its distinctive brown and white spotted pattern, and its large, expressive eyes gazing directly at the viewer.", "error": null, "sys_before": {"cpu_percent": 23.7, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.645, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 73.852}, "timestamp": "2026-01-30T22:05:09.989384"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1863.372, "latencies_ms": [1863.372], "images_per_second": 0.537, "prompt_tokens": 26, "response_tokens_est": 12, "n_tiles": 6, "output_text": "giraffe: 1\ntree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.697, "power_cpu_cv_mean_watts": 0.881, "power_sys_5v0_mean_watts": 7.973, "gpu_utilization_percent_mean": 82.133}, "timestamp": "2026-01-30T22:05:13.868963"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5729.862, "latencies_ms": [5729.862], "images_per_second": 0.175, "prompt_tokens": 30, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The main object in the foreground is a giraffe with a brown and white spotted coat. The giraffe is positioned near the center of the image, slightly off-center to the left. In the background, there are blurred greenery, indicating a natural setting. The giraffe is not directly in the foreground, but its presence is prominent due to the blurred background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.08, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-30T22:05:21.650902"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5245.826, "latencies_ms": [5245.826], "images_per_second": 0.191, "prompt_tokens": 24, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The image depicts a giraffe standing in a lush, green environment, likely a savanna or a similar habitat. The giraffe is facing the camera, with its head slightly tilted, and its long neck and legs are prominently visible. The background is filled with various shades of green, indicating a dense, natural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.418, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 69.614}, "timestamp": "2026-01-30T22:05:28.918293"}
{"image_index": 167, "image_name": "000000017031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017031.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2955.491, "latencies_ms": [2955.491], "images_per_second": 0.338, "prompt_tokens": 22, "response_tokens_est": 30, "n_tiles": 6, "output_text": "The giraffe in the image has a brown and white coat with distinctive black spots. The lighting is bright and natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.267, "power_cpu_cv_mean_watts": 1.385, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T22:05:33.900387"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2441.597, "latencies_ms": [2441.597], "images_per_second": 0.41, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "Two zebras stand in a fenced enclosure, with their distinctive black and white stripes clearly visible.", "error": null, "sys_before": {"cpu_percent": 23.9, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.431, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 77.4}, "timestamp": "2026-01-30T22:05:38.453305"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2154.642, "latencies_ms": [2154.642], "images_per_second": 0.464, "prompt_tokens": 26, "response_tokens_est": 17, "n_tiles": 6, "output_text": "zebra: 2\nfence: 1\nrock: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.289, "power_cpu_cv_mean_watts": 1.013, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 80.471}, "timestamp": "2026-01-30T22:05:42.654432"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5316.205, "latencies_ms": [5316.205], "images_per_second": 0.188, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main objects in the image are two zebras standing in a zoo enclosure. The foreground features the backs of the zebras, with their distinctive black and white stripes. The background shows a chain-link fence, indicating the enclosure's boundary. The zebras are positioned near the fence, with their heads turned slightly towards it.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.238, "power_cpu_cv_mean_watts": 1.824, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 69.489}, "timestamp": "2026-01-30T22:05:50.015725"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5301.072, "latencies_ms": [5301.072], "images_per_second": 0.189, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image depicts a scene in a zoo or a wildlife sanctuary, where two zebras are standing in a fenced enclosure. The zebras are facing the camera, and their distinctive black and white stripes are clearly visible. The ground is covered with dirt and scattered rocks, and the enclosure is surrounded by a chain-link fence.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.38, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 69.568}, "timestamp": "2026-01-30T22:05:57.344231"}
{"image_index": 168, "image_name": "000000017115.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017115.jpg", "image_width": 443, "image_height": 640, "image_resolution": "443x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4472.548, "latencies_ms": [4472.548], "images_per_second": 0.224, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The zebras in the image have black and white stripes, which are a notable visual attribute. The lighting is bright and natural, suggesting it is daytime. The ground is covered with dry leaves and patches of grass, indicating a dry season or a lack of rainfall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.129, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 70.541}, "timestamp": "2026-01-30T22:06:03.856430"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2648.438, "latencies_ms": [2648.438], "images_per_second": 0.378, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A group of horses stands in a line on a road, with a car parked on the right side of the road.", "error": null, "sys_before": {"cpu_percent": 27.5, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.964, "power_cpu_cv_mean_watts": 1.183, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 76.667}, "timestamp": "2026-01-30T22:06:08.606857"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3052.13, "latencies_ms": [3052.13], "images_per_second": 0.328, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Horse\n2. Horse\n3. Horse\n4. Horse\n5. Horse\n6. Horse\n7. Horse\n8. Car", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.239, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 74.76}, "timestamp": "2026-01-30T22:06:13.673729"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4199.337, "latencies_ms": [4199.337], "images_per_second": 0.238, "prompt_tokens": 30, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The main objects in the image are a wooden fence, a road, and a car. The wooden fence is on the left side of the image, the road is in the foreground, and the car is on the right side, near the fence.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.451, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 71.714}, "timestamp": "2026-01-30T22:06:19.907326"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5004.255, "latencies_ms": [5004.255], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a serene outdoor scene with a dirt road flanked by a wooden fence on one side and lush green trees on the other. A dark-colored car is parked on the right side of the road, and a group of horses is standing in the middle of the road, appearing calm and relaxed.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.495, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 70.024}, "timestamp": "2026-01-30T22:06:26.947574"}
{"image_index": 169, "image_name": "000000017178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017178.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4280.586, "latencies_ms": [4280.586], "images_per_second": 0.234, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The image features a serene scene with a wooden fence lining the road, a lush green tree providing shade, and a parked car in the foreground. The lighting is natural, with sunlight filtering through the foliage, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.326, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 71.171}, "timestamp": "2026-01-30T22:06:33.243193"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3654.029, "latencies_ms": [3654.029], "images_per_second": 0.274, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 6, "output_text": "The image shows a wooden desk with a stack of hardcover books on top, a small green bottle, and a red apple on the desk, with a framed picture hanging on the wall in the background.", "error": null, "sys_before": {"cpu_percent": 23.3, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.081, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.062, "gpu_utilization_percent_mean": 72.567}, "timestamp": "2026-01-30T22:06:39.016838"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2763.434, "latencies_ms": [2763.434], "images_per_second": 0.362, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 6, "output_text": "bookcase: 1\nbook: 1\napple: 1\nvase: 1\nchair: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.867, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 75.545}, "timestamp": "2026-01-30T22:06:43.795358"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4084.934, "latencies_ms": [4084.934], "images_per_second": 0.245, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The main objects in the image are a wooden desk and a bookshelf. The bookshelf is positioned in the background, while the desk is in the foreground. The bookshelf is near the door, and the desk is near the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.499, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 71.647}, "timestamp": "2026-01-30T22:06:49.897117"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5179.489, "latencies_ms": [5179.489], "images_per_second": 0.193, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a cozy, vintage library setting. The room is filled with wooden bookshelves, a wooden desk, and a chair, creating a warm and inviting atmosphere. The books on the desk and shelves suggest a rich collection of literature, while the overall ambiance conveys a sense of tranquility and intellectual pursuit.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.47, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.907}, "timestamp": "2026-01-30T22:06:57.122059"}
{"image_index": 170, "image_name": "000000017182.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017182.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4117.845, "latencies_ms": [4117.845], "images_per_second": 0.243, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image depicts a room with a dark, textured wall and a wooden desk. The desk is adorned with a stack of blue books and a small green bottle. The lighting is soft and warm, casting a cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.227, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 71.559}, "timestamp": "2026-01-30T22:07:03.295669"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4860.242, "latencies_ms": [4860.242], "images_per_second": 0.206, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "A yellow and white bus with the number 475 is seen in motion on a city street, with a white vehicle in the background and a person riding a motorcycle nearby.", "error": null, "sys_before": {"cpu_percent": 26.2, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.858, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 87.775}, "timestamp": "2026-01-30T22:07:10.304552"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6422.794, "latencies_ms": [6422.794], "images_per_second": 0.156, "prompt_tokens": 26, "response_tokens_est": 60, "n_tiles": 12, "output_text": "1. Bus: 1\n2. Motorcycle: 1\n3. Car: 1\n4. Street: 1\n5. Road: 1\n6. Pedestrian: 1\n7. Building: 1\n8. Street sign: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.569, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 86.264}, "timestamp": "2026-01-30T22:07:18.742095"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6257.579, "latencies_ms": [6257.579], "images_per_second": 0.16, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The image shows a yellow bus with the number \"475\" and some text in Hindi on its side. The bus is in motion, as indicated by the blurred background. The bus is positioned in the foreground, with the background showing a street scene with other vehicles and buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.659, "power_cpu_cv_mean_watts": 1.509, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 86.288}, "timestamp": "2026-01-30T22:07:27.046326"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6972.606, "latencies_ms": [6972.606], "images_per_second": 0.143, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a scene on a city street with a yellow and white bus in motion, indicating it is likely a bus stop. The bus has a sign with Hindi text, and there is a person riding a motorcycle in the background. The setting appears to be in a bustling urban area with other vehicles and buildings in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.242, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 85.254}, "timestamp": "2026-01-30T22:07:36.068117"}
{"image_index": 171, "image_name": "000000017207.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017207.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5776.606, "latencies_ms": [5776.606], "images_per_second": 0.173, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image features a yellow and white bus with red and black text, painted on its side. The bus is on a wet road, indicating recent rain. The lighting is natural, suggesting daytime, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.903, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 86.604}, "timestamp": "2026-01-30T22:07:43.876267"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4261.641, "latencies_ms": [4261.641], "images_per_second": 0.235, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 12, "output_text": "The image shows a bathroom with a sink, a mirror, and a toilet, all set against a tiled wall.", "error": null, "sys_before": {"cpu_percent": 27.9, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.538, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 89.171}, "timestamp": "2026-01-30T22:07:50.295735"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6113.359, "latencies_ms": [6113.359], "images_per_second": 0.164, "prompt_tokens": 26, "response_tokens_est": 55, "n_tiles": 12, "output_text": "- TV: 1\n- TV stand: 1\n- TV screen: 1\n- Mirror: 1\n- Sink: 1\n- Faucet: 1\n- Trash can: 1\n- Wall tiles: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.769, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 86.529}, "timestamp": "2026-01-30T22:07:58.447141"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6751.923, "latencies_ms": [6751.923], "images_per_second": 0.148, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The main objects in the image are a bathroom sink, a toilet paper holder, and a mirror. The sink is located in the foreground, with the toilet paper holder and mirror positioned near it. The toilet paper holder is situated to the right of the sink, and the mirror is positioned to the left of the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.473, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 85.679}, "timestamp": "2026-01-30T22:08:07.208591"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6661.289, "latencies_ms": [6661.289], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image depicts a bathroom with a modern and clean design. The setting is a bathroom with a sink, a mirror, and a tiled wall. The sink is empty, and there is a white soap dispenser on the counter. The wall behind the sink is tiled with beige and brown tiles.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.449, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 85.732}, "timestamp": "2026-01-30T22:08:15.889730"}
{"image_index": 172, "image_name": "000000017379.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017379.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4846.493, "latencies_ms": [4846.493], "images_per_second": 0.206, "prompt_tokens": 22, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image shows a bathroom with beige tiled walls and a brown door. The lighting is bright, and the materials used include tiles and a granite countertop.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.849, "power_cpu_cv_mean_watts": 1.271, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 89.075}, "timestamp": "2026-01-30T22:08:22.760659"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4089.859, "latencies_ms": [4089.859], "images_per_second": 0.245, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "A man is sitting on a bench in a park, looking down and appearing to be deep in thought.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.593, "power_cpu_cv_mean_watts": 1.06, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 90.559}, "timestamp": "2026-01-30T22:08:28.998969"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5408.235, "latencies_ms": [5408.235], "images_per_second": 0.185, "prompt_tokens": 26, "response_tokens_est": 43, "n_tiles": 12, "output_text": "1. Church\n2. Church steeple\n3. Church building\n4. Church clock\n5. Church clock tower\n6. Church bell\n7. Church spire\n8. Church arch", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.161, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 87.267}, "timestamp": "2026-01-30T22:08:36.443174"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7233.43, "latencies_ms": [7233.43], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The main objects in the image are a man sitting on a bench and a church tower. The man is positioned in the foreground, sitting on the bench, while the church tower is in the background, towering over the scene. The bench is located near the man, and the church tower is further away, creating a clear spatial relationship between the two objects.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.169, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 84.983}, "timestamp": "2026-01-30T22:08:45.692448"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7225.208, "latencies_ms": [7225.208], "images_per_second": 0.138, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The image depicts a serene, monochromatic scene of a park or garden with a man sitting on a bench. The setting appears to be a quiet, possibly urban area with well-maintained greenery and a small building in the background. The man seems to be resting or contemplating, while the surrounding environment is peaceful and orderly.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.033, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 84.508}, "timestamp": "2026-01-30T22:08:54.939705"}
{"image_index": 173, "image_name": "000000017436.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017436.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6994.143, "latencies_ms": [6994.143], "images_per_second": 0.143, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image is a black and white photograph featuring a man sitting on a bench in a park. The man is dressed in casual attire, and the park is surrounded by well-maintained hedges and trees. The lighting is soft and diffused, likely due to an overcast sky, creating a serene and contemplative atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.181, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 84.655}, "timestamp": "2026-01-30T22:09:03.952276"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4048.054, "latencies_ms": [4048.054], "images_per_second": 0.247, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "A street scene with cars parked and a person walking on the sidewalk, with a building in the background.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.052, "power_cpu_cv_mean_watts": 1.08, "power_sys_5v0_mean_watts": 8.876, "gpu_utilization_percent_mean": 89.455}, "timestamp": "2026-01-30T22:09:10.155800"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5706.232, "latencies_ms": [5706.232], "images_per_second": 0.175, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 12, "output_text": "- Car: 5\n- Car: 2\n- Car: 1\n- Car: 1\n- Car: 1\n- Car: 1\n- Car: 1\n- Car: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.947, "power_cpu_cv_mean_watts": 1.468, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 86.833}, "timestamp": "2026-01-30T22:09:17.916101"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5716.227, "latencies_ms": [5716.227], "images_per_second": 0.175, "prompt_tokens": 30, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The main objects in the image are parked cars and a building. The cars are parked in the foreground, with the closest one being a white sedan. The building is in the background, with a stone facade and a sign on it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.922, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 86.729}, "timestamp": "2026-01-30T22:09:25.685235"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7469.732, "latencies_ms": [7469.732], "images_per_second": 0.134, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The image depicts a bustling urban street scene, likely in a Middle Eastern city, given the architecture and the presence of a sign in Hebrew. The setting is characterized by a mix of modern and traditional elements, with cars parked along the side of the street and pedestrians walking. The sky is clear, suggesting a sunny day, and the overall atmosphere is busy yet orderly.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.97, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 84.048}, "timestamp": "2026-01-30T22:09:35.211879"}
{"image_index": 174, "image_name": "000000017627.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017627.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5829.773, "latencies_ms": [5829.773], "images_per_second": 0.172, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The image depicts a sunny day with clear blue skies. The scene is characterized by a mix of modern and traditional elements. The parking lot is filled with cars, and there are various signs and structures in the background, including a stone building.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.809, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.798, "gpu_utilization_percent_mean": 86.735}, "timestamp": "2026-01-30T22:09:43.081979"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4991.04, "latencies_ms": [4991.04], "images_per_second": 0.2, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 12, "output_text": "The image shows a plate of food consisting of a slice of banana bread, a cup of coffee, and a bowl of watermelon slices, all placed on a wooden table.", "error": null, "sys_before": {"cpu_percent": 29.7, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.625, "power_cpu_cv_mean_watts": 1.28, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 87.415}, "timestamp": "2026-01-30T22:09:50.212892"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5092.271, "latencies_ms": [5092.271], "images_per_second": 0.196, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "1. Plate\n2. Cereal\n3. Cup\n4. Cutting board\n5. Knife\n6. Fork\n7. Watermelon\n8. Banana", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18648.0, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.601, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 88.5}, "timestamp": "2026-01-30T22:09:57.345065"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7593.732, "latencies_ms": [7593.732], "images_per_second": 0.132, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The main objects in the image are a plate of food and a cup of coffee. The plate of food is positioned in the foreground, with a slice of banana and a piece of fruit on it. The cup of coffee is placed to the left of the plate, with a spoon inside it. The background features a wooden table, and the shadow of a person is cast on the floor.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18648.0, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.958, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 84.188}, "timestamp": "2026-01-30T22:10:06.966687"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6790.522, "latencies_ms": [6790.522], "images_per_second": 0.147, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a breakfast scene set on a wooden table with a marble floor. The table is adorned with a plate of food, including a slice of pancake, a bowl of fruit, and a cup of coffee. The setting suggests a cozy and relaxed atmosphere, likely in a home or a casual dining environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.343, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 85.018}, "timestamp": "2026-01-30T22:10:15.775700"}
{"image_index": 175, "image_name": "000000017714.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017714.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8427.029, "latencies_ms": [8427.029], "images_per_second": 0.119, "prompt_tokens": 22, "response_tokens_est": 93, "n_tiles": 12, "output_text": "The image depicts a warm and inviting breakfast setup on a wooden table. The table is adorned with a white plate holding a slice of pancake, a bowl of sliced bananas, a bowl of watermelon, and a cup of coffee. The lighting is natural, casting shadows on the table, indicating a sunny day. The colors are vibrant, with the white of the plate contrasting against the warm tones of the food and the wooden table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.662, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.846, "gpu_utilization_percent_mean": 84.113}, "timestamp": "2026-01-30T22:10:26.216656"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4203.869, "latencies_ms": [4203.869], "images_per_second": 0.238, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "An elderly woman is preparing a batch of homemade cookies on a wooden table, surrounded by various baking tools and ingredients.", "error": null, "sys_before": {"cpu_percent": 26.3, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.514, "power_cpu_cv_mean_watts": 1.11, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 88.943}, "timestamp": "2026-01-30T22:10:32.581133"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10569.488, "latencies_ms": [10569.488], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- plate: 1\n- bowl: 1\n- cookies: 8\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate: 1\n- plate", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.117, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.872, "gpu_utilization_percent_mean": 82.629}, "timestamp": "2026-01-30T22:10:45.168989"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7932.611, "latencies_ms": [7932.611], "images_per_second": 0.126, "prompt_tokens": 30, "response_tokens_est": 85, "n_tiles": 12, "output_text": "The main objects in the image are a woman, a table, and various baking items. The woman is seated at the table, focused on her baking activity. The table is the central object, with the baking items placed on it, including a metal cooling rack with baked goods, a glass of water, and a book with colorful illustrations. The background includes a couch and a door, suggesting a cozy living room setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.941, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.857, "gpu_utilization_percent_mean": 84.515}, "timestamp": "2026-01-30T22:10:55.130316"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6620.78, "latencies_ms": [6620.78], "images_per_second": 0.151, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts an indoor scene where an elderly woman is engaged in baking. She is surrounded by various baking ingredients and tools, including a wooden table, a metal cooling rack, and a variety of baked goods. The setting appears to be a cozy kitchen or dining area, with a window providing natural light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.442, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 85.855}, "timestamp": "2026-01-30T22:11:03.764947"}
{"image_index": 176, "image_name": "000000017899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017899.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8143.477, "latencies_ms": [8143.477], "images_per_second": 0.123, "prompt_tokens": 22, "response_tokens_est": 88, "n_tiles": 12, "output_text": "The image depicts a cozy, well-lit kitchen scene with a warm, inviting ambiance. The lighting is soft and natural, casting gentle shadows that enhance the textures of the wooden table and the various items on it. The colors are rich and varied, featuring the vibrant reds, greens, and blues of the children's books, the warm browns of the wooden table, and the metallic sheen of the baking tools.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.725, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 84.029}, "timestamp": "2026-01-30T22:11:13.921402"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4633.488, "latencies_ms": [4633.488], "images_per_second": 0.216, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "A man wearing a white t-shirt and khaki shorts stands in front of a traffic light, which is currently showing red, indicating that vehicles should stop.", "error": null, "sys_before": {"cpu_percent": 27.9, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.261, "power_cpu_cv_mean_watts": 1.314, "power_sys_5v0_mean_watts": 8.903, "gpu_utilization_percent_mean": 88.103}, "timestamp": "2026-01-30T22:11:20.703244"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6315.623, "latencies_ms": [6315.623], "images_per_second": 0.158, "prompt_tokens": 26, "response_tokens_est": 58, "n_tiles": 12, "output_text": "- man: 1\n- white t-shirt: 1\n- shorts: 1\n- sandals: 1\n- traffic light: 1\n- sign: 1\n- tree: 1\n- bush: 1\n- rocks: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.495, "power_cpu_cv_mean_watts": 1.549, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 86.453}, "timestamp": "2026-01-30T22:11:29.070301"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6275.784, "latencies_ms": [6275.784], "images_per_second": 0.159, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The main object in the foreground is a man standing next to a traffic light. The traffic light is positioned to the right of the man. The background features lush green plants and a sign that reads \"AUSTRALIA TRAFFIC LIGHT.\" The sign is located near the man.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.811, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.872, "gpu_utilization_percent_mean": 85.396}, "timestamp": "2026-01-30T22:11:37.372637"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6717.177, "latencies_ms": [6717.177], "images_per_second": 0.149, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image depicts a man standing in front of a traffic light, which is currently showing red. The setting appears to be outdoors, possibly in a park or garden area, with lush green plants and flowers in the background. The man is wearing a white t-shirt and light-colored shorts, and he is barefoot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.462, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.86, "gpu_utilization_percent_mean": 85.386}, "timestamp": "2026-01-30T22:11:46.103763"}
{"image_index": 177, "image_name": "000000017905.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017905.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5085.173, "latencies_ms": [5085.173], "images_per_second": 0.197, "prompt_tokens": 22, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image features a brightly lit scene with a man standing in front of a traffic light. The traffic light is red, and the surrounding area is lush with green foliage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.6, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 88.452}, "timestamp": "2026-01-30T22:11:53.219335"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4593.879, "latencies_ms": [4593.879], "images_per_second": 0.218, "prompt_tokens": 12, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a vibrant scene of a kite festival with a large, colorful fish-shaped kite flying high in the sky, surrounded by numerous other kites of various designs and colors, all set against a backdrop of a large crowd of people and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.741, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 70.718}, "timestamp": "2026-01-30T22:11:59.957952"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3559.443, "latencies_ms": [3559.443], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.257, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 72.621}, "timestamp": "2026-01-30T22:12:05.550433"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7736.011, "latencies_ms": [7736.011], "images_per_second": 0.129, "prompt_tokens": 30, "response_tokens_est": 109, "n_tiles": 6, "output_text": "The main objects in the image are kites, with the most prominent one being a large, colorful fish kite in the foreground. The fish kite is positioned near the center of the image, with its tail extending towards the right side. In the background, there are other kites, including a red and black kite and a blue and purple kite, all of which are positioned further away from the fish kite. The kites are spread out across the field, with some closer to the foreground and others further back.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.058, "power_cpu_cv_mean_watts": 2.015, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 67.831}, "timestamp": "2026-01-30T22:12:15.337318"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6740.98, "latencies_ms": [6740.98], "images_per_second": 0.148, "prompt_tokens": 24, "response_tokens_est": 93, "n_tiles": 6, "output_text": "The image depicts a vibrant outdoor scene at a public park where numerous people are gathered, enjoying a day of leisure and recreation. The setting is characterized by a grassy field, with a few scattered people and a few kites in the air. The kites, featuring colorful designs, are the main focus of the scene, with one particularly large kite featuring a fish design. The sky is partly cloudy, suggesting a pleasant day for outdoor activities.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.532, "power_cpu_cv_mean_watts": 2.009, "power_sys_5v0_mean_watts": 8.077, "gpu_utilization_percent_mean": 68.825}, "timestamp": "2026-01-30T22:12:24.115265"}
{"image_index": 178, "image_name": "000000017959.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000017959.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4704.819, "latencies_ms": [4704.819], "images_per_second": 0.213, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image showcases a vibrant kite flying high in the sky, featuring a striking red fish with black and white stripes. The kite is illuminated by the bright sunlight, casting a warm glow on the scene. The sky is clear, indicating a sunny day with good weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.751, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 70.359}, "timestamp": "2026-01-30T22:12:30.843430"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4403.25, "latencies_ms": [4403.25], "images_per_second": 0.227, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "A young boy is eating a slice of pizza from a box, while a man sits beside him, both in a cozy indoor setting.", "error": null, "sys_before": {"cpu_percent": 31.2, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.585, "power_cpu_cv_mean_watts": 1.157, "power_sys_5v0_mean_watts": 8.874, "gpu_utilization_percent_mean": 89.139}, "timestamp": "2026-01-30T22:12:37.395924"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5142.612, "latencies_ms": [5142.612], "images_per_second": 0.194, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 12, "output_text": "1. Pizza\n2. Pizza box\n3. Pizza slice\n4. Pizza box\n5. Pizza box\n6. Pizza box\n7. Pizza box\n8. Pizza box", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.466, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 88.0}, "timestamp": "2026-01-30T22:12:44.596766"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8163.45, "latencies_ms": [8163.45], "images_per_second": 0.122, "prompt_tokens": 30, "response_tokens_est": 89, "n_tiles": 12, "output_text": "The main objects in the image are a man and a young child. The man is seated on the left side of the image, while the child is on the right side. The man is holding a pizza slice in his right hand, and the child is holding a green toy in their left hand. The pizza slice is in the foreground, and the child is slightly behind it. The background includes a couch and a window with blinds.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.878, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 8.874, "gpu_utilization_percent_mean": 84.116}, "timestamp": "2026-01-30T22:12:54.797291"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6674.122, "latencies_ms": [6674.122], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image depicts a cozy indoor setting with a young boy and a man seated on a couch. The boy is holding a slice of pizza, while the man is eating from a box of pizza. The room has warm lighting, and there are various items on the couch, including a stuffed animal and a bottle.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.431, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 84.895}, "timestamp": "2026-01-30T22:13:03.497494"}
{"image_index": 179, "image_name": "000000018150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018150.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6166.396, "latencies_ms": [6166.396], "images_per_second": 0.162, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image features a young boy with curly hair, wearing a blue hoodie, sitting on a red couch. The boy is holding a slice of pizza, which is placed on a cardboard box. The room has warm lighting, and the overall atmosphere appears cozy and casual.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.801, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.844, "gpu_utilization_percent_mean": 86.327}, "timestamp": "2026-01-30T22:13:11.716644"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4094.403, "latencies_ms": [4094.403], "images_per_second": 0.244, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "A young woman is eating a hot dog from a sandwich, with a plate of nachos beside her.", "error": null, "sys_before": {"cpu_percent": 28.6, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.581, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 88.941}, "timestamp": "2026-01-30T22:13:17.945839"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4860.359, "latencies_ms": [4860.359], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Plate\n2. Sandwich\n3. Bag\n4. Woman\n5. Chair\n6. Food\n7. Plate\n8. Sandwich", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.81, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 88.675}, "timestamp": "2026-01-30T22:13:24.851766"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5957.469, "latencies_ms": [5957.469], "images_per_second": 0.168, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The main object in the foreground is a plate with a few pieces of potato chips. The plate is placed on a person's lap, which is in the foreground. The background consists of a dark, possibly outdoor setting with a tree branch and some rocks.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.79, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 86.58}, "timestamp": "2026-01-30T22:13:32.848215"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5514.188, "latencies_ms": [5514.188], "images_per_second": 0.181, "prompt_tokens": 24, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The image depicts a young woman sitting on a blue chair, holding a sandwich in her hand. She is surrounded by a dark, outdoor setting with a small pile of potato chips on a plate in front of her.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.255, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 87.609}, "timestamp": "2026-01-30T22:13:40.379134"}
{"image_index": 180, "image_name": "000000018193.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018193.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6198.105, "latencies_ms": [6198.105], "images_per_second": 0.161, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a young woman sitting on a blue chair, holding a sandwich with a fork. The lighting is dim, and the background is dark, suggesting it is nighttime. The woman is wearing a striped shirt and has a plate with some food on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.636, "power_cpu_cv_mean_watts": 1.517, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 85.5}, "timestamp": "2026-01-30T22:13:48.591168"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2598.951, "latencies_ms": [2598.951], "images_per_second": 0.385, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A large family is gathered around a table, enjoying a meal together, with various dishes and drinks visible on the table.", "error": null, "sys_before": {"cpu_percent": 28.1, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.213, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.09, "gpu_utilization_percent_mean": 75.952}, "timestamp": "2026-01-30T22:13:53.314154"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8732.334, "latencies_ms": [8732.334], "images_per_second": 0.115, "prompt_tokens": 26, "response_tokens_est": 126, "n_tiles": 6, "output_text": "- People: 8\n- Table: 1\n- Plate: 1\n- Glass: 1\n- Wine: 1\n- Bowl: 1\n- Cutlery: 1\n- Napkin: 1\n- Fork: 1\n- Knife: 1\n- Bread: 1\n- Meat: 1\n- Carrots: 1\n- Potatoes: 1\n- Chicken: 1\n- Dessert: 1\n- Beverage: 1\n- Glassware: 1\n- Tablecloth: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.913, "power_cpu_cv_mean_watts": 2.079, "power_sys_5v0_mean_watts": 8.083, "gpu_utilization_percent_mean": 67.863}, "timestamp": "2026-01-30T22:14:04.074292"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6508.073, "latencies_ms": [6508.073], "images_per_second": 0.154, "prompt_tokens": 30, "response_tokens_est": 89, "n_tiles": 6, "output_text": "The main objects in the image are a family gathered around a dining table. The family members are seated in a semi-circle, with the adults on the sides and the children in the center. The table is covered with a purple tablecloth, and various dishes, plates, and glasses are spread out on it. The family members are positioned near the center of the table, with the adults on the sides and the children in the middle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.68, "power_cpu_cv_mean_watts": 1.951, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 68.556}, "timestamp": "2026-01-30T22:14:12.597273"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5435.704, "latencies_ms": [5435.704], "images_per_second": 0.184, "prompt_tokens": 24, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The image depicts a family gathering in a warmly lit, cozy dining room. The family is seated around a large table covered with a purple tablecloth, filled with various dishes, including a plate of food, a bowl of fruit, and plates of food. The family members are smiling and posing for the camera, enjoying a meal together.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.219, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 69.689}, "timestamp": "2026-01-30T22:14:20.069465"}
{"image_index": 181, "image_name": "000000018380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018380.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4713.455, "latencies_ms": [4713.455], "images_per_second": 0.212, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a family gathering in a warmly lit, cozy kitchen. The table is covered with a purple tablecloth, and various dishes, including a plate of food and a bowl of fruit, are spread out. The lighting is soft and warm, creating a welcoming atmosphere.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.639, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 70.564}, "timestamp": "2026-01-30T22:14:26.823440"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3358.183, "latencies_ms": [3358.183], "images_per_second": 0.298, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "A baseball game is in progress on a sunny day, with players in protective gear on the field, including a catcher and a batter, and spectators watching from the stands.", "error": null, "sys_before": {"cpu_percent": 29.7, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.496, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 73.556}, "timestamp": "2026-01-30T22:14:32.291872"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4287.686, "latencies_ms": [4287.686], "images_per_second": 0.233, "prompt_tokens": 26, "response_tokens_est": 52, "n_tiles": 6, "output_text": "baseball player: 1\numpire: 1\ncatcher: 1\nbatter: 1\npitcher: 1\nhome plate: 1\ndirt infield: 1\ngrass outfield: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.05, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 70.806}, "timestamp": "2026-01-30T22:14:38.619081"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5366.491, "latencies_ms": [5366.491], "images_per_second": 0.186, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 6, "output_text": "In the image, the main objects are the baseball players and the baseball field. The players are positioned in the foreground, with one player sliding into the base and another player standing near the base. The baseball field is in the background, with the fence and spectators visible. The players are near the base, while the field is farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.262, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 69.667}, "timestamp": "2026-01-30T22:14:46.023109"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5304.536, "latencies_ms": [5304.536], "images_per_second": 0.189, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image captures a moment during a baseball game, with players in action on the field. The scene is set in a baseball field with a dirt infield and grass surrounding it, and a chain-link fence in the background. The focus is on a player sliding into first base, while another player is in the process of throwing the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.3, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 69.955}, "timestamp": "2026-01-30T22:14:53.357903"}
{"image_index": 182, "image_name": "000000018491.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018491.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5009.768, "latencies_ms": [5009.768], "images_per_second": 0.2, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image captures a baseball game in action, with players in dark uniforms and protective gear, including helmets and pads, on a well-maintained field. The lighting suggests it is either early morning or late afternoon, with shadows cast by the players and the fence, indicating the sun is low in the sky.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.466, "power_cpu_cv_mean_watts": 1.793, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 69.738}, "timestamp": "2026-01-30T22:15:00.398953"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4027.779, "latencies_ms": [4027.779], "images_per_second": 0.248, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "A skateboarder is performing a trick on a concrete ramp, with his shadow visible on the ground.", "error": null, "sys_before": {"cpu_percent": 22.9, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.148, "power_cpu_cv_mean_watts": 1.104, "power_sys_5v0_mean_watts": 8.867, "gpu_utilization_percent_mean": 89.455}, "timestamp": "2026-01-30T22:15:06.574119"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5711.848, "latencies_ms": [5711.848], "images_per_second": 0.175, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 12, "output_text": "1. Skateboarder\n2. Helmet\n3. Gloves\n4. Skateboard\n5. Concrete wall\n6. Skateboard ramp\n7. Skateboard\n8. Skateboarder", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.929, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 86.833}, "timestamp": "2026-01-30T22:15:14.334348"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7820.123, "latencies_ms": [7820.123], "images_per_second": 0.128, "prompt_tokens": 30, "response_tokens_est": 83, "n_tiles": 12, "output_text": "The main object in the foreground is a skateboarder performing a trick on a concrete ramp. The skateboarder is positioned near the center of the image, with their body leaning forward and arms extended. The background features a metal fence and a grassy area, with trees and a building visible in the distance. The skateboarder is near the fence, and the grassy area is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.946, "power_cpu_cv_mean_watts": 1.717, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 84.561}, "timestamp": "2026-01-30T22:15:24.195743"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7194.406, "latencies_ms": [7194.406], "images_per_second": 0.139, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The image captures a skateboarder performing a trick on a concrete ramp in a park-like setting. The skateboarder is wearing a black helmet, black gloves, and black shorts, and is in mid-air, executing a maneuver with his skateboard. The background features a metal fence, green grass, and a clear blue sky, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.171, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.85, "gpu_utilization_percent_mean": 85.393}, "timestamp": "2026-01-30T22:15:33.431219"}
{"image_index": 183, "image_name": "000000018519.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018519.jpg", "image_width": 515, "image_height": 640, "image_resolution": "515x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6953.012, "latencies_ms": [6953.012], "images_per_second": 0.144, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a skateboarder performing a trick on a concrete ramp. The skateboarder is wearing a black helmet, black gloves, and black shorts, and is captured in mid-air against a bright, sunny day. The lighting is natural, casting shadows on the ground, and the skateboarder's shadow is clearly visible.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.256, "power_cpu_cv_mean_watts": 1.657, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 85.0}, "timestamp": "2026-01-30T22:15:42.422235"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6128.234, "latencies_ms": [6128.234], "images_per_second": 0.163, "prompt_tokens": 12, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image shows a plate of food consisting of a slice of bread, a fried egg, a side of fries, a tomato, a pickle, and a lemon wedge, all arranged on a white plate, with a glass of water and a napkin in the background.", "error": null, "sys_before": {"cpu_percent": 26.5, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.689, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.854, "gpu_utilization_percent_mean": 84.038}, "timestamp": "2026-01-30T22:15:50.721632"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5341.323, "latencies_ms": [5341.323], "images_per_second": 0.187, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 12, "output_text": "- bread: 1\n- fries: 1\n- tomato: 1\n- pickle: 1\n- salad: 1\n- lemon: 1\n- dip: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.328, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 88.227}, "timestamp": "2026-01-30T22:15:58.079180"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6915.819, "latencies_ms": [6915.819], "images_per_second": 0.145, "prompt_tokens": 30, "response_tokens_est": 68, "n_tiles": 12, "output_text": "The main objects in the image are a plate of food, a glass of water, and a napkin. The plate of food is placed in the foreground, with the glass of water and napkin positioned behind it. The glass of water is on the right side of the plate, while the napkin is on the left side.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.203, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 84.814}, "timestamp": "2026-01-30T22:16:07.014771"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8621.222, "latencies_ms": [8621.222], "images_per_second": 0.116, "prompt_tokens": 24, "response_tokens_est": 97, "n_tiles": 12, "output_text": "The image depicts a well-arranged dining table with a variety of food items. The setting appears to be a restaurant or a dining area, as indicated by the presence of a tablecloth and a menu card. The food items on the table include a plate of French fries, a piece of bread, a pickle, a small bowl of salad, a glass of water, and a lemon. The overall scene suggests a casual dining experience, possibly in a restaurant setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.694, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 8.857, "gpu_utilization_percent_mean": 84.301}, "timestamp": "2026-01-30T22:16:17.675707"}
{"image_index": 184, "image_name": "000000018575.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018575.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6897.744, "latencies_ms": [6897.744], "images_per_second": 0.145, "prompt_tokens": 22, "response_tokens_est": 68, "n_tiles": 12, "output_text": "The image features a plate of food with a white plate, a glass of water, a napkin, and a small bowl of salad. The lighting is bright, and the colors are vibrant, with the golden-brown fries, green lettuce, red tomato, and lemon providing a colorful contrast against the white plate and napkin.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.355, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.859, "gpu_utilization_percent_mean": 85.569}, "timestamp": "2026-01-30T22:16:26.606410"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3456.385, "latencies_ms": [3456.385], "images_per_second": 0.289, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 6, "output_text": "A classic red motorcycle with chrome details is parked on a dusty road, with a wooden saddle and a red leather seat, surrounded by a fence and sparse vegetation under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 27.5, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.23, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 71.069}, "timestamp": "2026-01-30T22:16:32.160516"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8875.472, "latencies_ms": [8875.472], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "motorcycle: 1\nseat: 1\nsteering wheel: 1\nrear-view mirror: 1\nrear fender: 1\nrear tire: 1\nrear shock absorber: 1\nrear exhaust: 1\nrear bumper: 1\nrear light: 1\nrear license plate: 1\nrear storage box: 1\nrear seat: 1\nrear fender: 1\nrear tire: 1\nrear shock absorber: 1\nrear exhaust: 1\nrear bumper: 1\nrear light: 1\nrear license plate:", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.765, "power_cpu_cv_mean_watts": 2.087, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 67.803}, "timestamp": "2026-01-30T22:16:43.064882"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4280.17, "latencies_ms": [4280.17], "images_per_second": 0.234, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The main object in the foreground is a red motorcycle with a black seat and chrome details. The motorcycle is parked on a paved road, with a wooden fence visible in the background. The background also includes a few palm trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.27, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 71.278}, "timestamp": "2026-01-30T22:16:49.380607"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3965.996, "latencies_ms": [3965.996], "images_per_second": 0.252, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image depicts a red motorcycle parked on a dusty road with a clear blue sky in the background. The setting appears to be a desert or arid region, with sparse vegetation and a wooden fence visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18649.2, "ram_available_mb": 44191.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.586, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.094, "gpu_utilization_percent_mean": 72.091}, "timestamp": "2026-01-30T22:16:55.406558"}
{"image_index": 185, "image_name": "000000018737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018737.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3547.962, "latencies_ms": [3547.962], "images_per_second": 0.282, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The motorcycle in the image is painted in a vibrant red color, with chrome accents and a shiny finish. The lighting is bright and sunny, casting a clear shadow of the motorcycle on the ground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18649.2, "ram_available_mb": 44191.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18650.0, "ram_available_mb": 44190.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.271, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 72.448}, "timestamp": "2026-01-30T22:17:00.972452"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2561.088, "latencies_ms": [2561.088], "images_per_second": 0.39, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "The image shows a close-up of a man wearing a dark suit with a white shirt and a patterned tie.", "error": null, "sys_before": {"cpu_percent": 25.7, "ram_used_mb": 18650.0, "ram_available_mb": 44190.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.079, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 76.524}, "timestamp": "2026-01-30T22:17:05.626898"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3080.615, "latencies_ms": [3080.615], "images_per_second": 0.325, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Man\n2. Suit\n3. Tie\n4. Shirt\n5. Background\n6. Wall\n7. Light\n8. Door", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.049, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 74.04}, "timestamp": "2026-01-30T22:17:10.748769"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4521.269, "latencies_ms": [4521.269], "images_per_second": 0.221, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 6, "output_text": "The main object in the foreground is a man wearing a dark suit and tie. The background is blurred, but it appears to be an indoor setting with a dark wall. The man is positioned slightly to the right of the center, with the background being out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.061, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 70.676}, "timestamp": "2026-01-30T22:17:17.290435"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4001.422, "latencies_ms": [4001.422], "images_per_second": 0.25, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image depicts a man dressed in a formal black suit and tie, standing in an indoor setting. The background is dark, and the man appears to be in a formal or professional environment, possibly a business or office setting.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.549, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 71.121}, "timestamp": "2026-01-30T22:17:23.335601"}
{"image_index": 186, "image_name": "000000018770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018770.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4703.034, "latencies_ms": [4703.034], "images_per_second": 0.213, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The man in the image is wearing a dark suit with a white shirt and a dark tie. The lighting is soft and even, highlighting the contours of his face and the texture of his suit. The background is dark, providing a stark contrast that makes the man's attire stand out.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.741, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 70.59}, "timestamp": "2026-01-30T22:17:30.060556"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1843.075, "latencies_ms": [1843.075], "images_per_second": 0.543, "prompt_tokens": 12, "response_tokens_est": 12, "n_tiles": 6, "output_text": "A cat is sleeping on a pair of sneakers.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.829, "power_cpu_cv_mean_watts": 0.854, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 82.6}, "timestamp": "2026-01-30T22:17:34.044393"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1818.111, "latencies_ms": [1818.111], "images_per_second": 0.55, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 6, "output_text": "cat: 1\nshoe: 2", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.919, "power_cpu_cv_mean_watts": 0.744, "power_sys_5v0_mean_watts": 7.952, "gpu_utilization_percent_mean": 84.0}, "timestamp": "2026-01-30T22:17:37.890839"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3737.54, "latencies_ms": [3737.54], "images_per_second": 0.268, "prompt_tokens": 30, "response_tokens_est": 43, "n_tiles": 6, "output_text": "The main object in the foreground is a cat lying on a shoe. The shoe is placed on a surface with a patterned texture. The background is out of focus, emphasizing the cat and the shoe.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18651.7, "ram_available_mb": 44189.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.905, "power_cpu_cv_mean_watts": 1.652, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 72.094}, "timestamp": "2026-01-30T22:17:43.673646"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5191.382, "latencies_ms": [5191.382], "images_per_second": 0.193, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a serene scene of a cat resting on a pair of sneakers. The cat appears to be sleeping peacefully, with its head resting on the white sole of the sneakers. The setting is indoors, likely in a home or a cozy space, with a soft, textured wall in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18651.7, "ram_available_mb": 44189.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.291, "power_cpu_cv_mean_watts": 1.83, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-30T22:17:50.880171"}
{"image_index": 187, "image_name": "000000018833.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018833.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3960.41, "latencies_ms": [3960.41], "images_per_second": 0.252, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image features a cat lying on a pair of sneakers, which are predominantly gray with black accents. The lighting is soft and natural, casting gentle shadows that highlight the cat's relaxed posture and the texture of the sneakers.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.612, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 71.758}, "timestamp": "2026-01-30T22:17:56.895102"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5140.039, "latencies_ms": [5140.039], "images_per_second": 0.195, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 12, "output_text": "A green garbage truck is parked on the street, with two workers wearing safety vests and helmets, one of whom is standing next to the truck, and another is sitting inside the truck.", "error": null, "sys_before": {"cpu_percent": 32.4, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.54, "power_cpu_cv_mean_watts": 1.369, "power_sys_5v0_mean_watts": 8.838, "gpu_utilization_percent_mean": 87.0}, "timestamp": "2026-01-30T22:18:04.237367"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6043.006, "latencies_ms": [6043.006], "images_per_second": 0.165, "prompt_tokens": 26, "response_tokens_est": 54, "n_tiles": 12, "output_text": "1. Green truck\n2. Person in green vest\n3. Person in green hat\n4. Person in green jacket\n5. Person in green jacket\n6. Person in green jacket\n7. Person in green jacket\n8. Person in green jacket", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.843, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 86.471}, "timestamp": "2026-01-30T22:18:12.335021"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7219.217, "latencies_ms": [7219.217], "images_per_second": 0.139, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The main object in the foreground is a green truck with a person wearing a safety vest and a cap. The truck is parked on the street, with the person standing near the front of the vehicle. In the background, there is a building with a sign that reads \"Power Exchange.\" The truck's license plate is visible, and there is another vehicle parked nearby.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.323, "power_cpu_cv_mean_watts": 1.674, "power_sys_5v0_mean_watts": 8.888, "gpu_utilization_percent_mean": 85.541}, "timestamp": "2026-01-30T22:18:21.580779"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6608.624, "latencies_ms": [6608.624], "images_per_second": 0.151, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a scene on a city street where a green garbage truck is parked. Two individuals, one wearing a green vest and the other in a yellow cap, are seen interacting with the truck. The setting appears to be a busy urban area with buildings, trees, and other vehicles in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.451, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.464}, "timestamp": "2026-01-30T22:18:30.207960"}
{"image_index": 188, "image_name": "000000018837.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000018837.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4970.1, "latencies_ms": [4970.1], "images_per_second": 0.201, "prompt_tokens": 22, "response_tokens_est": 36, "n_tiles": 12, "output_text": "The image features a green garbage truck with a red and white striped front bumper. The truck is parked on a street with a clear sky overhead, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.544, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 88.333}, "timestamp": "2026-01-30T22:18:37.222196"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2760.605, "latencies_ms": [2760.605], "images_per_second": 0.362, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 6, "output_text": "A solitary bird stands on a rocky shoreline by a calm river, surrounded by lush greenery and a bridge in the background.", "error": null, "sys_before": {"cpu_percent": 23.2, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.449, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T22:18:42.089511"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3547.298, "latencies_ms": [3547.298], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.135, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 72.867}, "timestamp": "2026-01-30T22:18:47.680254"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4568.172, "latencies_ms": [4568.172], "images_per_second": 0.219, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The main objects in the image are a river, a bridge, and a bird standing on the riverbank. The bird is positioned near the riverbank, while the bridge is in the background. The foreground consists of the river and the bird, while the background features the bridge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.976, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 70.526}, "timestamp": "2026-01-30T22:18:54.286085"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4466.872, "latencies_ms": [4466.872], "images_per_second": 0.224, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The image depicts a serene river scene with a rocky shoreline in the foreground. A solitary bird is standing on the rocks, seemingly surveying its surroundings. The setting is peaceful, with a bridge visible in the background, suggesting a location near a populated area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.86, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 70.237}, "timestamp": "2026-01-30T22:19:00.800456"}
{"image_index": 189, "image_name": "000000019042.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019042.jpg", "image_width": 640, "image_height": 371, "image_resolution": "640x371", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4601.533, "latencies_ms": [4601.533], "images_per_second": 0.217, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a serene river scene with a clear blue sky overhead. The lighting is bright and natural, casting soft shadows on the riverbanks. The river is surrounded by lush greenery, and the water appears calm with a few small rocks scattered along the shore.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18652.4, "ram_available_mb": 44188.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.772, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.282}, "timestamp": "2026-01-30T22:19:07.450448"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3033.714, "latencies_ms": [3033.714], "images_per_second": 0.33, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "A row of parked motorcycles is lined up in front of a building with a red awning, while a few people are seen walking around the area.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.158, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 74.96}, "timestamp": "2026-01-30T22:19:12.603818"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5023.79, "latencies_ms": [5023.79], "images_per_second": 0.199, "prompt_tokens": 26, "response_tokens_est": 64, "n_tiles": 6, "output_text": "1. Motorcycles: 8\n2. Motorcycle: 1\n3. Motorcycle: 1\n4. Motorcycle: 1\n5. Motorcycle: 1\n6. Motorcycle: 1\n7. Motorcycle: 1\n8. Motorcycle: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.495, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 69.857}, "timestamp": "2026-01-30T22:19:19.648964"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4658.378, "latencies_ms": [4658.378], "images_per_second": 0.215, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The main objects in the image are a row of parked motorcycles and a building with a red awning. The motorcycles are parked in the foreground, with their fronts facing the camera. The building with the red awning is located in the background, slightly to the right.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18652.6, "ram_available_mb": 44188.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.781, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.128}, "timestamp": "2026-01-30T22:19:26.341124"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4754.325, "latencies_ms": [4754.325], "images_per_second": 0.21, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a street scene in a city, likely Paris, with a row of parked motorcycles lining the curb. The setting is urban, with buildings and shops in the background. People are seen walking and conversing, and there are various signs and advertisements visible on the buildings.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18652.6, "ram_available_mb": 44188.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18652.6, "ram_available_mb": 44188.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.599, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 70.325}, "timestamp": "2026-01-30T22:19:33.113361"}
{"image_index": 190, "image_name": "000000019109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019109.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4343.444, "latencies_ms": [4343.444], "images_per_second": 0.23, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The image depicts a row of parked motorcycles lined up against a backdrop of a historic building. The scene is bathed in soft, natural light, suggesting it is daytime. The motorcycles are predominantly black, with some featuring sleek designs and modern features.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.6, "ram_available_mb": 44188.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18652.6, "ram_available_mb": 44188.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.061, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 71.056}, "timestamp": "2026-01-30T22:19:39.481058"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3889.075, "latencies_ms": [3889.075], "images_per_second": 0.257, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 12, "output_text": "A hand is holding a small, green broccoli floret with a few leaves attached.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.026, "power_cpu_cv_mean_watts": 0.951, "power_sys_5v0_mean_watts": 8.778, "gpu_utilization_percent_mean": 90.5}, "timestamp": "2026-01-30T22:19:45.518916"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3467.697, "latencies_ms": [3467.697], "images_per_second": 0.288, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 12, "output_text": "broccoli: 1\npot: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.74, "power_cpu_cv_mean_watts": 0.815, "power_sys_5v0_mean_watts": 8.781, "gpu_utilization_percent_mean": 94.393}, "timestamp": "2026-01-30T22:19:51.001941"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6745.254, "latencies_ms": [6745.254], "images_per_second": 0.148, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The main object in the foreground is a person's hand holding a broccoli. The broccoli is positioned in the center of the image, with the person's hand slightly to the right and in the foreground. The background is blurred, with a dark, indistinct area that makes the broccoli stand out.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.394, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 85.232}, "timestamp": "2026-01-30T22:19:59.761466"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5824.4, "latencies_ms": [5824.4], "images_per_second": 0.172, "prompt_tokens": 24, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The image shows a close-up of a person's hand holding a small, green, broccoli-like vegetable. The hand is positioned against a dark background, and the focus is on the vegetable, which appears to be freshly picked or freshly cut.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.891, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 87.02}, "timestamp": "2026-01-30T22:20:07.619376"}
{"image_index": 191, "image_name": "000000019221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019221.jpg", "image_width": 640, "image_height": 478, "image_resolution": "640x478", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6645.724, "latencies_ms": [6645.724], "images_per_second": 0.15, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image features a close-up of a person's hand holding a green broccoli floret. The broccoli is bright green with small, tightly packed florets, and the hand is holding it with a slightly wrinkled skin texture. The lighting is natural, suggesting the photo was taken outdoors during the day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.536, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.847, "gpu_utilization_percent_mean": 83.927}, "timestamp": "2026-01-30T22:20:16.291110"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4139.073, "latencies_ms": [4139.073], "images_per_second": 0.242, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "The image shows a person wearing a green jacket, with their face partially obscured by the jacket's collar.", "error": null, "sys_before": {"cpu_percent": 26.8, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.665, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 89.294}, "timestamp": "2026-01-30T22:20:22.576238"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4734.221, "latencies_ms": [4734.221], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Woman\n2. Hat\n3. Light\n4. Background\n5. Person\n6. Light\n7. Person\n8. Light", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.921, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.797, "gpu_utilization_percent_mean": 89.231}, "timestamp": "2026-01-30T22:20:29.329377"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5775.795, "latencies_ms": [5775.795], "images_per_second": 0.173, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The main object in the foreground is a person wearing a green hat. The person's face is partially visible, with their mouth open. The background is out of focus, but there appears to be a lamp and some indistinct objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.98, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 86.729}, "timestamp": "2026-01-30T22:20:37.140365"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5234.225, "latencies_ms": [5234.225], "images_per_second": 0.191, "prompt_tokens": 24, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The image depicts a person wearing a green jacket, with their face partially obscured by the jacket. The background is blurred, but it appears to be an indoor setting with warm lighting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.265, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 87.409}, "timestamp": "2026-01-30T22:20:44.428893"}
{"image_index": 192, "image_name": "000000019402.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019402.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5558.2, "latencies_ms": [5558.2], "images_per_second": 0.18, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image features a person wearing a green jacket with a fur-lined hood, creating a striking contrast against the warm, yellowish lighting. The background is blurred, emphasizing the subject and the texture of the jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.139, "power_cpu_cv_mean_watts": 1.44, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 87.574}, "timestamp": "2026-01-30T22:20:52.010115"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3640.488, "latencies_ms": [3640.488], "images_per_second": 0.275, "prompt_tokens": 12, "response_tokens_est": 15, "n_tiles": 12, "output_text": "A tennis player is preparing to serve a ball on a blue court.", "error": null, "sys_before": {"cpu_percent": 34.0, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.599, "power_cpu_cv_mean_watts": 0.961, "power_sys_5v0_mean_watts": 8.855, "gpu_utilization_percent_mean": 90.567}, "timestamp": "2026-01-30T22:20:57.787495"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5133.191, "latencies_ms": [5133.191], "images_per_second": 0.195, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 12, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Court\n5. Chairs\n6. Stadium\n7. Blue surface\n8. White lines", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18651.7, "ram_available_mb": 44189.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.541, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 88.488}, "timestamp": "2026-01-30T22:21:04.937882"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6472.933, "latencies_ms": [6472.933], "images_per_second": 0.154, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The main object in the foreground is a tennis player holding a tennis racket. The player is standing on a blue tennis court with white lines marking the playing area. In the background, there are empty white chairs arranged in a row, suggesting that the court is set up for an event or match.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.7, "ram_available_mb": 44189.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.727, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.851, "gpu_utilization_percent_mean": 86.093}, "timestamp": "2026-01-30T22:21:13.438131"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6140.385, "latencies_ms": [6140.385], "images_per_second": 0.163, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image depicts a tennis player on a blue court, preparing to serve the ball. The player is dressed in a white shirt and black shorts, with a tennis racket in hand. The court is surrounded by white chairs, and the background shows a green wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18652.4, "ram_available_mb": 44188.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.645, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 85.863}, "timestamp": "2026-01-30T22:21:21.599961"}
{"image_index": 193, "image_name": "000000019432.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019432.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4521.106, "latencies_ms": [4521.106], "images_per_second": 0.221, "prompt_tokens": 22, "response_tokens_est": 29, "n_tiles": 12, "output_text": "The tennis court is a vibrant blue, with white lines marking the playing area. The lighting is bright and natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18652.4, "ram_available_mb": 44188.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.177, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 89.632}, "timestamp": "2026-01-30T22:21:28.171172"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5404.575, "latencies_ms": [5404.575], "images_per_second": 0.185, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image shows a candle with a lit wick on a white plate, placed on a wooden table, with a glass of amber-colored liquid beside it, and a string of white lights hanging above the table.", "error": null, "sys_before": {"cpu_percent": 23.8, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.261, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 86.533}, "timestamp": "2026-01-30T22:21:35.724827"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5218.776, "latencies_ms": [5218.776], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.333, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 87.682}, "timestamp": "2026-01-30T22:21:42.971403"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7619.477, "latencies_ms": [7619.477], "images_per_second": 0.131, "prompt_tokens": 30, "response_tokens_est": 80, "n_tiles": 12, "output_text": "The main objects in the image are a candle and a glass of amber-colored liquid. The candle is placed on a small, round, green plate near the left side of the image, while the glass of liquid is positioned in the center of the image, slightly to the right. The candle and the glass are in the foreground, with the plate serving as a supporting element in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.072, "power_cpu_cv_mean_watts": 1.688, "power_sys_5v0_mean_watts": 8.868, "gpu_utilization_percent_mean": 84.538}, "timestamp": "2026-01-30T22:21:52.612637"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6949.213, "latencies_ms": [6949.213], "images_per_second": 0.144, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a cozy indoor setting with a warm, inviting atmosphere. A glass of amber-colored liquid, possibly tea or a warm beverage, is placed on a small, round glass plate on a wooden table. The table is adorned with a string of small, white, string lights that add a festive touch to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.265, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.857, "gpu_utilization_percent_mean": 85.271}, "timestamp": "2026-01-30T22:22:01.599996"}
{"image_index": 194, "image_name": "000000019742.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019742.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5281.184, "latencies_ms": [5281.184], "images_per_second": 0.189, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image features a candle with a white base and a lit candle inside, placed on a green glass plate. The candle is surrounded by a string of white lights, creating a warm and cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.37, "power_cpu_cv_mean_watts": 1.374, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 87.682}, "timestamp": "2026-01-30T22:22:08.932296"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3753.827, "latencies_ms": [3753.827], "images_per_second": 0.266, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 12, "output_text": "A man is playing a video game while sitting on a couch in a room.", "error": null, "sys_before": {"cpu_percent": 34.1, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.374, "power_cpu_cv_mean_watts": 0.995, "power_sys_5v0_mean_watts": 8.866, "gpu_utilization_percent_mean": 89.613}, "timestamp": "2026-01-30T22:22:14.863807"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5157.289, "latencies_ms": [5157.289], "images_per_second": 0.194, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 12, "output_text": "1. man\n2. game controller\n3. game console\n4. game controller\n5. game controller\n6. game controller\n7. game controller\n8. game controller", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18651.3, "ram_available_mb": 44189.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.436, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 87.953}, "timestamp": "2026-01-30T22:22:22.036186"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5638.926, "latencies_ms": [5638.926], "images_per_second": 0.177, "prompt_tokens": 30, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The main object in the foreground is a black tripod stand with a white object on it. The white object is a laptop. The background features a person standing next to a couch, with a brown jacket hanging on a chair.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18651.3, "ram_available_mb": 44189.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.07, "power_cpu_cv_mean_watts": 1.414, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 86.809}, "timestamp": "2026-01-30T22:22:29.700252"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6922.551, "latencies_ms": [6922.551], "images_per_second": 0.144, "prompt_tokens": 24, "response_tokens_est": 68, "n_tiles": 12, "output_text": "The image depicts a man in a casual setting, possibly indoors, wearing a brown jacket and jeans. He is holding a white object in his hand and appears to be in motion, possibly walking or running. The background includes a couch, a table, and a piece of furniture, suggesting a living room or a similar indoor space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.229, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 85.259}, "timestamp": "2026-01-30T22:22:38.641707"}
{"image_index": 195, "image_name": "000000019786.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019786.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5295.488, "latencies_ms": [5295.488], "images_per_second": 0.189, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image features a man in a dark jacket and jeans standing in a room with a brown couch and a white chair. The lighting is bright, and the overall atmosphere appears to be warm and cozy.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18652.4, "ram_available_mb": 44188.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.246, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 87.523}, "timestamp": "2026-01-30T22:22:45.995368"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2816.761, "latencies_ms": [2816.761], "images_per_second": 0.355, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 1, "output_text": "The image features a black-and-white photograph of a woman wearing a wide-brimmed hat, a striped tank top, and a tie, holding a cigarette in her right hand and smiling broadly.", "error": null, "sys_before": {"cpu_percent": 23.9, "ram_used_mb": 18652.4, "ram_available_mb": 44188.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.509, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 6.95, "gpu_utilization_percent_mean": 67.348}, "timestamp": "2026-01-30T22:22:50.865531"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2720.151, "latencies_ms": [2720.151], "images_per_second": 0.368, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 1, "output_text": "1. Woman\n2. Hat\n3. Cigarette\n4. Necktie\n5. Sunglasses\n6. Sunglasses\n7. Sunglasses\n8. Sunglasses", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.559, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 6.969, "gpu_utilization_percent_mean": 67.136}, "timestamp": "2026-01-30T22:22:55.606377"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3515.879, "latencies_ms": [3515.879], "images_per_second": 0.284, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 1, "output_text": "The main object in the image is a woman wearing a wide-brimmed hat and a striped tank top. She is holding a cigarette in her right hand, which is near her mouth. The background is plain and does not provide any additional context.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18652.7, "ram_available_mb": 44188.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.557, "power_cpu_cv_mean_watts": 2.016, "power_sys_5v0_mean_watts": 7.063, "gpu_utilization_percent_mean": 67.414}, "timestamp": "2026-01-30T22:23:01.176916"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4863.008, "latencies_ms": [4863.008], "images_per_second": 0.206, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 1, "output_text": "The image depicts a black-and-white photograph of a woman wearing a wide-brimmed hat and a striped tank top. She is holding a cigarette in her right hand and appears to be smiling while looking at the camera. The setting is not clearly defined, but the woman's attire and the cigarette suggest a casual, possibly outdoor or relaxed environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18652.7, "ram_available_mb": 44188.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.442, "power_cpu_cv_mean_watts": 2.102, "power_sys_5v0_mean_watts": 7.149, "gpu_utilization_percent_mean": 67.1}, "timestamp": "2026-01-30T22:23:08.096785"}
{"image_index": 196, "image_name": "000000019924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000019924.jpg", "image_width": 458, "image_height": 500, "image_resolution": "458x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4076.986, "latencies_ms": [4076.986], "images_per_second": 0.245, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The notable visual attributes of the image include a black and white color scheme, a soft and diffused lighting that highlights the subject's features, and a woman wearing a wide-brimmed hat and a striped tank top. The hat casts a shadow over her face, adding depth to the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18653.6, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.542, "power_cpu_cv_mean_watts": 2.087, "power_sys_5v0_mean_watts": 7.104, "gpu_utilization_percent_mean": 65.333}, "timestamp": "2026-01-30T22:23:14.193740"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2566.138, "latencies_ms": [2566.138], "images_per_second": 0.39, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 6, "output_text": "A zebra is grazing on the green grass in a natural environment with trees and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 24.2, "ram_used_mb": 18653.6, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.869, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 75.381}, "timestamp": "2026-01-30T22:23:18.877263"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2763.723, "latencies_ms": [2763.723], "images_per_second": 0.362, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 6, "output_text": "zebra: 1\nrock: 1\ntree: 1\nbush: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.485, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 74.652}, "timestamp": "2026-01-30T22:23:23.660138"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5446.112, "latencies_ms": [5446.112], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The main object in the foreground is a zebra, which is positioned near the center of the image. The zebra is the primary focus of the scene. In the background, there is another zebra, which is slightly farther away. The zebra in the background is also grazing, contributing to the overall scene of a zebra enclosure.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.185, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 69.37}, "timestamp": "2026-01-30T22:23:31.139403"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5311.934, "latencies_ms": [5311.934], "images_per_second": 0.188, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image depicts a serene scene in a natural habitat, likely a zoo or wildlife reserve, where a zebra is grazing on the lush green grass. The zebra is the central focus, with its distinctive black and white stripes clearly visible. The background features a rocky outcrop and a tree, adding to the natural setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18654.4, "ram_available_mb": 44186.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.191, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 69.523}, "timestamp": "2026-01-30T22:23:38.479404"}
{"image_index": 197, "image_name": "000000020059.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020059.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4104.573, "latencies_ms": [4104.573], "images_per_second": 0.244, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image features a zebra standing in a lush, green meadow. The zebra's distinctive black and white stripes are clearly visible against the vibrant green grass. The lighting is bright and natural, suggesting it is daytime with clear weather.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18654.4, "ram_available_mb": 44186.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18654.5, "ram_available_mb": 44186.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.405, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.294}, "timestamp": "2026-01-30T22:23:44.640101"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3259.326, "latencies_ms": [3259.326], "images_per_second": 0.307, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The image shows an old, rusty fire hydrant with a chain attached to it, situated on a concrete surface with some greenery and a wall in the background.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18654.5, "ram_available_mb": 44186.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.495, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 73.63}, "timestamp": "2026-01-30T22:23:50.025393"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8843.165, "latencies_ms": [8843.165], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 6, "output_text": "fire hydrant: 1\nchain: 1\npipe: 1\npipe cap: 1\npipe bolt: 1\npipe nut: 1\npipe flange: 1\npipe flange bolt: 1\npipe flange nut: 1\npipe flange bolt cap: 1\npipe flange bolt cap nut: 1\npipe flange bolt cap nut chain: 1\npipe flange bolt cap nut chain: 1\npipe flange bolt cap nut chain: 1\npipe flange bolt cap nut chain: 1\npipe flange bolt cap nut chain", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.912, "power_cpu_cv_mean_watts": 2.078, "power_sys_5v0_mean_watts": 8.084, "gpu_utilization_percent_mean": 67.865}, "timestamp": "2026-01-30T22:24:00.894352"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5435.267, "latencies_ms": [5435.267], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The main object in the foreground is a rusty, beige fire hydrant with a chain attached to it. The chain is attached to the hydrant's cap. In the background, there is a wall with a mural depicting green trees. The hydrant is positioned on a concrete surface, and there are some leaves and twigs nearby.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.252, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.533}, "timestamp": "2026-01-30T22:24:08.357395"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5187.286, "latencies_ms": [5187.286], "images_per_second": 0.193, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts an old, rusty fire hydrant situated outdoors on a concrete surface. The hydrant is weathered and shows signs of wear, with a chain attached to it. The surrounding area appears to be a public space, possibly a park or a street, with some greenery and a wall in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.406, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 70.279}, "timestamp": "2026-01-30T22:24:15.582990"}
{"image_index": 198, "image_name": "000000020107.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020107.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3445.183, "latencies_ms": [3445.183], "images_per_second": 0.29, "prompt_tokens": 22, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The fire hydrant in the image has a rusty, peeling paint job, with a rusty metal cap and chain. The lighting is natural, suggesting it might be daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.489, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 72.786}, "timestamp": "2026-01-30T22:24:21.056129"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3752.919, "latencies_ms": [3752.919], "images_per_second": 0.266, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 12, "output_text": "A brown bear is standing on a dirt ground, looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 32.3, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.362, "power_cpu_cv_mean_watts": 0.995, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 90.581}, "timestamp": "2026-01-30T22:24:26.982645"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3452.264, "latencies_ms": [3452.264], "images_per_second": 0.29, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 12, "output_text": "bear: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.884, "power_cpu_cv_mean_watts": 0.829, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 94.429}, "timestamp": "2026-01-30T22:24:32.451000"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7409.995, "latencies_ms": [7409.995], "images_per_second": 0.135, "prompt_tokens": 30, "response_tokens_est": 76, "n_tiles": 12, "output_text": "The main object in the foreground is a brown bear, which is positioned near the center of the image. The bear is facing the camera and appears to be walking. In the background, there is a blurred brown bear, which is further away from the camera. The blurred bear is partially obscured by the foreground bear, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.99, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 84.46}, "timestamp": "2026-01-30T22:24:41.906329"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5153.644, "latencies_ms": [5153.644], "images_per_second": 0.194, "prompt_tokens": 24, "response_tokens_est": 39, "n_tiles": 12, "output_text": "The image depicts a brown bear walking on a sandy terrain, likely in a natural habitat. The bear appears to be in motion, with its fur slightly tousled by the wind.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.485, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.796, "gpu_utilization_percent_mean": 87.767}, "timestamp": "2026-01-30T22:24:49.095157"}
{"image_index": 199, "image_name": "000000020247.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020247.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6060.565, "latencies_ms": [6060.565], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image features a brown bear standing on a dusty, rocky ground. The lighting is natural, casting shadows on the ground, indicating it is daytime. The bear's fur appears thick and slightly matted, suggesting it is well-adapted to its environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18655.4, "ram_available_mb": 44185.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.725, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 86.412}, "timestamp": "2026-01-30T22:24:57.174932"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3573.341, "latencies_ms": [3573.341], "images_per_second": 0.28, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 6, "output_text": "A young child is kneeling in a shallow pit filled with soil, wearing a white shirt and a colorful tie, and appears to be engaged in an activity related to digging or playing in the dirt.", "error": null, "sys_before": {"cpu_percent": 27.0, "ram_used_mb": 18655.4, "ram_available_mb": 44185.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.097, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 72.3}, "timestamp": "2026-01-30T22:25:02.874500"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3738.601, "latencies_ms": [3738.601], "images_per_second": 0.267, "prompt_tokens": 26, "response_tokens_est": 43, "n_tiles": 6, "output_text": "1. Child\n2. Shovel\n3. Bucket\n4. Shovel handle\n5. Shovel blade\n6. Shovel base\n7. Shovel handle\n8. Shovel blade", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.934, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 72.677}, "timestamp": "2026-01-30T22:25:08.632199"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5065.917, "latencies_ms": [5065.917], "images_per_second": 0.197, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The main object in the foreground is a small child wearing a white shirt and a colorful tie. The child is kneeling on the ground, with a large metal bowl filled with soil in front of them. The background features a dark, leafy bush, providing a contrast to the bright colors of the child's clothing.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18654.5, "ram_available_mb": 44186.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.51, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 69.953}, "timestamp": "2026-01-30T22:25:15.741001"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5909.753, "latencies_ms": [5909.753], "images_per_second": 0.169, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image depicts a young child, likely a toddler, engaged in an outdoor activity. The child is kneeling on a patch of dirt, surrounded by a large metal bucket filled with dark soil. The child appears to be playing with the soil, possibly digging or examining it. The setting is outdoors, with a backdrop of lush green foliage, indicating a garden or park environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.5, "ram_available_mb": 44186.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18655.2, "ram_available_mb": 44185.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.958, "power_cpu_cv_mean_watts": 1.931, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 69.14}, "timestamp": "2026-01-30T22:25:23.709602"}
{"image_index": 200, "image_name": "000000020333.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020333.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3796.449, "latencies_ms": [3796.449], "images_per_second": 0.263, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The notable visual attributes of the image include a child with light-colored hair, wearing a white shirt and a colorful tie, and a black and white photograph. The lighting is natural, with shadows indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 18655.2, "ram_available_mb": 44185.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18655.3, "ram_available_mb": 44185.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.771, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 72.031}, "timestamp": "2026-01-30T22:25:29.522291"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4642.744, "latencies_ms": [4642.744], "images_per_second": 0.215, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "A small table is placed on the ground with a few items on it, including a bottle of beer, a small plant, and a few other objects.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18655.3, "ram_available_mb": 44185.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18654.4, "ram_available_mb": 44186.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.272, "power_cpu_cv_mean_watts": 1.244, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 88.658}, "timestamp": "2026-01-30T22:25:36.317644"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6300.012, "latencies_ms": [6300.012], "images_per_second": 0.159, "prompt_tokens": 26, "response_tokens_est": 58, "n_tiles": 12, "output_text": "1. Stuffed animals: 3\n2. Bottle: 1\n3. Bottle: 1\n4. Bottle: 1\n5. Bottle: 1\n6. Bottle: 1\n7. Bottle: 1\n8. Bottle: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.4, "ram_available_mb": 44186.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.638, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 86.415}, "timestamp": "2026-01-30T22:25:44.644045"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7465.439, "latencies_ms": [7465.439], "images_per_second": 0.134, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The main objects in the image are a collection of stuffed animals and a small table. The stuffed animals are positioned on the table, with one bear sitting on top of the table and another bear standing on the table. The table is placed in the foreground, with the stuffed animals and other objects placed on it. The background features a barren, sandy landscape with sparse vegetation.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.067, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 84.937}, "timestamp": "2026-01-30T22:25:54.155729"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5411.966, "latencies_ms": [5411.966], "images_per_second": 0.185, "prompt_tokens": 24, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image depicts a desert-like environment with a dirt ground and sparse vegetation. A small table is placed in the center, holding various items including a bottle, a small plant, and a few other objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.227, "power_cpu_cv_mean_watts": 1.38, "power_sys_5v0_mean_watts": 8.773, "gpu_utilization_percent_mean": 86.956}, "timestamp": "2026-01-30T22:26:01.596044"}
{"image_index": 201, "image_name": "000000020553.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020553.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6007.321, "latencies_ms": [6007.321], "images_per_second": 0.166, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image depicts a desert scene with a sandy ground and sparse vegetation. The lighting is bright and natural, casting shadows on the ground. The materials used include a wooden table, a red cross pillow, a green plastic bottle, and various stuffed animals.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18655.2, "ram_available_mb": 44185.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.766, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 86.66}, "timestamp": "2026-01-30T22:26:09.628255"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5669.102, "latencies_ms": [5669.102], "images_per_second": 0.176, "prompt_tokens": 12, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image depicts a harbor scene with a variety of boats and a calm body of water, featuring a green and yellow boat with the name \"AZALEA\" on its side, alongside other smaller boats and buoys scattered around.", "error": null, "sys_before": {"cpu_percent": 29.8, "ram_used_mb": 18655.2, "ram_available_mb": 44185.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.278, "power_cpu_cv_mean_watts": 1.449, "power_sys_5v0_mean_watts": 8.876, "gpu_utilization_percent_mean": 85.362}, "timestamp": "2026-01-30T22:26:17.478961"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10539.252, "latencies_ms": [10539.252], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "boat: 1\nbuoy: 1\nlifebuoy: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole: 1\npole", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18654.8, "ram_available_mb": 44186.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.185, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 8.882, "gpu_utilization_percent_mean": 82.337}, "timestamp": "2026-01-30T22:26:30.063791"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7234.088, "latencies_ms": [7234.088], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The main objects in the image are a weathered boat and a rusty metal sign. The boat is situated in the foreground, with its deck and various items like ropes and buoys visible. The sign is located near the boat, attached to a metal structure. The background features a calm body of water with several boats and a hilly landscape.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18654.8, "ram_available_mb": 44186.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18655.3, "ram_available_mb": 44185.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.081, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 84.18}, "timestamp": "2026-01-30T22:26:39.358843"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6599.217, "latencies_ms": [6599.217], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a harbor scene with a variety of boats and a calm body of water. The setting appears to be a coastal area with green hills in the background and a cloudy sky. There are several boats moored in the harbor, and a person can be seen standing near the water's edge.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18655.3, "ram_available_mb": 44185.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.515, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 85.945}, "timestamp": "2026-01-30T22:26:47.977706"}
{"image_index": 202, "image_name": "000000020571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020571.jpg", "image_width": 539, "image_height": 640, "image_resolution": "539x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7387.338, "latencies_ms": [7387.338], "images_per_second": 0.135, "prompt_tokens": 22, "response_tokens_est": 76, "n_tiles": 12, "output_text": "The image depicts a harbor scene with a variety of boats and a calm body of water. The boats are painted in different colors, including green, yellow, and red, and are equipped with various equipment such as lifebuoys and ropes. The lighting is soft and diffused, suggesting an overcast day, and the weather appears to be mild and pleasant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.122, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 85.113}, "timestamp": "2026-01-30T22:26:57.406100"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2458.14, "latencies_ms": [2458.14], "images_per_second": 0.407, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "A woman is eating a hot dog with her mouth open, and she is wearing a black scarf.", "error": null, "sys_before": {"cpu_percent": 22.0, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.154, "power_cpu_cv_mean_watts": 1.162, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-30T22:27:01.987153"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3076.808, "latencies_ms": [3076.808], "images_per_second": 0.325, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Woman\n2. Food\n3. Plate\n4. Bowl\n5. Bowl\n6. Bowl\n7. Bowl\n8. Bowl", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.05, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 73.64}, "timestamp": "2026-01-30T22:27:07.088633"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4051.166, "latencies_ms": [4051.166], "images_per_second": 0.247, "prompt_tokens": 30, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The main object in the foreground is a person holding a hot dog. The person is wearing a black scarf and has a focused expression. The background is blurred, with indistinct shapes and lights, suggesting an indoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.502, "power_cpu_cv_mean_watts": 1.651, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 71.485}, "timestamp": "2026-01-30T22:27:13.159727"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4340.497, "latencies_ms": [4340.497], "images_per_second": 0.23, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The image depicts a close-up of a person eating a hot dog, with their mouth open and tongue visible. The setting appears to be indoors, possibly in a dimly lit area, as suggested by the blurred background and the warm, soft lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.005, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 71.056}, "timestamp": "2026-01-30T22:27:19.530651"}
{"image_index": 203, "image_name": "000000020992.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000020992.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3128.978, "latencies_ms": [3128.978], "images_per_second": 0.32, "prompt_tokens": 22, "response_tokens_est": 33, "n_tiles": 6, "output_text": "The image features a person with short hair, wearing a dark-colored scarf. The lighting is dim, with a warm glow illuminating the subject's face.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.783, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 74.538}, "timestamp": "2026-01-30T22:27:24.720512"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2851.645, "latencies_ms": [2851.645], "images_per_second": 0.351, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "A man and a woman are standing in a room, with the man holding a martini glass and the woman looking off to the side.", "error": null, "sys_before": {"cpu_percent": 22.1, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18656.3, "ram_available_mb": 44184.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.588, "power_cpu_cv_mean_watts": 1.428, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 72.913}, "timestamp": "2026-01-30T22:27:29.667179"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4509.641, "latencies_ms": [4509.641], "images_per_second": 0.222, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 6, "output_text": "1. Man: 1\n2. Woman: 1\n3. Man: 1\n4. Woman: 1\n5. Man: 1\n6. Woman: 1\n7. Man: 1\n8. Woman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.3, "ram_available_mb": 44184.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18655.9, "ram_available_mb": 44185.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.891, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 70.605}, "timestamp": "2026-01-30T22:27:36.210240"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4337.043, "latencies_ms": [4337.043], "images_per_second": 0.231, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The main objects in the image are a man and a woman standing close to each other. The man is in the foreground, while the woman is slightly behind him. The background is slightly blurred, indicating that the focus is on the man and the woman.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18655.9, "ram_available_mb": 44185.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.319, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 71.222}, "timestamp": "2026-01-30T22:27:42.572257"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5927.324, "latencies_ms": [5927.324], "images_per_second": 0.169, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image depicts a man and a woman standing in an indoor setting, possibly a hallway or a room. The man is dressed in a formal black suit and tie, holding a martini glass with a drink. The woman is wearing a dark, sleeveless dress and has her hair tied back. They appear to be engaged in a conversation, with the man looking slightly to his right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.918, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 69.469}, "timestamp": "2026-01-30T22:27:50.523621"}
{"image_index": 204, "image_name": "000000021167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021167.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4833.296, "latencies_ms": [4833.296], "images_per_second": 0.207, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image features a man and a woman standing indoors. The man is dressed in a black suit with a white shirt and a dark tie, while the woman is wearing a dark, sleeveless dress. The lighting is dim, and the overall atmosphere appears to be indoors with a warm, soft glow.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.567, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 70.35}, "timestamp": "2026-01-30T22:27:57.392853"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3654.088, "latencies_ms": [3654.088], "images_per_second": 0.274, "prompt_tokens": 12, "response_tokens_est": 53, "n_tiles": 2, "output_text": "The image shows a cluttered blue table with various items scattered on it, including a metal pitcher, a small plate, a basket, and a wooden chair, all set against a backdrop of a rustic wooden table and a green surface with a small figurine.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.953, "power_cpu_cv_mean_watts": 1.938, "power_sys_5v0_mean_watts": 7.254, "gpu_utilization_percent_mean": 62.613}, "timestamp": "2026-01-30T22:28:03.122687"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2874.116, "latencies_ms": [2874.116], "images_per_second": 0.348, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 2, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.453, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.201, "gpu_utilization_percent_mean": 64.826}, "timestamp": "2026-01-30T22:28:08.039493"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3851.794, "latencies_ms": [3851.794], "images_per_second": 0.26, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 2, "output_text": "The main objects in the image are a blue table and a green table. The blue table is in the foreground, while the green table is in the background. The objects on the blue table are closer to the viewer, while the objects on the green table are farther away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18656.7, "ram_available_mb": 44184.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.13, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.273, "gpu_utilization_percent_mean": 63.375}, "timestamp": "2026-01-30T22:28:13.920480"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5364.897, "latencies_ms": [5364.897], "images_per_second": 0.186, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 2, "output_text": "The image depicts an outdoor setting with a rustic, vintage-style table and chair. The table is painted blue and has various items on it, including a metal pitcher, a small plate, and a few cups. The chair is yellow and has a wooden seat. The table and chair are surrounded by a concrete floor, and there is a green tabletop with a white border visible in the background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18656.7, "ram_available_mb": 44184.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18655.9, "ram_available_mb": 44185.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.671, "power_cpu_cv_mean_watts": 2.074, "power_sys_5v0_mean_watts": 7.302, "gpu_utilization_percent_mean": 62.756}, "timestamp": "2026-01-30T22:28:21.305324"}
{"image_index": 205, "image_name": "000000021465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021465.jpg", "image_width": 500, "image_height": 281, "image_resolution": "500x281", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4188.897, "latencies_ms": [4188.897], "images_per_second": 0.239, "prompt_tokens": 22, "response_tokens_est": 62, "n_tiles": 2, "output_text": "The image showcases a vibrant blue table with a rustic, weathered look. The table is adorned with various metallic objects, including vases and cups, and is surrounded by a mix of wooden and metal furniture pieces. The lighting is natural, casting soft shadows and highlighting the textures of the objects.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18655.7, "ram_available_mb": 44185.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18655.7, "ram_available_mb": 44185.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.052, "power_cpu_cv_mean_watts": 2.014, "power_sys_5v0_mean_watts": 7.26, "gpu_utilization_percent_mean": 63.286}, "timestamp": "2026-01-30T22:28:27.533756"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4853.591, "latencies_ms": [4853.591], "images_per_second": 0.206, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image shows a close-up view of a plate with a slice of cheesecake, which is topped with a layer of cream and has a golden-brown crust.", "error": null, "sys_before": {"cpu_percent": 29.0, "ram_used_mb": 18655.7, "ram_available_mb": 44185.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18655.0, "ram_available_mb": 44185.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.11, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 8.847, "gpu_utilization_percent_mean": 88.4}, "timestamp": "2026-01-30T22:28:34.549976"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6066.88, "latencies_ms": [6066.88], "images_per_second": 0.165, "prompt_tokens": 26, "response_tokens_est": 54, "n_tiles": 12, "output_text": "- 1 pizza\n- 1 slice of pizza\n- 1 slice of bread\n- 1 slice of bread\n- 1 slice of bread\n- 1 slice of bread\n- 1 slice of bread\n- 1 slice of bread", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.0, "ram_available_mb": 44185.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18654.6, "ram_available_mb": 44186.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.89, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 86.176}, "timestamp": "2026-01-30T22:28:42.641292"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7123.694, "latencies_ms": [7123.694], "images_per_second": 0.14, "prompt_tokens": 30, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The main objects in the image are a plate of cheesy breadsticks. The cheesy breadsticks are positioned in the foreground, with the plate serving as the background. The cheesy breadsticks are near the center of the image, while the background is slightly blurred, emphasizing the cheesy breadsticks as the main focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.6, "ram_available_mb": 44186.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.283, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 85.783}, "timestamp": "2026-01-30T22:28:51.777150"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7084.062, "latencies_ms": [7084.062], "images_per_second": 0.141, "prompt_tokens": 24, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The image depicts a close-up view of a plate with several pieces of a cheesy, golden-brown pastry, likely a type of bread or pastry. The setting appears to be indoors, possibly in a kitchen or dining area, with a blurred background featuring a computer mouse and a keyboard, suggesting a workspace or a home environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.169, "power_cpu_cv_mean_watts": 1.655, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 84.55}, "timestamp": "2026-01-30T22:29:00.906880"}
{"image_index": 206, "image_name": "000000021503.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021503.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6593.379, "latencies_ms": [6593.379], "images_per_second": 0.152, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image features a close-up view of a plate with a slice of cake, which has a light, creamy frosting. The background is softly blurred, with a hint of a computer keyboard and a mouse, suggesting a home or office setting. The lighting is warm and soft, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.403, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 85.446}, "timestamp": "2026-01-30T22:29:09.525423"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4426.552, "latencies_ms": [4426.552], "images_per_second": 0.226, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "The image shows a man dressed in a dark suit, white shirt, and a tie adorned with small, red, glowing lights.", "error": null, "sys_before": {"cpu_percent": 29.7, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.337, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 87.135}, "timestamp": "2026-01-30T22:29:16.103450"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4972.906, "latencies_ms": [4972.906], "images_per_second": 0.201, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 12, "output_text": "1. Man\n2. Suits\n3. Tie\n4. Glasses\n5. Shirt\n6. Background\n7. Lighting\n8. Mannequin", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18654.7, "ram_available_mb": 44186.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.583, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 88.071}, "timestamp": "2026-01-30T22:29:23.123830"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5800.058, "latencies_ms": [5800.058], "images_per_second": 0.172, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The main object in the foreground is a man wearing a black suit and tie. The tie has a series of small, red lights embedded in it. The man is standing against a dark background, with the tie and lights creating a striking contrast.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.163, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 8.852, "gpu_utilization_percent_mean": 85.816}, "timestamp": "2026-01-30T22:29:30.967618"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6582.728, "latencies_ms": [6582.728], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a man dressed in a formal black suit and tie, standing against a dark, neutral background. He is adjusting his tie, with a slight smile on his face, suggesting a moment of personal grooming or preparation. The overall scene conveys a sense of professionalism and attention to detail.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18654.8, "ram_available_mb": 44186.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.431, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 86.089}, "timestamp": "2026-01-30T22:29:39.588276"}
{"image_index": 207, "image_name": "000000021604.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021604.jpg", "image_width": 512, "image_height": 640, "image_resolution": "512x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6000.732, "latencies_ms": [6000.732], "images_per_second": 0.167, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The man in the image is wearing a black suit with a white shirt and a dark tie. The tie has a unique design with small, red lights embedded in it. The lighting in the image is soft and focused on the man, creating a dramatic effect.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.8, "ram_available_mb": 44186.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18655.1, "ram_available_mb": 44185.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.715, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.798, "gpu_utilization_percent_mean": 86.294}, "timestamp": "2026-01-30T22:29:47.619886"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4393.908, "latencies_ms": [4393.908], "images_per_second": 0.228, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 12, "output_text": "A woman is walking down a street at night, passing by a building with a sign that reads \"TADU RIA.\"", "error": null, "sys_before": {"cpu_percent": 28.0, "ram_used_mb": 18655.1, "ram_available_mb": 44185.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18655.5, "ram_available_mb": 44185.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.274, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 88.75}, "timestamp": "2026-01-30T22:29:54.152358"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4556.439, "latencies_ms": [4556.439], "images_per_second": 0.219, "prompt_tokens": 26, "response_tokens_est": 29, "n_tiles": 12, "output_text": "- Street light\n- Street sign\n- Pedestrian\n- Building\n- Street\n- Car\n- Storefront\n- Sign", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.5, "ram_available_mb": 44185.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18655.7, "ram_available_mb": 44185.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.029, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 89.0}, "timestamp": "2026-01-30T22:30:00.739196"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6084.204, "latencies_ms": [6084.204], "images_per_second": 0.164, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The main object in the foreground is a person walking on the street. The person is near the street, with a building and a traffic light in the background. The building is on the right side of the image, and the traffic light is on the left side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.7, "ram_available_mb": 44185.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18655.7, "ram_available_mb": 44185.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.748, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 86.608}, "timestamp": "2026-01-30T22:30:08.847430"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7287.656, "latencies_ms": [7287.656], "images_per_second": 0.137, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The image depicts a nighttime street scene in an urban area, likely in a city with a European architectural style. A woman is walking on the sidewalk, carrying a bag, while a streetlight and traffic signal are visible in the foreground. The building in the background has a sign that reads \"TADU RIA,\" indicating a possible business or establishment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18655.7, "ram_available_mb": 44185.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18655.5, "ram_available_mb": 44185.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.067, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 84.77}, "timestamp": "2026-01-30T22:30:18.154633"}
{"image_index": 208, "image_name": "000000021839.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021839.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6057.121, "latencies_ms": [6057.121], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image depicts a nighttime scene with a building illuminated by warm, yellow lights. The building's exterior is white, and it has multiple balconies with glass windows. The street is dark, and the sky is clear, indicating it is nighttime.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18655.5, "ram_available_mb": 44185.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.788, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 86.431}, "timestamp": "2026-01-30T22:30:26.259499"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2822.558, "latencies_ms": [2822.558], "images_per_second": 0.354, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 6, "output_text": "A young woman is surfing on a blue surfboard, balancing on the waves, while another person is also surfing on a blue board.", "error": null, "sys_before": {"cpu_percent": 26.6, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18656.9, "ram_available_mb": 44184.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.43, "power_cpu_cv_mean_watts": 1.358, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 75.435}, "timestamp": "2026-01-30T22:30:31.199232"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2569.219, "latencies_ms": [2569.219], "images_per_second": 0.389, "prompt_tokens": 26, "response_tokens_est": 24, "n_tiles": 6, "output_text": "surfboard: 1\nwoman: 1\nman: 1\nwetsuit: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.9, "ram_available_mb": 44184.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18656.9, "ram_available_mb": 44184.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.195, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 77.19}, "timestamp": "2026-01-30T22:30:35.810403"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4993.968, "latencies_ms": [4993.968], "images_per_second": 0.2, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main objects in the image are a blue surfboard and a person in a black wetsuit. The person is in the foreground, closer to the camera, while the surfboard is in the background, further away. The person is also closer to the water's edge, indicating a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.9, "ram_available_mb": 44184.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18657.3, "ram_available_mb": 44183.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.629, "power_cpu_cv_mean_watts": 1.831, "power_sys_5v0_mean_watts": 8.095, "gpu_utilization_percent_mean": 70.571}, "timestamp": "2026-01-30T22:30:42.835692"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6279.768, "latencies_ms": [6279.768], "images_per_second": 0.159, "prompt_tokens": 24, "response_tokens_est": 85, "n_tiles": 6, "output_text": "The image captures a dynamic scene at the beach, where a young woman is surfing on a blue surfboard. She is skillfully riding a wave, with her body leaning forward and her arms outstretched for balance. In the background, another person is seen lying on a surfboard, seemingly relaxed and enjoying the ocean. The setting is a sunny day at the beach, with clear blue water and a calm atmosphere.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18657.3, "ram_available_mb": 44183.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18657.2, "ram_available_mb": 44183.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.654, "power_cpu_cv_mean_watts": 1.934, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 68.547}, "timestamp": "2026-01-30T22:30:51.147951"}
{"image_index": 209, "image_name": "000000021879.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021879.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4153.474, "latencies_ms": [4153.474], "images_per_second": 0.241, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a scene of a young woman surfing on a blue surfboard in the ocean. The water is a light blue-green color, and the waves are small and gentle. The lighting is bright and natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18657.2, "ram_available_mb": 44183.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18657.2, "ram_available_mb": 44183.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.257, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 71.886}, "timestamp": "2026-01-30T22:30:57.337115"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5042.334, "latencies_ms": [5042.334], "images_per_second": 0.198, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "A man in a white shirt is standing on a concrete platform, reaching out to touch the trunk of an elephant, which is standing on a grassy area with trees in the background.", "error": null, "sys_before": {"cpu_percent": 29.1, "ram_used_mb": 18657.2, "ram_available_mb": 44183.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18657.4, "ram_available_mb": 44183.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.716, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.863, "gpu_utilization_percent_mean": 85.905}, "timestamp": "2026-01-30T22:31:04.540832"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6239.056, "latencies_ms": [6239.056], "images_per_second": 0.16, "prompt_tokens": 26, "response_tokens_est": 57, "n_tiles": 12, "output_text": "1. Elephant: 1\n2. Man: 1\n3. Person: 1\n4. Person: 1\n5. Person: 1\n6. Person: 1\n7. Person: 1\n8. Person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18657.4, "ram_available_mb": 44183.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18657.9, "ram_available_mb": 44183.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.622, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 85.811}, "timestamp": "2026-01-30T22:31:12.821773"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6066.667, "latencies_ms": [6066.667], "images_per_second": 0.165, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The main object in the foreground is a man standing near a fence, with his right hand extended towards an elephant. The elephant is positioned to the left of the man. The background features a dense green area with trees and foliage, creating a natural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18657.9, "ram_available_mb": 44183.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18658.6, "ram_available_mb": 44182.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.739, "power_cpu_cv_mean_watts": 1.531, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 86.529}, "timestamp": "2026-01-30T22:31:20.928013"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6231.809, "latencies_ms": [6231.809], "images_per_second": 0.16, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image depicts an outdoor scene with a man in a white shirt and khaki pants standing on a concrete platform, holding onto a metal fence. In the background, there is a lush green area with trees and foliage, suggesting a park or garden setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18658.6, "ram_available_mb": 44182.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18659.6, "ram_available_mb": 44181.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.291, "power_cpu_cv_mean_watts": 1.511, "power_sys_5v0_mean_watts": 8.723, "gpu_utilization_percent_mean": 84.679}, "timestamp": "2026-01-30T22:31:29.192753"}
{"image_index": 210, "image_name": "000000021903.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000021903.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5347.272, "latencies_ms": [5347.272], "images_per_second": 0.187, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image depicts a man in a white shirt and khaki pants standing next to a fence, with a large elephant in the background. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18659.6, "ram_available_mb": 44181.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18659.3, "ram_available_mb": 44181.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.277, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 87.591}, "timestamp": "2026-01-30T22:31:36.553370"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2194.995, "latencies_ms": [2194.995], "images_per_second": 0.456, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 6, "output_text": "A brown dog is sitting on a bed with various clothes and items scattered around it.", "error": null, "sys_before": {"cpu_percent": 25.5, "ram_used_mb": 18659.3, "ram_available_mb": 44181.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.016, "power_cpu_cv_mean_watts": 1.091, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 79.278}, "timestamp": "2026-01-30T22:31:40.848014"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3142.963, "latencies_ms": [3142.963], "images_per_second": 0.318, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 6, "output_text": "dog: 1\npillow: 1\nblanket: 1\nclothes: 1\npaper: 1\nbox: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18657.5, "ram_available_mb": 44183.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.819, "power_cpu_cv_mean_watts": 1.464, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 73.269}, "timestamp": "2026-01-30T22:31:46.045763"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6874.587, "latencies_ms": [6874.587], "images_per_second": 0.145, "prompt_tokens": 30, "response_tokens_est": 95, "n_tiles": 6, "output_text": "The main object in the foreground is a brown dog, which is positioned near the center of the image. The dog is sitting on a bed with various items scattered around it, including a red bag, a white pillow, and a pink blanket. The background consists of a white curtain and a wooden door frame, which are partially visible. The dog appears to be the focal point of the image, with the other objects in the foreground and background providing context to the scene.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18657.5, "ram_available_mb": 44183.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18657.4, "ram_available_mb": 44183.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.469, "power_cpu_cv_mean_watts": 1.981, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 68.491}, "timestamp": "2026-01-30T22:31:54.937689"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3912.187, "latencies_ms": [3912.187], "images_per_second": 0.256, "prompt_tokens": 24, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The image depicts a cluttered bedroom setting with a brown dog sitting on a bed. The bed is covered with various items, including clothes, pillows, and a blanket, creating a messy and disorganized appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18657.4, "ram_available_mb": 44183.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18657.6, "ram_available_mb": 44183.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.613, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 71.606}, "timestamp": "2026-01-30T22:32:00.874237"}
{"image_index": 211, "image_name": "000000022192.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022192.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4712.723, "latencies_ms": [4712.723], "images_per_second": 0.212, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a cluttered room with a brown dog sitting on a bed. The dog has a dark coat and is looking directly at the camera. The room is dimly lit, with a soft, natural light coming from the left side, creating a cozy and somewhat mysterious atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18657.6, "ram_available_mb": 44183.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18657.6, "ram_available_mb": 44183.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.658, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 69.475}, "timestamp": "2026-01-30T22:32:07.605710"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3540.186, "latencies_ms": [3540.186], "images_per_second": 0.282, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The image depicts a man dressed in a white shirt and blue tie, seated at a desk with a laptop, pen, and some papers, appearing to be deep in thought or contemplation.", "error": null, "sys_before": {"cpu_percent": 28.1, "ram_used_mb": 18657.6, "ram_available_mb": 44183.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18658.1, "ram_available_mb": 44182.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.091, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 72.517}, "timestamp": "2026-01-30T22:32:13.261568"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4040.707, "latencies_ms": [4040.707], "images_per_second": 0.247, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 6, "output_text": "object: 1 laptop\nobject: 1 pen\nobject: 1 notebook\nobject: 1 pen\nobject: 1 notebook\nobject: 1 notebook\nobject: 1 notebook\nobject: 1 notebook", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18658.1, "ram_available_mb": 44182.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18657.8, "ram_available_mb": 44183.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.563, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 71.667}, "timestamp": "2026-01-30T22:32:19.343030"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4683.141, "latencies_ms": [4683.141], "images_per_second": 0.214, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The main object in the foreground is a man sitting at a desk, writing in a notebook. The laptop is placed to his left, and a pen is on the desk near the man. The background is blurred, but it appears to be an office setting with a light blue wall.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18657.8, "ram_available_mb": 44183.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18657.8, "ram_available_mb": 44183.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.019, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 70.744}, "timestamp": "2026-01-30T22:32:26.064186"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4929.983, "latencies_ms": [4929.983], "images_per_second": 0.203, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The image depicts a man in a professional setting, seated at a desk with a laptop and a pen. He appears to be engaged in a task, possibly reviewing or writing something on a piece of paper. The background is minimalistic, with a plain light blue wall, suggesting a clean and organized workspace.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18657.8, "ram_available_mb": 44183.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18658.1, "ram_available_mb": 44182.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.678, "power_cpu_cv_mean_watts": 1.841, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 70.381}, "timestamp": "2026-01-30T22:32:33.031509"}
{"image_index": 212, "image_name": "000000022371.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022371.jpg", "image_width": 425, "image_height": 282, "image_resolution": "425x282", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3509.169, "latencies_ms": [3509.169], "images_per_second": 0.285, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The man in the image is wearing a white shirt with a blue tie. The background is a light blue wall, and the lighting is bright, creating a clear and well-lit scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18658.1, "ram_available_mb": 44182.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.204, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 73.207}, "timestamp": "2026-01-30T22:32:38.560444"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4250.762, "latencies_ms": [4250.762], "images_per_second": 0.235, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 12, "output_text": "The image depicts a large, full moon in the sky, with a brightly lit airplane flying in the background.", "error": null, "sys_before": {"cpu_percent": 29.5, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.517, "power_cpu_cv_mean_watts": 1.122, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 89.171}, "timestamp": "2026-01-30T22:32:44.962396"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4926.026, "latencies_ms": [4926.026], "images_per_second": 0.203, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 12, "output_text": "1. Moon\n2. Airplane\n3. Sky\n4. Earth\n5. Sun\n6. Stars\n7. Clouds\n8. Atmosphere", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.595, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.769, "gpu_utilization_percent_mean": 88.098}, "timestamp": "2026-01-30T22:32:51.939915"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5516.708, "latencies_ms": [5516.708], "images_per_second": 0.181, "prompt_tokens": 30, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The main objects in the image are the moon and the airplane. The moon is positioned in the background, while the airplane is in the foreground. The airplane is closer to the viewer, while the moon is further away.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18658.8, "ram_available_mb": 44182.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.213, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 87.565}, "timestamp": "2026-01-30T22:32:59.490694"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6682.305, "latencies_ms": [6682.305], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image captures a clear blue sky with a single, large, and brightly lit moon visible in the background. The moon is positioned slightly to the left of the center of the image, and it appears to be a full moon, with its surface showing a range of colors from deep craters to lighter areas.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18658.8, "ram_available_mb": 44182.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18658.1, "ram_available_mb": 44182.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.245, "power_cpu_cv_mean_watts": 1.581, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.125}, "timestamp": "2026-01-30T22:33:08.208585"}
{"image_index": 213, "image_name": "000000022396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022396.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6116.123, "latencies_ms": [6116.123], "images_per_second": 0.164, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image features a large, partially illuminated moon with a reddish hue, set against a clear blue sky. The lighting is soft and diffused, with no harsh shadows, indicating either a cloudy day or a time when the sun is not directly overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18658.1, "ram_available_mb": 44182.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18658.0, "ram_available_mb": 44182.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.819, "power_cpu_cv_mean_watts": 1.492, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 86.353}, "timestamp": "2026-01-30T22:33:16.346289"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1861.854, "latencies_ms": [1861.854], "images_per_second": 0.537, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 1, "output_text": "A skateboarder is performing a trick in a skate park, with a colorful board and a focus on the action.", "error": null, "sys_before": {"cpu_percent": 21.8, "ram_used_mb": 18658.0, "ram_available_mb": 44182.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18657.0, "ram_available_mb": 44183.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.133, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 6.753, "gpu_utilization_percent_mean": 73.333}, "timestamp": "2026-01-30T22:33:20.308631"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2830.907, "latencies_ms": [2830.907], "images_per_second": 0.353, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 1, "output_text": "1. Skateboarder\n2. T-shirt\n3. Sunglasses\n4. Headphones\n5. Legs\n6. Skateboard\n7. Park\n8. Trees", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18657.0, "ram_available_mb": 44183.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18657.2, "ram_available_mb": 44183.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.545, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 6.937, "gpu_utilization_percent_mean": 67.261}, "timestamp": "2026-01-30T22:33:25.161742"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5010.094, "latencies_ms": [5010.094], "images_per_second": 0.2, "prompt_tokens": 30, "response_tokens_est": 76, "n_tiles": 1, "output_text": "The main object in the foreground is a skateboarder performing a trick on a concrete ramp. The skateboarder is in the center of the frame, with the skateboard tilted at an angle, indicating a mid-air maneuver. The background features a park with palm trees, a building, and other recreational structures, creating a sense of depth and context for the action.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18657.2, "ram_available_mb": 44183.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18657.2, "ram_available_mb": 44183.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.615, "power_cpu_cv_mean_watts": 2.11, "power_sys_5v0_mean_watts": 7.127, "gpu_utilization_percent_mean": 66.293}, "timestamp": "2026-01-30T22:33:32.197265"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5017.109, "latencies_ms": [5017.109], "images_per_second": 0.199, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 1, "output_text": "The image captures a dynamic moment at a skate park, where a skateboarder is performing a trick. The skateboarder, dressed in a colorful tie-dye shirt and black pants, is airborne, showcasing impressive skill and control. The background features a park setting with palm trees, a concrete ramp, and other recreational structures, creating a vibrant and energetic atmosphere.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18657.2, "ram_available_mb": 44183.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18656.9, "ram_available_mb": 44184.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.548, "power_cpu_cv_mean_watts": 2.155, "power_sys_5v0_mean_watts": 7.154, "gpu_utilization_percent_mean": 66.286}, "timestamp": "2026-01-30T22:33:39.261904"}
{"image_index": 214, "image_name": "000000022479.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022479.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2399.565, "latencies_ms": [2399.565], "images_per_second": 0.417, "prompt_tokens": 22, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The skateboarder is wearing a colorful tie-dye shirt and black pants. The scene is well-lit with natural sunlight, creating a vibrant and energetic atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18656.9, "ram_available_mb": 44184.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.549, "power_cpu_cv_mean_watts": 1.791, "power_sys_5v0_mean_watts": 6.907, "gpu_utilization_percent_mean": 71.316}, "timestamp": "2026-01-30T22:33:43.689422"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4592.325, "latencies_ms": [4592.325], "images_per_second": 0.218, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The image shows a group of sheep in a pastoral setting, with a wire fence enclosing them and a lush, green forest in the background.", "error": null, "sys_before": {"cpu_percent": 36.3, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.344, "power_cpu_cv_mean_watts": 1.233, "power_sys_5v0_mean_watts": 8.861, "gpu_utilization_percent_mean": 88.579}, "timestamp": "2026-01-30T22:33:50.481838"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5232.702, "latencies_ms": [5232.702], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "1. Sheep\n2. Sheep\n3. Sheep\n4. Sheep\n5. Sheep\n6. Sheep\n7. Sheep\n8. Sheep", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18656.3, "ram_available_mb": 44184.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.284, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 87.523}, "timestamp": "2026-01-30T22:33:57.759799"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6034.225, "latencies_ms": [6034.225], "images_per_second": 0.166, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The main objects in the image are sheep, which are located in the foreground. The sheep are positioned near a wire fence, with the wire extending from the foreground to the background. The background features a lush, green forest with trees and a grassy area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.3, "ram_available_mb": 44184.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18656.5, "ram_available_mb": 44184.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.735, "power_cpu_cv_mean_watts": 1.498, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 86.04}, "timestamp": "2026-01-30T22:34:05.805586"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7101.945, "latencies_ms": [7101.945], "images_per_second": 0.141, "prompt_tokens": 24, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The image depicts a pastoral scene in a rural setting, likely a farm or a farmyard, with a focus on sheep. The sheep are gathered in a fenced area, with their woolly coats prominently displayed. The background features a lush, green forest with trees and a grassy field, suggesting a serene and natural environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18656.5, "ram_available_mb": 44184.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18656.5, "ram_available_mb": 44184.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.184, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 85.034}, "timestamp": "2026-01-30T22:34:14.925024"}
{"image_index": 215, "image_name": "000000022589.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022589.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6144.718, "latencies_ms": [6144.718], "images_per_second": 0.163, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image features a flock of sheep with fluffy, light brown wool. The sheep are situated in a lush, green forested area, with a clear sky overhead. The lighting is natural, suggesting it is daytime, and the overall atmosphere is serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.5, "ram_available_mb": 44184.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.613, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.752, "gpu_utilization_percent_mean": 86.314}, "timestamp": "2026-01-30T22:34:23.085366"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4749.022, "latencies_ms": [4749.022], "images_per_second": 0.211, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The image shows a close-up of a silver-colored electronic device with a round, illuminated button in the center, featuring a red symbol and a white background.", "error": null, "sys_before": {"cpu_percent": 27.0, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.879, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 87.897}, "timestamp": "2026-01-30T22:34:29.979033"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6213.613, "latencies_ms": [6213.613], "images_per_second": 0.161, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 12, "output_text": "- mouse pad: 1\n- mouse: 1\n- keyboard: 1\n- computer mouse: 1\n- computer: 1\n- computer mouse pad: 1\n- computer mouse pad: 1\n- computer mouse pad: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.615, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 85.577}, "timestamp": "2026-01-30T22:34:38.223526"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5578.374, "latencies_ms": [5578.374], "images_per_second": 0.179, "prompt_tokens": 30, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The main object in the foreground is a silver-colored electronic device with a button on its right side. The button has a red symbol on it. The background is out of focus, but it appears to be a dark surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18656.3, "ram_available_mb": 44184.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.054, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 87.319}, "timestamp": "2026-01-30T22:34:45.837862"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6327.078, "latencies_ms": [6327.078], "images_per_second": 0.158, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The image shows a close-up view of a computer keyboard with a focus on the keys. The keys are illuminated by a light source, creating a warm and inviting atmosphere. The keyboard appears to be placed on a desk or table, and the overall setting suggests a workspace or study area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18656.3, "ram_available_mb": 44184.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18656.3, "ram_available_mb": 44184.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.676, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 8.851, "gpu_utilization_percent_mean": 85.962}, "timestamp": "2026-01-30T22:34:54.192181"}
{"image_index": 216, "image_name": "000000022623.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022623.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6300.755, "latencies_ms": [6300.755], "images_per_second": 0.159, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image features a close-up of a silver-colored electronic device with a glossy finish. The lighting is soft and warm, casting a gentle glow on the device's surface. The device appears to be made of a metallic material, possibly aluminum, and has a sleek, modern design.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18656.3, "ram_available_mb": 44184.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.577, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 85.925}, "timestamp": "2026-01-30T22:35:02.513259"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4185.755, "latencies_ms": [4185.755], "images_per_second": 0.239, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "A woman is standing in a kitchen, holding a glass of orange juice, wearing a black dress and black shoes.", "error": null, "sys_before": {"cpu_percent": 31.1, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18656.4, "ram_available_mb": 44184.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.527, "power_cpu_cv_mean_watts": 1.144, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 89.0}, "timestamp": "2026-01-30T22:35:08.867337"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6343.26, "latencies_ms": [6343.26], "images_per_second": 0.158, "prompt_tokens": 26, "response_tokens_est": 59, "n_tiles": 12, "output_text": "- Woman: 1\n- Dress: 1\n- Glass: 1\n- Candle: 1\n- Bottle: 1\n- Cups: 1\n- Refrigerator: 1\n- Cabinet: 1\n- Floor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.4, "ram_available_mb": 44184.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18656.7, "ram_available_mb": 44184.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.668, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 86.34}, "timestamp": "2026-01-30T22:35:17.226397"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5751.562, "latencies_ms": [5751.562], "images_per_second": 0.174, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The main object in the foreground is a woman standing next to a stainless steel refrigerator. She is holding a glass of orange juice and wearing a black dress with a starry pattern. The background features wooden cabinets and a tiled backsplash.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.7, "ram_available_mb": 44184.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18656.4, "ram_available_mb": 44184.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.105, "power_cpu_cv_mean_watts": 1.418, "power_sys_5v0_mean_watts": 8.854, "gpu_utilization_percent_mean": 86.375}, "timestamp": "2026-01-30T22:35:25.022587"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6597.545, "latencies_ms": [6597.545], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a woman standing in a kitchen, holding a glass of orange juice. She is wearing a black dress and black shoes, and the kitchen has wooden cabinets and a stainless steel refrigerator. The woman appears to be in a relaxed and happy mood, possibly enjoying a casual drink in her home kitchen.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18656.4, "ram_available_mb": 44184.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.408, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.858, "gpu_utilization_percent_mean": 85.571}, "timestamp": "2026-01-30T22:35:33.643183"}
{"image_index": 217, "image_name": "000000022705.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022705.jpg", "image_width": 482, "image_height": 640, "image_resolution": "482x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6764.617, "latencies_ms": [6764.617], "images_per_second": 0.148, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image features a woman standing in a kitchen with a silver refrigerator and wooden cabinets. The kitchen has a warm, cozy atmosphere with beige tiles on the floor and a mix of light and dark wood tones in the cabinetry. The lighting is soft and natural, likely from a nearby window, creating a welcoming ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.2, "ram_available_mb": 44184.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.335, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.85, "gpu_utilization_percent_mean": 85.789}, "timestamp": "2026-01-30T22:35:42.438119"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4741.042, "latencies_ms": [4741.042], "images_per_second": 0.211, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The image shows a close-up view of a bus mirror reflecting a yellow school bus on a road, with other vehicles and a cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 31.7, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.958, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.857, "gpu_utilization_percent_mean": 87.205}, "timestamp": "2026-01-30T22:35:49.323505"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4735.742, "latencies_ms": [4735.742], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Bus\n2. Car\n3. Car\n4. Car\n5. Car\n6. Car\n7. Car\n8. Car", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.939, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 88.872}, "timestamp": "2026-01-30T22:35:56.089695"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7637.61, "latencies_ms": [7637.61], "images_per_second": 0.131, "prompt_tokens": 30, "response_tokens_est": 80, "n_tiles": 12, "output_text": "The main object in the foreground is a bicycle handlebar, which is positioned near the center of the image. The bicycle handlebar is in sharp focus, while the background is slightly blurred, indicating that the focus is on the handlebar itself. The background features a bus and a road, with the bus being slightly out of focus, suggesting that the bus is farther away from the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.987, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 84.625}, "timestamp": "2026-01-30T22:36:05.775645"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6600.181, "latencies_ms": [6600.181], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a scene from a bus stop, with a focus on a bus mirror reflecting the surroundings. The bus stop is situated outdoors, and the mirror captures a glimpse of a busy street with cars and a yellow bus. The setting appears to be during the day, with a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18655.5, "ram_available_mb": 44185.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.508, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 85.8}, "timestamp": "2026-01-30T22:36:14.388214"}
{"image_index": 218, "image_name": "000000022755.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022755.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6267.63, "latencies_ms": [6267.63], "images_per_second": 0.16, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The image features a bus with a yellow color scheme, reflecting the surrounding environment. The lighting is natural, likely during the daytime, with a soft, diffused quality. The weather appears to be overcast, as the sky is gray and the overall lighting is subdued.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18655.5, "ram_available_mb": 44185.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18655.1, "ram_available_mb": 44185.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.502, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 85.528}, "timestamp": "2026-01-30T22:36:22.671179"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2647.57, "latencies_ms": [2647.57], "images_per_second": 0.378, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A gray cat is sitting on a wooden table, observing a small plant with green leaves and a small pot of soil.", "error": null, "sys_before": {"cpu_percent": 29.8, "ram_used_mb": 18655.0, "ram_available_mb": 44185.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18655.0, "ram_available_mb": 44185.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.982, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 76.571}, "timestamp": "2026-01-30T22:36:27.412169"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3065.632, "latencies_ms": [3065.632], "images_per_second": 0.326, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "cat: 1\ndog: 1\nplant: 2\npot: 2\ntray: 1\ncans: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18655.0, "ram_available_mb": 44185.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18654.1, "ram_available_mb": 44186.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.032, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 74.68}, "timestamp": "2026-01-30T22:36:32.533605"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4211.456, "latencies_ms": [4211.456], "images_per_second": 0.237, "prompt_tokens": 30, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The main objects in the image are a cat and a dog. The cat is positioned in the foreground, while the dog is slightly blurred in the background. The cat is sitting on a wooden table, and the dog is standing near the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.1, "ram_available_mb": 44186.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.291, "power_cpu_cv_mean_watts": 1.682, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-30T22:36:38.798636"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3985.115, "latencies_ms": [3985.115], "images_per_second": 0.251, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image depicts a cozy indoor scene with a cat and a dog sitting on a wooden table. The cat is looking at the dog, and both are surrounded by various plants and gardening supplies, suggesting a relaxed and domestic atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.587, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 71.879}, "timestamp": "2026-01-30T22:36:44.800853"}
{"image_index": 219, "image_name": "000000022892.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022892.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3022.955, "latencies_ms": [3022.955], "images_per_second": 0.331, "prompt_tokens": 22, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The cat in the image has a gray coat and is sitting on a wooden table. The lighting is bright, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.048, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 73.48}, "timestamp": "2026-01-30T22:36:49.876491"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4560.183, "latencies_ms": [4560.183], "images_per_second": 0.219, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 12, "output_text": "The image shows a female soccer player in a blue jersey with a logo on the chest, holding a soccer ball, and wearing a headband.", "error": null, "sys_before": {"cpu_percent": 29.8, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.039, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 88.474}, "timestamp": "2026-01-30T22:36:56.570285"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4729.763, "latencies_ms": [4729.763], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "ball: 1\nwoman: 2\nshorts: 1\nshirt: 1\nheadband: 1\nhair: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.972, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 89.154}, "timestamp": "2026-01-30T22:37:03.314898"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7566.814, "latencies_ms": [7566.814], "images_per_second": 0.132, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The main object in the foreground is a young woman wearing a blue sports jersey with a logo on the left side of her chest. She is holding a volleyball in her right hand, which is near her body. The background features another person wearing a yellow shirt, slightly out of focus. The volleyball and the woman are in the foreground, while the other person is in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18655.5, "ram_available_mb": 44185.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.994, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.848, "gpu_utilization_percent_mean": 84.75}, "timestamp": "2026-01-30T22:37:12.904781"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7318.32, "latencies_ms": [7318.32], "images_per_second": 0.137, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The image captures a moment on a sports field where two female athletes are engaged in a game. The setting is outdoors, and the focus is on the players, with one of them in a blue jersey and the other in a yellow jersey. The players are actively participating in the game, with the blue jersey player in motion, possibly running or preparing to strike the ball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.5, "ram_available_mb": 44185.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.158, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.844, "gpu_utilization_percent_mean": 85.016}, "timestamp": "2026-01-30T22:37:22.244788"}
{"image_index": 220, "image_name": "000000022935.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022935.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6666.511, "latencies_ms": [6666.511], "images_per_second": 0.15, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image features a young woman in a blue sports jersey with white and red accents, standing on a grassy field. The lighting is bright, casting a clear view of her attire and the surrounding environment. The weather appears to be clear and sunny, enhancing the vivid colors of her jersey and the green grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.402, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 85.768}, "timestamp": "2026-01-30T22:37:30.972107"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3725.589, "latencies_ms": [3725.589], "images_per_second": 0.268, "prompt_tokens": 12, "response_tokens_est": 16, "n_tiles": 12, "output_text": "A giraffe is standing in a pen, eating from a wooden fence.", "error": null, "sys_before": {"cpu_percent": 30.3, "ram_used_mb": 18655.7, "ram_available_mb": 44185.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.272, "power_cpu_cv_mean_watts": 0.93, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 90.968}, "timestamp": "2026-01-30T22:37:36.848630"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3938.104, "latencies_ms": [3938.104], "images_per_second": 0.254, "prompt_tokens": 26, "response_tokens_est": 19, "n_tiles": 12, "output_text": "giraffe: 1\nfence: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.077, "power_cpu_cv_mean_watts": 0.976, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 92.031}, "timestamp": "2026-01-30T22:37:42.814565"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7265.007, "latencies_ms": [7265.007], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The giraffes are positioned in the foreground of the image, with the giraffe on the left and the one on the right standing near the wooden fence. The giraffes are near the wooden fence, which is in the background. The fence separates the grassy area from the dirt path, creating a clear spatial relationship between the animals and their environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.232, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 84.902}, "timestamp": "2026-01-30T22:37:52.101092"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5533.062, "latencies_ms": [5533.062], "images_per_second": 0.181, "prompt_tokens": 24, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The image depicts a giraffe standing in a grassy area with a wooden fence in the background. The giraffe appears to be eating from a patch of dirt, surrounded by lush green trees and a clear sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.144, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 86.957}, "timestamp": "2026-01-30T22:37:59.659647"}
{"image_index": 221, "image_name": "000000022969.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000022969.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5246.212, "latencies_ms": [5246.212], "images_per_second": 0.191, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The giraffes in the image have a brown and white spotted coat, standing out against the lush greenery of the surrounding trees. The lighting is bright and natural, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18654.5, "ram_available_mb": 44186.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.32, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 87.273}, "timestamp": "2026-01-30T22:38:06.925536"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6090.416, "latencies_ms": [6090.416], "images_per_second": 0.164, "prompt_tokens": 12, "response_tokens_est": 94, "n_tiles": 1, "output_text": "The image depicts a black and white scene featuring a large, gray suitcase with a zippered compartment on top, positioned on a carpeted floor against a backdrop of draped curtains. To the left of the suitcase, there is a large trash bag with a reflective surface, and to the right, a smaller, black, zippered bag is visible. Additionally, a stack of books is placed on the carpeted floor in front of the suitcase.", "error": null, "sys_before": {"cpu_percent": 22.6, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18654.3, "ram_available_mb": 44186.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.553, "power_cpu_cv_mean_watts": 2.18, "power_sys_5v0_mean_watts": 7.166, "gpu_utilization_percent_mean": 64.673}, "timestamp": "2026-01-30T22:38:15.067573"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3869.986, "latencies_ms": [3869.986], "images_per_second": 0.258, "prompt_tokens": 26, "response_tokens_est": 57, "n_tiles": 1, "output_text": "1. Luggage: 2\n2. Bag: 2\n3. Bag: 1\n4. Bag: 1\n5. Bag: 1\n6. Bag: 1\n7. Bag: 1\n8. Bag: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.3, "ram_available_mb": 44186.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.426, "power_cpu_cv_mean_watts": 2.04, "power_sys_5v0_mean_watts": 7.09, "gpu_utilization_percent_mean": 67.469}, "timestamp": "2026-01-30T22:38:20.968248"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5218.162, "latencies_ms": [5218.162], "images_per_second": 0.192, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 1, "output_text": "The main objects in the image are a large gray suitcase and a black bag. The suitcase is positioned in the center of the image, with the black bag to its right. The suitcase is closer to the foreground, while the black bag is further back. The large gray suitcase is placed on a carpeted floor, and the black bag is leaning against a curtain backdrop.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18653.8, "ram_available_mb": 44187.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.542, "power_cpu_cv_mean_watts": 2.148, "power_sys_5v0_mean_watts": 7.154, "gpu_utilization_percent_mean": 66.591}, "timestamp": "2026-01-30T22:38:28.209704"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3257.486, "latencies_ms": [3257.486], "images_per_second": 0.307, "prompt_tokens": 24, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The image depicts a black and white scene featuring a suitcase, a trash bag, and a small pile of books on a carpeted floor. The setting appears to be indoors, possibly in a room with curtains in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18653.8, "ram_available_mb": 44187.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.584, "power_cpu_cv_mean_watts": 1.987, "power_sys_5v0_mean_watts": 7.024, "gpu_utilization_percent_mean": 67.423}, "timestamp": "2026-01-30T22:38:33.494249"}
{"image_index": 222, "image_name": "000000023023.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023023.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4812.359, "latencies_ms": [4812.359], "images_per_second": 0.208, "prompt_tokens": 22, "response_tokens_est": 72, "n_tiles": 1, "output_text": "The image features a black and white photograph of a suitcase, a trash bag, and a small black bag on a carpeted floor. The suitcase is gray with a zipper and a handle, while the trash bag is black with a reflective surface. The lighting is soft and even, casting minimal shadows, and the background is a plain curtain.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.595, "power_cpu_cv_mean_watts": 2.153, "power_sys_5v0_mean_watts": 7.071, "gpu_utilization_percent_mean": 65.0}, "timestamp": "2026-01-30T22:38:40.324194"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2591.034, "latencies_ms": [2591.034], "images_per_second": 0.386, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "A man in a blue shirt and a red bandana is riding a horse through a rocky, forested area.", "error": null, "sys_before": {"cpu_percent": 30.7, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18652.8, "ram_available_mb": 44188.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.573, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-30T22:38:45.048009"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3080.902, "latencies_ms": [3080.902], "images_per_second": 0.325, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Man\n2. Horse\n3. Horse\n4. Man\n5. Horse\n6. Man\n7. Horse\n8. Man", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18652.8, "ram_available_mb": 44188.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.14, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-30T22:38:50.154425"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4754.929, "latencies_ms": [4754.929], "images_per_second": 0.21, "prompt_tokens": 30, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The main objects in the image are a man and two horses. The man is riding a horse in the foreground, while the other horse is in the background. The man is wearing a blue shirt and has a backpack on his back. The horses are walking on a rocky path surrounded by trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.935, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 71.051}, "timestamp": "2026-01-30T22:38:56.930050"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4573.397, "latencies_ms": [4573.397], "images_per_second": 0.219, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a man in a blue shirt and a red bandana riding a horse through a forested area. The man is smiling and appears to be enjoying the ride. The setting is a natural environment with trees and a dirt path, suggesting a leisurely outdoor activity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.986, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 70.974}, "timestamp": "2026-01-30T22:39:03.555212"}
{"image_index": 223, "image_name": "000000023034.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023034.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3620.871, "latencies_ms": [3620.871], "images_per_second": 0.276, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The image depicts a man in a blue shirt and an orange bandana riding a horse through a forested area. The sunlight filters through the trees, casting dappled shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.018, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 71.6}, "timestamp": "2026-01-30T22:39:09.199724"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2165.943, "latencies_ms": [2165.943], "images_per_second": 0.462, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 6, "output_text": "A man is riding a horse in a blurry, monochrome image.", "error": null, "sys_before": {"cpu_percent": 32.5, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.079, "power_cpu_cv_mean_watts": 0.966, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 80.471}, "timestamp": "2026-01-30T22:39:13.476007"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3895.288, "latencies_ms": [3895.288], "images_per_second": 0.257, "prompt_tokens": 26, "response_tokens_est": 46, "n_tiles": 6, "output_text": "1. Horse\n2. Rider\n3. Horse's mane\n4. Horse's tail\n5. Horse's hooves\n6. Horse's bridle\n7. Horse's saddle\n8. Horse's legs", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.746, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 72.091}, "timestamp": "2026-01-30T22:39:19.389476"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5010.682, "latencies_ms": [5010.682], "images_per_second": 0.2, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main object in the foreground is a horse, which is being ridden by a man. The horse is positioned near the center of the image, slightly to the right. The background features a blurred horse, indicating motion. The man is standing on the horse's back, near the center of the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.524, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 69.595}, "timestamp": "2026-01-30T22:39:26.435476"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5136.523, "latencies_ms": [5136.523], "images_per_second": 0.195, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The image depicts a man riding a horse in what appears to be a race or competition. The horse is in motion, with its mane and tail flowing, and the man is dressed in a racing outfit. The setting is an outdoor area, likely a racetrack, with a blurred background suggesting speed and movement.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.349, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 70.302}, "timestamp": "2026-01-30T22:39:33.606842"}
{"image_index": 224, "image_name": "000000023126.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023126.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3971.188, "latencies_ms": [3971.188], "images_per_second": 0.252, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image is a black and white photograph featuring a man riding a horse. The horse is in motion, creating a blur effect in the background. The man is wearing a jacket with a logo on the left side of his chest.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.534, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 71.235}, "timestamp": "2026-01-30T22:39:39.609379"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4519.704, "latencies_ms": [4519.704], "images_per_second": 0.221, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 12, "output_text": "The image depicts a serene scene of a group of geese swimming in a calm body of water surrounded by tall grass and shrubs.", "error": null, "sys_before": {"cpu_percent": 30.1, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18650.2, "ram_available_mb": 44190.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.314, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 87.342}, "timestamp": "2026-01-30T22:39:46.276812"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3746.02, "latencies_ms": [3746.02], "images_per_second": 0.267, "prompt_tokens": 26, "response_tokens_est": 16, "n_tiles": 12, "output_text": "birds: 2\nwater: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.2, "ram_available_mb": 44190.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18650.2, "ram_available_mb": 44190.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.389, "power_cpu_cv_mean_watts": 0.956, "power_sys_5v0_mean_watts": 8.797, "gpu_utilization_percent_mean": 92.323}, "timestamp": "2026-01-30T22:39:52.060528"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5984.819, "latencies_ms": [5984.819], "images_per_second": 0.167, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The main objects in the image are geese swimming in a body of water. The geese are positioned in the foreground, with their heads and necks visible. The background consists of a dense, green bushy area, which is slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18650.2, "ram_available_mb": 44190.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18649.2, "ram_available_mb": 44191.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.811, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 86.569}, "timestamp": "2026-01-30T22:40:00.089681"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5452.548, "latencies_ms": [5452.548], "images_per_second": 0.183, "prompt_tokens": 24, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image depicts a serene natural scene featuring a calm body of water with a group of geese swimming. The geese are surrounded by tall grass and shrubs, creating a peaceful and tranquil environment.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18649.2, "ram_available_mb": 44191.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.221, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 86.891}, "timestamp": "2026-01-30T22:40:07.587345"}
{"image_index": 225, "image_name": "000000023230.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023230.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5037.912, "latencies_ms": [5037.912], "images_per_second": 0.198, "prompt_tokens": 22, "response_tokens_est": 37, "n_tiles": 12, "output_text": "The image depicts a serene scene of a calm body of water with a lush green shoreline. The lighting is bright and natural, suggesting a sunny day with clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.429, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 87.791}, "timestamp": "2026-01-30T22:40:14.673447"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4539.607, "latencies_ms": [4539.607], "images_per_second": 0.22, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 12, "output_text": "A black car with a shiny chrome grille and a Mercedes emblem is parked in front of a building with a green fence and a window.", "error": null, "sys_before": {"cpu_percent": 31.2, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.166, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 88.211}, "timestamp": "2026-01-30T22:40:21.359363"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4786.168, "latencies_ms": [4786.168], "images_per_second": 0.209, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 12, "output_text": "car: 1\nmirror: 1\nbuilding: 1\nwindow: 1\ntrees: 1\nfence: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.877, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 88.3}, "timestamp": "2026-01-30T22:40:28.162952"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6717.352, "latencies_ms": [6717.352], "images_per_second": 0.149, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The main objects in the image are a car and a cat. The car is positioned in the foreground, with its front end visible. The cat is perched on the car's roof, near the windshield. The background features a building and a green fence, which are further away from the car and the cat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.392, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.846, "gpu_utilization_percent_mean": 85.491}, "timestamp": "2026-01-30T22:40:36.899628"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5628.606, "latencies_ms": [5628.606], "images_per_second": 0.178, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The image depicts a scene of a black car parked in front of a building with a green fence and a tree in the background. A ginger and white cat is perched on the car's roof, seemingly enjoying the view.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.098, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 87.532}, "timestamp": "2026-01-30T22:40:44.551113"}
{"image_index": 226, "image_name": "000000023272.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023272.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4315.25, "latencies_ms": [4315.25], "images_per_second": 0.232, "prompt_tokens": 22, "response_tokens_est": 25, "n_tiles": 12, "output_text": "The car in the image is black with a shiny, reflective surface. The lighting is bright, indicating it is daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.317, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 8.785, "gpu_utilization_percent_mean": 89.75}, "timestamp": "2026-01-30T22:40:50.910406"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2760.284, "latencies_ms": [2760.284], "images_per_second": 0.362, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 6, "output_text": "A snowboarder is captured mid-air, performing a trick against a clear blue sky, with snowflakes scattered around him.", "error": null, "sys_before": {"cpu_percent": 34.5, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.63, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 75.727}, "timestamp": "2026-01-30T22:40:55.778381"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4535.211, "latencies_ms": [4535.211], "images_per_second": 0.22, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 6, "output_text": "1. Snowboarder\n2. Snow\n3. Snowboard\n4. Snowboarder's clothing\n5. Snowboarder's hat\n6. Snowboarder's gloves\n7. Snowboarder's goggles\n8. Snowboarder's helmet", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.018, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.757}, "timestamp": "2026-01-30T22:41:02.335377"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5390.137, "latencies_ms": [5390.137], "images_per_second": 0.186, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The main object in the image is a snowboarder performing a jump over a snowy slope. The snowboarder is positioned in the foreground, with the snowy slope extending into the background. The snowboarder is near the bottom of the slope, while the snow is accumulating around them, creating a dynamic and visually engaging scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.13, "power_cpu_cv_mean_watts": 1.851, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 69.2}, "timestamp": "2026-01-30T22:41:09.772040"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5308.626, "latencies_ms": [5308.626], "images_per_second": 0.188, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image captures a snowboarder mid-air, performing a trick against a clear blue sky. The snowboarder is dressed in a brown jacket and bright yellow pants, and the snowboard is visible beneath them. The scene is set on a snowy slope, with the snowboarder's motion creating a dynamic and visually striking image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.3, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 69.841}, "timestamp": "2026-01-30T22:41:17.113407"}
{"image_index": 227, "image_name": "000000023359.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023359.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4489.652, "latencies_ms": [4489.652], "images_per_second": 0.223, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The snowboarder is dressed in a brown jacket and bright yellow pants, contrasting sharply against the clear blue sky. The snowboard is white, and the snowboarder is captured mid-air, with snowflakes scattered around, indicating a bright and sunny day.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.714, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 70.189}, "timestamp": "2026-01-30T22:41:23.620719"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4308.933, "latencies_ms": [4308.933], "images_per_second": 0.232, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "The image shows a small bathroom with a white bathtub and a wooden toilet, both placed on a tiled floor.", "error": null, "sys_before": {"cpu_percent": 29.7, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.548, "power_cpu_cv_mean_watts": 1.133, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 88.771}, "timestamp": "2026-01-30T22:41:30.064211"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4803.067, "latencies_ms": [4803.067], "images_per_second": 0.208, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 12, "output_text": "toilet: 1\nsink: 1\ntub: 1\npipe: 1\nwall: 1\ndoor: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.799, "power_cpu_cv_mean_watts": 1.271, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 88.775}, "timestamp": "2026-01-30T22:41:36.889192"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6550.631, "latencies_ms": [6550.631], "images_per_second": 0.153, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The main objects in the image are a toilet and a bathtub. The toilet is located in the foreground, while the bathtub is positioned in the background. The toilet is situated near the bathtub, with the bathtub's faucet visible on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.456, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 85.709}, "timestamp": "2026-01-30T22:41:45.462084"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5884.866, "latencies_ms": [5884.866], "images_per_second": 0.17, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The image depicts a small, unlit bathroom with a wooden toilet and a white bathtub. The setting appears to be indoors, possibly in a residential or small commercial space, with a dark wooden door and a white wall in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.803, "power_cpu_cv_mean_watts": 1.471, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 86.551}, "timestamp": "2026-01-30T22:41:53.375555"}
{"image_index": 228, "image_name": "000000023666.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023666.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5636.191, "latencies_ms": [5636.191], "images_per_second": 0.177, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The image depicts a small, rustic bathroom with a wooden toilet seat and basin. The walls and floor are tiled in a reddish-brown color, and the lighting is dim, creating a cozy and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.006, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 87.085}, "timestamp": "2026-01-30T22:42:01.060210"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2744.482, "latencies_ms": [2744.482], "images_per_second": 0.364, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 6, "output_text": "The image shows a statue of a child holding a kite, set against a backdrop of a building with a light-colored facade.", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.832, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 76.773}, "timestamp": "2026-01-30T22:42:05.909833"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3551.505, "latencies_ms": [3551.505], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "1. Statue\n2. Statue\n3. Statue\n4. Statue\n5. Statue\n6. Statue\n7. Statue\n8. Statue", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.273, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 72.793}, "timestamp": "2026-01-30T22:42:11.496882"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3926.628, "latencies_ms": [3926.628], "images_per_second": 0.255, "prompt_tokens": 30, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The main objects in the image are a statue of a child and a kite. The statue is located in the foreground, standing on a raised platform. The kite is in the background, flying high above the statue.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.744, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 72.062}, "timestamp": "2026-01-30T22:42:17.455297"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3497.06, "latencies_ms": [3497.06], "images_per_second": 0.286, "prompt_tokens": 24, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image depicts a statue of a child holding a kite in a cityscape. The statue is situated on a ledge, with a building and a clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.133, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 72.724}, "timestamp": "2026-01-30T22:42:22.985762"}
{"image_index": 229, "image_name": "000000023751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023751.jpg", "image_width": 430, "image_height": 640, "image_resolution": "430x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4828.714, "latencies_ms": [4828.714], "images_per_second": 0.207, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The notable visual attributes of the image include a statue of a child holding a kite, which is made of metal. The statue is set against a backdrop of a building with a light-colored facade and a clear sky. The lighting is natural, suggesting daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.67, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 70.625}, "timestamp": "2026-01-30T22:42:29.839934"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4759.88, "latencies_ms": [4759.88], "images_per_second": 0.21, "prompt_tokens": 12, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image showcases a variety of fresh vegetables and fruits arranged neatly on a table, including a basket of green beans, a bunch of broccoli, a bunch of radishes, a bunch of carrots, and a bunch of strawberries, all presented in a colorful and appetizing manner.", "error": null, "sys_before": {"cpu_percent": 29.3, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.531, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 69.925}, "timestamp": "2026-01-30T22:42:36.710847"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3787.219, "latencies_ms": [3787.219], "images_per_second": 0.264, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 6, "output_text": "strawberries: 8\nbroccoli: 1\ncucumber: 1\nradishes: 8\npeas: 1\ncarrots: 8\npotatoes: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.936, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 72.226}, "timestamp": "2026-01-30T22:42:42.534017"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8360.267, "latencies_ms": [8360.267], "images_per_second": 0.12, "prompt_tokens": 30, "response_tokens_est": 119, "n_tiles": 6, "output_text": "The main objects in the image are a variety of fresh produce arranged on a table. The left side of the image features a basket filled with strawberries, while the right side displays a basket of green beans. In the foreground, there is a white plastic bag filled with green peas. In the background, there are several types of vegetables including cucumbers, carrots, and beets. The produce is arranged in a way that showcases the different colors and types of vegetables, with the strawberries and green beans in the left and right sides, and the peas in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.918, "power_cpu_cv_mean_watts": 2.054, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 67.757}, "timestamp": "2026-01-30T22:42:52.906602"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5376.469, "latencies_ms": [5376.469], "images_per_second": 0.186, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The image depicts a vibrant and colorful assortment of fresh produce arranged on a table. The scene is set in a market or grocery store, with various vegetables and fruits displayed in baskets and containers. The produce includes green beans, carrots, beets, potatoes, and strawberries, all neatly arranged to showcase their freshness and variety.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.166, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 69.467}, "timestamp": "2026-01-30T22:43:00.311238"}
{"image_index": 230, "image_name": "000000023781.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023781.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5912.379, "latencies_ms": [5912.379], "images_per_second": 0.169, "prompt_tokens": 22, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image showcases a vibrant and colorful assortment of fresh produce, including bright red strawberries, green broccoli, red radishes, green peas, carrots, and potatoes. The lighting is natural, with a soft, diffused glow that highlights the freshness and vibrancy of the colors. The overall atmosphere is warm and inviting, suggesting a sunny day at a local farmer's market.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.951, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 68.939}, "timestamp": "2026-01-30T22:43:08.237845"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2772.652, "latencies_ms": [2772.652], "images_per_second": 0.361, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 6, "output_text": "Two young men are sitting on a bed, laughing and holding controllers, while a projector is on a table in the background.", "error": null, "sys_before": {"cpu_percent": 25.9, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.649, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 76.455}, "timestamp": "2026-01-30T22:43:13.121087"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4528.286, "latencies_ms": [4528.286], "images_per_second": 0.221, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 6, "output_text": "1. Person: 1\n2. Person: 1\n3. Person: 1\n4. Person: 1\n5. Person: 1\n6. Person: 1\n7. Person: 1\n8. Person: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.965, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 71.054}, "timestamp": "2026-01-30T22:43:19.662809"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6449.476, "latencies_ms": [6449.476], "images_per_second": 0.155, "prompt_tokens": 30, "response_tokens_est": 88, "n_tiles": 6, "output_text": "The main objects in the image are three people sitting on a couch. The person in the foreground is holding a remote control, while the person in the middle is also holding a remote control. The person in the background is not holding a remote control. The couch is positioned in the center of the image, with the people sitting on it. The background is slightly blurred, indicating that the focus is on the people and their actions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.716, "power_cpu_cv_mean_watts": 1.965, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 69.111}, "timestamp": "2026-01-30T22:43:28.128334"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5071.387, "latencies_ms": [5071.387], "images_per_second": 0.197, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The scene depicts a cozy, dimly lit room where three individuals are engaged in a shared activity. They are seated on a couch, each holding a white remote control, and appear to be playing a video game. The atmosphere is casual and relaxed, with the focus on their interaction and the shared experience of gaming.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.38, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 69.548}, "timestamp": "2026-01-30T22:43:35.233354"}
{"image_index": 231, "image_name": "000000023899.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023899.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3674.3, "latencies_ms": [3674.3], "images_per_second": 0.272, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 6, "output_text": "The image depicts a dimly lit room with a warm, soft glow from a projector. The individuals are seated on colorful, patterned cushions, and the overall atmosphere is cozy and intimate.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.95, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 72.267}, "timestamp": "2026-01-30T22:43:40.940421"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3104.067, "latencies_ms": [3104.067], "images_per_second": 0.322, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 6, "output_text": "The image depicts a serene pastoral scene with a group of cows lying on a lush green field, surrounded by a tree trunk and some greenery.", "error": null, "sys_before": {"cpu_percent": 20.2, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.999, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 74.64}, "timestamp": "2026-01-30T22:43:46.137751"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3145.019, "latencies_ms": [3145.019], "images_per_second": 0.318, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 6, "output_text": "1. Cows\n2. Grass\n3. Trees\n4. Trees\n5. Trees\n6. Trees\n7. Trees\n8. Trees", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.786, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 73.423}, "timestamp": "2026-01-30T22:43:51.299000"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4777.074, "latencies_ms": [4777.074], "images_per_second": 0.209, "prompt_tokens": 30, "response_tokens_est": 60, "n_tiles": 6, "output_text": "In the image, the main objects are a group of cows lying on a lush green field. The cows are positioned in the foreground, with the foreground being the grassy area where they are resting. The background features a tree trunk and some greenery, indicating the presence of a natural environment.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.815, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 70.949}, "timestamp": "2026-01-30T22:43:58.098676"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5498.551, "latencies_ms": [5498.551], "images_per_second": 0.182, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts a serene pastoral scene with a lush green field in the foreground, where a group of cows is peacefully resting. The cows are scattered across the grass, with some lying down and others standing. The setting appears to be a rural area, possibly a farm, with a tree trunk visible in the right side of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.098, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 69.391}, "timestamp": "2026-01-30T22:44:05.648416"}
{"image_index": 232, "image_name": "000000023937.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000023937.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4413.148, "latencies_ms": [4413.148], "images_per_second": 0.227, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The image depicts a lush, green field with a few cows lying down, enjoying the sunshine. The cows are mostly white with some black patches, and the grass is vibrant and fresh. The lighting is bright and natural, suggesting a sunny day with clear skies.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.041, "power_cpu_cv_mean_watts": 1.743, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 70.892}, "timestamp": "2026-01-30T22:44:12.075564"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3440.245, "latencies_ms": [3440.245], "images_per_second": 0.291, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The image is a black and white photograph of a large group of children and a few adults posing for a school photo in Goodmayes Boys' School, dated April 1929.", "error": null, "sys_before": {"cpu_percent": 28.8, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.262, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 73.5}, "timestamp": "2026-01-30T22:44:17.628709"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8876.313, "latencies_ms": [8876.313], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.727, "power_cpu_cv_mean_watts": 2.076, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 67.421}, "timestamp": "2026-01-30T22:44:28.526144"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4884.778, "latencies_ms": [4884.778], "images_per_second": 0.205, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The main objects in the image are the students of Goodmayes Boys' School, arranged in a large group. The students are positioned in the foreground, with the school building serving as the background. The students are arranged in a somewhat staggered formation, with some sitting on the ground and others standing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.679, "power_cpu_cv_mean_watts": 1.788, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.122}, "timestamp": "2026-01-30T22:44:35.442449"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5438.262, "latencies_ms": [5438.262], "images_per_second": 0.184, "prompt_tokens": 24, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The image depicts a large group of children, likely from a school, gathered in front of a brick building. They are dressed in formal school uniforms, with some sitting on the ground and others standing. The setting appears to be an outdoor location, possibly a schoolyard, with the date \"April 1929\" inscribed on the photo.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.185, "power_cpu_cv_mean_watts": 1.854, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 69.391}, "timestamp": "2026-01-30T22:44:42.913099"}
{"image_index": 233, "image_name": "000000024021.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024021.jpg", "image_width": 640, "image_height": 390, "image_resolution": "640x390", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3816.732, "latencies_ms": [3816.732], "images_per_second": 0.262, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The black and white photograph features a large group of children and a few adults posing for a school photo. The lighting is natural, and the image has a vintage feel, likely from the early 20th century.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.593, "power_cpu_cv_mean_watts": 1.64, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 71.531}, "timestamp": "2026-01-30T22:44:48.778275"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5212.238, "latencies_ms": [5212.238], "images_per_second": 0.192, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image depicts a vibrant kite flying high in the sky, with a clear blue sky and fluffy white clouds in the background, surrounded by a park with green grass and a few trees.", "error": null, "sys_before": {"cpu_percent": 28.1, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.589, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.856, "gpu_utilization_percent_mean": 86.442}, "timestamp": "2026-01-30T22:44:56.122892"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5197.603, "latencies_ms": [5197.603], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.456, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 87.409}, "timestamp": "2026-01-30T22:45:03.372321"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6690.945, "latencies_ms": [6690.945], "images_per_second": 0.149, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The main objects in the image are a kite and a person. The kite is in the foreground, flying high in the sky, while the person is near the kite, standing on the grass. The background features a park with trees and buildings, providing a serene setting for the kite flying.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.323, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 85.357}, "timestamp": "2026-01-30T22:45:12.086237"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5565.736, "latencies_ms": [5565.736], "images_per_second": 0.18, "prompt_tokens": 24, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image depicts a serene park scene with a clear blue sky adorned with fluffy white clouds. In the foreground, a person is seen walking on a grassy field, surrounded by trees and a few buildings.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.179, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.13}, "timestamp": "2026-01-30T22:45:19.666389"}
{"image_index": 234, "image_name": "000000024027.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024027.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6554.381, "latencies_ms": [6554.381], "images_per_second": 0.153, "prompt_tokens": 22, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The image features a vibrant kite with a gradient of colors, predominantly in shades of purple, blue, and orange, soaring against a partly cloudy sky. The lighting is bright and natural, suggesting it is daytime, and the weather appears to be pleasant with a mix of clouds and clear patches.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.426, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 85.6}, "timestamp": "2026-01-30T22:45:28.254806"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4157.445, "latencies_ms": [4157.445], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "The image shows a slice of pizza with melted cheese and pepperoni toppings, resting on a cardboard pizza box.", "error": null, "sys_before": {"cpu_percent": 25.2, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.835, "power_cpu_cv_mean_watts": 1.133, "power_sys_5v0_mean_watts": 8.851, "gpu_utilization_percent_mean": 88.771}, "timestamp": "2026-01-30T22:45:34.574890"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5098.352, "latencies_ms": [5098.352], "images_per_second": 0.196, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "1. Pizza\n2. Pizza box\n3. Pita bread\n4. Cheese\n5. Tomato\n6. Pepperoni\n7. Sauce\n8. Spices", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.41, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 88.07}, "timestamp": "2026-01-30T22:45:41.703838"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6197.069, "latencies_ms": [6197.069], "images_per_second": 0.161, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The main object in the image is a pizza placed on a cardboard box. The pizza is positioned in the foreground, with its crust and toppings clearly visible. The cardboard box is situated in the background, providing a neutral backdrop that contrasts with the pizza's vibrant colors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.63, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 85.827}, "timestamp": "2026-01-30T22:45:49.927243"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6182.209, "latencies_ms": [6182.209], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image shows a slice of pizza placed on a cardboard pizza box. The pizza appears to be freshly baked, with melted cheese and a crispy crust. The setting suggests that the pizza is ready to be eaten, and the box is likely being used for transport or storage.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.63, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 85.846}, "timestamp": "2026-01-30T22:45:58.136801"}
{"image_index": 235, "image_name": "000000024144.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024144.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5444.493, "latencies_ms": [5444.493], "images_per_second": 0.184, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image shows a freshly baked pizza with a golden-brown crust, melted cheese, and a red tomato topping. The lighting is bright, highlighting the colors of the pizza and the cardboard box it is placed on.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.178, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 87.087}, "timestamp": "2026-01-30T22:46:05.623221"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4263.645, "latencies_ms": [4263.645], "images_per_second": 0.235, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 12, "output_text": "A woman is sitting on a bench outside a refrigerator, holding a beer in her hand, and smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 30.5, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.537, "power_cpu_cv_mean_watts": 1.087, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 89.086}, "timestamp": "2026-01-30T22:46:12.053691"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4927.411, "latencies_ms": [4927.411], "images_per_second": 0.203, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 12, "output_text": "1. Woman\n2. Beer\n3. Refrigerator\n4. Window\n5. Street\n6. Person\n7. Person\n8. Person", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.693, "power_cpu_cv_mean_watts": 1.28, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 88.561}, "timestamp": "2026-01-30T22:46:19.012020"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6921.658, "latencies_ms": [6921.658], "images_per_second": 0.144, "prompt_tokens": 30, "response_tokens_est": 68, "n_tiles": 12, "output_text": "The main objects in the image are a woman sitting on a bench, a refrigerator, and a person standing on the sidewalk. The woman is positioned in the foreground, sitting on the bench, while the refrigerator is in the background, slightly to the right. The person standing on the sidewalk is near the refrigerator, slightly to the right.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.231, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 85.017}, "timestamp": "2026-01-30T22:46:27.969049"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7159.207, "latencies_ms": [7159.207], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a scene on a city street, likely in a European city given the architecture and the style of the buildings. A woman is sitting on a bench, leaning against a white refrigerator, with a smile on her face. She is holding a drink in her hand. The setting appears to be a casual, everyday moment in a public space.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18649.2, "ram_available_mb": 44191.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.173, "power_cpu_cv_mean_watts": 1.656, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 85.217}, "timestamp": "2026-01-30T22:46:37.189184"}
{"image_index": 236, "image_name": "000000024243.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024243.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7559.439, "latencies_ms": [7559.439], "images_per_second": 0.132, "prompt_tokens": 22, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The image depicts a scene with a woman sitting on a bench in an urban setting. The bench is made of metal, and the bench itself is white. The woman is wearing a brown jacket and blue jeans, and she is holding a glass of beer. The lighting is natural, suggesting it is daytime. The weather appears to be cool, as the woman is wearing a jacket.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.2, "ram_available_mb": 44191.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18649.5, "ram_available_mb": 44191.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.85, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 84.063}, "timestamp": "2026-01-30T22:46:46.786996"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4854.988, "latencies_ms": [4854.988], "images_per_second": 0.206, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image shows a man holding a tray of hot dogs, each with a red ketchup and a mustard sauce, all placed on a piece of aluminum foil.", "error": null, "sys_before": {"cpu_percent": 29.4, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.93, "power_cpu_cv_mean_watts": 1.312, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 87.875}, "timestamp": "2026-01-30T22:46:53.829915"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10561.77, "latencies_ms": [10561.77], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "hot dog: 8\nbuns: 8\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork: 1\nfork", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.089, "power_cpu_cv_mean_watts": 1.897, "power_sys_5v0_mean_watts": 8.856, "gpu_utilization_percent_mean": 82.418}, "timestamp": "2026-01-30T22:47:06.409936"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7106.592, "latencies_ms": [7106.592], "images_per_second": 0.141, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main objects in the image are a tray of hot dogs, which are placed on a blue-lined aluminum foil tray. The hot dogs are arranged in a row, with the closest ones to the foreground and the far ones in the background. The tray is situated on a wooden surface, and there is a white plastic chair visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.177, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.848, "gpu_utilization_percent_mean": 85.117}, "timestamp": "2026-01-30T22:47:15.566789"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6974.471, "latencies_ms": [6974.471], "images_per_second": 0.143, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a man holding a tray of hot dogs, which are placed on a piece of aluminum foil. The hot dogs are arranged in a neat row, with each bun holding a different type of hot dog. The man is wearing a green shirt and a hat, and the background shows a grassy area with a wooden fence.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.278, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 84.897}, "timestamp": "2026-01-30T22:47:24.554513"}
{"image_index": 237, "image_name": "000000024567.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024567.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5991.824, "latencies_ms": [5991.824], "images_per_second": 0.167, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image features a tray of hot dogs, each coated in a glossy, red sauce. The hot dogs are placed on a piece of aluminum foil, which is likely used to keep them warm. The lighting is bright and natural, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.87, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 86.18}, "timestamp": "2026-01-30T22:47:32.571915"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5043.443, "latencies_ms": [5043.443], "images_per_second": 0.198, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image depicts a cluttered living room with a bookshelf filled with various books, a computer on a table, a couch with a backpack, and a television on the floor.", "error": null, "sys_before": {"cpu_percent": 28.9, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.572, "power_cpu_cv_mean_watts": 1.297, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 87.31}, "timestamp": "2026-01-30T22:47:39.794437"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5011.548, "latencies_ms": [5011.548], "images_per_second": 0.2, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 12, "output_text": "1. Laptop\n2. Chair\n3. Bookshelf\n4. Book\n5. Backpack\n6. TV stand\n7. TV\n8. Cushions", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.81, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.857, "gpu_utilization_percent_mean": 87.667}, "timestamp": "2026-01-30T22:47:46.823076"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6733.269, "latencies_ms": [6733.269], "images_per_second": 0.149, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The main objects in the image are a bookshelf filled with books, a computer on a desk, and a couch in the background. The bookshelf is located in the foreground, while the computer and couch are in the background. The bookshelf is near the computer and couch, indicating a casual and comfortable living space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.508, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 85.536}, "timestamp": "2026-01-30T22:47:55.574302"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5460.98, "latencies_ms": [5460.98], "images_per_second": 0.183, "prompt_tokens": 24, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a cluttered desk and bookshelf filled with various items. The room is dimly lit, suggesting it is either late at night or in a dimly lit room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.253, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 87.578}, "timestamp": "2026-01-30T22:48:03.049583"}
{"image_index": 238, "image_name": "000000024610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024610.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6622.256, "latencies_ms": [6622.256], "images_per_second": 0.151, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a cozy, dimly lit room with a beige wall and a brown carpet. The lighting is soft and warm, creating a comfortable atmosphere. The room features a wooden desk with a laptop, a bookshelf filled with books, a chair, and a couch with various items on it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.352, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 85.321}, "timestamp": "2026-01-30T22:48:11.689019"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2282.002, "latencies_ms": [2282.002], "images_per_second": 0.438, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 6, "output_text": "Two elephants are walking through a grassy savannah, surrounded by dense vegetation and trees.", "error": null, "sys_before": {"cpu_percent": 28.6, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.677, "power_cpu_cv_mean_watts": 1.046, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 78.667}, "timestamp": "2026-01-30T22:48:16.113571"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2310.831, "latencies_ms": [2310.831], "images_per_second": 0.433, "prompt_tokens": 26, "response_tokens_est": 19, "n_tiles": 6, "output_text": "elephant: 2\nbushes: 10\ntrees: 5", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.4, "power_cpu_cv_mean_watts": 1.075, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 76.526}, "timestamp": "2026-01-30T22:48:20.468282"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3994.194, "latencies_ms": [3994.194], "images_per_second": 0.25, "prompt_tokens": 30, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The main objects in the image are two elephants. The elephants are positioned in the foreground, with the one on the left slightly closer to the camera. The background features a hazy, misty landscape with trees and shrubs.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.441, "power_cpu_cv_mean_watts": 1.663, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 71.455}, "timestamp": "2026-01-30T22:48:26.520364"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4893.813, "latencies_ms": [4893.813], "images_per_second": 0.204, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image depicts a serene African savanna landscape with two elephants walking through a dense thicket of greenery. The elephants appear to be in a natural, undisturbed environment, with a misty, hazy atmosphere that adds to the tranquil and peaceful ambiance of the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.374, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 70.171}, "timestamp": "2026-01-30T22:48:33.441733"}
{"image_index": 239, "image_name": "000000024919.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000024919.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5474.11, "latencies_ms": [5474.11], "images_per_second": 0.183, "prompt_tokens": 22, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The image depicts two elephants in a natural, grassy environment with a misty, overcast sky. The elephants are brown, with the larger one having prominent tusks and the smaller one having a smaller head. The lighting is soft and diffused, with a muted color palette, contributing to the serene and peaceful atmosphere of the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.975, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 68.935}, "timestamp": "2026-01-30T22:48:40.973035"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3155.011, "latencies_ms": [3155.011], "images_per_second": 0.317, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 6, "output_text": "A shirtless man in sunglasses and a baseball cap is holding a frisbee in his right hand while standing on a grassy field with trees in the background.", "error": null, "sys_before": {"cpu_percent": 29.4, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.924, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 73.885}, "timestamp": "2026-01-30T22:48:46.252720"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3314.728, "latencies_ms": [3314.728], "images_per_second": 0.302, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 6, "output_text": "1. Frisbee\n2. Man\n3. Sunglasses\n4. Cap\n5. Shirt\n6. Shorts\n7. Belt\n8. Shoes", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.615, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 74.111}, "timestamp": "2026-01-30T22:48:51.600327"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5148.89, "latencies_ms": [5148.89], "images_per_second": 0.194, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The main object in the foreground is a man standing on a grassy field. He is holding a white frisbee in his right hand and appears to be preparing to throw it. In the background, there is another person walking away from the camera. The trees and clear blue sky provide a natural backdrop to the scene.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.349, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 69.767}, "timestamp": "2026-01-30T22:48:58.778289"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5739.052, "latencies_ms": [5739.052], "images_per_second": 0.174, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The image depicts a man standing on a grassy field, holding a white frisbee in his right hand. He is wearing a white baseball cap, sunglasses, and a necklace. In the background, there is a dense line of trees, and another person is visible walking away from the camera. The setting appears to be a park or recreational area during the daytime.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.837, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 68.837}, "timestamp": "2026-01-30T22:49:06.558879"}
{"image_index": 240, "image_name": "000000025057.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025057.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4115.735, "latencies_ms": [4115.735], "images_per_second": 0.243, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image depicts a man in a green shirt and khaki shorts, barefoot, holding a green bottle in his right hand. The setting is a lush, green field under a clear blue sky, suggesting a warm, sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.335, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 71.235}, "timestamp": "2026-01-30T22:49:12.710463"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4245.002, "latencies_ms": [4245.002], "images_per_second": 0.236, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 12, "output_text": "A young boy is sitting on a table, looking at a cake decorated with a toy airplane and a toy airplane figure.", "error": null, "sys_before": {"cpu_percent": 30.9, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.638, "power_cpu_cv_mean_watts": 1.156, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 87.8}, "timestamp": "2026-01-30T22:49:19.105324"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10670.599, "latencies_ms": [10670.599], "images_per_second": 0.094, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.933, "power_cpu_cv_mean_watts": 1.901, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 82.154}, "timestamp": "2026-01-30T22:49:31.818469"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6998.882, "latencies_ms": [6998.882], "images_per_second": 0.143, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The main object in the foreground is a cake with a chocolate icing design, which is placed on a table covered with a colorful tablecloth. In the background, there is a boy wearing a blue jersey, and a white plate is visible on the table. The boy is leaning over the table, possibly preparing to cut the cake.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.209, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 84.898}, "timestamp": "2026-01-30T22:49:40.861771"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6312.514, "latencies_ms": [6312.514], "images_per_second": 0.158, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a young boy sitting at a table, focused on a cake. The cake is decorated with various elements, including a toy airplane, a toy dinosaur, and chocolate pieces. The boy is wearing a blue shirt and appears to be enjoying a moment of cake decorating.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.592, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 86.075}, "timestamp": "2026-01-30T22:49:49.206223"}
{"image_index": 241, "image_name": "000000025096.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025096.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4920.468, "latencies_ms": [4920.468], "images_per_second": 0.203, "prompt_tokens": 22, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The cake is richly decorated with chocolate and red icing, and it is placed on a colorful tablecloth. The lighting is warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.642, "power_cpu_cv_mean_watts": 1.28, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 88.561}, "timestamp": "2026-01-30T22:49:56.188520"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2593.178, "latencies_ms": [2593.178], "images_per_second": 0.386, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "The image shows a close-up of a zebra's face, with its distinctive black and white stripes clearly visible.", "error": null, "sys_before": {"cpu_percent": 21.2, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.982, "power_cpu_cv_mean_watts": 1.24, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 76.333}, "timestamp": "2026-01-30T22:50:00.895987"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2177.932, "latencies_ms": [2177.932], "images_per_second": 0.459, "prompt_tokens": 26, "response_tokens_est": 17, "n_tiles": 6, "output_text": "zebra: 1\nfence: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.077, "power_cpu_cv_mean_watts": 0.989, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 79.353}, "timestamp": "2026-01-30T22:50:05.106313"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5909.998, "latencies_ms": [5909.998], "images_per_second": 0.169, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The main object in the foreground is a zebra, which is positioned near the right side of the image. The zebra's stripes are clearly visible, and it appears to be standing close to a metal fence. The background features a green tree and some rocks, which are slightly out of focus. The zebra is positioned near the fence, with the tree and rocks in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.982, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.429}, "timestamp": "2026-01-30T22:50:13.046647"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4394.222, "latencies_ms": [4394.222], "images_per_second": 0.228, "prompt_tokens": 24, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The image depicts a zebra standing in a pen, with its head turned slightly to the side. The zebra's distinctive black and white stripes are clearly visible, and it appears to be in a naturalistic enclosure, possibly at a zoo or wildlife sanctuary.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.161, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 71.139}, "timestamp": "2026-01-30T22:50:19.471491"}
{"image_index": 242, "image_name": "000000025139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025139.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4111.166, "latencies_ms": [4111.166], "images_per_second": 0.243, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The zebra in the image has a striking black and white striped pattern, which is highly visible against the natural backdrop. The lighting is bright and natural, casting shadows on the ground, indicating that the photo was taken during the day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.404, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 71.412}, "timestamp": "2026-01-30T22:50:25.596946"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2882.777, "latencies_ms": [2882.777], "images_per_second": 0.347, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "The image depicts a black and white photograph of a train station platform with a train approaching, and a sign indicating the station's name.", "error": null, "sys_before": {"cpu_percent": 29.5, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.307, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 75.565}, "timestamp": "2026-01-30T22:50:30.591826"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3564.171, "latencies_ms": [3564.171], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.243, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 72.931}, "timestamp": "2026-01-30T22:50:36.191444"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4716.995, "latencies_ms": [4716.995], "images_per_second": 0.212, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The main objects in the image are the train and the platform. The train is positioned on the right side of the image, while the platform is on the left side. The train is closer to the foreground, and the platform is further back, creating a clear spatial relationship between the two.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.801, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 70.205}, "timestamp": "2026-01-30T22:50:42.946255"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6417.109, "latencies_ms": [6417.109], "images_per_second": 0.156, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 6, "output_text": "The image depicts a railway station with a train stationed at the platform. The station is in a rural or semi-rural area, as indicated by the presence of mountains in the background. There are people present at the station, but they are not the focus of the image. The station has a covered area with a sign that reads \"La Spezia Centrale,\" suggesting it is a central station in the area.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.492, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 68.481}, "timestamp": "2026-01-30T22:50:51.377673"}
{"image_index": 243, "image_name": "000000025181.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025181.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3939.862, "latencies_ms": [3939.862], "images_per_second": 0.254, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The image is a black and white photograph of a train station platform. The platform is made of brick, and there is a concrete pillar in the center. The station has overhead signage, and the sky is overcast.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.489, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 71.455}, "timestamp": "2026-01-30T22:50:57.342873"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2293.055, "latencies_ms": [2293.055], "images_per_second": 0.436, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 6, "output_text": "A person is sitting on a red surfboard, looking out at the ocean during sunset.", "error": null, "sys_before": {"cpu_percent": 30.5, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.676, "power_cpu_cv_mean_watts": 1.046, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 79.667}, "timestamp": "2026-01-30T22:51:01.764030"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2855.205, "latencies_ms": [2855.205], "images_per_second": 0.35, "prompt_tokens": 26, "response_tokens_est": 28, "n_tiles": 6, "output_text": "surfboard: 1\nwoman: 1\nwater: 1\nocean: 1\nsun: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.447, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 75.478}, "timestamp": "2026-01-30T22:51:06.663765"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6255.785, "latencies_ms": [6255.785], "images_per_second": 0.16, "prompt_tokens": 30, "response_tokens_est": 85, "n_tiles": 6, "output_text": "The main object in the foreground is a person sitting on a red surfboard. The person is positioned near the center of the image, with their back to the camera. The background features a vast body of water, likely the ocean, with a cloudy sky above. The surfboard is positioned in the foreground, closer to the camera, while the person is further away, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.788, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 69.269}, "timestamp": "2026-01-30T22:51:14.947529"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5132.725, "latencies_ms": [5132.725], "images_per_second": 0.195, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The image captures a serene scene of a person sitting on a red surfboard, likely on a body of water during sunset. The person is wearing a black wetsuit and appears to be enjoying the tranquil moment, with the soft glow of the setting sun casting a warm light on the water and the surrounding landscape.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.321, "power_cpu_cv_mean_watts": 1.835, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 69.884}, "timestamp": "2026-01-30T22:51:22.115206"}
{"image_index": 244, "image_name": "000000025228.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025228.jpg", "image_width": 640, "image_height": 436, "image_resolution": "640x436", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5001.331, "latencies_ms": [5001.331], "images_per_second": 0.2, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image captures a serene scene of a person riding a surfboard on a body of water during sunset. The sky is filled with dramatic clouds, casting a warm, golden hue over the water. The surfboard is vibrant red, contrasting sharply with the darker tones of the water and the overcast sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.467, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 70.19}, "timestamp": "2026-01-30T22:51:29.161413"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2954.698, "latencies_ms": [2954.698], "images_per_second": 0.338, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 6, "output_text": "A man and a woman are seated in a train carriage, with the man holding chopsticks and the woman holding a small bag of snacks.", "error": null, "sys_before": {"cpu_percent": 28.3, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.163, "power_cpu_cv_mean_watts": 1.418, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 74.958}, "timestamp": "2026-01-30T22:51:34.264362"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4780.294, "latencies_ms": [4780.294], "images_per_second": 0.209, "prompt_tokens": 26, "response_tokens_est": 60, "n_tiles": 6, "output_text": "1. Man: 1\n2. Woman: 1\n3. Chopsticks: 2\n4. Plate: 1\n5. Bag: 1\n6. Tray: 1\n7. Table: 1\n8. Food: 4", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.671, "power_cpu_cv_mean_watts": 1.793, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 70.275}, "timestamp": "2026-01-30T22:51:41.070592"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6901.116, "latencies_ms": [6901.116], "images_per_second": 0.145, "prompt_tokens": 30, "response_tokens_est": 95, "n_tiles": 6, "output_text": "The main objects in the image are a man and a woman seated next to each other. The man is on the left side of the image, while the woman is on the right side. The man is holding chopsticks and appears to be eating something from a small plate. The woman is holding a plastic bag and seems to be eating or preparing to eat something. The background features a window with curtains, a yellow sign, and a glimpse of a train interior.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.32, "power_cpu_cv_mean_watts": 1.969, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 68.119}, "timestamp": "2026-01-30T22:51:50.009431"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5490.048, "latencies_ms": [5490.048], "images_per_second": 0.182, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts a man and a woman seated in a train carriage, sharing a meal. The man is holding chopsticks and appears to be eating a sushi roll, while the woman is holding a small bag and seems to be eating something from it. The setting is inside a train, with a window and a seat visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.221, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 67.217}, "timestamp": "2026-01-30T22:51:57.549193"}
{"image_index": 245, "image_name": "000000025386.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025386.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4778.368, "latencies_ms": [4778.368], "images_per_second": 0.209, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image depicts a man and a woman seated in a train carriage, with the man wearing a plaid shirt and the woman in a red and white checkered top. The lighting is bright, and the carriage appears to be well-lit, with a yellow sign visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.708, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 70.4}, "timestamp": "2026-01-30T22:52:04.369210"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3707.202, "latencies_ms": [3707.202], "images_per_second": 0.27, "prompt_tokens": 12, "response_tokens_est": 16, "n_tiles": 12, "output_text": "A man in a suit and tie is walking down a street at night.", "error": null, "sys_before": {"cpu_percent": 29.4, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.275, "power_cpu_cv_mean_watts": 0.995, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 90.613}, "timestamp": "2026-01-30T22:52:10.259121"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5652.029, "latencies_ms": [5652.029], "images_per_second": 0.177, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 12, "output_text": "- man: 1\n- suit: 1\n- tie: 1\n- shirt: 1\n- pants: 1\n- shoes: 1\n- building: 1\n- street: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.262, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 86.896}, "timestamp": "2026-01-30T22:52:17.950024"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7275.411, "latencies_ms": [7275.411], "images_per_second": 0.137, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The main object in the foreground is a man dressed in a dark suit and tie, walking on a sidewalk. The man is positioned near a street lamp, which is on the left side of the image. The background features a building with a sign that reads \"Hierro Albero,\" and there are other indistinct objects and structures in the distance.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.128, "power_cpu_cv_mean_watts": 1.679, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 84.806}, "timestamp": "2026-01-30T22:52:27.241235"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7499.697, "latencies_ms": [7499.697], "images_per_second": 0.133, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The image depicts a man walking on a city street at night. He is dressed in a formal black suit, white shirt, and a striped tie, and appears to be in a hurry. The street is dimly lit, with a few streetlights illuminating the area. The man is walking past a building with a sign that reads \"Hierro Albero.\"", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.0, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 84.651}, "timestamp": "2026-01-30T22:52:36.774654"}
{"image_index": 246, "image_name": "000000025393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025393.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6616.868, "latencies_ms": [6616.868], "images_per_second": 0.151, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a man dressed in a formal black suit and tie walking on a city street at night. The lighting is dim, with streetlights illuminating the scene, casting a warm glow on the man's face. The background features buildings with lit signs, a crosswalk, and a metal pole.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.425, "power_cpu_cv_mean_watts": 1.558, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 85.782}, "timestamp": "2026-01-30T22:52:45.418962"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3879.743, "latencies_ms": [3879.743], "images_per_second": 0.258, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 12, "output_text": "A man is holding a bottle of wine and a glass of wine in a bar setting.", "error": null, "sys_before": {"cpu_percent": 34.6, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.053, "power_cpu_cv_mean_watts": 0.989, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 90.281}, "timestamp": "2026-01-30T22:52:51.490262"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5697.77, "latencies_ms": [5697.77], "images_per_second": 0.176, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 12, "output_text": "1. Glass of wine\n2. Glass of wine\n3. Glass of wine\n4. Glass of wine\n5. Glass of wine\n6. Glass of wine\n7. Glass of wine\n8. Glass of wine", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.063, "power_cpu_cv_mean_watts": 1.415, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 87.383}, "timestamp": "2026-01-30T22:52:59.201115"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6685.041, "latencies_ms": [6685.041], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The main object in the foreground is a glass of red wine, held by a person's hand. The glass is placed on a wooden table. In the background, there is a man wearing glasses and a gray sweater, standing near a wooden cabinet filled with wine bottles. The cabinet is situated on a wooden counter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.395, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 85.804}, "timestamp": "2026-01-30T22:53:07.913585"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6856.167, "latencies_ms": [6856.167], "images_per_second": 0.146, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a man in a cozy, dimly lit bar setting, holding a bottle of wine and a glass. He appears to be engaged in a conversation or perhaps tasting the wine. The background features a wooden bar counter with various bottles and glasses, a wine rack, and a small table with a menu or card.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.271, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 85.719}, "timestamp": "2026-01-30T22:53:16.803825"}
{"image_index": 247, "image_name": "000000025394.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025394.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5653.306, "latencies_ms": [5653.306], "images_per_second": 0.177, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The image depicts a man in a cozy, dimly lit bar setting. He is holding a wine glass and a bottle, with a bottle opener nearby. The lighting is warm and subdued, creating a relaxed atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.019, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 86.979}, "timestamp": "2026-01-30T22:53:24.498153"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3026.675, "latencies_ms": [3026.675], "images_per_second": 0.33, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "A tennis player is captured mid-action, with his racket in motion, preparing to hit a tennis ball on a well-maintained grass court.", "error": null, "sys_before": {"cpu_percent": 24.2, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.081, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 74.708}, "timestamp": "2026-01-30T22:53:29.619066"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3796.083, "latencies_ms": [3796.083], "images_per_second": 0.263, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. White shirt\n5. White shorts\n6. White wristband\n7. White wristband\n8. White wristband", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.931, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.062, "gpu_utilization_percent_mean": 72.839}, "timestamp": "2026-01-30T22:53:35.443174"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4896.637, "latencies_ms": [4896.637], "images_per_second": 0.204, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The main object in the foreground is a tennis player, who is captured mid-action, with their back to the camera. The player is wearing a white shirt and white shorts, and is holding a tennis racket. The background features a well-maintained grass tennis court, with white boundary lines visible.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.52, "power_cpu_cv_mean_watts": 1.768, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.268}, "timestamp": "2026-01-30T22:53:42.378380"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6027.602, "latencies_ms": [6027.602], "images_per_second": 0.166, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 6, "output_text": "The image captures a moment during a tennis match on a well-maintained grass court. A player is in the midst of a powerful serve, with their racket swung high and their body leaning forward, indicating the force and intensity of the shot. The player is dressed in white attire, and the background shows the lush green grass of the court, emphasizing the sport's natural setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.851, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 69.32}, "timestamp": "2026-01-30T22:53:50.424262"}
{"image_index": 248, "image_name": "000000025424.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025424.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5478.786, "latencies_ms": [5478.786], "images_per_second": 0.183, "prompt_tokens": 22, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image captures a tennis player in mid-action, wearing a white shirt and white shorts. The player is holding a tennis racket, and the background shows a well-maintained grass court with white boundary lines. The lighting is bright, indicating it is daytime, and the colors are vibrant, with the green grass and white lines providing a stark contrast.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.202, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.37}, "timestamp": "2026-01-30T22:53:57.925802"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4071.237, "latencies_ms": [4071.237], "images_per_second": 0.246, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "A ginger and white cat is perched on a wooden shelf, seemingly watching something on the television screen.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.883, "power_cpu_cv_mean_watts": 1.056, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 88.97}, "timestamp": "2026-01-30T22:54:04.127414"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5080.861, "latencies_ms": [5080.861], "images_per_second": 0.197, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "1. Cat\n2. TV\n3. Shelf\n4. Coffee cup\n5. TV stand\n6. Remote control\n7. DVD player\n8. Bookshelf", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.484, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 87.907}, "timestamp": "2026-01-30T22:54:11.252234"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7056.529, "latencies_ms": [7056.529], "images_per_second": 0.142, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main object in the foreground is a cat, which is perched on a wooden shelf. The cat is positioned near the bottom right corner of the image. In the background, there is a television set on a stand, slightly to the left of the cat. The television is positioned behind the cat, making it the focal point of the image.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.325, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.86, "gpu_utilization_percent_mean": 85.2}, "timestamp": "2026-01-30T22:54:20.368353"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6766.943, "latencies_ms": [6766.943], "images_per_second": 0.148, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a cozy indoor setting with a television screen displaying a man in a suit. A cat is perched on a wooden shelf next to the TV, seemingly curious about the screen. The room appears to be a living room or a study, with a bookshelf and a cup of coffee visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.406, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 85.544}, "timestamp": "2026-01-30T22:54:29.160637"}
{"image_index": 249, "image_name": "000000025560.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025560.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7511.86, "latencies_ms": [7511.86], "images_per_second": 0.133, "prompt_tokens": 22, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The image features a cat with a white and orange coat, perched on a wooden shelf. The cat's fur appears soft and fluffy, and its tail is slightly curled. The background includes a television set with a dark screen, a white mug on a table, and a wooden bookshelf. The lighting in the room is dim, with a warm, cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.95, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 84.156}, "timestamp": "2026-01-30T22:54:38.714531"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4294.083, "latencies_ms": [4294.083], "images_per_second": 0.233, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "The image shows a blue circular sign with white silhouettes of a person and a bicycle, indicating a pedestrian crossing area.", "error": null, "sys_before": {"cpu_percent": 26.4, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.475, "power_cpu_cv_mean_watts": 1.19, "power_sys_5v0_mean_watts": 8.858, "gpu_utilization_percent_mean": 88.806}, "timestamp": "2026-01-30T22:54:45.195245"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4244.697, "latencies_ms": [4244.697], "images_per_second": 0.236, "prompt_tokens": 26, "response_tokens_est": 24, "n_tiles": 12, "output_text": "- sign: 2\n- bicycle: 1\n- person: 1\n- tree: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.352, "power_cpu_cv_mean_watts": 1.079, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 89.639}, "timestamp": "2026-01-30T22:54:51.484142"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8417.86, "latencies_ms": [8417.86], "images_per_second": 0.119, "prompt_tokens": 30, "response_tokens_est": 93, "n_tiles": 12, "output_text": "The main objects in the image are a signpost with a bicycle symbol and a sign with Japanese characters. The bicycle symbol is located on the top of the signpost, while the sign with Japanese characters is positioned below it. The signpost is situated in the foreground, with the sign and its symbols being the most prominent features. The background consists of a clear blue sky, and the signpost is slightly elevated, indicating it is likely a street signpost.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.725, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.844, "gpu_utilization_percent_mean": 83.887}, "timestamp": "2026-01-30T22:55:01.919133"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6930.958, "latencies_ms": [6930.958], "images_per_second": 0.144, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a street sign with a blue background and white silhouettes of a person and a bicycle. The sign is mounted on a pole, and there are green leaves and a clear blue sky in the background. The sign appears to be for a pedestrian crossing or a bike lane, indicating a safe area for walking or cycling.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.339, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.868, "gpu_utilization_percent_mean": 85.424}, "timestamp": "2026-01-30T22:55:10.883496"}
{"image_index": 250, "image_name": "000000025593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025593.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5688.747, "latencies_ms": [5688.747], "images_per_second": 0.176, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The image features a blue circular sign with white silhouettes of a person and a bicycle. The sign is mounted on a pole and is set against a clear blue sky. The lighting is bright and natural, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.113, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 86.583}, "timestamp": "2026-01-30T22:55:18.600573"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4601.667, "latencies_ms": [4601.667], "images_per_second": 0.217, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "A young girl with dark hair is sitting at a table in a restaurant, eating a slice of pizza with a glass of water in front of her.", "error": null, "sys_before": {"cpu_percent": 29.4, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.262, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.854, "gpu_utilization_percent_mean": 87.316}, "timestamp": "2026-01-30T22:55:25.344707"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5153.231, "latencies_ms": [5153.231], "images_per_second": 0.194, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 12, "output_text": "1. Pizza\n2. Glass of water\n3. Napkin\n4. Glass\n5. Pieces of pizza\n6. Book\n7. Water bottle\n8. Glass", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.513, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 88.349}, "timestamp": "2026-01-30T22:55:32.526780"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8622.1, "latencies_ms": [8622.1], "images_per_second": 0.116, "prompt_tokens": 30, "response_tokens_est": 96, "n_tiles": 12, "output_text": "The main objects in the image are a glass of water, a glass of soda, a pizza, a napkin, and a book. The pizza is on the table in the foreground, while the glass of soda and the glass of water are placed near the pizza. The napkin is placed in front of the pizza. The book is on the table near the pizza. The pizza is the most prominent object in the foreground, while the other items are arranged around it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.579, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 83.644}, "timestamp": "2026-01-30T22:55:43.203926"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6994.216, "latencies_ms": [6994.216], "images_per_second": 0.143, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a young girl sitting at a table in a dimly lit restaurant, possibly a pizzeria, with a pizza on the table. She is holding a glass of water and appears to be enjoying her meal. The setting is cozy and intimate, with other patrons visible in the background, creating a casual dining atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.19, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 84.983}, "timestamp": "2026-01-30T22:55:52.225565"}
{"image_index": 251, "image_name": "000000025603.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025603.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6064.305, "latencies_ms": [6064.305], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image depicts a young girl with dark hair and blue eyes, wearing a white sleeveless top and a gold bracelet. She is seated at a wooden table in a dimly lit restaurant, with a glass of water and a partially eaten pizza on the table.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.805, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 86.46}, "timestamp": "2026-01-30T22:56:00.317024"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5366.015, "latencies_ms": [5366.015], "images_per_second": 0.186, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image shows a kitchen counter with various food items, including a bowl of broccoli, a plate of rice, a glass of water, and a plate with a dish that appears to be a curry or stew.", "error": null, "sys_before": {"cpu_percent": 24.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.565, "power_cpu_cv_mean_watts": 1.42, "power_sys_5v0_mean_watts": 8.871, "gpu_utilization_percent_mean": 86.386}, "timestamp": "2026-01-30T22:56:07.832338"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10522.269, "latencies_ms": [10522.269], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- plate: 1\n- bowl: 2\n- spoon: 1\n- cup: 1\n- plate: 1\n- bowl: 1\n- plate: 1\n- bowl: 1\n- plate: 1\n- bowl: 1\n- plate: 1\n- bowl: 1\n- plate: 1\n- bowl: 1\n- plate: 1\n- bowl: 1\n- plate: 1\n- bowl: 1\n- plate: 1\n- bowl: 1\n- plate: 1\n- bowl", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.227, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 8.88, "gpu_utilization_percent_mean": 83.034}, "timestamp": "2026-01-30T22:56:20.385392"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7353.705, "latencies_ms": [7353.705], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The main objects in the image are a bowl of broccoli and a plate of food. The broccoli is in the bowl, while the plate of food is in the foreground. The plate of food is placed on a table, and there is a glass of water nearby. The background includes a yellow box and a silver bowl, but they are not the main focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.076, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.865, "gpu_utilization_percent_mean": 84.839}, "timestamp": "2026-01-30T22:56:29.784418"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7085.493, "latencies_ms": [7085.493], "images_per_second": 0.141, "prompt_tokens": 24, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The image depicts a kitchen scene with a focus on a plate of food. The plate contains a mix of cooked vegetables, possibly including broccoli, and a portion of what appears to be a meat-based dish. The setting is a kitchen with a stainless steel countertop, and there are other kitchen utensils and ingredients visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.299, "power_cpu_cv_mean_watts": 1.636, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 85.237}, "timestamp": "2026-01-30T22:56:38.885254"}
{"image_index": 252, "image_name": "000000025986.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000025986.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6365.603, "latencies_ms": [6365.603], "images_per_second": 0.157, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The image features a kitchen counter with various food items. The countertop is metallic, and there is a silver bowl filled with broccoli and a silver spoon. The lighting is bright, and the colors are vibrant, with the broccoli being green and the other items being white and silver.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.661, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 86.0}, "timestamp": "2026-01-30T22:56:47.288866"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2596.056, "latencies_ms": [2596.056], "images_per_second": 0.385, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "A busy city street scene with a variety of vehicles, including a bus and cars, is captured in the image.", "error": null, "sys_before": {"cpu_percent": 21.6, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.927, "power_cpu_cv_mean_watts": 1.297, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 73.905}, "timestamp": "2026-01-30T22:56:51.999473"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3079.142, "latencies_ms": [3079.142], "images_per_second": 0.325, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Bus\n2. Car\n3. Car\n4. Car\n5. Car\n6. Car\n7. Car\n8. Car", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.096, "power_cpu_cv_mean_watts": 1.426, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 75.08}, "timestamp": "2026-01-30T22:56:57.129257"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6061.523, "latencies_ms": [6061.523], "images_per_second": 0.165, "prompt_tokens": 30, "response_tokens_est": 82, "n_tiles": 6, "output_text": "The main objects in the image are a bus, a car, and a building. The bus is in the foreground, slightly to the right, and is moving towards the left side of the frame. The car is in the foreground, closer to the viewer, and is positioned in the center of the image. The building is in the background, to the right, and is taller than the other objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.906, "power_cpu_cv_mean_watts": 1.947, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 69.431}, "timestamp": "2026-01-30T22:57:05.246348"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6698.656, "latencies_ms": [6698.656], "images_per_second": 0.149, "prompt_tokens": 24, "response_tokens_est": 92, "n_tiles": 6, "output_text": "The image depicts a bustling urban street scene, likely in a city with a mix of commercial and residential buildings. The street is busy with various vehicles, including a white bus with the number 1, a silver sedan, and several cars parked along the curb. Pedestrians can be seen walking on the sidewalks, and there are street signs indicating directions and traffic rules. The overall atmosphere is typical of a busy city street during the day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.519, "power_cpu_cv_mean_watts": 1.967, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 68.893}, "timestamp": "2026-01-30T22:57:14.003522"}
{"image_index": 253, "image_name": "000000026204.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026204.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6162.37, "latencies_ms": [6162.37], "images_per_second": 0.162, "prompt_tokens": 22, "response_tokens_est": 83, "n_tiles": 6, "output_text": "The image depicts a bustling urban street scene with a mix of vehicles, pedestrians, and buildings. Notable visual attributes include the vibrant red car in the foreground, the white bus with the number \"1\" on it, and the clear, bright lighting that suggests daytime. The scene is well-lit, with the red car and the bus providing a striking contrast against the surrounding buildings and greenery.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.72, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 68.981}, "timestamp": "2026-01-30T22:57:22.225637"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5081.639, "latencies_ms": [5081.639], "images_per_second": 0.197, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 12, "output_text": "The image shows a laptop with a black keyboard and a screen displaying a desktop interface, alongside a smartphone and a small, rectangular device with a red button, all resting on a white surface.", "error": null, "sys_before": {"cpu_percent": 28.6, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.59, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 87.262}, "timestamp": "2026-01-30T22:57:29.446011"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4287.72, "latencies_ms": [4287.72], "images_per_second": 0.233, "prompt_tokens": 26, "response_tokens_est": 25, "n_tiles": 12, "output_text": "- laptop: 1\n- phone: 2\n- calculator: 1\n- remote control: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.491, "power_cpu_cv_mean_watts": 1.135, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 90.25}, "timestamp": "2026-01-30T22:57:35.782255"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6823.79, "latencies_ms": [6823.79], "images_per_second": 0.147, "prompt_tokens": 30, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The main objects in the image are a laptop, a smartphone, and a small black object. The laptop is positioned in the foreground, with the smartphone and the small black object placed near it. The smartphone is slightly to the right of the laptop, while the small black object is closer to the bottom left corner of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.362, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.859, "gpu_utilization_percent_mean": 85.414}, "timestamp": "2026-01-30T22:57:44.650631"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6596.537, "latencies_ms": [6596.537], "images_per_second": 0.152, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image shows a cluttered desk with various items scattered around. The desk appears to be in a room with a white wall and a window, and the items include a laptop, a smartphone, a small black object, and a black and silver object. The scene suggests a casual, possibly work-related environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.467, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 85.714}, "timestamp": "2026-01-30T22:57:53.273203"}
{"image_index": 254, "image_name": "000000026465.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026465.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5265.156, "latencies_ms": [5265.156], "images_per_second": 0.19, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image features a laptop with a black keyboard and a silver-colored mouse. The laptop is placed on a white surface, and the lighting is bright, casting clear reflections on the laptop's surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.409, "power_cpu_cv_mean_watts": 1.374, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 87.864}, "timestamp": "2026-01-30T22:58:00.571866"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2991.523, "latencies_ms": [2991.523], "images_per_second": 0.334, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The image shows a well-organized workspace with a desktop computer, a keyboard, a mouse, and a laptop, all placed on a desk.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.331, "power_cpu_cv_mean_watts": 1.418, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 74.917}, "timestamp": "2026-01-30T22:58:05.685981"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3802.077, "latencies_ms": [3802.077], "images_per_second": 0.263, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 6, "output_text": "- computer monitor: 1\n- keyboard: 1\n- mouse: 1\n- laptop: 1\n- book: 5\n- pen: 1\n- water bottle: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.778, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 71.452}, "timestamp": "2026-01-30T22:58:11.528864"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5846.724, "latencies_ms": [5846.724], "images_per_second": 0.171, "prompt_tokens": 30, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The main objects in the image are a desk with various items on it, including a laptop, a keyboard, a mouse, and a water bottle. The laptop is positioned in the background, slightly to the right, while the keyboard and mouse are in the foreground, closer to the viewer. The water bottle is placed near the keyboard, indicating that it is easily accessible for the user.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.006, "power_cpu_cv_mean_watts": 1.913, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.49}, "timestamp": "2026-01-30T22:58:19.401936"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6707.214, "latencies_ms": [6707.214], "images_per_second": 0.149, "prompt_tokens": 24, "response_tokens_est": 92, "n_tiles": 6, "output_text": "The image depicts a well-organized workspace with a desk set up for a computer. The desk is equipped with a laptop, a keyboard, a mouse, and a cup of coffee. The workspace is brightly lit by natural light coming through a window, and there are various items scattered around, including books, a pen, and a small stuffed animal. The overall setting suggests a comfortable and functional workspace, likely in a home or office environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.542, "power_cpu_cv_mean_watts": 1.974, "power_sys_5v0_mean_watts": 8.076, "gpu_utilization_percent_mean": 68.429}, "timestamp": "2026-01-30T22:58:28.126552"}
{"image_index": 255, "image_name": "000000026564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026564.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4698.23, "latencies_ms": [4698.23], "images_per_second": 0.213, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a well-organized workspace with a light-colored desk. The desk is equipped with a laptop, a keyboard, a mouse, and a water bottle. The lighting is bright, likely from natural light coming through a window, and the overall atmosphere is clean and tidy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.753, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 70.564}, "timestamp": "2026-01-30T22:58:34.845378"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2444.956, "latencies_ms": [2444.956], "images_per_second": 0.409, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "A skateboarder is performing a trick in an indoor arena, with spectators watching from the stands.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.394, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-30T22:58:39.424847"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5502.67, "latencies_ms": [5502.67], "images_per_second": 0.182, "prompt_tokens": 26, "response_tokens_est": 72, "n_tiles": 6, "output_text": "1. Skateboarder\n2. Skateboard\n3. Skateboarder's helmet\n4. Skateboarder's knee pads\n5. Skateboarder's wrist guard\n6. Skateboarder's wrist guard\n7. Skateboarder's wrist guard\n8. Skateboarder's wrist guard", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.117, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 68.891}, "timestamp": "2026-01-30T22:58:46.950719"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7365.144, "latencies_ms": [7365.144], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 103, "n_tiles": 6, "output_text": "The main object in the foreground is a skateboarder performing a trick in mid-air. The skateboarder is wearing a black shirt and gray shorts, and is holding onto a skateboard with both hands. The skateboarder is positioned near the center of the image, with the audience in the background. The audience is seated on a tiered seating area, with some individuals standing and others sitting. The skateboarder is the focal point of the image, with the audience providing context for the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.212, "power_cpu_cv_mean_watts": 2.009, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 68.063}, "timestamp": "2026-01-30T22:58:56.364320"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5605.645, "latencies_ms": [5605.645], "images_per_second": 0.178, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 6, "output_text": "The image captures a dynamic moment at an indoor skateboarding event, likely a competition or exhibition. A skateboarder is in mid-air, performing a trick, while a crowd of spectators watches from the bleachers. The setting is an indoor arena with a high ceiling, and the atmosphere is energetic, with the skateboarder's performance being the focal point.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.01, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 70.125}, "timestamp": "2026-01-30T22:59:03.996077"}
{"image_index": 256, "image_name": "000000026690.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026690.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4589.78, "latencies_ms": [4589.78], "images_per_second": 0.218, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a vibrant and dynamic scene in an indoor sports arena. The lighting is bright, highlighting the action taking place. The arena's ceiling is adorned with a patterned design, and the audience is seated on tiered seating, with some individuals wearing protective gear.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.978, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 70.579}, "timestamp": "2026-01-30T22:59:10.621073"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3051.52, "latencies_ms": [3051.52], "images_per_second": 0.328, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image features a red fire hydrant with a black face painted on it, standing on a sidewalk with a yellow line and a tree in the background.", "error": null, "sys_before": {"cpu_percent": 25.9, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.146, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 74.84}, "timestamp": "2026-01-30T22:59:15.784182"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3545.357, "latencies_ms": [3545.357], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.451, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.093, "gpu_utilization_percent_mean": 73.138}, "timestamp": "2026-01-30T22:59:21.361017"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5210.597, "latencies_ms": [5210.597], "images_per_second": 0.192, "prompt_tokens": 30, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The main object in the foreground is a red fire hydrant. It is positioned on the right side of the image, near the sidewalk. In the background, there is a tree and a building, which are further away. The hydrant is the closest object to the viewer, and the tree and building are in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.322, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 69.419}, "timestamp": "2026-01-30T22:59:28.592498"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4872.583, "latencies_ms": [4872.583], "images_per_second": 0.205, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image depicts a vibrant red fire hydrant situated on a city street. The hydrant is painted with a black smiley face, adding a playful and cheerful element to the urban scene. The background shows a street lined with buildings, trees, and parked cars, indicating a typical city environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.748, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 70.775}, "timestamp": "2026-01-30T22:59:35.484690"}
{"image_index": 257, "image_name": "000000026926.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026926.jpg", "image_width": 423, "image_height": 640, "image_resolution": "423x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4155.91, "latencies_ms": [4155.91], "images_per_second": 0.241, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The notable visual attributes of the image include a vivid red fire hydrant with a black cap and handle, which stands out against the urban backdrop. The lighting is natural, suggesting it is daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.441, "power_cpu_cv_mean_watts": 1.708, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 71.794}, "timestamp": "2026-01-30T22:59:41.671486"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3103.685, "latencies_ms": [3103.685], "images_per_second": 0.322, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 6, "output_text": "The image shows a collection of old, worn suitcases stacked on top of each other, with one suitcase in the foreground being the largest and most prominent.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.126, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 74.32}, "timestamp": "2026-01-30T22:59:46.895067"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4839.323, "latencies_ms": [4839.323], "images_per_second": 0.207, "prompt_tokens": 26, "response_tokens_est": 61, "n_tiles": 6, "output_text": "1. Green cart\n2. 2 green suitcases\n3. 2 brown suitcases\n4. 2 blue suitcases\n5. 2 green suitcases\n6. 2 brown suitcases\n7. 2 blue suitcases\n8. 2 green suitcases", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.598, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 69.9}, "timestamp": "2026-01-30T22:59:53.775891"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6390.834, "latencies_ms": [6390.834], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 87, "n_tiles": 6, "output_text": "The main objects in the image are a collection of old suitcases stacked on top of each other. The suitcases are positioned in the foreground, with the largest one on the left and the smallest one on the right. The green cart is situated in the middle ground, serving as a platform for the suitcases. The background features a green door and a poster, while the left side of the image shows a green trash can.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.721, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 68.736}, "timestamp": "2026-01-30T23:00:02.211125"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5614.722, "latencies_ms": [5614.722], "images_per_second": 0.178, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 6, "output_text": "The image depicts a collection of old, weathered suitcases stacked on top of each other on a green cart. The suitcases appear to be from different eras, with varying colors and designs, suggesting they have been used for travel. The setting appears to be outdoors, possibly in a storage area or a place where old luggage is being stored or displayed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.049, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 69.511}, "timestamp": "2026-01-30T23:00:09.861558"}
{"image_index": 258, "image_name": "000000026941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000026941.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5074.47, "latencies_ms": [5074.47], "images_per_second": 0.197, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The image features a collection of vintage suitcases stacked on top of each other, with a green cart in the foreground. The suitcases are made of various materials, including metal and fabric, and exhibit signs of wear and age. The lighting is natural, suggesting daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.542, "power_cpu_cv_mean_watts": 1.831, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 70.214}, "timestamp": "2026-01-30T23:00:16.950444"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2703.54, "latencies_ms": [2703.54], "images_per_second": 0.37, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A young girl is sitting on a couch, wearing a pink dress with a floral pattern, and holding a white remote control.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.759, "power_cpu_cv_mean_watts": 1.329, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 75.773}, "timestamp": "2026-01-30T23:00:21.775797"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3567.225, "latencies_ms": [3567.225], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.218, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 72.31}, "timestamp": "2026-01-30T23:00:27.357974"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5410.83, "latencies_ms": [5410.83], "images_per_second": 0.185, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The main object in the foreground is a young girl wearing a pink dress with a floral pattern. She is holding a white remote control in her right hand. The background features a window with white blinds, partially drawn, allowing natural light to enter the room. The couch is positioned to the right of the girl, with a brown pillow on it.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.326, "power_cpu_cv_mean_watts": 1.851, "power_sys_5v0_mean_watts": 8.089, "gpu_utilization_percent_mean": 70.111}, "timestamp": "2026-01-30T23:00:34.810046"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4440.947, "latencies_ms": [4440.947], "images_per_second": 0.225, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The image depicts a young girl sitting on a couch in a cozy living room. She is holding a white remote control and appears to be watching something on the screen. The room has a warm ambiance with blinds partially drawn, allowing natural light to filter in.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.03, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 71.162}, "timestamp": "2026-01-30T23:00:41.276376"}
{"image_index": 259, "image_name": "000000027186.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027186.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4171.044, "latencies_ms": [4171.044], "images_per_second": 0.24, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image features a young girl in a pink dress with a floral pattern, sitting on a beige couch. The room has a warm, cozy ambiance with natural light coming through partially closed white blinds, creating a soft and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.12, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 7.966, "gpu_utilization_percent_mean": 71.114}, "timestamp": "2026-01-30T23:00:47.498680"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5070.693, "latencies_ms": [5070.693], "images_per_second": 0.197, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 12, "output_text": "The image shows a cluttered office desk with a computer, a keyboard, a mouse, headphones, a trash can, and a chair, all arranged in a somewhat disorganized manner.", "error": null, "sys_before": {"cpu_percent": 28.3, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.715, "power_cpu_cv_mean_watts": 1.344, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 87.429}, "timestamp": "2026-01-30T23:00:54.715487"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4895.045, "latencies_ms": [4895.045], "images_per_second": 0.204, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 12, "output_text": "1. Desk\n2. Computer\n3. Monitor\n4. Headphones\n5. Cable\n6. Keyboard\n7. Mouse\n8. Trash can", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.82, "power_cpu_cv_mean_watts": 1.299, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 88.561}, "timestamp": "2026-01-30T23:01:01.649440"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8916.458, "latencies_ms": [8916.458], "images_per_second": 0.112, "prompt_tokens": 30, "response_tokens_est": 101, "n_tiles": 12, "output_text": "The main objects in the image are a desk, a computer, a keyboard, a mouse, headphones, a trash can, and a chair. The desk is positioned in the foreground, with the computer and keyboard placed on top of it. The keyboard is near the mouse, and the mouse is on the desk. The headphones are placed on the desk, and the trash can is positioned to the left of the chair. The chair is in the foreground, with the computer and keyboard on the desk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.495, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 83.039}, "timestamp": "2026-01-30T23:01:12.612340"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6967.602, "latencies_ms": [6967.602], "images_per_second": 0.144, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a cluttered office desk with various items scattered around. The desk is cluttered with a computer monitor, a keyboard, a mouse, a pair of headphones, a trash can, and other miscellaneous objects. The setting appears to be an office or workspace, with a window in the background and a radiator visible.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.237, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 85.5}, "timestamp": "2026-01-30T23:01:21.612700"}
{"image_index": 260, "image_name": "000000027620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027620.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6484.309, "latencies_ms": [6484.309], "images_per_second": 0.154, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image shows a cluttered office desk with a cluttered computer setup. The desk is cluttered with various items such as a computer monitor, keyboard, mouse, headphones, and a trash can. The lighting in the room is dim, and the overall atmosphere appears to be somewhat disorganized.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.52, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 86.13}, "timestamp": "2026-01-30T23:01:30.127295"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3819.446, "latencies_ms": [3819.446], "images_per_second": 0.262, "prompt_tokens": 12, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image shows a freshly baked pizza with a variety of toppings, including melted cheese, sliced green peppers, and chunks of mushrooms, all resting on a white plate with a red and white checkered tablecloth.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.729, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 71.438}, "timestamp": "2026-01-30T23:01:36.096490"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3326.248, "latencies_ms": [3326.248], "images_per_second": 0.301, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 6, "output_text": "1. Pizza\n2. Pork\n3. Mushrooms\n4. Pepperoni\n5. Tomato\n6. Cheese\n7. Sauce\n8. Plate", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.447, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 72.179}, "timestamp": "2026-01-30T23:01:41.465080"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5425.28, "latencies_ms": [5425.28], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The main object in the foreground is a freshly baked pizza with toppings such as pepperoni, mushrooms, and red bell peppers. The pizza is placed on a white plate, which is placed on a red and white checkered tablecloth. In the background, there is a fork partially visible, suggesting that someone is about to eat the pizza.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.212, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 69.457}, "timestamp": "2026-01-30T23:01:48.946615"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4218.707, "latencies_ms": [4218.707], "images_per_second": 0.237, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image shows a freshly baked pizza with a variety of toppings, including green peppers, mushrooms, and possibly some cheese. The pizza is placed on a white plate, and there is a red and white checkered tablecloth in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.245, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 70.857}, "timestamp": "2026-01-30T23:01:55.205111"}
{"image_index": 261, "image_name": "000000027696.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027696.jpg", "image_width": 640, "image_height": 410, "image_resolution": "640x410", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4480.839, "latencies_ms": [4480.839], "images_per_second": 0.223, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The image features a freshly baked pizza with a golden-brown crust, topped with melted cheese, red tomato sauce, green bell peppers, and chunks of mushrooms. The lighting is bright, highlighting the vibrant colors of the pizza and the checkered tablecloth beneath it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.871, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 70.579}, "timestamp": "2026-01-30T23:02:01.736509"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5701.304, "latencies_ms": [5701.304], "images_per_second": 0.175, "prompt_tokens": 12, "response_tokens_est": 88, "n_tiles": 1, "output_text": "The image depicts a modern city bus, specifically the Metropolitan Transit System, with the route number 2, 3, or 4 displayed on the front, and a driver wearing a uniform. The bus is white with red accents and has large windows, allowing passengers to view the surroundings. The bus is parked on a street with a clear sky above, and there are trees in the background, indicating a suburban or urban setting.", "error": null, "sys_before": {"cpu_percent": 17.6, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.598, "power_cpu_cv_mean_watts": 2.182, "power_sys_5v0_mean_watts": 7.177, "gpu_utilization_percent_mean": 65.082}, "timestamp": "2026-01-30T23:02:09.511533"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8184.606, "latencies_ms": [8184.606], "images_per_second": 0.122, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 1, "output_text": "- Bus: 1\n- Bus driver: 1\n- Bus stop sign: 1\n- Bus stop signboard: 1\n- Bus stop signboard (partially visible): 1\n- Bus stop signboard (partially visible): 1\n- Bus stop signboard (partially visible): 1\n- Bus stop signboard (partially visible): 1\n- Bus stop signboard (partially visible): 1\n- Bus stop signboard (partially visible): 1\n- Bus stop signboard (partially visible): 1\n- Bus stop signboard (part", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.706, "power_cpu_cv_mean_watts": 2.243, "power_sys_5v0_mean_watts": 7.227, "gpu_utilization_percent_mean": 65.143}, "timestamp": "2026-01-30T23:02:19.717692"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4312.203, "latencies_ms": [4312.203], "images_per_second": 0.232, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 1, "output_text": "The main object in the image is a bus, which is positioned in the foreground. The bus is white with red accents and has a destination sign on its front. The bus is parked on the street, and there are trees in the background. The bus has a driver inside, and there are other vehicles parked nearby.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.759, "power_cpu_cv_mean_watts": 2.103, "power_sys_5v0_mean_watts": 7.081, "gpu_utilization_percent_mean": 66.833}, "timestamp": "2026-01-30T23:02:26.060974"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6920.235, "latencies_ms": [6920.235], "images_per_second": 0.145, "prompt_tokens": 24, "response_tokens_est": 107, "n_tiles": 1, "output_text": "The image depicts a city bus in motion on a city street, with a clear blue sky overhead. The bus is part of the Metropolitan Transit System, as indicated by the text on its side. The bus is white with red accents and has a digital display showing the route number \"D 1\" and the destination \"DONATE.\" The bus is parked on the side of the street, and a person is visible inside the bus, possibly a driver. The background features modern buildings and trees, suggesting an urban setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.805, "power_cpu_cv_mean_watts": 2.22, "power_sys_5v0_mean_watts": 7.213, "gpu_utilization_percent_mean": 65.186}, "timestamp": "2026-01-30T23:02:35.031853"}
{"image_index": 262, "image_name": "000000027768.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027768.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4218.917, "latencies_ms": [4218.917], "images_per_second": 0.237, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The bus is predominantly white with red accents, featuring a modern design with a large front windshield and a digital display. The windows are tinted, and the bus has a sleek, streamlined appearance. The scene is bright and sunny, with shadows cast by the bus and trees, indicating a clear day.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.592, "power_cpu_cv_mean_watts": 2.071, "power_sys_5v0_mean_watts": 7.058, "gpu_utilization_percent_mean": 67.343}, "timestamp": "2026-01-30T23:02:41.301852"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2403.921, "latencies_ms": [2403.921], "images_per_second": 0.416, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 1, "output_text": "The image shows a baseball glove and a baseball cap resting on a ground with a small amount of gravel, with the cap's logo prominently displayed on the front.", "error": null, "sys_before": {"cpu_percent": 21.1, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.454, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 6.95, "gpu_utilization_percent_mean": 71.75}, "timestamp": "2026-01-30T23:02:45.771042"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1148.427, "latencies_ms": [1148.427], "images_per_second": 0.871, "prompt_tokens": 26, "response_tokens_est": 14, "n_tiles": 1, "output_text": "baseball cap: 1\nbaseball glove: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.924, "power_cpu_cv_mean_watts": 1.29, "power_sys_5v0_mean_watts": 6.328, "gpu_utilization_percent_mean": 73.111}, "timestamp": "2026-01-30T23:02:48.944675"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3825.118, "latencies_ms": [3825.118], "images_per_second": 0.261, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The main objects in the image are a baseball glove and a baseball cap. The baseball glove is positioned on the left side of the image, while the baseball cap is placed on top of the glove. The baseball cap is in the foreground, and the glove is in the background.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.564, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.052, "gpu_utilization_percent_mean": 66.0}, "timestamp": "2026-01-30T23:02:54.829544"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3155.128, "latencies_ms": [3155.128], "images_per_second": 0.317, "prompt_tokens": 24, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The image depicts a baseball glove and a baseball cap placed on a dirt surface, likely a baseball field. The glove is open, revealing a baseball inside, and the cap is worn with a white logo on the front.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.553, "power_cpu_cv_mean_watts": 1.972, "power_sys_5v0_mean_watts": 6.966, "gpu_utilization_percent_mean": 66.808}, "timestamp": "2026-01-30T23:03:00.044589"}
{"image_index": 263, "image_name": "000000027932.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027932.jpg", "image_width": 288, "image_height": 307, "image_resolution": "288x307", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3336.815, "latencies_ms": [3336.815], "images_per_second": 0.3, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The image features a dark blue baseball cap with a white logo on the front, resting on a baseball glove. The glove is made of leather with a black and white design, and the cap is placed on a gravel surface under natural lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.584, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 6.992, "gpu_utilization_percent_mean": 67.963}, "timestamp": "2026-01-30T23:03:05.417726"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2345.016, "latencies_ms": [2345.016], "images_per_second": 0.426, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 6, "output_text": "A surfer is riding a wave in the ocean, wearing a red shirt and black shorts.", "error": null, "sys_before": {"cpu_percent": 29.4, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.121, "power_cpu_cv_mean_watts": 1.09, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 74.722}, "timestamp": "2026-01-30T23:03:09.876609"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2587.969, "latencies_ms": [2587.969], "images_per_second": 0.386, "prompt_tokens": 26, "response_tokens_est": 24, "n_tiles": 6, "output_text": "surfboard: 1\nsurfer: 1\nwater: 1\nocean: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.195, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 7.949, "gpu_utilization_percent_mean": 76.714}, "timestamp": "2026-01-30T23:03:14.512277"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4413.109, "latencies_ms": [4413.109], "images_per_second": 0.227, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The main object in the foreground is a surfer riding a wave. The surfer is positioned on a surfboard, which is partially submerged in the water. The background features a large, frothy wave, indicating the surfer's position in the ocean.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.208, "power_cpu_cv_mean_watts": 1.691, "power_sys_5v0_mean_watts": 7.991, "gpu_utilization_percent_mean": 70.611}, "timestamp": "2026-01-30T23:03:20.935613"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5559.072, "latencies_ms": [5559.072], "images_per_second": 0.18, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The image captures a surfer riding a wave in a vibrant blue ocean. The surfer, dressed in a red shirt and black wetsuit, is skillfully maneuvering a white surfboard with yellow and green accents. The scene is set in a dynamic and energetic environment, showcasing the thrill and excitement of surfing in a natural, aquatic setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.133, "power_cpu_cv_mean_watts": 1.837, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 69.63}, "timestamp": "2026-01-30T23:03:28.520981"}
{"image_index": 264, "image_name": "000000027972.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027972.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3931.749, "latencies_ms": [3931.749], "images_per_second": 0.254, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The image depicts a surfer riding a wave in a vibrant turquoise ocean. The surfer is wearing a red wetsuit, and the wave is breaking with white foam, indicating a sunny and windy day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.655, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 71.562}, "timestamp": "2026-01-30T23:03:34.467041"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3307.429, "latencies_ms": [3307.429], "images_per_second": 0.302, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 6, "output_text": "The image shows a black and white photograph of a bathroom, featuring a toilet with its lid open, a toilet brush, a toilet paper roll, and a small trash can.", "error": null, "sys_before": {"cpu_percent": 22.8, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.542, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 73.889}, "timestamp": "2026-01-30T23:03:39.895369"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3379.471, "latencies_ms": [3379.471], "images_per_second": 0.296, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 6, "output_text": "toilet paper: 8\ntoilet brush: 1\ntoilet paper roll: 1\ntoilet paper bag: 1\ntoilet paper: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.344, "power_cpu_cv_mean_watts": 1.459, "power_sys_5v0_mean_watts": 7.956, "gpu_utilization_percent_mean": 72.679}, "timestamp": "2026-01-30T23:03:45.307134"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4838.085, "latencies_ms": [4838.085], "images_per_second": 0.207, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The toilet is positioned in the foreground, with its lid open and seat down. To the right of the toilet, there is a stack of toilet paper rolls. The background features a wall with a patterned tile design, and a small, dark object is visible on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.739, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 70.225}, "timestamp": "2026-01-30T23:03:52.173728"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5072.803, "latencies_ms": [5072.803], "images_per_second": 0.197, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The image depicts a bathroom setting with a white toilet positioned against a tiled wall. The toilet is accompanied by a toilet brush and a roll of toilet paper, indicating that the scene is likely in a bathroom. The overall setting appears to be a typical bathroom environment with a focus on the toilet and its associated items.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.486, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 7.958, "gpu_utilization_percent_mean": 69.81}, "timestamp": "2026-01-30T23:03:59.269138"}
{"image_index": 265, "image_name": "000000027982.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000027982.jpg", "image_width": 500, "image_height": 334, "image_resolution": "500x334", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3928.944, "latencies_ms": [3928.944], "images_per_second": 0.255, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The image is a black and white photograph of a bathroom setting. The walls and floor are tiled, and there is a white toilet with a seat and lid. The lighting is soft and diffused, casting gentle shadows.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.667, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 71.156}, "timestamp": "2026-01-30T23:04:05.216053"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3343.082, "latencies_ms": [3343.082], "images_per_second": 0.299, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "The image features a white clock tower with a blue dome, set against a backdrop of a clear blue sky and lush green trees, with a tiled roof visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 22.9, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.574, "power_cpu_cv_mean_watts": 1.528, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 73.852}, "timestamp": "2026-01-30T23:04:10.662002"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3556.104, "latencies_ms": [3556.104], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.273, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 73.172}, "timestamp": "2026-01-30T23:04:16.247953"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5083.914, "latencies_ms": [5083.914], "images_per_second": 0.197, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The main objects in the image are a white clock tower and a tiled roof. The clock tower is positioned in the background, while the tiled roof is in the foreground. The clock tower is near the top of the image, and the roof is at the bottom, creating a clear spatial relationship between the two.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.544, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.881}, "timestamp": "2026-01-30T23:04:23.364270"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4715.238, "latencies_ms": [4715.238], "images_per_second": 0.212, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a quaint, historic building with a white tower and a clock, set against a backdrop of a clear blue sky and lush greenery. The scene is likely in a tropical or subtropical region, given the presence of the greenery and the style of the architecture.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.742, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 7.982, "gpu_utilization_percent_mean": 70.821}, "timestamp": "2026-01-30T23:04:30.113152"}
{"image_index": 266, "image_name": "000000028285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028285.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4219.961, "latencies_ms": [4219.961], "images_per_second": 0.237, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image features a white clock tower with a blue dome, set against a clear blue sky. The tower is adorned with intricate metalwork and has a tiled roof. The lighting is bright and natural, suggesting it is daytime with clear weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.213, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 7.969, "gpu_utilization_percent_mean": 71.086}, "timestamp": "2026-01-30T23:04:36.382093"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2998.61, "latencies_ms": [2998.61], "images_per_second": 0.333, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The image depicts a group of elephants in a natural, outdoor setting, with one elephant in the foreground prominently displaying its trunk and tusks.", "error": null, "sys_before": {"cpu_percent": 23.2, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.265, "power_cpu_cv_mean_watts": 1.418, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 75.292}, "timestamp": "2026-01-30T23:04:41.482026"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2230.796, "latencies_ms": [2230.796], "images_per_second": 0.448, "prompt_tokens": 26, "response_tokens_est": 18, "n_tiles": 6, "output_text": "elephant: 3\nbushes: 1\ntree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.811, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 7.979, "gpu_utilization_percent_mean": 78.778}, "timestamp": "2026-01-30T23:04:45.757846"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5145.552, "latencies_ms": [5145.552], "images_per_second": 0.194, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The main objects in the image are elephants. The foreground features a large elephant with its trunk raised, while the background shows several other elephants, some of which are slightly out of focus. The elephants are positioned in a natural, outdoor setting with greenery and dirt in the foreground, and trees and bushes in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.379, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 70.023}, "timestamp": "2026-01-30T23:04:52.940840"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4467.613, "latencies_ms": [4467.613], "images_per_second": 0.224, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The image depicts a group of elephants in a natural, outdoor setting. The elephants are standing on a dirt path surrounded by greenery, with some foliage visible in the foreground. The elephants appear to be in a relaxed state, possibly grazing or resting.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.065, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 70.946}, "timestamp": "2026-01-30T23:04:59.429775"}
{"image_index": 267, "image_name": "000000028449.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028449.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5319.939, "latencies_ms": [5319.939], "images_per_second": 0.188, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image features a group of elephants in a natural, outdoor setting. The elephants are depicted with their skin appearing wet and muddy, indicating recent activity in a wet environment. The lighting is natural, with sunlight filtering through the foliage, creating a soft, diffused light that enhances the texture and color of the elephants' skin.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.166, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-30T23:05:06.802764"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4705.931, "latencies_ms": [4705.931], "images_per_second": 0.212, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The image shows a refrigerator with a partially open door, revealing a small section of the interior, and a toilet with its lid open, revealing a toilet bowl.", "error": null, "sys_before": {"cpu_percent": 30.7, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.209, "power_cpu_cv_mean_watts": 1.294, "power_sys_5v0_mean_watts": 8.838, "gpu_utilization_percent_mean": 88.59}, "timestamp": "2026-01-30T23:05:13.650353"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6553.599, "latencies_ms": [6553.599], "images_per_second": 0.153, "prompt_tokens": 26, "response_tokens_est": 62, "n_tiles": 12, "output_text": "- Refrigerator: 1\n- Water bottle: 1\n- Bowl: 1\n- Bowl holder: 1\n- Dish rack: 1\n- Dish: 1\n- Dish rack: 1\n- Dish: 1\n- Dish rack: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.507, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 85.527}, "timestamp": "2026-01-30T23:05:22.259172"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6136.897, "latencies_ms": [6136.897], "images_per_second": 0.163, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The refrigerator is located in the foreground, with its door open, revealing its contents. The sink is situated to the right of the refrigerator, with a bottle of liquid placed on the countertop. The toilet is in the background, slightly to the right of the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.811, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 86.137}, "timestamp": "2026-01-30T23:05:30.423676"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5874.773, "latencies_ms": [5874.773], "images_per_second": 0.17, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The image shows a small, well-lit kitchen area with a refrigerator and a toilet. The refrigerator is open, revealing its contents, while the toilet is closed. The setting appears to be a domestic environment, possibly a kitchen or a small bathroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.793, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 86.796}, "timestamp": "2026-01-30T23:05:38.342694"}
{"image_index": 268, "image_name": "000000028452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028452.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5713.16, "latencies_ms": [5713.16], "images_per_second": 0.175, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The image shows a white refrigerator with a glass door, illuminated by a warm, soft light. The refrigerator is placed on a tiled floor, and the overall scene appears to be indoors, possibly in a kitchen or dining area.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.979, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.767, "gpu_utilization_percent_mean": 87.043}, "timestamp": "2026-01-30T23:05:46.068144"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2490.544, "latencies_ms": [2490.544], "images_per_second": 0.402, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 1, "output_text": "The image shows a close-up view of a bunch of ripe, yellow bananas arranged on a surface, with a blurred background that suggests a bright, possibly indoor environment.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18637.3, "ram_available_mb": 44203.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.674, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 6.849, "gpu_utilization_percent_mean": 67.35}, "timestamp": "2026-01-30T23:05:50.604565"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 753.139, "latencies_ms": [753.139], "images_per_second": 1.328, "prompt_tokens": 26, "response_tokens_est": 7, "n_tiles": 1, "output_text": "- Bananas: 8", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18637.3, "ram_available_mb": 44203.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 2.8, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.691, "power_cpu_cv_mean_watts": 0.8, "power_sys_5v0_mean_watts": 6.007, "gpu_utilization_percent_mean": 76.8}, "timestamp": "2026-01-30T23:05:53.374813"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3649.233, "latencies_ms": [3649.233], "images_per_second": 0.274, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The main objects in the image are bananas, which are located in the foreground. The bananas are arranged in a row, with the closest ones to the viewer. The background is blurred, indicating that the focus is on the bananas in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.681, "power_cpu_cv_mean_watts": 2.016, "power_sys_5v0_mean_watts": 7.008, "gpu_utilization_percent_mean": 66.733}, "timestamp": "2026-01-30T23:05:59.064364"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5367.075, "latencies_ms": [5367.075], "images_per_second": 0.186, "prompt_tokens": 24, "response_tokens_est": 82, "n_tiles": 1, "output_text": "The image depicts a close-up view of a bunch of ripe bananas placed on a surface, likely a countertop or table. The bananas are yellow and appear fresh, with some showing signs of ripeness such as slight browning on the edges. The background is blurred, but it seems to be an indoor setting with a purple hue, possibly from a light source or a decorative element.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.751, "power_cpu_cv_mean_watts": 2.139, "power_sys_5v0_mean_watts": 7.163, "gpu_utilization_percent_mean": 65.0}, "timestamp": "2026-01-30T23:06:06.458658"}
{"image_index": 269, "image_name": "000000028809.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028809.jpg", "image_width": 498, "image_height": 500, "image_resolution": "498x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3211.74, "latencies_ms": [3211.74], "images_per_second": 0.311, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 1, "output_text": "The image features a bunch of ripe, yellow bananas with a slightly blurred background, suggesting a shallow depth of field. The lighting is soft and diffused, casting gentle shadows and highlighting the smooth texture of the bananas.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.768, "power_cpu_cv_mean_watts": 1.956, "power_sys_5v0_mean_watts": 6.982, "gpu_utilization_percent_mean": 64.962}, "timestamp": "2026-01-30T23:06:11.685672"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3009.069, "latencies_ms": [3009.069], "images_per_second": 0.332, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The image depicts a row of rusty, cylindrical fire hydrants standing on a paved surface, with a backdrop of a cityscape featuring modern high-rise buildings and a mix of urban architecture.", "error": null, "sys_before": {"cpu_percent": 18.5, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.648, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 6.963, "gpu_utilization_percent_mean": 66.583}, "timestamp": "2026-01-30T23:06:16.765053"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3097.017, "latencies_ms": [3097.017], "images_per_second": 0.323, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 1, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18636.5, "ram_available_mb": 44204.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.532, "power_cpu_cv_mean_watts": 1.938, "power_sys_5v0_mean_watts": 6.935, "gpu_utilization_percent_mean": 67.6}, "timestamp": "2026-01-30T23:06:21.885430"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5724.393, "latencies_ms": [5724.393], "images_per_second": 0.175, "prompt_tokens": 30, "response_tokens_est": 88, "n_tiles": 1, "output_text": "The main objects in the image are three rusty, cylindrical objects placed in the foreground. They are positioned near the center of the image, with one slightly closer to the foreground and the other two slightly further back. The background features a cityscape with tall buildings, including a prominent skyscraper with a blue facade. The ground is a mix of concrete and patches of snow, suggesting a cold, possibly winter day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18636.5, "ram_available_mb": 44204.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.836, "power_cpu_cv_mean_watts": 2.164, "power_sys_5v0_mean_watts": 7.109, "gpu_utilization_percent_mean": 65.447}, "timestamp": "2026-01-30T23:06:29.625838"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4918.188, "latencies_ms": [4918.188], "images_per_second": 0.203, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 1, "output_text": "The image depicts a cityscape with a row of rusty, cylindrical fire hydrants standing on a paved area. In the background, there are tall buildings and a few trees, suggesting an urban environment. The scene appears to be a public space, possibly a plaza or a city square, with the fire hydrants serving as a focal point.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18636.2, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.8, "power_cpu_cv_mean_watts": 2.11, "power_sys_5v0_mean_watts": 7.08, "gpu_utilization_percent_mean": 64.195}, "timestamp": "2026-01-30T23:06:36.584441"}
{"image_index": 270, "image_name": "000000028993.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000028993.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3744.894, "latencies_ms": [3744.894], "images_per_second": 0.267, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 1, "output_text": "The image features a row of rust-colored, cylindrical objects, likely fire hydrants, set against a backdrop of a cityscape with modern high-rise buildings. The scene is illuminated by natural daylight, casting soft shadows and highlighting the textures of the metal surfaces.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18636.2, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18636.0, "ram_available_mb": 44204.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.782, "power_cpu_cv_mean_watts": 2.015, "power_sys_5v0_mean_watts": 6.981, "gpu_utilization_percent_mean": 64.742}, "timestamp": "2026-01-30T23:06:42.387470"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3990.09, "latencies_ms": [3990.09], "images_per_second": 0.251, "prompt_tokens": 12, "response_tokens_est": 21, "n_tiles": 12, "output_text": "A jockey is riding a horse in a race, with the number 8 on the saddle.", "error": null, "sys_before": {"cpu_percent": 32.1, "ram_used_mb": 18636.0, "ram_available_mb": 44204.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18636.4, "ram_available_mb": 44204.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.089, "power_cpu_cv_mean_watts": 1.056, "power_sys_5v0_mean_watts": 8.854, "gpu_utilization_percent_mean": 90.606}, "timestamp": "2026-01-30T23:06:48.566101"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10538.341, "latencies_ms": [10538.341], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18636.4, "ram_available_mb": 44204.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18636.4, "ram_available_mb": 44204.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.158, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 82.393}, "timestamp": "2026-01-30T23:07:01.116758"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8546.229, "latencies_ms": [8546.229], "images_per_second": 0.117, "prompt_tokens": 30, "response_tokens_est": 94, "n_tiles": 12, "output_text": "The main object in the foreground is a brown horse with a white blaze on its face, wearing a bridle and a saddle. The number \"8\" is attached to the saddle. The background features a dirt track with a yellow and blue sign that reads \"Magnum\" and \"www.magnum.co.nz.\" The sign is mounted on a pole. The horse is positioned near the track, with the number \"8\" clearly visible on the saddle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.4, "ram_available_mb": 44204.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18636.5, "ram_available_mb": 44204.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.743, "power_cpu_cv_mean_watts": 1.752, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 84.069}, "timestamp": "2026-01-30T23:07:11.723086"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5754.675, "latencies_ms": [5754.675], "images_per_second": 0.174, "prompt_tokens": 24, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image depicts a horse race track with a jockey in a yellow jacket and helmet riding a brown horse. The horse is equipped with a bridle and a number tag, and the track is surrounded by a fence and advertising boards.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18636.5, "ram_available_mb": 44204.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18636.6, "ram_available_mb": 44204.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.073, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 86.854}, "timestamp": "2026-01-30T23:07:19.534394"}
{"image_index": 271, "image_name": "000000029187.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029187.jpg", "image_width": 640, "image_height": 491, "image_resolution": "640x491", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6366.569, "latencies_ms": [6366.569], "images_per_second": 0.157, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The horse in the image is brown with a white blaze on its face. The horse is wearing a bridle and a saddle, and it is being ridden by a person wearing a helmet. The lighting is bright, indicating it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.6, "ram_available_mb": 44204.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.691, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 85.792}, "timestamp": "2026-01-30T23:07:27.916808"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3822.508, "latencies_ms": [3822.508], "images_per_second": 0.262, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 12, "output_text": "A brown dog is standing on a blue ledge, looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 28.0, "ram_used_mb": 18636.9, "ram_available_mb": 44204.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18636.0, "ram_available_mb": 44204.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.3, "power_cpu_cv_mean_watts": 0.982, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 89.903}, "timestamp": "2026-01-30T23:07:33.880421"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4419.069, "latencies_ms": [4419.069], "images_per_second": 0.226, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 12, "output_text": "dog: 1\nlemon: 1\ntree: 1\nfence: 1\nbench: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18636.0, "ram_available_mb": 44204.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.369, "power_cpu_cv_mean_watts": 1.147, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 89.892}, "timestamp": "2026-01-30T23:07:40.350701"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6815.27, "latencies_ms": [6815.27], "images_per_second": 0.147, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The main object in the foreground is a brown dog standing on a blue ledge. The dog is positioned near the left side of the image. In the background, there is a wooden fence and a tree with green leaves. The fence is located behind the tree, and the tree is situated to the right of the fence.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18636.1, "ram_available_mb": 44204.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.224, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.798, "gpu_utilization_percent_mean": 85.035}, "timestamp": "2026-01-30T23:07:49.224563"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6320.329, "latencies_ms": [6320.329], "images_per_second": 0.158, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a serene outdoor scene with a brown dog standing on a blue ledge, surrounded by lush greenery and a wooden fence. The dog appears to be looking directly at the camera, while the sunlight casts shadows on the ground, creating a peaceful and natural atmosphere.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18636.1, "ram_available_mb": 44204.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18636.6, "ram_available_mb": 44204.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.493, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.797, "gpu_utilization_percent_mean": 85.509}, "timestamp": "2026-01-30T23:07:57.592067"}
{"image_index": 272, "image_name": "000000029393.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029393.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6005.198, "latencies_ms": [6005.198], "images_per_second": 0.167, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image features a dog standing on a blue ledge, with its fur appearing light brown and its tail curled up. The dog is surrounded by lush green foliage, and the scene is bathed in bright sunlight, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.6, "ram_available_mb": 44204.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18636.3, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.893, "power_cpu_cv_mean_watts": 1.466, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 86.76}, "timestamp": "2026-01-30T23:08:05.618318"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2686.373, "latencies_ms": [2686.373], "images_per_second": 0.372, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "The image shows a wooden bench with a blue sign attached to it, placed on a red brick surface against a concrete wall.", "error": null, "sys_before": {"cpu_percent": 30.1, "ram_used_mb": 18636.3, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.831, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 76.227}, "timestamp": "2026-01-30T23:08:10.425486"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3573.251, "latencies_ms": [3573.251], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.203, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 72.414}, "timestamp": "2026-01-30T23:08:16.019949"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4424.924, "latencies_ms": [4424.924], "images_per_second": 0.226, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The main object in the foreground is a wooden bench with a blue sign attached to its side. The bench is positioned on a red brick floor, and the sign is placed near the bench's base. The background features a concrete wall, which is slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.373, "power_cpu_cv_mean_watts": 1.78, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 71.417}, "timestamp": "2026-01-30T23:08:22.472431"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6440.531, "latencies_ms": [6440.531], "images_per_second": 0.155, "prompt_tokens": 24, "response_tokens_est": 88, "n_tiles": 6, "output_text": "The image depicts a wooden bench placed on a brick-paved surface, possibly outdoors. The bench has a rustic appearance with visible wood grain and metal pegs for support. A blue sign with handwritten text is attached to the bench, though the content of the message is not entirely clear. The setting appears to be a public area, possibly a park or a street corner, given the presence of the bench and the brick flooring.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.597, "power_cpu_cv_mean_watts": 1.951, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 68.852}, "timestamp": "2026-01-30T23:08:30.954538"}
{"image_index": 273, "image_name": "000000029397.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029397.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4696.823, "latencies_ms": [4696.823], "images_per_second": 0.213, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image features a wooden bench with a rustic, weathered appearance. The bench is situated on a red brick surface, and the bench itself has a natural, light brown finish. The lighting in the image is soft and diffused, casting gentle shadows and highlighting the texture of the wood.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18637.3, "ram_available_mb": 44203.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.853, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 71.077}, "timestamp": "2026-01-30T23:08:37.664783"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3959.75, "latencies_ms": [3959.75], "images_per_second": 0.253, "prompt_tokens": 12, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image depicts a well-appointed hotel room with a cozy, inviting atmosphere, featuring a red sofa, a wooden dining table with a white tablecloth, a wooden cabinet, and a television mounted on the wall.", "error": null, "sys_before": {"cpu_percent": 26.4, "ram_used_mb": 18637.3, "ram_available_mb": 44203.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.489, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 71.485}, "timestamp": "2026-01-30T23:08:43.742230"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3545.941, "latencies_ms": [3545.941], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.41, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 72.69}, "timestamp": "2026-01-30T23:08:49.314823"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7361.077, "latencies_ms": [7361.077], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 103, "n_tiles": 6, "output_text": "The main objects in the image are arranged in a way that showcases a cozy and well-organized living space. The foreground features a red sofa with a beige pillow, positioned near a wooden side table with a lamp. In the background, there is a large window with curtains, allowing natural light to illuminate the room. To the right, a wooden cabinet with a television on top is visible. The overall arrangement creates a sense of comfort and functionality, making the space inviting and easy to navigate.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.317, "power_cpu_cv_mean_watts": 1.996, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 68.113}, "timestamp": "2026-01-30T23:08:58.714393"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6634.183, "latencies_ms": [6634.183], "images_per_second": 0.151, "prompt_tokens": 24, "response_tokens_est": 91, "n_tiles": 6, "output_text": "The image depicts a well-appointed hotel room with a cozy and inviting atmosphere. The room features a red sofa, a wooden table with a white tablecloth, a wooden chair, a small side table with a lamp, and a television on the wall. The room is well-lit with natural light coming through the window, and there is a framed picture on the wall. The overall setting suggests a comfortable and relaxing environment for guests.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.593, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.073}, "timestamp": "2026-01-30T23:09:07.366871"}
{"image_index": 274, "image_name": "000000029596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029596.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3497.113, "latencies_ms": [3497.113], "images_per_second": 0.286, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The room is warmly lit with natural light streaming through large windows covered with sheer curtains. The walls are painted in a soft yellow hue, complemented by a wooden dining table and chairs.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18637.0, "ram_available_mb": 44203.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.326, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 72.897}, "timestamp": "2026-01-30T23:09:12.892612"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4607.79, "latencies_ms": [4607.79], "images_per_second": 0.217, "prompt_tokens": 12, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The image shows a well-composed and colorful vegetable and meat stir-fry in a black wok, featuring a mix of broccoli, carrots, zucchini, and possibly other vegetables, all cooked with pieces of ham or bacon, creating a vibrant and appetizing meal.", "error": null, "sys_before": {"cpu_percent": 25.5, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.04, "power_cpu_cv_mean_watts": 1.781, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 69.132}, "timestamp": "2026-01-30T23:09:19.610895"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3018.556, "latencies_ms": [3018.556], "images_per_second": 0.331, "prompt_tokens": 26, "response_tokens_est": 31, "n_tiles": 6, "output_text": "broccoli: 10\ncarrots: 3\nonions: 1\nsausage: 1\npotatoes: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.098, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 73.96}, "timestamp": "2026-01-30T23:09:24.662617"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8084.295, "latencies_ms": [8084.295], "images_per_second": 0.124, "prompt_tokens": 30, "response_tokens_est": 115, "n_tiles": 6, "output_text": "The main object in the image is a black frying pan containing a colorful and well-arranged salad. The salad consists of various vegetables and pieces of meat, with the vegetables including broccoli, carrots, and possibly zucchini, and the meat pieces are likely ham or bacon. The frying pan is placed on a dark surface, possibly a countertop, and there is a metal utensil, possibly a spatula, partially visible in the foreground. The background is mostly out of focus, emphasizing the salad and the utensil.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.6, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.033, "power_cpu_cv_mean_watts": 2.044, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 67.632}, "timestamp": "2026-01-30T23:09:34.804077"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4194.105, "latencies_ms": [4194.105], "images_per_second": 0.238, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image shows a close-up view of a black frying pan containing a colorful and healthy vegetable and meat mixture. The pan is on a stove, and a metal spatula is partially visible, suggesting that the dish is being prepared or cooked.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.478, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 71.514}, "timestamp": "2026-01-30T23:09:41.042912"}
{"image_index": 275, "image_name": "000000029640.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029640.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3483.708, "latencies_ms": [3483.708], "images_per_second": 0.287, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image showcases a vibrant and colorful dish of broccoli, ham, and other vegetables in a black frying pan. The lighting is bright, highlighting the fresh colors of the ingredients.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.387, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 73.214}, "timestamp": "2026-01-30T23:09:46.539728"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4091.991, "latencies_ms": [4091.991], "images_per_second": 0.244, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "The image shows a close-up of two hot dogs with mustard on them, placed on a dark plate.", "error": null, "sys_before": {"cpu_percent": 22.9, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.994, "power_cpu_cv_mean_watts": 1.119, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 90.118}, "timestamp": "2026-01-30T23:09:52.778468"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4303.327, "latencies_ms": [4303.327], "images_per_second": 0.232, "prompt_tokens": 26, "response_tokens_est": 25, "n_tiles": 12, "output_text": "hot dog: 2\nbun: 2\nketchup: 2\nmustard: 2", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.559, "power_cpu_cv_mean_watts": 1.098, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 91.257}, "timestamp": "2026-01-30T23:09:59.096209"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6191.363, "latencies_ms": [6191.363], "images_per_second": 0.162, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The main objects in the image are two hot dogs placed on a dark plate. The hot dogs are positioned in the foreground, with the one on the left slightly overlapping the one on the right. The background is out of focus, emphasizing the hot dogs in the foreground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.823, "power_cpu_cv_mean_watts": 1.517, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 86.212}, "timestamp": "2026-01-30T23:10:07.303355"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5606.462, "latencies_ms": [5606.462], "images_per_second": 0.178, "prompt_tokens": 24, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image depicts a close-up view of two hot dogs placed on a dark surface, possibly a table. The hot dogs are topped with yellow mustard, and the background includes a glimpse of a blue magazine or book.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.944, "power_cpu_cv_mean_watts": 1.389, "power_sys_5v0_mean_watts": 8.773, "gpu_utilization_percent_mean": 87.085}, "timestamp": "2026-01-30T23:10:14.926842"}
{"image_index": 276, "image_name": "000000029675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029675.jpg", "image_width": 478, "image_height": 640, "image_resolution": "478x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6141.526, "latencies_ms": [6141.526], "images_per_second": 0.163, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image features a hot dog with a yellow mustard and ketchup topping, placed on a dark plate. The lighting is soft and natural, casting a warm glow on the food. The background is blurred, emphasizing the hot dog as the focal point.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.606, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 8.766, "gpu_utilization_percent_mean": 85.824}, "timestamp": "2026-01-30T23:10:23.112251"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4444.695, "latencies_ms": [4444.695], "images_per_second": 0.225, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "A group of people are swimming in the ocean, with a green umbrella providing shade for a couple of chairs on the sandy shore.", "error": null, "sys_before": {"cpu_percent": 26.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.066, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.748, "gpu_utilization_percent_mean": 88.514}, "timestamp": "2026-01-30T23:10:29.693282"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5209.665, "latencies_ms": [5209.665], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.373, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 88.047}, "timestamp": "2026-01-30T23:10:36.914845"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6863.097, "latencies_ms": [6863.097], "images_per_second": 0.146, "prompt_tokens": 30, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The main objects in the image are a beach umbrella, a beach chair, and a person in the water. The beach umbrella is located in the foreground, near the sandy shore. The beach chair is positioned to the right of the umbrella, near the water. The person in the water is further away, in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.37, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 85.105}, "timestamp": "2026-01-30T23:10:45.801804"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6309.43, "latencies_ms": [6309.43], "images_per_second": 0.158, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a serene beach scene with a calm ocean and a sandy shore. There are several people in the water, enjoying the sun and the sea breeze. A green and white parasol is placed on a beach chair, providing shade for someone relaxing on the sand.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.578, "power_cpu_cv_mean_watts": 1.527, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 86.019}, "timestamp": "2026-01-30T23:10:54.125517"}
{"image_index": 277, "image_name": "000000029984.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000029984.jpg", "image_width": 640, "image_height": 492, "image_resolution": "640x492", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6069.725, "latencies_ms": [6069.725], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image depicts a beach scene with a clear sky and calm ocean waters. The sandy shore is visible, and there are several beach chairs with colorful covers, including pink, blue, and green. The lighting is bright and natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.661, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 85.98}, "timestamp": "2026-01-30T23:11:02.210878"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4740.41, "latencies_ms": [4740.41], "images_per_second": 0.211, "prompt_tokens": 12, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image depicts a vintage kitchen with a retro design, featuring a green-painted wooden cabinet, a white sink with a silver faucet, a wooden table with various items, a green-painted dresser, a wooden chair, and a basket of fruit on top of a white cabinet.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.72, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 70.128}, "timestamp": "2026-01-30T23:11:09.065706"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8845.022, "latencies_ms": [8845.022], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 6, "output_text": "- Kitchen\n  - Kitchen cabinets\n  - White sink\n  - White cabinet\n  - Wooden cabinet\n  - Wooden table\n  - Wooden chair\n  - Wooden basket\n  - Wooden bucket\n  - Wooden shelf\n  - Wooden drawer\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  - Wooden cabinet\n  -", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.834, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 67.693}, "timestamp": "2026-01-30T23:11:19.931119"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8856.37, "latencies_ms": [8856.37], "images_per_second": 0.113, "prompt_tokens": 30, "response_tokens_est": 129, "n_tiles": 6, "output_text": "The main objects in the image are arranged in a way that showcases the spatial relationships between them. The left side of the image features a green dresser with drawers, a white sink, and a wooden table. The sink is positioned near the dresser. In the background, there is a wooden cabinet with a mirror above it. The right side of the image shows a white cabinet with a mirror on the door, a wooden chair, and a basket of fruit on top of it. The basket is placed near the cabinet. The floor is covered with a patterned rug, and there is a wooden basket on the floor near the chair", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.818, "power_cpu_cv_mean_watts": 2.088, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 67.613}, "timestamp": "2026-01-30T23:11:30.846986"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4583.771, "latencies_ms": [4583.771], "images_per_second": 0.218, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a vintage kitchen with a retro aesthetic, featuring a green-painted wooden cabinet, a white sink, and a countertop with various items. The room has a patterned wallpaper, a wooden chair, and a basket of fruit on top of a white cabinet.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.849, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.98, "gpu_utilization_percent_mean": 70.868}, "timestamp": "2026-01-30T23:11:37.457802"}
{"image_index": 278, "image_name": "000000030213.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030213.jpg", "image_width": 640, "image_height": 449, "image_resolution": "640x449", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2829.78, "latencies_ms": [2829.78], "images_per_second": 0.353, "prompt_tokens": 22, "response_tokens_est": 28, "n_tiles": 6, "output_text": "The room features a vintage aesthetic with a green and white color scheme. The lighting is warm and soft, casting a cozy ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.623, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 75.217}, "timestamp": "2026-01-30T23:11:42.305952"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3883.652, "latencies_ms": [3883.652], "images_per_second": 0.257, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 12, "output_text": "A small dog is seen in a forest clearing, sniffing the ground with its nose.", "error": null, "sys_before": {"cpu_percent": 25.7, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.225, "power_cpu_cv_mean_watts": 0.989, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 89.344}, "timestamp": "2026-01-30T23:11:48.369182"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4064.846, "latencies_ms": [4064.846], "images_per_second": 0.246, "prompt_tokens": 26, "response_tokens_est": 21, "n_tiles": 12, "output_text": "dog: 1\nleaves: 1\ntree: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.906, "power_cpu_cv_mean_watts": 1.031, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 92.061}, "timestamp": "2026-01-30T23:11:54.461252"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7522.275, "latencies_ms": [7522.275], "images_per_second": 0.133, "prompt_tokens": 30, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The main object in the foreground is a dog, which is positioned near the center of the image. The dog is facing to the right, with its head turned slightly towards the camera. The background consists of a large tree trunk, which is situated to the right of the dog. The ground is covered with a mix of dirt and fallen leaves, creating a natural and somewhat rustic setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.039, "power_cpu_cv_mean_watts": 1.685, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 84.81}, "timestamp": "2026-01-30T23:12:04.021523"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5336.571, "latencies_ms": [5336.571], "images_per_second": 0.187, "prompt_tokens": 24, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image depicts a small dog in a lush, green forest setting. The dog is standing on a dirt path surrounded by fallen leaves and greenery, with its tail raised and ears perked up.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.361, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 88.409}, "timestamp": "2026-01-30T23:12:11.368389"}
{"image_index": 279, "image_name": "000000030494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030494.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6853.083, "latencies_ms": [6853.083], "images_per_second": 0.146, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a dog standing on a forest floor covered with brown leaves and dirt. The dog has a black and white coat, and its fur appears to be slightly matted. The lighting is natural, suggesting it is daytime, and the weather seems to be mild, as there are no signs of rain or extreme heat.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.363, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 85.491}, "timestamp": "2026-01-30T23:12:20.236924"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4612.69, "latencies_ms": [4612.69], "images_per_second": 0.217, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "A skier is standing on a snowy slope, holding ski poles, wearing a helmet, and a jacket, with a backpack on their back.", "error": null, "sys_before": {"cpu_percent": 26.6, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.155, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 88.079}, "timestamp": "2026-01-30T23:12:27.008960"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5220.769, "latencies_ms": [5220.769], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "1. Skis\n2. Skier\n3. Snow\n4. Snowboard\n5. Snowboarder\n6. Snow\n7. Snowboard\n8. Snowboarder", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.446, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 87.558}, "timestamp": "2026-01-30T23:12:34.250032"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7647.671, "latencies_ms": [7647.671], "images_per_second": 0.131, "prompt_tokens": 30, "response_tokens_est": 80, "n_tiles": 12, "output_text": "The main object in the foreground is a person standing on skis, wearing green boots and a black jacket. The person is holding ski poles and appears to be in motion, possibly skiing downhill. The background features a snowy landscape with trees and a clear blue sky. The person is positioned near the center of the image, with the skis and poles extending towards the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.006, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 84.469}, "timestamp": "2026-01-30T23:12:43.926616"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6119.556, "latencies_ms": [6119.556], "images_per_second": 0.163, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image depicts a person skiing down a snowy slope. The individual is wearing a helmet, goggles, and a jacket, and is holding ski poles. The snowy landscape is covered with tracks, indicating that the area is frequently used for skiing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.706, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 86.275}, "timestamp": "2026-01-30T23:12:52.071556"}
{"image_index": 280, "image_name": "000000030504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030504.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6109.486, "latencies_ms": [6109.486], "images_per_second": 0.164, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image depicts a person skiing in a snowy landscape. The individual is wearing a black jacket, black pants, and green ski boots, and is holding ski poles. The snow is bright white, and the sky is clear blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.745, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 86.529}, "timestamp": "2026-01-30T23:13:00.202974"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2917.772, "latencies_ms": [2917.772], "images_per_second": 0.343, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 2, "output_text": "The image depicts a large, orange locomotive with the number 6309, labeled \"BNSF,\" traveling on a railway track surrounded by a barren landscape with leafless trees.", "error": null, "sys_before": {"cpu_percent": 23.0, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18645.6, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.283, "power_cpu_cv_mean_watts": 1.836, "power_sys_5v0_mean_watts": 7.141, "gpu_utilization_percent_mean": 60.875}, "timestamp": "2026-01-30T23:13:05.214970"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2893.705, "latencies_ms": [2893.705], "images_per_second": 0.346, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 2, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18645.6, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.33, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 7.196, "gpu_utilization_percent_mean": 64.696}, "timestamp": "2026-01-30T23:13:10.151637"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5432.696, "latencies_ms": [5432.696], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 82, "n_tiles": 2, "output_text": "The main object in the image is a train, which is positioned in the foreground on the right side of the frame. The train is painted in orange and yellow, with the number \"6309\" prominently displayed on its side. The train is moving along a railroad track, which is visible in the background. The surrounding environment includes a clear blue sky, leafless trees, and a gravel bed.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 18652.4, "ram_available_mb": 44188.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.642, "power_cpu_cv_mean_watts": 2.185, "power_sys_5v0_mean_watts": 7.325, "gpu_utilization_percent_mean": 61.978}, "timestamp": "2026-01-30T23:13:17.635290"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3510.741, "latencies_ms": [3510.741], "images_per_second": 0.285, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 2, "output_text": "The image depicts a train traveling on a railway track, with a clear blue sky above and leafless trees in the background. The train is painted in bright orange and black colors, and the number \"6309\" is visible on its side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.4, "ram_available_mb": 44188.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18652.7, "ram_available_mb": 44188.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.138, "power_cpu_cv_mean_watts": 1.976, "power_sys_5v0_mean_watts": 7.281, "gpu_utilization_percent_mean": 63.7}, "timestamp": "2026-01-30T23:13:23.178059"}
{"image_index": 281, "image_name": "000000030675.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030675.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4341.077, "latencies_ms": [4341.077], "images_per_second": 0.23, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 2, "output_text": "The image features a bright orange locomotive with the number 6309 prominently displayed on its side. The locomotive is painted in a striking orange color with black and yellow accents, and it is situated on a railroad track surrounded by a barren landscape with leafless trees under a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.7, "ram_available_mb": 44188.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 7.0, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.926, "power_cpu_cv_mean_watts": 2.113, "power_sys_5v0_mean_watts": 7.342, "gpu_utilization_percent_mean": 62.806}, "timestamp": "2026-01-30T23:13:29.579008"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5182.149, "latencies_ms": [5182.149], "images_per_second": 0.193, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image shows a plate of food, including a piece of bread topped with guacamole, a bowl of broccoli, and a small bowl of what appears to be a sauce or dressing.", "error": null, "sys_before": {"cpu_percent": 25.8, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.669, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.852, "gpu_utilization_percent_mean": 87.047}, "timestamp": "2026-01-30T23:13:36.917033"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5516.802, "latencies_ms": [5516.802], "images_per_second": 0.181, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 12, "output_text": "- plate: 1\n- bowl: 2\n- broccoli: 2\n- avocado: 1\n- bread: 1\n- lettuce: 0\n- cheese: 0", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18655.6, "ram_available_mb": 44185.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.201, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 87.348}, "timestamp": "2026-01-30T23:13:44.448239"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6661.787, "latencies_ms": [6661.787], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The main objects in the image are a plate of food and a bowl of broccoli. The plate of food is positioned in the foreground, with the bowl of broccoli placed in the background. The plate of food is placed on a wooden surface, while the bowl of broccoli is on a different wooden surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18655.3, "ram_available_mb": 44185.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.48, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 85.589}, "timestamp": "2026-01-30T23:13:53.129076"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6392.859, "latencies_ms": [6392.859], "images_per_second": 0.156, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The image depicts a plate of food arranged on a wooden table. The plate contains a portion of avocado, a serving of broccoli, and a small bowl of what appears to be a sauce or dressing. The setting suggests a casual dining environment, possibly a home or a casual restaurant.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18656.1, "ram_available_mb": 44184.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.606, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 86.074}, "timestamp": "2026-01-30T23:14:01.568020"}
{"image_index": 282, "image_name": "000000030785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030785.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6790.929, "latencies_ms": [6790.929], "images_per_second": 0.147, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image features a plate of food with a light blue rim and a white interior, placed on a wooden table. The food includes a piece of bread topped with a green spread, broccoli, and a small bowl of what appears to be a sauce or dressing. The lighting is warm and soft, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18657.5, "ram_available_mb": 44183.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.279, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 85.298}, "timestamp": "2026-01-30T23:14:10.376471"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2321.45, "latencies_ms": [2321.45], "images_per_second": 0.431, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 6, "output_text": "A person is lying on a bench in a park, covered with a quilted orange blanket.", "error": null, "sys_before": {"cpu_percent": 23.0, "ram_used_mb": 18657.3, "ram_available_mb": 44183.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18658.0, "ram_available_mb": 44182.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.677, "power_cpu_cv_mean_watts": 1.181, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 75.895}, "timestamp": "2026-01-30T23:14:14.805759"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3559.789, "latencies_ms": [3559.789], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18658.0, "ram_available_mb": 44182.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18658.0, "ram_available_mb": 44182.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.02, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 72.067}, "timestamp": "2026-01-30T23:14:20.419333"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4036.033, "latencies_ms": [4036.033], "images_per_second": 0.248, "prompt_tokens": 30, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The main objects in the image are a bench and a person lying on it. The bench is located in the foreground, while the person is lying on it. The person is near the bench, and the bench is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18658.0, "ram_available_mb": 44182.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18658.0, "ram_available_mb": 44182.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.504, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 71.559}, "timestamp": "2026-01-30T23:14:26.508686"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4877.764, "latencies_ms": [4877.764], "images_per_second": 0.205, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image depicts a park bench with a person lying down on it, covered with a quilted orange blanket. The bench is situated on a grassy area with a metal fence in the background, and there are two parking meters visible. The scene suggests a quiet, possibly cold day in the park.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18658.0, "ram_available_mb": 44182.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18658.7, "ram_available_mb": 44182.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.641, "power_cpu_cv_mean_watts": 1.827, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 69.878}, "timestamp": "2026-01-30T23:14:33.431824"}
{"image_index": 283, "image_name": "000000030828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000030828.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5243.709, "latencies_ms": [5243.709], "images_per_second": 0.191, "prompt_tokens": 22, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The image depicts a bench in a park with a vivid orange quilted cover, contrasting sharply against the green grass and the blue sky. The bench is made of metal, and there are two parking meters visible in the background. The lighting is natural, suggesting it is daytime, and the overall atmosphere is serene and quiet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18658.7, "ram_available_mb": 44182.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18658.7, "ram_available_mb": 44182.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.375, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 69.636}, "timestamp": "2026-01-30T23:14:40.715473"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4213.056, "latencies_ms": [4213.056], "images_per_second": 0.237, "prompt_tokens": 12, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image shows a collection of decorative items displayed on a wall, including a large, colorful vase with a blue and yellow pattern, a small, decorative plant, and various other objects that appear to be part of an art exhibit or museum display.", "error": null, "sys_before": {"cpu_percent": 25.9, "ram_used_mb": 18658.7, "ram_available_mb": 44182.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18659.0, "ram_available_mb": 44181.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.235, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 71.457}, "timestamp": "2026-01-30T23:14:47.033374"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3550.306, "latencies_ms": [3550.306], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18659.0, "ram_available_mb": 44181.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18659.7, "ram_available_mb": 44181.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.426, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 72.793}, "timestamp": "2026-01-30T23:14:52.599757"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6930.954, "latencies_ms": [6930.954], "images_per_second": 0.144, "prompt_tokens": 30, "response_tokens_est": 96, "n_tiles": 6, "output_text": "The main object in the foreground is a large, colorful vase with a blue and yellow pattern. It is placed on a white shelf or stand. To the left of the vase, there is a smaller, dark-colored vase. In the background, there is a brown wall with various decorative items, including a small sculpture and a plant. The sculpture is placed on a pedestal, and there is a small, round object on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18659.7, "ram_available_mb": 44181.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18659.7, "ram_available_mb": 44181.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.513, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 8.079, "gpu_utilization_percent_mean": 68.695}, "timestamp": "2026-01-30T23:15:01.559469"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7594.285, "latencies_ms": [7594.285], "images_per_second": 0.132, "prompt_tokens": 24, "response_tokens_est": 107, "n_tiles": 6, "output_text": "The image depicts an indoor setting, likely a museum or gallery, showcasing various decorative items. The focal point is a large, ornate vase with a blue and yellow pattern, placed on a white pedestal. To the left, there is a smaller, dark-colored vase with a similar design. The background features a wall with a brownish hue and a few other decorative items, including a small, round, metallic object and a plant-like sculpture. The overall atmosphere suggests a curated display of art and artifacts.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18659.7, "ram_available_mb": 44181.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18659.7, "ram_available_mb": 44181.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.132, "power_cpu_cv_mean_watts": 2.027, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 68.062}, "timestamp": "2026-01-30T23:15:11.173348"}
{"image_index": 284, "image_name": "000000031050.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031050.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4571.462, "latencies_ms": [4571.462], "images_per_second": 0.219, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image showcases a collection of art pieces, including a strikingly colorful vase with blue and yellow hues, a rustic wooden sculpture, and a dark, metallic sculpture. The lighting is soft and warm, casting gentle shadows that enhance the textures and colors of the objects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18659.7, "ram_available_mb": 44181.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18658.9, "ram_available_mb": 44182.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.987, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 70.553}, "timestamp": "2026-01-30T23:15:17.773919"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3906.507, "latencies_ms": [3906.507], "images_per_second": 0.256, "prompt_tokens": 12, "response_tokens_est": 46, "n_tiles": 6, "output_text": "A skateboarder is performing a trick on a concrete ramp at a skate park, wearing a white t-shirt, blue jeans, and a helmet with a logo, while another person is standing on the side of the ramp.", "error": null, "sys_before": {"cpu_percent": 23.5, "ram_used_mb": 18658.9, "ram_available_mb": 44182.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18659.4, "ram_available_mb": 44181.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.625, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 72.219}, "timestamp": "2026-01-30T23:15:23.784166"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3602.601, "latencies_ms": [3602.601], "images_per_second": 0.278, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "1. Skateboarder\n2. Helmet\n3. T-shirt\n4. Gloves\n5. Pads\n6. Leggings\n7. Shoes\n8. Ramp", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18659.4, "ram_available_mb": 44181.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18659.7, "ram_available_mb": 44181.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.253, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 8.042, "gpu_utilization_percent_mean": 72.633}, "timestamp": "2026-01-30T23:15:29.422334"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7397.053, "latencies_ms": [7397.053], "images_per_second": 0.135, "prompt_tokens": 30, "response_tokens_est": 104, "n_tiles": 6, "output_text": "The main object in the foreground is a skateboarder performing a trick on a concrete ramp. The skateboarder is wearing a white t-shirt, blue jeans, and a helmet. The skateboard is in motion, with the skateboarder's feet on the board. In the background, there is another person standing on the ramp, and a person is working on a machine near the ramp. The skateboarder is positioned near the center of the image, while the background elements are slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18659.7, "ram_available_mb": 44181.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18659.3, "ram_available_mb": 44181.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.335, "power_cpu_cv_mean_watts": 2.021, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 68.048}, "timestamp": "2026-01-30T23:15:38.875794"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6322.95, "latencies_ms": [6322.95], "images_per_second": 0.158, "prompt_tokens": 24, "response_tokens_est": 86, "n_tiles": 6, "output_text": "The image captures a skateboarder performing a trick in a concrete bowl at a skate park during twilight. The skateboarder is wearing a white t-shirt, blue jeans, and a helmet, and is in mid-air, showcasing a dynamic and athletic posture. The setting is a well-maintained skate park with a smooth, curved concrete bowl, and the lighting suggests it is either early morning or late afternoon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18659.3, "ram_available_mb": 44181.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18659.4, "ram_available_mb": 44181.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.72, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.019}, "timestamp": "2026-01-30T23:15:47.229505"}
{"image_index": 285, "image_name": "000000031093.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031093.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4048.741, "latencies_ms": [4048.741], "images_per_second": 0.247, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The skateboarder is wearing a white t-shirt, blue jeans, and white sneakers. The skateboard is black with white wheels. The setting is outdoors during the evening, with the sun casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18659.4, "ram_available_mb": 44181.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18659.6, "ram_available_mb": 44181.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.417, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T23:15:53.324898"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6685.953, "latencies_ms": [6685.953], "images_per_second": 0.15, "prompt_tokens": 12, "response_tokens_est": 92, "n_tiles": 6, "output_text": "The image depicts a bustling city street at night, illuminated by a variety of colorful Christmas lights, with a large, ornate Christmas tree adorned with white lights and blue lights, standing prominently in the center. The tree is surrounded by a festive atmosphere, with people gathered around it, some standing and others sitting on benches. The street is lined with buildings, and the overall ambiance suggests a lively and cheerful holiday season.", "error": null, "sys_before": {"cpu_percent": 17.7, "ram_used_mb": 18659.6, "ram_available_mb": 44181.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18659.9, "ram_available_mb": 44181.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.509, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 68.875}, "timestamp": "2026-01-30T23:16:02.102324"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3562.013, "latencies_ms": [3562.013], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18659.2, "ram_available_mb": 44181.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18658.5, "ram_available_mb": 44182.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.176, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 72.31}, "timestamp": "2026-01-30T23:16:07.705989"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5917.791, "latencies_ms": [5917.791], "images_per_second": 0.169, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The main objects in the image are a large Christmas tree and a clock tower. The Christmas tree is situated in the foreground, while the clock tower is in the background. The tree is decorated with white lights and blue ornaments, and it is positioned near the clock tower. The clock tower is illuminated with white lights, and it is situated on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18658.5, "ram_available_mb": 44182.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18658.2, "ram_available_mb": 44182.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.957, "power_cpu_cv_mean_watts": 1.904, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 69.143}, "timestamp": "2026-01-30T23:16:15.664719"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5496.13, "latencies_ms": [5496.13], "images_per_second": 0.182, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts a bustling city street at night, illuminated by a variety of lights. A large Christmas tree adorned with white lights stands prominently in the center, surrounded by people and shops. The scene is lively, with people walking and engaging in various activities, while the festive decorations add a touch of holiday cheer to the urban setting.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18658.2, "ram_available_mb": 44182.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18658.6, "ram_available_mb": 44182.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.202, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 69.174}, "timestamp": "2026-01-30T23:16:23.206677"}
{"image_index": 286, "image_name": "000000031118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5721.124, "latencies_ms": [5721.124], "images_per_second": 0.175, "prompt_tokens": 22, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The image depicts a festive scene at night, featuring a large Christmas tree adorned with white lights and blue lights. The tree is situated in front of a historic building with a clock tower, illuminated by warm, string lights. The ground appears wet, suggesting recent rain, and the overall atmosphere is bright and cheerful, with a mix of traditional and modern elements.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18658.6, "ram_available_mb": 44182.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.008, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 69.646}, "timestamp": "2026-01-30T23:16:30.949186"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2694.472, "latencies_ms": [2694.472], "images_per_second": 0.371, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A young man is playing tennis on a court, with a net separating him from the background of trees and foliage.", "error": null, "sys_before": {"cpu_percent": 30.4, "ram_used_mb": 18659.1, "ram_available_mb": 44181.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18658.5, "ram_available_mb": 44182.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.845, "power_cpu_cv_mean_watts": 1.311, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 75.773}, "timestamp": "2026-01-30T23:16:35.784632"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3443.538, "latencies_ms": [3443.538], "images_per_second": 0.29, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Tennis court\n5. Fence\n6. Trees\n7. Net\n8. Person", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18658.5, "ram_available_mb": 44182.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18657.7, "ram_available_mb": 44183.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.471, "power_cpu_cv_mean_watts": 1.559, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 73.321}, "timestamp": "2026-01-30T23:16:41.268176"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5805.14, "latencies_ms": [5805.14], "images_per_second": 0.172, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The main object in the foreground is a young male tennis player, dressed in a blue shirt and black shorts, holding a tennis racket. He is positioned on a tennis court, with a chain-link fence and trees in the background. The tennis ball is in the air, slightly to the right of the player, indicating that the player is in the process of hitting the ball.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18657.7, "ram_available_mb": 44183.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18657.4, "ram_available_mb": 44183.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.967, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 69.167}, "timestamp": "2026-01-30T23:16:49.083970"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4340.678, "latencies_ms": [4340.678], "images_per_second": 0.23, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The image depicts a young male tennis player in a blue shirt and black shorts, actively engaged in a game of tennis on a court. The court is surrounded by a chain-link fence and a dense forest in the background, indicating a secluded outdoor setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18656.8, "ram_available_mb": 44184.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.072, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 70.667}, "timestamp": "2026-01-30T23:16:55.477105"}
{"image_index": 287, "image_name": "000000031217.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031217.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5429.076, "latencies_ms": [5429.076], "images_per_second": 0.184, "prompt_tokens": 22, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The image depicts a young tennis player in a blue shirt and black shorts, actively engaged in a game on a gray tennis court. The court is surrounded by a chain-link fence, and the background features dense greenery, indicating a park or recreational area. The lighting is natural, suggesting daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.166, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 69.957}, "timestamp": "2026-01-30T23:17:02.944447"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4047.933, "latencies_ms": [4047.933], "images_per_second": 0.247, "prompt_tokens": 12, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image depicts a well-appointed living room with a classic white fireplace, a plush armchair, and a small side table with a lamp, all set against a backdrop of bookshelves filled with books and decorative items.", "error": null, "sys_before": {"cpu_percent": 31.8, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.558, "power_cpu_cv_mean_watts": 1.72, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 70.412}, "timestamp": "2026-01-30T23:17:09.096533"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3557.15, "latencies_ms": [3557.15], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18656.0, "ram_available_mb": 44184.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.338, "power_cpu_cv_mean_watts": 1.671, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 72.621}, "timestamp": "2026-01-30T23:17:14.664023"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4894.655, "latencies_ms": [4894.655], "images_per_second": 0.204, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The main objects in the image are a bookshelf filled with books, a fireplace, a chair, and a lamp. The bookshelf is located in the background, while the chair and lamp are in the foreground. The bookshelf is near the fireplace, and the chair is positioned close to the lamp.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18656.6, "ram_available_mb": 44184.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.656, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 70.049}, "timestamp": "2026-01-30T23:17:21.581836"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5128.524, "latencies_ms": [5128.524], "images_per_second": 0.195, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The image depicts a cozy, well-appointed living room with a classic and elegant decor. The room features a white fireplace with a green marble surround, a plush armchair, a small side table with a lamp, and a potted plant. The setting suggests a comfortable and inviting space for relaxation and conversation.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18655.8, "ram_available_mb": 44185.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18655.9, "ram_available_mb": 44185.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.503, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 70.095}, "timestamp": "2026-01-30T23:17:28.723511"}
{"image_index": 288, "image_name": "000000031248.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031248.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4389.252, "latencies_ms": [4389.252], "images_per_second": 0.228, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The room features a classic and elegant design with a white fireplace, marble mantel, and a white mantel. The room is well-lit with natural light, and the furniture and decor are made of high-quality materials, including wood, marble, and fabric.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18655.9, "ram_available_mb": 44185.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18652.8, "ram_available_mb": 44188.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.228, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 71.194}, "timestamp": "2026-01-30T23:17:35.128032"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5120.538, "latencies_ms": [5120.538], "images_per_second": 0.195, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 12, "output_text": "The image depicts a group of zebras grazing in a grassy field, with their distinctive black and white striped patterns clearly visible against the backdrop of a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 27.1, "ram_used_mb": 18652.8, "ram_available_mb": 44188.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18652.7, "ram_available_mb": 44188.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.387, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.768, "gpu_utilization_percent_mean": 86.093}, "timestamp": "2026-01-30T23:17:42.437228"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3830.462, "latencies_ms": [3830.462], "images_per_second": 0.261, "prompt_tokens": 26, "response_tokens_est": 17, "n_tiles": 12, "output_text": "zebra: 2\ngrass: 1\ntrees: 1", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18652.7, "ram_available_mb": 44188.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.168, "power_cpu_cv_mean_watts": 0.93, "power_sys_5v0_mean_watts": 8.775, "gpu_utilization_percent_mean": 92.452}, "timestamp": "2026-01-30T23:17:48.288279"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8008.525, "latencies_ms": [8008.525], "images_per_second": 0.125, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 12, "output_text": "The main objects in the image are two zebras. The foreground features a zebra with a prominent black and white striped pattern, standing in a muddy patch. The background shows another zebra, slightly out of focus, grazing in the same area. The zebra in the foreground is closer to the viewer, while the one in the background is further away, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.855, "power_cpu_cv_mean_watts": 1.722, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 84.373}, "timestamp": "2026-01-30T23:17:58.326816"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5420.017, "latencies_ms": [5420.017], "images_per_second": 0.185, "prompt_tokens": 24, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image depicts a serene savanna scene with two zebras grazing in a field. The zebras are surrounded by tall grasses and scattered trees, creating a natural and peaceful environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.166, "power_cpu_cv_mean_watts": 1.37, "power_sys_5v0_mean_watts": 8.766, "gpu_utilization_percent_mean": 86.822}, "timestamp": "2026-01-30T23:18:05.760117"}
{"image_index": 289, "image_name": "000000031269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031269.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6887.355, "latencies_ms": [6887.355], "images_per_second": 0.145, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a scene of two zebras grazing in a grassy field. The zebras have distinctive black and white stripes on their bodies, and the lighting is bright, indicating a sunny day. The ground is covered with dry grass and patches of soil, and the overall atmosphere is serene and natural.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.17, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 84.897}, "timestamp": "2026-01-30T23:18:14.661854"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2791.482, "latencies_ms": [2791.482], "images_per_second": 0.358, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 6, "output_text": "A group of people are seated around a long table in a restaurant, with some engaged in conversation while others are focused on their meals.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.586, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 74.826}, "timestamp": "2026-01-30T23:18:19.562013"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8863.238, "latencies_ms": [8863.238], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 6, "output_text": "- table: 8\n- chairs: 8\n- people: 10\n- tablecloth: 1\n- napkins: 2\n- cups: 2\n- plates: 2\n- condiments: 2\n- cups of coffee: 2\n- cups of tea: 2\n- napkins: 2\n- plates: 2\n- cups: 2\n- condiments: 2\n- napkins: 2\n- cups: 2\n- condiments: 2\n- napkins: 2\n- cups: 2\n-", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.7, "ram_available_mb": 44187.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18652.8, "ram_available_mb": 44188.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.781, "power_cpu_cv_mean_watts": 2.082, "power_sys_5v0_mean_watts": 8.084, "gpu_utilization_percent_mean": 67.427}, "timestamp": "2026-01-30T23:18:30.453398"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5797.192, "latencies_ms": [5797.192], "images_per_second": 0.172, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 6, "output_text": "In the image, the main objects are a group of people seated around a long wooden table in a restaurant. The table is positioned in the foreground, with the people seated around it. The background features additional tables and chairs, as well as a counter with various items and a person standing behind it. The overall setting is a typical restaurant environment with a focus on the dining area.", "error": null, "sys_before": {"cpu_percent": 30.0, "ram_used_mb": 18652.8, "ram_available_mb": 44188.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.016, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.667}, "timestamp": "2026-01-30T23:18:38.269318"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4957.69, "latencies_ms": [4957.69], "images_per_second": 0.202, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The image depicts a group of people seated around a long wooden table in a cozy, rustic restaurant. The setting is warmly lit, with a rustic brick wall and wooden floors. The individuals appear to be engaged in a casual conversation, with some looking at their phones while others are focused on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.48, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 70.0}, "timestamp": "2026-01-30T23:18:45.247904"}
{"image_index": 290, "image_name": "000000031296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4420.014, "latencies_ms": [4420.014], "images_per_second": 0.226, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The image depicts a warmly lit, rustic restaurant with wooden floors and brick walls. The lighting is soft and warm, creating a cozy atmosphere. The wooden tables and chairs, along with the red and black chairs, add a touch of color to the scene.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.93, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-30T23:18:51.710526"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2815.867, "latencies_ms": [2815.867], "images_per_second": 0.355, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 6, "output_text": "A group of white swans is swimming in a calm body of water, with a few of them standing on the water's surface.", "error": null, "sys_before": {"cpu_percent": 28.1, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.549, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 75.652}, "timestamp": "2026-01-30T23:18:56.633452"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1501.637, "latencies_ms": [1501.637], "images_per_second": 0.666, "prompt_tokens": 26, "response_tokens_est": 6, "n_tiles": 6, "output_text": "swan: 8", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 2.7, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.862, "power_cpu_cv_mean_watts": 0.634, "power_sys_5v0_mean_watts": 7.965, "gpu_utilization_percent_mean": 89.75}, "timestamp": "2026-01-30T23:19:00.179244"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5174.117, "latencies_ms": [5174.117], "images_per_second": 0.193, "prompt_tokens": 30, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The main objects in the image are a group of white swans swimming in a body of water. The foreground features a single white swan, while the background shows a row of boats moored in the harbor. The water is calm, and the scene is peaceful, with the swans and boats creating a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18653.8, "ram_available_mb": 44187.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.473, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 69.864}, "timestamp": "2026-01-30T23:19:07.407000"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3747.664, "latencies_ms": [3747.664], "images_per_second": 0.267, "prompt_tokens": 24, "response_tokens_est": 43, "n_tiles": 6, "output_text": "The image depicts a serene marina scene with several white swans swimming in a calm body of water. The setting is peaceful, with the swans peacefully floating and enjoying the tranquil environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18653.8, "ram_available_mb": 44187.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18654.1, "ram_available_mb": 44186.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.87, "power_cpu_cv_mean_watts": 1.576, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 71.387}, "timestamp": "2026-01-30T23:19:13.170528"}
{"image_index": 291, "image_name": "000000031322.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031322.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5815.042, "latencies_ms": [5815.042], "images_per_second": 0.172, "prompt_tokens": 22, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The image depicts a serene scene of a group of white swans swimming in a calm body of water. The lighting is soft and warm, suggesting either early morning or late afternoon, with the sun casting a gentle glow on the water and the swans. The overall atmosphere is peaceful and tranquil, with the swans appearing to be at ease in their natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18654.1, "ram_available_mb": 44186.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18654.6, "ram_available_mb": 44186.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.669, "power_cpu_cv_mean_watts": 1.904, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 68.735}, "timestamp": "2026-01-30T23:19:21.020120"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4016.176, "latencies_ms": [4016.176], "images_per_second": 0.249, "prompt_tokens": 12, "response_tokens_est": 21, "n_tiles": 12, "output_text": "A bride and groom are cutting a cake together in a decorated room with a white canopy overhead.", "error": null, "sys_before": {"cpu_percent": 28.7, "ram_used_mb": 18654.3, "ram_available_mb": 44186.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.822, "power_cpu_cv_mean_watts": 1.007, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 89.394}, "timestamp": "2026-01-30T23:19:27.203084"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10561.355, "latencies_ms": [10561.355], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "- tablecloth: 1\n- table: 1\n- chairs: 1\n- microphone: 1\n- speaker: 1\n- cake: 1\n- cake stand: 1\n- tablecloth: 1\n- table: 1\n- chairs: 1\n- microphone: 1\n- speaker: 1\n- cake: 1\n- cake stand: 1\n- tablecloth: 1\n- table: 1\n- chairs: 1\n- microphone: 1\n- speaker: 1\n- cake: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18653.8, "ram_available_mb": 44187.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.062, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 82.461}, "timestamp": "2026-01-30T23:19:39.816436"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6837.187, "latencies_ms": [6837.187], "images_per_second": 0.146, "prompt_tokens": 30, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The main objects in the image are the bride and groom, who are standing near a table. The table is positioned in the foreground, with the bride and groom positioned on the left side of the table. The background features a stage with a microphone stand and a guitar, indicating that the event is likely a wedding reception or ceremony.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.8, "ram_available_mb": 44187.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18654.3, "ram_available_mb": 44186.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.382, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.848, "gpu_utilization_percent_mean": 83.81}, "timestamp": "2026-01-30T23:19:48.703838"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6350.495, "latencies_ms": [6350.495], "images_per_second": 0.157, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The image depicts a wedding reception taking place in a tented venue. Guests are seated around tables covered with white tablecloths, while a couple stands at the center, cutting a cake together. The setting is intimate and festive, with string lights and decorative elements enhancing the ambiance.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18654.3, "ram_available_mb": 44186.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.578, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 85.593}, "timestamp": "2026-01-30T23:19:57.087074"}
{"image_index": 292, "image_name": "000000031620.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031620.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6757.457, "latencies_ms": [6757.457], "images_per_second": 0.148, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a wedding reception with a warm and inviting atmosphere. The venue features a ceiling adorned with white drapes and a string of colorful triangular flags, creating a festive ambiance. The lighting is soft and warm, with a combination of natural and artificial light sources, enhancing the overall mood of the event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.398, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.844, "gpu_utilization_percent_mean": 85.982}, "timestamp": "2026-01-30T23:20:05.859379"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5218.24, "latencies_ms": [5218.24], "images_per_second": 0.192, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a red wall, a dark blue sofa, a small round wooden table with a lamp, a potted plant, and a framed picture on the wall.", "error": null, "sys_before": {"cpu_percent": 27.5, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.561, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 86.0}, "timestamp": "2026-01-30T23:20:13.223582"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5759.673, "latencies_ms": [5759.673], "images_per_second": 0.174, "prompt_tokens": 26, "response_tokens_est": 49, "n_tiles": 12, "output_text": "- table: 2\n- sofa: 1\n- lamp: 1\n- plant: 1\n- vase: 1\n- window: 1\n- curtain: 1\n- rug: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.914, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 86.49}, "timestamp": "2026-01-30T23:20:21.022842"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8169.792, "latencies_ms": [8169.792], "images_per_second": 0.122, "prompt_tokens": 30, "response_tokens_est": 89, "n_tiles": 12, "output_text": "The main objects in the image are a sofa, a coffee table, and a small round table. The sofa is positioned in the foreground, with a blue throw blanket draped over it. The coffee table is located to the left of the sofa, and the small round table is positioned to the right of the sofa. The sofa is near the center of the image, while the coffee table and small round table are positioned in the foreground.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.805, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 8.854, "gpu_utilization_percent_mean": 84.377}, "timestamp": "2026-01-30T23:20:31.226704"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7677.556, "latencies_ms": [7677.556], "images_per_second": 0.13, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a rich red wall and a large window allowing natural light to filter in. The room features a dark blue sofa adorned with cushions, a small round wooden table with a lamp, a glass coffee table, and a potted plant. The overall atmosphere is warm and inviting, with a mix of traditional and modern elements creating a comfortable and stylish space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.6, "ram_available_mb": 44187.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.035, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 84.891}, "timestamp": "2026-01-30T23:20:40.930894"}
{"image_index": 293, "image_name": "000000031735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031735.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5452.513, "latencies_ms": [5452.513], "images_per_second": 0.183, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The room features a rich red wall, a large window with white lace curtains, and a wooden floor. The lighting is warm and natural, with sunlight streaming in through the window, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.168, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 87.733}, "timestamp": "2026-01-30T23:20:48.397544"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3288.435, "latencies_ms": [3288.435], "images_per_second": 0.304, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 4, "output_text": "The image depicts a surreal and whimsical scene featuring a clock with a human face, a woman with red hair, and a wooden table, all set against a textured, vintage background.", "error": null, "sys_before": {"cpu_percent": 31.0, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5451.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.239, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 7.671, "gpu_utilization_percent_mean": 63.296}, "timestamp": "2026-01-30T23:20:53.792001"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3155.0, "latencies_ms": [3155.0], "images_per_second": 0.317, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 4, "output_text": "object: 1\nobject: 2\nobject: 3\nobject: 4\nobject: 5\nobject: 6\nobject: 7\nobject: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5463.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.516, "power_cpu_cv_mean_watts": 1.725, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 65.423}, "timestamp": "2026-01-30T23:20:58.992893"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7685.244, "latencies_ms": [7685.244], "images_per_second": 0.13, "prompt_tokens": 30, "response_tokens_est": 114, "n_tiles": 4, "output_text": "The main object in the image is a clock with a face that is partially obscured by a humanoid figure. The clock is positioned on the left side of the image, with its face facing towards the right. The figure, which appears to be a doll or a mannequin, is placed in the foreground, slightly to the right of the clock. The background is a plain, light-colored wall, which helps to highlight the clock and the figure. The overall composition places the clock and the figure in the foreground, with the background being a neutral space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5465.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.727, "power_cpu_cv_mean_watts": 2.121, "power_sys_5v0_mean_watts": 7.736, "gpu_utilization_percent_mean": 63.672}, "timestamp": "2026-01-30T23:21:08.721547"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6442.599, "latencies_ms": [6442.599], "images_per_second": 0.155, "prompt_tokens": 24, "response_tokens_est": 94, "n_tiles": 4, "output_text": "The image depicts a surreal and whimsical scene featuring a clock with a human face. The clock is placed on a wooden surface, and the face of the clock is a realistic depiction of a person's face, complete with eyes, nose, and mouth. The clock's hands are in a specific position, suggesting it is set to a specific time. The overall setting appears to be indoors, possibly in a room with a warm, ambient light.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5460.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.066, "power_cpu_cv_mean_watts": 2.062, "power_sys_5v0_mean_watts": 7.707, "gpu_utilization_percent_mean": 64.278}, "timestamp": "2026-01-30T23:21:17.181676"}
{"image_index": 294, "image_name": "000000031749.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031749.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4138.179, "latencies_ms": [4138.179], "images_per_second": 0.242, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 4, "output_text": "The image features a clock with a vintage design, predominantly in a warm yellow hue. The clock's hands are black, and it has a white face with black numerals. The clock is placed on a wooden surface, and the background has a textured, aged appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5459.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.366, "power_cpu_cv_mean_watts": 1.888, "power_sys_5v0_mean_watts": 7.667, "gpu_utilization_percent_mean": 65.6}, "timestamp": "2026-01-30T23:21:23.365217"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2720.287, "latencies_ms": [2720.287], "images_per_second": 0.368, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 2, "output_text": "A person is sitting on a motorcycle, wearing a beige jacket, beige pants, and black shoes, with a helmet on their head, and appears to be looking downwards.", "error": null, "sys_before": {"cpu_percent": 20.7, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.597, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.161, "gpu_utilization_percent_mean": 64.5}, "timestamp": "2026-01-30T23:21:28.156623"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3286.572, "latencies_ms": [3286.572], "images_per_second": 0.304, "prompt_tokens": 26, "response_tokens_est": 47, "n_tiles": 2, "output_text": "helmet: 1\nshirt: 1\npants: 1\nglove: 1\nfootwear: 1\nmotorcycle: 1\nseat: 1\nseatbelt: 1", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.268, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 7.295, "gpu_utilization_percent_mean": 64.037}, "timestamp": "2026-01-30T23:21:33.460233"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3979.185, "latencies_ms": [3979.185], "images_per_second": 0.251, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 2, "output_text": "The main object in the foreground is a person wearing a beige jacket and beige pants, seated on a motorcycle. The motorcycle is positioned to the right of the person. In the background, there are other people and a red vehicle, which is further away from the main subject.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.956, "power_cpu_cv_mean_watts": 1.978, "power_sys_5v0_mean_watts": 7.248, "gpu_utilization_percent_mean": 63.606}, "timestamp": "2026-01-30T23:21:39.478816"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4285.47, "latencies_ms": [4285.47], "images_per_second": 0.233, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 2, "output_text": "The image depicts a person riding a motorcycle, wearing a beige jacket and beige pants, with a helmet on their head. The individual is seated on the motorcycle, with their hands resting on the handlebars. In the background, there are other people and a red vehicle, suggesting an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.865, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 7.263, "gpu_utilization_percent_mean": 62.829}, "timestamp": "2026-01-30T23:21:45.782514"}
{"image_index": 295, "image_name": "000000031817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000031817.jpg", "image_width": 334, "image_height": 640, "image_resolution": "334x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3597.73, "latencies_ms": [3597.73], "images_per_second": 0.278, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 2, "output_text": "The image features a person wearing a beige jacket and khaki pants, seated on a black motorcycle. The helmet is transparent, and the person is wearing black shoes with yellow laces. The lighting is natural, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18653.5, "ram_available_mb": 44187.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.043, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 7.22, "gpu_utilization_percent_mean": 63.467}, "timestamp": "2026-01-30T23:21:51.426514"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2996.236, "latencies_ms": [2996.236], "images_per_second": 0.334, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "A large, freshly baked pizza with melted cheese and green herbs is placed on a wooden table, with a person's hand partially visible in the background.", "error": null, "sys_before": {"cpu_percent": 33.6, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.579, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 72.292}, "timestamp": "2026-01-30T23:21:56.559884"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8883.808, "latencies_ms": [8883.808], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 6, "output_text": "pizza: 1\nbutter: 1\nbutter knife: 1\nbutter paper: 1\nbutter paper tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray: 1\nbutter tray", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.794, "power_cpu_cv_mean_watts": 2.077, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 67.453}, "timestamp": "2026-01-30T23:22:07.475277"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4724.334, "latencies_ms": [4724.334], "images_per_second": 0.212, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The main object in the foreground is a freshly baked pizza with melted cheese and green herbs on top. The pizza is placed on a wooden surface, likely a table or countertop. In the background, there are other kitchen items and utensils, suggesting that this is a kitchen setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.758, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 70.59}, "timestamp": "2026-01-30T23:22:14.241142"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4468.753, "latencies_ms": [4468.753], "images_per_second": 0.224, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The image depicts a close-up view of a freshly baked pizza on a wooden surface, likely in a kitchen or dining area. The pizza is topped with melted cheese and green herbs, and there are other pizzas and kitchen utensils visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.971, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 7.95, "gpu_utilization_percent_mean": 70.595}, "timestamp": "2026-01-30T23:22:20.740525"}
{"image_index": 296, "image_name": "000000032038.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032038.jpg", "image_width": 333, "image_height": 500, "image_resolution": "333x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3615.442, "latencies_ms": [3615.442], "images_per_second": 0.277, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The image features a freshly baked pizza with a golden-brown crust and a melted, gooey cheese topping. The lighting is dim, casting shadows and highlighting the texture of the crust and cheese.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.09, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 72.6}, "timestamp": "2026-01-30T23:22:26.412372"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4473.156, "latencies_ms": [4473.156], "images_per_second": 0.224, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "A tennis player is in the middle of a match, wearing a white outfit and a headband, and is holding a tennis racket.", "error": null, "sys_before": {"cpu_percent": 25.9, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.33, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.847, "gpu_utilization_percent_mean": 89.486}, "timestamp": "2026-01-30T23:22:33.030290"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4824.493, "latencies_ms": [4824.493], "images_per_second": 0.207, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "woman: 1\ntennis racket: 1\ntennis ball: 1\ntennis court: 1\ntennis net: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.965, "power_cpu_cv_mean_watts": 1.271, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 89.2}, "timestamp": "2026-01-30T23:22:39.878504"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5763.219, "latencies_ms": [5763.219], "images_per_second": 0.174, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The main object in the foreground is a tennis player, who is positioned near the net. The player is wearing a white outfit and white shoes. The background features a tennis court with a net, and the grass is well-maintained.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.969, "power_cpu_cv_mean_watts": 1.435, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 86.771}, "timestamp": "2026-01-30T23:22:47.659988"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6727.03, "latencies_ms": [6727.03], "images_per_second": 0.149, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image depicts a tennis player in a white outfit, including a skirt and shoes, preparing to hit a tennis ball on a well-maintained grass court. The player is captured in a dynamic pose, with one arm raised and the other holding the racket, indicating the moment of action during a tennis match.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.275, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.351}, "timestamp": "2026-01-30T23:22:56.438326"}
{"image_index": 297, "image_name": "000000032081.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032081.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5201.33, "latencies_ms": [5201.33], "images_per_second": 0.192, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The tennis player is wearing a white outfit, including a sleeveless top and skirt, and white shoes. The lighting is bright, indicating it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.477, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 87.744}, "timestamp": "2026-01-30T23:23:03.673426"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3230.508, "latencies_ms": [3230.508], "images_per_second": 0.31, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The image shows a small bathroom with a white toilet, a towel rack with a dark towel hanging on it, a tiled floor, and a shower curtain partially drawn.", "error": null, "sys_before": {"cpu_percent": 24.0, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.687, "power_cpu_cv_mean_watts": 1.542, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 73.074}, "timestamp": "2026-01-30T23:23:09.030247"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3668.215, "latencies_ms": [3668.215], "images_per_second": 0.273, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 6, "output_text": "1. Toilet\n2. Shower curtain\n3. Towel\n4. Shelf\n5. Floor tiles\n6. Wall tiles\n7. Wall outlet\n8. Recessed light", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.148, "power_cpu_cv_mean_watts": 1.562, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 72.567}, "timestamp": "2026-01-30T23:23:14.730440"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7828.627, "latencies_ms": [7828.627], "images_per_second": 0.128, "prompt_tokens": 30, "response_tokens_est": 111, "n_tiles": 6, "output_text": "The toilet is positioned on the left side of the image, with its lid closed. The toilet paper roll is placed near the toilet. The shower curtain is hanging on the right side of the toilet, partially covering the bathtub. The bathtub is located in the background, and the shower curtain is near the bathtub. The shelves are located to the right of the toilet, and the towels are placed on the shelves. The towels are near the right side of the image, while the toilet paper roll is near the left side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.172, "power_cpu_cv_mean_watts": 2.039, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 68.242}, "timestamp": "2026-01-30T23:23:24.576316"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6217.597, "latencies_ms": [6217.597], "images_per_second": 0.161, "prompt_tokens": 24, "response_tokens_est": 84, "n_tiles": 6, "output_text": "The image depicts a small, well-organized bathroom with a white toilet and a bathtub. The walls are painted in a light yellow color, and there is a towel rack with a black towel hanging on it. The floor is covered with brown tiles, and there are white shelves with folded towels on them. The bathroom appears to be in a residential setting, possibly a bedroom or a guest room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.697, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 68.769}, "timestamp": "2026-01-30T23:23:32.825484"}
{"image_index": 298, "image_name": "000000032285.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032285.jpg", "image_width": 640, "image_height": 423, "image_resolution": "640x423", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3923.97, "latencies_ms": [3923.97], "images_per_second": 0.255, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The bathroom features a light yellow wall, a white toilet, and a white bathtub. The lighting is soft and natural, likely from a nearby window, and the materials include ceramic tiles for the floor and white fixtures.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.526, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 71.424}, "timestamp": "2026-01-30T23:23:38.791252"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4651.987, "latencies_ms": [4651.987], "images_per_second": 0.215, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "The image depicts a group of people gathered in a casual indoor setting, with two individuals holding wine glasses, one of whom is smiling at the camera.", "error": null, "sys_before": {"cpu_percent": 32.0, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.152, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 87.667}, "timestamp": "2026-01-30T23:23:45.592769"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4913.798, "latencies_ms": [4913.798], "images_per_second": 0.204, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 12, "output_text": "1. Glasses\n2. Woman\n3. Man\n4. Table\n5. Wine\n6. Wine glass\n7. Wine bottle\n8. Wine", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.727, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 88.293}, "timestamp": "2026-01-30T23:23:52.565748"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7468.475, "latencies_ms": [7468.475], "images_per_second": 0.134, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The main objects in the image are a man and a woman. The man is in the foreground, holding a wine glass, while the woman is in the background, also holding a wine glass. The man is closer to the camera, while the woman is slightly out of focus. The wine glasses are placed on a table, and there is a doorway visible in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18652.8, "ram_available_mb": 44188.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.988, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 84.476}, "timestamp": "2026-01-30T23:24:02.070137"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7148.094, "latencies_ms": [7148.094], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a social gathering in a cozy, well-lit room with a warm ambiance. The setting appears to be a restaurant or a bar, as evidenced by the presence of a table with menus and wine glasses. The individuals are engaged in conversation, with some smiling and others looking at the camera, creating a relaxed and friendly atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.8, "ram_available_mb": 44188.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.144, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 84.65}, "timestamp": "2026-01-30T23:24:11.230939"}
{"image_index": 299, "image_name": "000000032334.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032334.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4923.767, "latencies_ms": [4923.767], "images_per_second": 0.203, "prompt_tokens": 22, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image features a brightly lit indoor setting with natural light streaming in through a window. The individuals are wearing casual clothing, and the overall atmosphere is warm and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.707, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 89.146}, "timestamp": "2026-01-30T23:24:18.196964"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2887.769, "latencies_ms": [2887.769], "images_per_second": 0.346, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "A surfer is riding a wave in the ocean, skillfully maneuvering the surfboard amidst the frothy, blue-green waters.", "error": null, "sys_before": {"cpu_percent": 31.5, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.16, "power_cpu_cv_mean_watts": 1.368, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 74.167}, "timestamp": "2026-01-30T23:24:23.224940"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2584.626, "latencies_ms": [2584.626], "images_per_second": 0.387, "prompt_tokens": 26, "response_tokens_est": 24, "n_tiles": 6, "output_text": "surfboard: 1\nsurfer: 1\nocean: 1\nwater: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.057, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 76.952}, "timestamp": "2026-01-30T23:24:27.857258"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3141.264, "latencies_ms": [3141.264], "images_per_second": 0.318, "prompt_tokens": 30, "response_tokens_est": 33, "n_tiles": 6, "output_text": "The main object in the foreground is a surfer riding a wave. The wave is in the background, and the surfer is near the water's surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.905, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 73.885}, "timestamp": "2026-01-30T23:24:33.036445"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6088.233, "latencies_ms": [6088.233], "images_per_second": 0.164, "prompt_tokens": 24, "response_tokens_est": 82, "n_tiles": 6, "output_text": "The image captures a dynamic scene of a surfer riding a wave in the ocean. The surfer, dressed in a black wetsuit, is skillfully maneuvering a surfboard amidst a frothy, white-capped wave. The setting is a sunny beach, with the ocean's vibrant blue-green color and the surfer's white wetsuit contrasting against the clear, sunny sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.819, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 68.824}, "timestamp": "2026-01-30T23:24:41.138620"}
{"image_index": 300, "image_name": "000000032570.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032570.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4581.356, "latencies_ms": [4581.356], "images_per_second": 0.218, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image captures a surfer riding a wave in clear, blue-green water, with the sun shining brightly, creating a vivid and dynamic scene. The surfer is wearing a black wetsuit, and the water is splashing around, indicating a strong and powerful wave.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.942, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 70.447}, "timestamp": "2026-01-30T23:24:47.734786"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3410.06, "latencies_ms": [3410.06], "images_per_second": 0.293, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The image shows a cluttered desk with various electronic devices, including laptops, a tablet, and a smartphone, all connected to a network, and a black bag with a red interior.", "error": null, "sys_before": {"cpu_percent": 27.0, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.485, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 73.607}, "timestamp": "2026-01-30T23:24:53.288019"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3494.672, "latencies_ms": [3494.672], "images_per_second": 0.286, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 6, "output_text": "1. Laptop bag\n2. Laptop\n3. Laptop bag\n4. Laptop bag\n5. Laptop bag\n6. Laptop bag\n7. Laptop bag\n8. Laptop bag", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.311, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 72.759}, "timestamp": "2026-01-30T23:24:58.806398"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7224.501, "latencies_ms": [7224.501], "images_per_second": 0.138, "prompt_tokens": 30, "response_tokens_est": 101, "n_tiles": 6, "output_text": "The main objects in the image are a laptop, a black bag, and a black computer tower. The laptop is positioned in the foreground on the right side of the image, while the black bag is on the left side, closer to the foreground. The black computer tower is in the background, slightly to the right. The laptop screen is visible, displaying a webpage with various icons and text. The laptop and the computer tower are connected by a black cable, which is also visible on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.352, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 68.279}, "timestamp": "2026-01-30T23:25:08.053332"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4279.223, "latencies_ms": [4279.223], "images_per_second": 0.234, "prompt_tokens": 24, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The image depicts a cluttered workspace with various electronic devices and cables spread across a wooden surface. The setting appears to be a home or office environment, possibly a study or a workspace, with a focus on the disarray of technology and personal items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.0, "ram_available_mb": 44187.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.313, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 71.343}, "timestamp": "2026-01-30T23:25:14.361382"}
{"image_index": 301, "image_name": "000000032610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4045.138, "latencies_ms": [4045.138], "images_per_second": 0.247, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image depicts a cluttered workspace with a variety of laptops and a black bag on a wooden surface. The lighting is dim, and the overall atmosphere appears to be somewhat disorganized, with cables and devices strewn about.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.438, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 71.212}, "timestamp": "2026-01-30T23:25:20.437476"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3409.104, "latencies_ms": [3409.104], "images_per_second": 0.293, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 6, "output_text": "A skier in a vibrant red and green suit is performing a jump over a snowy slope, with their skis angled upwards and their body stretched out in a dynamic pose.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.486, "power_cpu_cv_mean_watts": 1.545, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 73.393}, "timestamp": "2026-01-30T23:25:25.969002"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3494.493, "latencies_ms": [3494.493], "images_per_second": 0.286, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 6, "output_text": "1. Skier\n2. Ski poles\n3. Ski\n4. Ski poles\n5. Ski jacket\n6. Ski pants\n7. Ski boots\n8. Ski helmet", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.1, "ram_available_mb": 44188.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.367, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 72.793}, "timestamp": "2026-01-30T23:25:31.503100"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5680.589, "latencies_ms": [5680.589], "images_per_second": 0.176, "prompt_tokens": 30, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The main object in the foreground is a skier in mid-air, performing a jump. The skier is wearing a bright red and green suit, and is holding ski poles. The background features a snowy mountain slope, with another skier visible further away. The skier in the foreground is closer to the camera, while the other skier is further away.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.008, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 69.417}, "timestamp": "2026-01-30T23:25:39.237819"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6656.101, "latencies_ms": [6656.101], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 91, "n_tiles": 6, "output_text": "The image captures a dynamic moment at a ski resort, where a skier is performing a jump. The skier, dressed in vibrant red and green gear, is airborne, with their skis angled upwards and their body slightly tilted. In the background, another skier is visible, also in motion, descending the slope. The scene is set against a clear blue sky, and the snow-covered landscape suggests a winter sports environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.44, "power_cpu_cv_mean_watts": 1.974, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 68.393}, "timestamp": "2026-01-30T23:25:47.954203"}
{"image_index": 302, "image_name": "000000032735.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032735.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6066.181, "latencies_ms": [6066.181], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 82, "n_tiles": 6, "output_text": "The image captures a skier in mid-air, dressed in a vibrant red and green suit, with a green helmet and goggles. The skier is performing a jump over a snowy slope, with a clear blue sky and a few clouds in the background. The lighting is bright and natural, indicating daytime, and the snow appears to be freshly groomed, with no visible signs of recent activity.", "error": null, "sys_before": {"cpu_percent": 4.0, "ram_used_mb": 18654.2, "ram_available_mb": 44186.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18654.1, "ram_available_mb": 44186.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.819, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 68.922}, "timestamp": "2026-01-30T23:25:56.044660"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4233.851, "latencies_ms": [4233.851], "images_per_second": 0.236, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 12, "output_text": "A small bird is perched on the edge of a rusty window, looking out at a calm body of water.", "error": null, "sys_before": {"cpu_percent": 24.6, "ram_used_mb": 18654.1, "ram_available_mb": 44186.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.693, "power_cpu_cv_mean_watts": 1.121, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 89.543}, "timestamp": "2026-01-30T23:26:02.422702"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5105.152, "latencies_ms": [5105.152], "images_per_second": 0.196, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "bird: 1\nwindow: 1\ndoor: 1\nframe: 1\ndoor handle: 1\ndoor knob: 1\ndoor lock: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.47, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 88.286}, "timestamp": "2026-01-30T23:26:09.562323"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7032.105, "latencies_ms": [7032.105], "images_per_second": 0.142, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The main object in the foreground is a bird perched on a rusty metal railing near the window. The window is located in the middle ground, slightly to the left, and is framed by a dark wall. The background features a dark, indistinct area, possibly a room, with a door partially visible on the right side.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18653.2, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.184, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 85.068}, "timestamp": "2026-01-30T23:26:18.612294"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5340.265, "latencies_ms": [5340.265], "images_per_second": 0.187, "prompt_tokens": 24, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image depicts a dimly lit room with a large, old-fashioned television set on a stand. A bird is perched on the edge of the television screen, seemingly observing the scene outside.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.2, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.348, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 87.818}, "timestamp": "2026-01-30T23:26:25.976546"}
{"image_index": 303, "image_name": "000000032811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032811.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7100.265, "latencies_ms": [7100.265], "images_per_second": 0.141, "prompt_tokens": 22, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The image shows a dark, dimly lit room with a rusted window frame. The window is reflecting a view of a calm body of water, possibly a lake or sea, with a small bird perched on the window sill. The overall atmosphere is somber and subdued due to the low lighting and the presence of the bird.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18653.4, "ram_available_mb": 44187.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.159, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 84.644}, "timestamp": "2026-01-30T23:26:35.098903"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3844.392, "latencies_ms": [3844.392], "images_per_second": 0.26, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 12, "output_text": "A man is bending over a toilet in a bathroom, picking up a white towel.", "error": null, "sys_before": {"cpu_percent": 29.0, "ram_used_mb": 18654.6, "ram_available_mb": 44186.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.913, "power_cpu_cv_mean_watts": 0.964, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 90.25}, "timestamp": "2026-01-30T23:26:41.103572"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5530.442, "latencies_ms": [5530.442], "images_per_second": 0.181, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 12, "output_text": "1. Toilet\n2. Trash can\n3. Shelf\n4. Trash bag\n5. Shelf\n6. Trash bag\n7. Trash bag\n8. Trash bag", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18654.9, "ram_available_mb": 44186.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18654.6, "ram_available_mb": 44186.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.098, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.778, "gpu_utilization_percent_mean": 86.913}, "timestamp": "2026-01-30T23:26:48.662091"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6008.412, "latencies_ms": [6008.412], "images_per_second": 0.166, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The main object in the foreground is a black trash can filled with various items, including a white towel. The trash can is positioned near the toilet, which is in the background. The person is bending over the toilet, possibly picking something up or cleaning it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18654.0, "ram_available_mb": 44186.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.759, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 86.6}, "timestamp": "2026-01-30T23:26:56.701497"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4813.03, "latencies_ms": [4813.03], "images_per_second": 0.208, "prompt_tokens": 24, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The image depicts a cluttered bathroom with a toilet and a trash can. A person is seen bending over the toilet, possibly cleaning or organizing the area.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18653.9, "ram_available_mb": 44187.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.684, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.772, "gpu_utilization_percent_mean": 88.7}, "timestamp": "2026-01-30T23:27:03.573236"}
{"image_index": 304, "image_name": "000000032817.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032817.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4560.879, "latencies_ms": [4560.879], "images_per_second": 0.219, "prompt_tokens": 22, "response_tokens_est": 29, "n_tiles": 12, "output_text": "The image shows a bathroom with a beige wall and a white toilet. The lighting is dim, and the scene appears to be indoors.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.034, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.774, "gpu_utilization_percent_mean": 89.132}, "timestamp": "2026-01-30T23:27:10.188923"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2642.832, "latencies_ms": [2642.832], "images_per_second": 0.378, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A man is standing in a rainy room, holding an umbrella, and looking at his reflection in the doorway.", "error": null, "sys_before": {"cpu_percent": 19.6, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.039, "power_cpu_cv_mean_watts": 1.239, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 76.571}, "timestamp": "2026-01-30T23:27:14.941653"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3193.048, "latencies_ms": [3193.048], "images_per_second": 0.313, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 6, "output_text": "1. Person\n2. Rain\n3. Door\n4. Wall\n5. Mirror\n6. Umbrella\n7. Window\n8. Light", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.911, "power_cpu_cv_mean_watts": 1.483, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 73.481}, "timestamp": "2026-01-30T23:27:20.178808"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5686.052, "latencies_ms": [5686.052], "images_per_second": 0.176, "prompt_tokens": 30, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The main object in the foreground is a person holding an umbrella, standing in a corridor with red walls. The person is positioned near the center of the image, slightly to the left. The background features a door and a framed picture on the wall, which are further away from the person. The corridor appears to be narrow, with the person standing in the middle of it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18653.1, "ram_available_mb": 44187.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.242, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 69.625}, "timestamp": "2026-01-30T23:27:27.912869"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4996.849, "latencies_ms": [4996.849], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The scene depicts a man standing in a corridor under a rainy sky. He is holding an umbrella, which is partially obscuring his reflection in the doorway. The setting appears to be indoors, possibly in a residential or commercial building, with a red door and a dark-colored wall visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.2, "ram_available_mb": 44187.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.53, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 70.381}, "timestamp": "2026-01-30T23:27:34.944763"}
{"image_index": 305, "image_name": "000000032861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032861.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5686.366, "latencies_ms": [5686.366], "images_per_second": 0.176, "prompt_tokens": 22, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The image depicts a person standing in a corridor under a dark, rainy sky. The rain is visibly falling, creating a dynamic and somewhat dramatic atmosphere. The person is wearing a blue shirt and dark pants, and the corridor is painted in a striking red color. The lighting is dim, with the rain adding a cool, moody tone to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18653.3, "ram_available_mb": 44187.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18652.7, "ram_available_mb": 44188.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.001, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 68.854}, "timestamp": "2026-01-30T23:27:42.678102"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4382.504, "latencies_ms": [4382.504], "images_per_second": 0.228, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 12, "output_text": "A man in hiking gear stands on a rocky path surrounded by lush greenery, with a signpost in the background indicating directions.", "error": null, "sys_before": {"cpu_percent": 25.8, "ram_used_mb": 18652.7, "ram_available_mb": 44188.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.333, "power_cpu_cv_mean_watts": 1.157, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 88.778}, "timestamp": "2026-01-30T23:27:49.215490"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6496.938, "latencies_ms": [6496.938], "images_per_second": 0.154, "prompt_tokens": 26, "response_tokens_est": 61, "n_tiles": 12, "output_text": "1. Man: 1\n2. Backpack: 1\n3. Hiking stick: 1\n4. Rock: 1\n5. Path: 1\n6. Waterfall: 1\n7. Tree: 1\n8. Pathway: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.522, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 85.556}, "timestamp": "2026-01-30T23:27:57.740976"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6683.851, "latencies_ms": [6683.851], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The main object in the foreground is a man wearing a red long-sleeve shirt and blue jeans, equipped with a backpack and walking stick. He is standing on a rocky path surrounded by greenery and rocks. In the background, there is a signpost with directional arrows, indicating the path's direction.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.409, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 85.625}, "timestamp": "2026-01-30T23:28:06.445124"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6008.738, "latencies_ms": [6008.738], "images_per_second": 0.166, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image depicts a hiker in a forested area, equipped with a backpack and trekking poles, navigating a rocky path. The hiker is surrounded by lush greenery and appears to be in a natural, possibly mountainous or forested region.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.787, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 86.6}, "timestamp": "2026-01-30T23:28:14.495851"}
{"image_index": 306, "image_name": "000000032887.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032887.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6792.699, "latencies_ms": [6792.699], "images_per_second": 0.147, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a person in a red long-sleeve shirt and blue jeans, equipped with a backpack and walking stick, standing on a rocky path surrounded by lush greenery. The lighting is natural, suggesting it is daytime, and the weather appears to be mild, with no visible signs of rain or extreme heat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.341, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 85.702}, "timestamp": "2026-01-30T23:28:23.342968"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4314.122, "latencies_ms": [4314.122], "images_per_second": 0.232, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "The image depicts three men standing together in a room, with two of them smiling and one man leaning on a chair.", "error": null, "sys_before": {"cpu_percent": 31.2, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.415, "power_cpu_cv_mean_watts": 1.157, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 87.444}, "timestamp": "2026-01-30T23:28:29.838981"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4442.13, "latencies_ms": [4442.13], "images_per_second": 0.225, "prompt_tokens": 26, "response_tokens_est": 28, "n_tiles": 12, "output_text": "- Two men\n- Two men\n- Two men\n- Two men\n- Two men\n- Two men\n- Two men", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.435, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 90.541}, "timestamp": "2026-01-30T23:28:36.325298"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9556.846, "latencies_ms": [9556.846], "images_per_second": 0.105, "prompt_tokens": 30, "response_tokens_est": 112, "n_tiles": 12, "output_text": "The main objects in the image are three men standing in a room. The man on the left is wearing a checkered shirt and has his left hand on the shoulder of the man next to him. The man in the middle is wearing a striped shirt and a red tie, and he has his right hand on the shoulder of the man on the right. The man on the right is wearing a light blue shirt and has his left hand on the back of the man in the middle. The background includes a red chair and a shelf with various bottles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.446, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 8.86, "gpu_utilization_percent_mean": 83.568}, "timestamp": "2026-01-30T23:28:47.915150"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7812.531, "latencies_ms": [7812.531], "images_per_second": 0.128, "prompt_tokens": 24, "response_tokens_est": 83, "n_tiles": 12, "output_text": "The image depicts a group of three men standing in an indoor setting, likely a room or hall. They are smiling and appear to be posing for a photo. The men are dressed in casual to semi-formal attire, with one wearing a checkered shirt and the other two in button-up shirts. The background shows a red wall and a glimpse of a bar or counter with various items on it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.886, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 84.076}, "timestamp": "2026-01-30T23:28:57.754788"}
{"image_index": 307, "image_name": "000000032901.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032901.jpg", "image_width": 640, "image_height": 546, "image_resolution": "640x546", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8552.286, "latencies_ms": [8552.286], "images_per_second": 0.117, "prompt_tokens": 22, "response_tokens_est": 95, "n_tiles": 12, "output_text": "The image features three men standing in an indoor setting. The man on the left is wearing a light blue checkered shirt and dark pants, the man in the middle is dressed in a white shirt and light-colored pants, and the man on the right is wearing a light blue shirt and dark pants. The lighting is warm and ambient, with a soft glow illuminating the scene. The colors are muted, with the men's clothing and the background being primarily neutral tones.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18650.9, "ram_available_mb": 44190.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.608, "power_cpu_cv_mean_watts": 1.758, "power_sys_5v0_mean_watts": 8.861, "gpu_utilization_percent_mean": 83.875}, "timestamp": "2026-01-30T23:29:08.319514"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4145.625, "latencies_ms": [4145.625], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A yellow traffic sign with a black border is mounted on a black pole, indicating a one-way traffic direction.", "error": null, "sys_before": {"cpu_percent": 37.7, "ram_used_mb": 18650.9, "ram_available_mb": 44190.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.67, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 89.647}, "timestamp": "2026-01-30T23:29:14.624968"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5237.699, "latencies_ms": [5237.699], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18650.0, "ram_available_mb": 44190.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.407, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 87.744}, "timestamp": "2026-01-30T23:29:21.892680"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6065.538, "latencies_ms": [6065.538], "images_per_second": 0.165, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The main objects in the image are a traffic light, a yellow sign, and a black pole. The traffic light is positioned in the background, while the yellow sign is placed near the pole. The black pole is situated in the foreground, close to the curb.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.0, "ram_available_mb": 44190.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18649.1, "ram_available_mb": 44191.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.722, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 86.529}, "timestamp": "2026-01-30T23:29:29.970968"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8913.223, "latencies_ms": [8913.223], "images_per_second": 0.112, "prompt_tokens": 24, "response_tokens_est": 101, "n_tiles": 12, "output_text": "The image depicts a street scene in an urban area during the daytime. The street is lined with buildings, and there is a traffic light visible in the foreground. A yellow sign with a black border is placed on the sidewalk, and a black metal structure, possibly a traffic light or sign, is also present. A few cars are visible on the road, and a person is walking on the sidewalk. The overall setting appears to be a typical city street with a mix of commercial and residential buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.1, "ram_available_mb": 44191.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.574, "power_cpu_cv_mean_watts": 1.789, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 83.467}, "timestamp": "2026-01-30T23:29:40.899549"}
{"image_index": 308, "image_name": "000000032941.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000032941.jpg", "image_width": 458, "image_height": 640, "image_resolution": "458x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6720.969, "latencies_ms": [6720.969], "images_per_second": 0.149, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image depicts a street scene with a yellow traffic sign mounted on a black pole. The sign is illuminated by a bright light, indicating it is likely daytime. The surrounding area is wet, suggesting recent rain, and the buildings are made of brick and stone, with some windows showing reflections of the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.45, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 85.625}, "timestamp": "2026-01-30T23:29:49.651549"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2427.071, "latencies_ms": [2427.071], "images_per_second": 0.412, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "A young man is standing on a tennis court, preparing to hit a tennis ball with his racket.", "error": null, "sys_before": {"cpu_percent": 24.5, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.63, "power_cpu_cv_mean_watts": 1.159, "power_sys_5v0_mean_watts": 8.075, "gpu_utilization_percent_mean": 75.158}, "timestamp": "2026-01-30T23:29:54.184406"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3606.099, "latencies_ms": [3606.099], "images_per_second": 0.277, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "1. Tennis court\n2. Tennis player\n3. Tennis racket\n4. Tennis ball\n5. Fence\n6. Green net\n7. Green fence\n8. Red sign", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.055, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 72.8}, "timestamp": "2026-01-30T23:29:59.827125"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4640.112, "latencies_ms": [4640.112], "images_per_second": 0.216, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The main object in the foreground is a young man standing on a tennis court, holding a tennis racket. The background features a green fence, a red sign, and a distant green area. The tennis court is surrounded by a fence, and the sign is mounted on the fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.934, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 70.605}, "timestamp": "2026-01-30T23:30:06.490128"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5060.878, "latencies_ms": [5060.878], "images_per_second": 0.198, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The image depicts a young male tennis player on a tennis court during nighttime. He is holding a tennis racket and appears to be preparing to serve or return a shot. The court is enclosed by a green fence, and there is a sign with the text \"VOX SPORTS\" in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.552, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 70.286}, "timestamp": "2026-01-30T23:30:13.593703"}
{"image_index": 309, "image_name": "000000033005.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033005.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3017.229, "latencies_ms": [3017.229], "images_per_second": 0.331, "prompt_tokens": 22, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The image depicts a tennis court at night, illuminated by artificial lighting. The court surface is green, and the net is made of metal.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.17, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 74.68}, "timestamp": "2026-01-30T23:30:18.647399"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4965.775, "latencies_ms": [4965.775], "images_per_second": 0.201, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 12, "output_text": "A group of skiers is gathered around a net, with one skier wearing a helmet and goggles, and another in a black jacket, while others are standing behind them.", "error": null, "sys_before": {"cpu_percent": 27.4, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.664, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 88.143}, "timestamp": "2026-01-30T23:30:25.772786"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10527.505, "latencies_ms": [10527.505], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "object: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject: helmet\n1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.164, "power_cpu_cv_mean_watts": 1.905, "power_sys_5v0_mean_watts": 8.881, "gpu_utilization_percent_mean": 82.578}, "timestamp": "2026-01-30T23:30:38.314979"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7277.922, "latencies_ms": [7277.922], "images_per_second": 0.137, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The main objects in the image are skiers and a net. The skiers are positioned in the foreground, with one skier in the center foreground and another skier on the right side. The net is situated between the skiers, with the skiers standing near it. The background features a snowy landscape with other skiers and a snowy ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.066, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 84.597}, "timestamp": "2026-01-30T23:30:47.653527"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7259.18, "latencies_ms": [7259.18], "images_per_second": 0.138, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The image depicts a group of skiers in a snowy environment, likely at a ski resort. They are gathered around a blue netting, possibly for safety or to mark a specific area. The skiers are dressed in winter gear, including helmets, goggles, and ski jackets, and are engaged in conversation or preparing for their skiing activities.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.192, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.854, "gpu_utilization_percent_mean": 84.613}, "timestamp": "2026-01-30T23:30:56.961441"}
{"image_index": 310, "image_name": "000000033104.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033104.jpg", "image_width": 428, "image_height": 500, "image_resolution": "428x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6050.502, "latencies_ms": [6050.502], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image depicts a group of skiers in winter gear, including helmets and goggles, standing on a snowy slope. The skiers are wearing blue and white ski gear, and the scene is illuminated by natural light, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.857, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 86.235}, "timestamp": "2026-01-30T23:31:05.059762"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4142.395, "latencies_ms": [4142.395], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A large blue truck is driving down a wet street, with other vehicles and a residential area in the background.", "error": null, "sys_before": {"cpu_percent": 27.6, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.648, "power_cpu_cv_mean_watts": 1.06, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 89.735}, "timestamp": "2026-01-30T23:31:11.354544"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5084.511, "latencies_ms": [5084.511], "images_per_second": 0.197, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "1. Blue truck\n2. Blue car\n3. Bus\n4. House\n5. Street light\n6. Tree\n7. Sidewalk\n8. Green grass", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.616, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 88.929}, "timestamp": "2026-01-30T23:31:18.477369"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7352.021, "latencies_ms": [7352.021], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The main object in the foreground is a blue truck with the text \"HUISMANGROUP.COM\" on its side. The truck is positioned on the right side of the road, near the curb. In the background, there are residential houses, a street lamp, and a tree. The truck is relatively close to the sidewalk, indicating it is near the road.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.137, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.865, "gpu_utilization_percent_mean": 84.623}, "timestamp": "2026-01-30T23:31:27.869338"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5949.69, "latencies_ms": [5949.69], "images_per_second": 0.168, "prompt_tokens": 24, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The image depicts a wet street scene with a blue truck in the foreground, a bus in the background, and a residential area with houses and trees. The setting appears to be during the day, with a partly cloudy sky and wet road conditions.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.907, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 86.592}, "timestamp": "2026-01-30T23:31:35.840222"}
{"image_index": 311, "image_name": "000000033109.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033109.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6482.588, "latencies_ms": [6482.588], "images_per_second": 0.154, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image depicts a blue truck with a white stripe running along its side, parked on a wet street. The truck's design features a large windshield and a prominent logo on the front. The surrounding environment includes a residential area with houses, a wet street, and a partly cloudy sky.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.554, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 86.185}, "timestamp": "2026-01-30T23:31:44.358731"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4962.665, "latencies_ms": [4962.665], "images_per_second": 0.202, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 12, "output_text": "The image shows a view of an airport runway with a plane on the tarmac, surrounded by various airport equipment and signs, including traffic lights and a red fire hydrant.", "error": null, "sys_before": {"cpu_percent": 23.8, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.771, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.863, "gpu_utilization_percent_mean": 87.0}, "timestamp": "2026-01-30T23:31:51.490985"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5215.528, "latencies_ms": [5215.528], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.504, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 88.605}, "timestamp": "2026-01-30T23:31:58.732600"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7336.306, "latencies_ms": [7336.306], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The main objects in the image are a row of traffic lights positioned in the foreground, with a few more in the background. The traffic lights are located near the edge of the road, with the closest one being the most prominent. The background features a hazy landscape with mountains and a body of water, while the foreground shows a mix of grass and a concrete surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.165, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 84.607}, "timestamp": "2026-01-30T23:32:08.102296"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6108.398, "latencies_ms": [6108.398], "images_per_second": 0.164, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image depicts a scene at an airport with a large airplane on the tarmac, preparing to take off or having just landed. The background shows a hazy, overcast sky and a distant mountain range, indicating a possibly humid or foggy day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.779, "power_cpu_cv_mean_watts": 1.523, "power_sys_5v0_mean_watts": 8.895, "gpu_utilization_percent_mean": 86.392}, "timestamp": "2026-01-30T23:32:16.252977"}
{"image_index": 312, "image_name": "000000033114.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033114.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6918.388, "latencies_ms": [6918.388], "images_per_second": 0.145, "prompt_tokens": 22, "response_tokens_est": 68, "n_tiles": 12, "output_text": "The image features a scene with a wet runway, where a large airplane is preparing to take off. The runway is surrounded by a fence, and there are several red and white traffic lights in the foreground. The lighting is soft and diffused, likely due to the overcast sky, and the overall atmosphere is calm and serene.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.272, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 85.5}, "timestamp": "2026-01-30T23:32:25.189940"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2517.085, "latencies_ms": [2517.085], "images_per_second": 0.397, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 6, "output_text": "A group of people is walking on a sandy beach, with one person carrying a baby in a carrier.", "error": null, "sys_before": {"cpu_percent": 27.8, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.17, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 77.45}, "timestamp": "2026-01-30T23:32:29.813994"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4508.217, "latencies_ms": [4508.217], "images_per_second": 0.222, "prompt_tokens": 26, "response_tokens_est": 56, "n_tiles": 6, "output_text": "1. Woman: 1\n2. Woman: 1\n3. Woman: 1\n4. Woman: 1\n5. Woman: 1\n6. Woman: 1\n7. Woman: 1\n8. Woman: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.137, "power_cpu_cv_mean_watts": 1.775, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 70.595}, "timestamp": "2026-01-30T23:32:36.347422"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5436.649, "latencies_ms": [5436.649], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "In the image, the main objects are a group of people walking on a sandy beach. The person in the foreground is holding a blue towel and wearing an orange shirt. The person in the background is holding a black baton. The group is walking towards the right side of the image, with the beach and the ocean visible in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.209, "power_cpu_cv_mean_watts": 1.851, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 69.556}, "timestamp": "2026-01-30T23:32:43.820922"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4635.427, "latencies_ms": [4635.427], "images_per_second": 0.216, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The scene is set on a sandy beach with a group of people walking along the shore. The individuals are dressed in casual beach attire, and some are carrying bags. The setting appears to be a sunny day with clear skies, and there are some vehicles parked in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.831, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 70.538}, "timestamp": "2026-01-30T23:32:50.490999"}
{"image_index": 313, "image_name": "000000033221.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033221.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3679.786, "latencies_ms": [3679.786], "images_per_second": 0.272, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 6, "output_text": "The image depicts a sunny beach scene with clear blue skies and a few scattered clouds. The sandy beach is dotted with orange traffic cones, and a few people are walking along the shoreline.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.069, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 72.567}, "timestamp": "2026-01-30T23:32:56.200435"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2751.411, "latencies_ms": [2751.411], "images_per_second": 0.363, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 6, "output_text": "A tennis player is standing on a blue court, holding a tennis racket, and appears to be contemplating his next move.", "error": null, "sys_before": {"cpu_percent": 25.7, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.7, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 75.773}, "timestamp": "2026-01-30T23:33:01.052596"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3614.763, "latencies_ms": [3614.763], "images_per_second": 0.277, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Tennis court\n5. Blue surface\n6. White shorts\n7. White socks\n8. White shoes", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.042, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 71.833}, "timestamp": "2026-01-30T23:33:06.697262"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5587.865, "latencies_ms": [5587.865], "images_per_second": 0.179, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 6, "output_text": "The main object in the image is a tennis player standing on a blue tennis court. The player is positioned in the foreground, slightly to the left, and is holding a tennis racket in his right hand. The court is marked with white lines and features a logo near the bottom right corner. The background is mostly dark, emphasizing the player and the court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.219, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 69.787}, "timestamp": "2026-01-30T23:33:14.335865"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6688.875, "latencies_ms": [6688.875], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 92, "n_tiles": 6, "output_text": "The image depicts a tennis player on a blue court, likely during a match or practice session. The player is dressed in a light blue shirt, white shorts, and white socks, holding a tennis racket in his right hand. The court is marked with the word \"TENNIS\" in white letters, and the player appears to be in a moment of rest or contemplation, possibly after a point or during a break in the game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.425, "power_cpu_cv_mean_watts": 1.981, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 68.464}, "timestamp": "2026-01-30T23:33:23.071344"}
{"image_index": 314, "image_name": "000000033368.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033368.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4928.371, "latencies_ms": [4928.371], "images_per_second": 0.203, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The image features a tennis player on a blue court, illuminated by bright sunlight. The player is wearing a light blue shirt, white shorts, and white socks, with a tennis racket in hand. The bright lighting casts a shadow of the player on the court, highlighting the texture of the blue surface.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.667, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 70.659}, "timestamp": "2026-01-30T23:33:30.060560"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2207.187, "latencies_ms": [2207.187], "images_per_second": 0.453, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 6, "output_text": "A woman is standing by a black stove, looking at a bowl on the counter.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.764, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 79.0}, "timestamp": "2026-01-30T23:33:34.361481"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4188.868, "latencies_ms": [4188.868], "images_per_second": 0.239, "prompt_tokens": 26, "response_tokens_est": 50, "n_tiles": 6, "output_text": "1. Kitchen counter\n2. Kitchen sink\n3. Kitchen cabinet\n4. Kitchen utensils\n5. Kitchen utensils\n6. Kitchen utensils\n7. Kitchen utensils\n8. Kitchen utensils", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.107, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-30T23:33:40.593623"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6097.272, "latencies_ms": [6097.272], "images_per_second": 0.164, "prompt_tokens": 30, "response_tokens_est": 82, "n_tiles": 6, "output_text": "In the image, the main object is a black stove with a metal base and a brick surround. The person is standing near the stove, leaning slightly forward. The background features a kitchen with various items such as a white cabinet, a window with a white curtain, and a shelf holding plates and other kitchenware. The stove is positioned in the foreground, while the person is in the mid-ground.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.779, "power_cpu_cv_mean_watts": 1.91, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 69.096}, "timestamp": "2026-01-30T23:33:48.710895"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4206.755, "latencies_ms": [4206.755], "images_per_second": 0.238, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image depicts a kitchen scene with a woman standing by a black stove, seemingly engaged in cooking or preparing food. The kitchen is cluttered with various kitchen items, including plates, bowls, and pots, indicating a busy and lived-in space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.301, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-30T23:33:54.953786"}
{"image_index": 315, "image_name": "000000033638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033638.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5053.888, "latencies_ms": [5053.888], "images_per_second": 0.198, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The image depicts a kitchen scene with a woman standing by a black stove, wearing a floral top and khaki shorts. The lighting is dim, with a single hanging light fixture providing illumination. The kitchen has a rustic, vintage feel, with wooden cabinets, a brick stove, and various kitchen items scattered around.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.568, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 70.381}, "timestamp": "2026-01-30T23:34:02.066960"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2557.263, "latencies_ms": [2557.263], "images_per_second": 0.391, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The image depicts a giraffe standing next to a baby giraffe, both in a naturalistic setting with a building and trees in the background, surrounded by rocks and vegetation.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.499, "power_cpu_cv_mean_watts": 1.888, "power_sys_5v0_mean_watts": 6.883, "gpu_utilization_percent_mean": 69.571}, "timestamp": "2026-01-30T23:34:06.674741"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3018.902, "latencies_ms": [3018.902], "images_per_second": 0.331, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 1, "output_text": "- giraffe: 2\n- building: 1\n- tree: 1\n- fence: 1\n- rocks: 1\n- dirt path: 1\n- grass: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.596, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 6.963, "gpu_utilization_percent_mean": 67.16}, "timestamp": "2026-01-30T23:34:11.729348"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3888.979, "latencies_ms": [3888.979], "images_per_second": 0.257, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 1, "output_text": "The main objects in the image are two giraffes standing in front of a building. The giraffe on the left is closer to the camera, while the one on the right is slightly behind it. The building is in the background, and the rocky ground is in the foreground.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.615, "power_cpu_cv_mean_watts": 2.04, "power_sys_5v0_mean_watts": 7.034, "gpu_utilization_percent_mean": 66.781}, "timestamp": "2026-01-30T23:34:17.638413"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4209.629, "latencies_ms": [4209.629], "images_per_second": 0.238, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 1, "output_text": "The image depicts a serene scene at a zoo, featuring two giraffes standing close to each other in front of a beige building. The giraffes are surrounded by a rocky terrain, and the background includes lush green trees and a cloudy sky, creating a tranquil and natural environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.66, "power_cpu_cv_mean_watts": 2.06, "power_sys_5v0_mean_watts": 7.093, "gpu_utilization_percent_mean": 66.857}, "timestamp": "2026-01-30T23:34:23.900566"}
{"image_index": 316, "image_name": "000000033707.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033707.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3408.713, "latencies_ms": [3408.713], "images_per_second": 0.293, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 1, "output_text": "The image depicts a giraffe standing next to a building, with a backdrop of lush green trees and a cloudy sky. The giraffe's coat is a mix of brown and tan, and the building is made of light-colored stone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.513, "power_cpu_cv_mean_watts": 1.988, "power_sys_5v0_mean_watts": 6.969, "gpu_utilization_percent_mean": 69.143}, "timestamp": "2026-01-30T23:34:29.352186"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5209.694, "latencies_ms": [5209.694], "images_per_second": 0.192, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 12, "output_text": "A young baseball player is in the middle of a game, swinging a bat with his right hand, while wearing a green jersey and white pants, and a black helmet with a red and white design.", "error": null, "sys_before": {"cpu_percent": 32.5, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.692, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 87.114}, "timestamp": "2026-01-30T23:34:36.766020"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5394.54, "latencies_ms": [5394.54], "images_per_second": 0.185, "prompt_tokens": 26, "response_tokens_est": 43, "n_tiles": 12, "output_text": "baseball bat: 1\nbaseball: 1\nhelmet: 1\nuniform: 1\nsocks: 2\nglove: 1\nbaseball glove: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.304, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.795, "gpu_utilization_percent_mean": 87.333}, "timestamp": "2026-01-30T23:34:44.215315"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7554.416, "latencies_ms": [7554.416], "images_per_second": 0.132, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The main object in the foreground is a baseball player wearing a green jersey and white pants, holding a blue bat. The player is positioned near the center of the image, slightly to the left. The background features a chain-link fence, a green fence, and a grassy area. The fence is positioned behind the player, and the grassy area is to the right of the fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.123, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 84.656}, "timestamp": "2026-01-30T23:34:53.781933"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6491.445, "latencies_ms": [6491.445], "images_per_second": 0.154, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image depicts a young baseball player in a green jersey and white pants, equipped with a blue helmet and a baseball bat, positioned on a dirt field with a chain-link fence in the background. The player appears to be in the middle of a batting stance, ready to hit the incoming baseball.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.455, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.808, "gpu_utilization_percent_mean": 85.509}, "timestamp": "2026-01-30T23:35:02.288989"}
{"image_index": 317, "image_name": "000000033759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5365.736, "latencies_ms": [5365.736], "images_per_second": 0.186, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The baseball player is wearing a green jersey with yellow accents, white pants, and black shoes. The scene is bright and sunny, with the player's shadow visible on the ground, indicating a clear day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.164, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.773, "gpu_utilization_percent_mean": 86.867}, "timestamp": "2026-01-30T23:35:09.670240"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2705.028, "latencies_ms": [2705.028], "images_per_second": 0.37, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A vintage car and motorcycle are parked on a cobblestone street, with a crowd of people walking around in the background.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.738, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 75.364}, "timestamp": "2026-01-30T23:35:14.491997"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3071.997, "latencies_ms": [3071.997], "images_per_second": 0.326, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "car: 2\nmotorcycle: 3\nbus: 1\nstreet light: 1\nbuilding: 1\nflag: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.159, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 74.08}, "timestamp": "2026-01-30T23:35:19.579534"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5427.999, "latencies_ms": [5427.999], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "In the image, the main objects are parked vehicles, including a classic black car, a vintage red bus, and a motorcycle. The classic black car is positioned in the foreground, while the vintage red bus is in the background. The motorcycle is located near the classic car, and the background features a cobblestone street and a crowd of people.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.132, "power_cpu_cv_mean_watts": 1.854, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.587}, "timestamp": "2026-01-30T23:35:27.061023"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4219.743, "latencies_ms": [4219.743], "images_per_second": 0.237, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image depicts a bustling outdoor scene with vintage cars parked on a cobblestone street. The setting appears to be a public area, possibly a fair or a historical exhibition, with various people milling about and a red bus in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.236, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 71.457}, "timestamp": "2026-01-30T23:35:33.298310"}
{"image_index": 318, "image_name": "000000033854.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000033854.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5013.304, "latencies_ms": [5013.304], "images_per_second": 0.199, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image features a cobblestone street lined with vintage cars, including a black car and a blue car, parked along the side. The cobblestones are arranged in a pattern, and the street is surrounded by green trees and a clear blue sky. The lighting is bright and natural, suggesting it is daytime.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.447, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 70.214}, "timestamp": "2026-01-30T23:35:40.349914"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3190.532, "latencies_ms": [3190.532], "images_per_second": 0.313, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 6, "output_text": "The image depicts a close-up view of two parking meters, with a blurred background featuring a cityscape at sunset, creating a warm and nostalgic atmosphere.", "error": null, "sys_before": {"cpu_percent": 29.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.723, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 74.115}, "timestamp": "2026-01-30T23:35:45.653245"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1979.55, "latencies_ms": [1979.55], "images_per_second": 0.505, "prompt_tokens": 26, "response_tokens_est": 14, "n_tiles": 6, "output_text": "parking meter: 2\nparking meter: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.609, "power_cpu_cv_mean_watts": 0.876, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 82.188}, "timestamp": "2026-01-30T23:35:49.656093"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5373.204, "latencies_ms": [5373.204], "images_per_second": 0.186, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The main objects in the image are two parking meters positioned in the foreground. The foreground is the closest and most detailed part of the image, while the background is slightly blurred, indicating a shallow depth of field. The parking meters are positioned near each other, with the closest one slightly to the left and the one further back to the right.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.246, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 69.356}, "timestamp": "2026-01-30T23:35:57.050128"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6647.778, "latencies_ms": [6647.778], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 91, "n_tiles": 6, "output_text": "The image depicts a dimly lit scene with a focus on two parking meters, which are situated in an urban environment. The setting appears to be during twilight or early evening, as the sky is dim with a warm, golden hue, and the sun is low on the horizon, casting a soft glow on the scene. The blurred background suggests the presence of buildings and possibly other city elements, contributing to the overall atmosphere of the image.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.464, "power_cpu_cv_mean_watts": 1.952, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 68.339}, "timestamp": "2026-01-30T23:36:05.756718"}
{"image_index": 319, "image_name": "000000034071.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034071.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5242.21, "latencies_ms": [5242.21], "images_per_second": 0.191, "prompt_tokens": 22, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The image features two parking meters with a warm, golden hue, likely due to the lighting conditions. The lighting creates a soft, blurred effect, with bokeh lights visible in the background, suggesting a cityscape at sunset. The colors are dominated by warm tones, with the metallic surfaces of the meters reflecting the ambient light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.33, "power_cpu_cv_mean_watts": 1.82, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 69.523}, "timestamp": "2026-01-30T23:36:13.033857"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4567.224, "latencies_ms": [4567.224], "images_per_second": 0.219, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The image shows a brown suitcase with various stickers and a sign on it, placed on a platform, with a group of people standing behind it.", "error": null, "sys_before": {"cpu_percent": 27.5, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.283, "power_cpu_cv_mean_watts": 1.233, "power_sys_5v0_mean_watts": 8.877, "gpu_utilization_percent_mean": 88.711}, "timestamp": "2026-01-30T23:36:19.737563"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4796.791, "latencies_ms": [4796.791], "images_per_second": 0.208, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 12, "output_text": "1. Suitcase\n2. Man\n3. Woman\n4. Man\n5. Man\n6. Man\n7. Man\n8. Man", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.781, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 88.825}, "timestamp": "2026-01-30T23:36:26.549393"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7399.271, "latencies_ms": [7399.271], "images_per_second": 0.135, "prompt_tokens": 30, "response_tokens_est": 76, "n_tiles": 12, "output_text": "The main object in the foreground is a brown suitcase with various stickers and a sign on it. The suitcase is placed on a platform. In the background, there is a man and a woman standing next to each other. The man is wearing a black jacket and the woman is wearing a blue jacket. The sign on the suitcase is near the man and woman.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.09, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 84.419}, "timestamp": "2026-01-30T23:36:35.968473"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7389.729, "latencies_ms": [7389.729], "images_per_second": 0.135, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 12, "output_text": "The image depicts a group of people standing in front of a building with a sign that reads \"Fidelity Investments.\" The setting appears to be an outdoor area, possibly a plaza or a public square, with a large, brown suitcase prominently displayed on a platform. The individuals are dressed in casual attire, and the overall atmosphere seems relaxed and informal.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.104, "power_cpu_cv_mean_watts": 1.667, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 85.032}, "timestamp": "2026-01-30T23:36:45.387360"}
{"image_index": 320, "image_name": "000000034139.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034139.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8165.7, "latencies_ms": [8165.7], "images_per_second": 0.122, "prompt_tokens": 22, "response_tokens_est": 89, "n_tiles": 12, "output_text": "The image features a brown leather suitcase with various stickers and a sign on it. The suitcase is placed on a platform with a sign that reads \"GOD BLESS AMERICA\" by J. Seward Johnson. The background includes a building with a sign for \"Fidelity Investments\" and a couple of people standing nearby. The lighting is natural, suggesting it is daytime, and the overall weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.798, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 84.221}, "timestamp": "2026-01-30T23:36:55.566797"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3610.068, "latencies_ms": [3610.068], "images_per_second": 0.277, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The image showcases a plate of seared scallops, garnished with fresh green parsley, and accompanied by a side of broccoli, all presented in a visually appealing and appetizing manner.", "error": null, "sys_before": {"cpu_percent": 24.8, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.859, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 72.333}, "timestamp": "2026-01-30T23:37:01.294960"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8844.735, "latencies_ms": [8844.735], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.882, "power_cpu_cv_mean_watts": 2.084, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 67.743}, "timestamp": "2026-01-30T23:37:12.181028"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4529.354, "latencies_ms": [4529.354], "images_per_second": 0.221, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 6, "output_text": "The main objects in the image are a plate of food, which includes a piece of fish, mushrooms, and broccoli. The fish is positioned in the foreground, with the mushrooms and broccoli surrounding it. The broccoli is in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.019, "power_cpu_cv_mean_watts": 1.754, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 70.892}, "timestamp": "2026-01-30T23:37:18.726468"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6209.575, "latencies_ms": [6209.575], "images_per_second": 0.161, "prompt_tokens": 24, "response_tokens_est": 84, "n_tiles": 6, "output_text": "The image showcases a close-up view of a dish featuring a piece of grilled fish, likely a salmon or similar white fish, garnished with fresh green herbs. The fish is placed on a bed of saut\u00e9ed mushrooms, which appear to be cooked to a tender consistency. The setting suggests a culinary presentation, possibly in a restaurant or a home kitchen, highlighting the freshness and flavor of the ingredients.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.75, "power_cpu_cv_mean_watts": 1.941, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 69.096}, "timestamp": "2026-01-30T23:37:26.988028"}
{"image_index": 321, "image_name": "000000034205.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034205.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4660.889, "latencies_ms": [4660.889], "images_per_second": 0.215, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The image showcases a dish featuring a grilled or seared piece of fish, garnished with fresh green herbs and a sprinkle of black pepper. The lighting highlights the golden-brown crust of the fish, while the vibrant green of the herbs and broccoli adds a fresh contrast.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.69, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 70.205}, "timestamp": "2026-01-30T23:37:33.695172"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3170.705, "latencies_ms": [3170.705], "images_per_second": 0.315, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 6, "output_text": "The image shows a variety of fresh vegetables, including carrots, cabbages, and onions, all neatly arranged in baskets, displayed in a market setting.", "error": null, "sys_before": {"cpu_percent": 27.5, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.754, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 73.885}, "timestamp": "2026-01-30T23:37:38.975465"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2656.427, "latencies_ms": [2656.427], "images_per_second": 0.376, "prompt_tokens": 26, "response_tokens_est": 25, "n_tiles": 6, "output_text": "carrots: 20\nonions: 10\nlettuce: 10\ncabbage: 10", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.907, "power_cpu_cv_mean_watts": 1.202, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 75.714}, "timestamp": "2026-01-30T23:37:43.644208"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4654.166, "latencies_ms": [4654.166], "images_per_second": 0.215, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The main objects in the image are a basket filled with carrots and a bunch of green vegetables. The carrots are in the foreground, while the green vegetables are in the background. The basket is placed near the center of the image, and the vegetables are stacked on top of each other.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.775, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 70.487}, "timestamp": "2026-01-30T23:37:50.339285"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5470.571, "latencies_ms": [5470.571], "images_per_second": 0.183, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts a vibrant and colorful display of fresh vegetables at a market stall. The stall is filled with a variety of leafy greens, including lettuce, cabbage, and kale, alongside a basket of carrots and a bunch of onions. The scene is bright and inviting, showcasing the freshness and variety of produce available for purchase.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.177, "power_cpu_cv_mean_watts": 1.889, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.761}, "timestamp": "2026-01-30T23:37:57.837235"}
{"image_index": 322, "image_name": "000000034257.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034257.jpg", "image_width": 500, "image_height": 309, "image_resolution": "500x309", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5812.427, "latencies_ms": [5812.427], "images_per_second": 0.172, "prompt_tokens": 22, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The image showcases a vibrant and colorful display of fresh vegetables, including leafy greens, carrots, and onions, all arranged in a basket. The lighting is bright and natural, highlighting the freshness and vibrancy of the produce. The colors range from the deep green of the leafy greens to the bright orange of the carrots, creating a visually appealing and appetizing scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.795, "power_cpu_cv_mean_watts": 1.888, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 68.735}, "timestamp": "2026-01-30T23:38:05.692784"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4465.918, "latencies_ms": [4465.918], "images_per_second": 0.224, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "The image depicts a bustling bakery with multiple doughnut machines in operation, producing a large number of freshly baked doughnuts.", "error": null, "sys_before": {"cpu_percent": 24.6, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.36, "power_cpu_cv_mean_watts": 1.234, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 88.703}, "timestamp": "2026-01-30T23:38:12.289181"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10553.973, "latencies_ms": [10553.973], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.149, "power_cpu_cv_mean_watts": 1.886, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 82.539}, "timestamp": "2026-01-30T23:38:24.879998"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6382.393, "latencies_ms": [6382.393], "images_per_second": 0.157, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The main objects in the image are a doughnut machine and a doughnut stand. The doughnut machine is located in the foreground, with doughnuts being processed on the conveyor belt. The doughnut stand is situated in the background, with doughnuts being displayed on the shelves.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.57, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 86.0}, "timestamp": "2026-01-30T23:38:33.294502"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8068.868, "latencies_ms": [8068.868], "images_per_second": 0.124, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 12, "output_text": "The image depicts a bustling bakery or doughnut shop with a focus on the production line for donuts. The setting is indoors, likely in a commercial kitchen or bakery, with various donuts being prepared and packaged. The workers are actively engaged in their tasks, with one person in the foreground handling a donut, while others are seen behind the conveyor belt, contributing to the overall busy atmosphere of the shop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.802, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 83.779}, "timestamp": "2026-01-30T23:38:43.398691"}
{"image_index": 323, "image_name": "000000034417.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034417.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4626.42, "latencies_ms": [4626.42], "images_per_second": 0.216, "prompt_tokens": 22, "response_tokens_est": 30, "n_tiles": 12, "output_text": "The image depicts a bakery with a bright and clean environment. The lighting is artificial, and the materials used are primarily metal and glass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.984, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.766, "gpu_utilization_percent_mean": 89.289}, "timestamp": "2026-01-30T23:38:50.064808"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4029.872, "latencies_ms": [4029.872], "images_per_second": 0.248, "prompt_tokens": 12, "response_tokens_est": 21, "n_tiles": 12, "output_text": "A man is playing frisbee in a forest, wearing a green jacket and khaki shorts.", "error": null, "sys_before": {"cpu_percent": 28.7, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.894, "power_cpu_cv_mean_watts": 1.007, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 90.364}, "timestamp": "2026-01-30T23:38:56.243747"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5234.301, "latencies_ms": [5234.301], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "frisbee: 1\nman: 1\nhat: 1\nshorts: 1\nsocks: 1\nfootwear: 1\ntree: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.303, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.777, "gpu_utilization_percent_mean": 87.341}, "timestamp": "2026-01-30T23:39:03.516949"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7213.768, "latencies_ms": [7213.768], "images_per_second": 0.139, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The main object in the foreground is a man wearing a green jacket and khaki shorts, who is bending over to pick up an orange frisbee. The background consists of a dense forest with tall trees and a mix of green and brown leaves on the ground. The man is positioned near the center of the image, with the trees forming a natural backdrop.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.18, "power_cpu_cv_mean_watts": 1.668, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 84.803}, "timestamp": "2026-01-30T23:39:12.764074"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5905.967, "latencies_ms": [5905.967], "images_per_second": 0.169, "prompt_tokens": 24, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The image depicts a serene forest scene with a man in a green jacket and cap playing with a frisbee. The ground is covered with fallen leaves and twigs, and the trees are bare, indicating it might be late fall or winter.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.919, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 87.32}, "timestamp": "2026-01-30T23:39:20.716505"}
{"image_index": 324, "image_name": "000000034452.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034452.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6947.0, "latencies_ms": [6947.0], "images_per_second": 0.144, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a forest scene with a man wearing a green jacket and khaki shorts. The ground is covered with fallen leaves and pine needles, and the trees are bare, indicating it might be autumn or winter. The lighting is soft and diffused, likely due to the overcast sky, casting a gentle glow on the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.339, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 85.508}, "timestamp": "2026-01-30T23:39:29.696985"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3002.047, "latencies_ms": [3002.047], "images_per_second": 0.333, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The image shows a bathroom with a white sink, a toilet, and a shower curtain, all set against a beige tiled floor and walls.", "error": null, "sys_before": {"cpu_percent": 24.5, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.146, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 74.583}, "timestamp": "2026-01-30T23:39:34.788942"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3535.303, "latencies_ms": [3535.303], "images_per_second": 0.283, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18651.6, "ram_available_mb": 44189.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.227, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 73.3}, "timestamp": "2026-01-30T23:39:40.359247"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5608.219, "latencies_ms": [5608.219], "images_per_second": 0.178, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 6, "output_text": "The bathroom sink is located on the left side of the image, with a white porcelain toilet and a white towel rack to its right. The shower curtain is partially visible on the right side of the image, with a towel hanging on the shower rod. The floor is tiled in a light beige color, and the wall is painted in a light color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.142, "power_cpu_cv_mean_watts": 1.909, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 69.511}, "timestamp": "2026-01-30T23:39:48.004362"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5334.118, "latencies_ms": [5334.118], "images_per_second": 0.187, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image depicts a bathroom with a beige tiled floor and walls. The room features a white sink, a toilet, and a shower with a curtain. The setting appears to be a well-maintained and clean bathroom, with various bathroom items such as a can of shampoo and a soap dispenser on the countertop.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18650.2, "ram_available_mb": 44190.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.182, "power_cpu_cv_mean_watts": 1.851, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.089}, "timestamp": "2026-01-30T23:39:55.380362"}
{"image_index": 325, "image_name": "000000034760.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034760.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3771.841, "latencies_ms": [3771.841], "images_per_second": 0.265, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The bathroom features a beige tiled floor and walls, with a white sink and faucet. The shower curtain is striped in blue and white. The lighting is soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.2, "ram_available_mb": 44190.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.062, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 72.452}, "timestamp": "2026-01-30T23:40:01.186853"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4589.581, "latencies_ms": [4589.581], "images_per_second": 0.218, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The image shows a kitchen with a wooden dining table and chairs, a black countertop, a white sink, and a window with greenery outside.", "error": null, "sys_before": {"cpu_percent": 25.7, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.291, "power_cpu_cv_mean_watts": 1.265, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 88.579}, "timestamp": "2026-01-30T23:40:07.952672"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4108.529, "latencies_ms": [4108.529], "images_per_second": 0.243, "prompt_tokens": 26, "response_tokens_est": 22, "n_tiles": 12, "output_text": "- sink\n- faucet\n- cabinet\n- table\n- chairs\n- window\n- floor", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.698, "power_cpu_cv_mean_watts": 1.06, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 91.059}, "timestamp": "2026-01-30T23:40:14.116511"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6380.763, "latencies_ms": [6380.763], "images_per_second": 0.157, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The main objects in the image are a kitchen sink, a wooden dining table, and a wooden cabinet. The sink is located in the foreground, near the cabinet, while the dining table is in the background, slightly to the right. The cabinet is situated to the left of the sink.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.534, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 85.426}, "timestamp": "2026-01-30T23:40:22.538045"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8926.403, "latencies_ms": [8926.403], "images_per_second": 0.112, "prompt_tokens": 24, "response_tokens_est": 101, "n_tiles": 12, "output_text": "The image depicts a well-organized kitchen with a modern design. The kitchen features a large, oval wooden dining table surrounded by six chairs, all made of dark wood. The countertops are made of a dark material, possibly granite, and there is a stainless steel sink with a modern faucet. The room is brightly lit with natural light coming through a window with white frames, and there is a white door to the left. The overall atmosphere is clean, tidy, and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.393, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 8.852, "gpu_utilization_percent_mean": 83.427}, "timestamp": "2026-01-30T23:40:33.517546"}
{"image_index": 326, "image_name": "000000034873.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000034873.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6014.765, "latencies_ms": [6014.765], "images_per_second": 0.166, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The kitchen features a white countertop with a black granite sink and a stainless steel faucet. The wooden cabinets and chairs add warmth to the space. The room is well-lit with natural light coming through the windows, creating a bright and airy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.749, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.776, "gpu_utilization_percent_mean": 86.52}, "timestamp": "2026-01-30T23:40:41.563259"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2629.154, "latencies_ms": [2629.154], "images_per_second": 0.38, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A baby is lying in a bed covered with a blanket that has a pattern of white daisies with orange centers.", "error": null, "sys_before": {"cpu_percent": 30.2, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.966, "power_cpu_cv_mean_watts": 1.259, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 77.095}, "timestamp": "2026-01-30T23:40:46.299398"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2585.453, "latencies_ms": [2585.453], "images_per_second": 0.387, "prompt_tokens": 26, "response_tokens_est": 24, "n_tiles": 6, "output_text": "bed: 1\npillow: 1\nblanket: 1\ndresser: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.006, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 75.762}, "timestamp": "2026-01-30T23:40:50.931755"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5029.105, "latencies_ms": [5029.105], "images_per_second": 0.199, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main object in the foreground is a bed with a patterned blanket. The blanket is spread out and covers the entire bed. The pattern on the blanket consists of white daisies with orange centers. The background includes a nightstand with a lamp, and the lamp is positioned to the right of the bed.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.477, "power_cpu_cv_mean_watts": 1.793, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 69.857}, "timestamp": "2026-01-30T23:40:58.010848"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5352.578, "latencies_ms": [5352.578], "images_per_second": 0.187, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image depicts a cozy, dimly lit bedroom scene where a child is lying on a bed, wrapped in a blanket with a pattern of white daisies and orange centers. The child appears to be sleeping peacefully, with the blanket covering their body and head. The room is softly lit, creating a warm and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.138, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 69.795}, "timestamp": "2026-01-30T23:41:05.394840"}
{"image_index": 327, "image_name": "000000035062.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035062.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3021.99, "latencies_ms": [3021.99], "images_per_second": 0.331, "prompt_tokens": 22, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The image features a bed with a dark blue blanket adorned with white daisy patterns. The lighting is dim, creating a cozy and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.0, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 74.6}, "timestamp": "2026-01-30T23:41:10.465295"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3105.438, "latencies_ms": [3105.438], "images_per_second": 0.322, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 6, "output_text": "A skateboarder is captured mid-action on a skateboard, with a black and white photograph emphasizing the contrast between the skateboard and the urban environment.", "error": null, "sys_before": {"cpu_percent": 33.6, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.846, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 73.692}, "timestamp": "2026-01-30T23:41:15.731875"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5052.59, "latencies_ms": [5052.59], "images_per_second": 0.198, "prompt_tokens": 26, "response_tokens_est": 65, "n_tiles": 6, "output_text": "skateboard: 1\nskateboarder: 1\nskateboard: 1\nskateboarder: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1\nskateboard: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.58, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 70.214}, "timestamp": "2026-01-30T23:41:22.801238"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6394.63, "latencies_ms": [6394.63], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 87, "n_tiles": 6, "output_text": "The main object in the foreground is a skateboard, which is positioned near the bottom left corner of the image. The skateboard has a visible wheel and a deck. In the background, there is a person standing on the sidewalk, slightly to the right of the skateboard. The person is wearing shorts and sneakers. The skateboard and the person are in the foreground, while the background features a building and a tree.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.68, "power_cpu_cv_mean_watts": 1.965, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 68.778}, "timestamp": "2026-01-30T23:41:31.230884"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5656.632, "latencies_ms": [5656.632], "images_per_second": 0.177, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The image depicts a skateboarder in motion, captured in black and white, performing a trick on a skateboard. The skateboarder is wearing a white t-shirt, plaid shorts, and sneakers, with a shadow cast on the ground. In the background, there is a building and another person, both blurred, suggesting a busy urban environment.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.135, "power_cpu_cv_mean_watts": 1.892, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 69.638}, "timestamp": "2026-01-30T23:41:38.900741"}
{"image_index": 328, "image_name": "000000035197.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035197.jpg", "image_width": 429, "image_height": 640, "image_resolution": "429x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5928.089, "latencies_ms": [5928.089], "images_per_second": 0.169, "prompt_tokens": 22, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image is a black and white photograph featuring a skateboarder in motion, captured with a high-contrast, sharp focus. The skateboarder is wearing a white t-shirt, plaid shorts, and sneakers, with a shadow cast on the ground. The lighting is bright, likely from a clear sky, and the skateboarder's shadow is clearly visible on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.106, "power_cpu_cv_mean_watts": 1.929, "power_sys_5v0_mean_watts": 8.09, "gpu_utilization_percent_mean": 69.571}, "timestamp": "2026-01-30T23:41:46.840209"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4860.1, "latencies_ms": [4860.1], "images_per_second": 0.206, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image shows a person lying on the floor with various items scattered around, including a laptop, a camera, a smartphone, a book, and a tennis racket.", "error": null, "sys_before": {"cpu_percent": 34.6, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.89, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 86.25}, "timestamp": "2026-01-30T23:41:53.845085"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4966.254, "latencies_ms": [4966.254], "images_per_second": 0.201, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 12, "output_text": "1. Laptop\n2. Phone\n3. Camera\n4. Book\n5. Tennis racket\n6. Tennis ball\n7. Water bottle\n8. Key", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.668, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.796, "gpu_utilization_percent_mean": 88.286}, "timestamp": "2026-01-30T23:42:00.844771"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9015.084, "latencies_ms": [9015.084], "images_per_second": 0.111, "prompt_tokens": 30, "response_tokens_est": 103, "n_tiles": 12, "output_text": "The main objects in the image are a laptop, a smartphone, a camera, a book, and a tennis racket. The laptop is positioned in the background, slightly to the left, while the smartphone and camera are in the foreground, closer to the center. The book is placed near the bottom right corner, and the tennis racket is near the bottom left corner. The book is the most prominent object in the image, with the other items arranged around it in a way that highlights their spatial relationships.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.548, "power_cpu_cv_mean_watts": 1.808, "power_sys_5v0_mean_watts": 8.87, "gpu_utilization_percent_mean": 83.408}, "timestamp": "2026-01-30T23:42:11.906018"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6201.347, "latencies_ms": [6201.347], "images_per_second": 0.161, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a cluttered indoor setting with a person lying on the floor, surrounded by various items. The person is lying on a carpeted floor, and there is a laptop, a smartphone, a camera, a book, and other miscellaneous objects scattered around.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.561, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 86.154}, "timestamp": "2026-01-30T23:42:20.129669"}
{"image_index": 329, "image_name": "000000035279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035279.jpg", "image_width": 640, "image_height": 463, "image_resolution": "640x463", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5490.244, "latencies_ms": [5490.244], "images_per_second": 0.182, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image features a laptop with a black keyboard and a red and black mouse. The laptop screen displays a green snake image. The carpeted floor has a beige color, and the lighting is soft and natural.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.983, "power_cpu_cv_mean_watts": 1.384, "power_sys_5v0_mean_watts": 8.777, "gpu_utilization_percent_mean": 87.283}, "timestamp": "2026-01-30T23:42:27.646247"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4763.471, "latencies_ms": [4763.471], "images_per_second": 0.21, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image shows a kitchen countertop with a black stove top, a black oven door, and a variety of kitchen utensils and containers on the countertop.", "error": null, "sys_before": {"cpu_percent": 28.8, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.082, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.865, "gpu_utilization_percent_mean": 86.897}, "timestamp": "2026-01-30T23:42:34.558960"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 6907.648, "latencies_ms": [6907.648], "images_per_second": 0.145, "prompt_tokens": 26, "response_tokens_est": 68, "n_tiles": 12, "output_text": "- stove: 1\n- oven: 1\n- oven mitt: 1\n- oven rack: 1\n- oven door: 1\n- oven handle: 1\n- oven knob: 1\n- oven pan: 1\n- oven tray: 1\n- oven drawer: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.292, "power_cpu_cv_mean_watts": 1.623, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 85.276}, "timestamp": "2026-01-30T23:42:43.501740"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8147.397, "latencies_ms": [8147.397], "images_per_second": 0.123, "prompt_tokens": 30, "response_tokens_est": 88, "n_tiles": 12, "output_text": "The main objects in the image are a kitchen countertop, a stove, and various kitchen utensils. The countertop is located in the foreground, while the stove is situated in the middle ground. The kitchen utensils are placed near the stove, with a knife and a pair of scissors on the countertop. The background features a backsplash with marble tiles, and a towel or cloth is hanging on the wall.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.744, "power_cpu_cv_mean_watts": 1.73, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 83.899}, "timestamp": "2026-01-30T23:42:53.693714"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6798.108, "latencies_ms": [6798.108], "images_per_second": 0.147, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a kitchen countertop with a black stove and a black oven. The countertop is adorned with various kitchen items, including a black trash can, a black oven mitt, and a black oven rack. The setting appears to be a well-organized kitchen with a focus on functionality and cleanliness.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.315, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 85.561}, "timestamp": "2026-01-30T23:43:02.521542"}
{"image_index": 330, "image_name": "000000035326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035326.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7289.556, "latencies_ms": [7289.556], "images_per_second": 0.137, "prompt_tokens": 22, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The image shows a kitchen counter with a dark countertop and a black stove. The counter is adorned with various kitchen items, including a black trash can, a black oven, and a black stove with white cooking rings. The lighting in the kitchen is dim, with a soft glow illuminating the countertop and stove. The overall atmosphere is cozy and functional.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.085, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 84.672}, "timestamp": "2026-01-30T23:43:11.827618"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5366.794, "latencies_ms": [5366.794], "images_per_second": 0.186, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 12, "output_text": "A young man is sitting at a table in a restaurant, holding a donut with pink icing and colorful sprinkles, while a tray of donuts and a cup of coffee are visible in the background.", "error": null, "sys_before": {"cpu_percent": 33.1, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.283, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 8.839, "gpu_utilization_percent_mean": 86.25}, "timestamp": "2026-01-30T23:43:19.347193"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10569.684, "latencies_ms": [10569.684], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "- donut: 3\n- cup: 1\n- plate: 1\n- tray: 1\n- napkin: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut: 1\n- donut:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.063, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 82.404}, "timestamp": "2026-01-30T23:43:31.937552"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8489.396, "latencies_ms": [8489.396], "images_per_second": 0.118, "prompt_tokens": 30, "response_tokens_est": 94, "n_tiles": 12, "output_text": "The main object in the foreground is a plate of donuts, which are placed on a tray. The plate is positioned near the center of the image, with the donuts arranged in a visually appealing manner. In the background, there is a person seated at a counter, and a table with various items, including a cup of coffee and a tablet. The person is slightly out of focus, indicating that the main focus is on the donuts and the tray.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.731, "power_cpu_cv_mean_watts": 1.774, "power_sys_5v0_mean_watts": 8.844, "gpu_utilization_percent_mean": 83.583}, "timestamp": "2026-01-30T23:43:42.457473"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7261.121, "latencies_ms": [7261.121], "images_per_second": 0.138, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The image depicts a cozy and inviting setting, likely in a caf\u00e9 or restaurant, with a tray of desserts and a cup of coffee. The focus is on a plate of chocolate-covered donuts, some of which are adorned with colorful sprinkles, and a cup of coffee. The background shows other patrons and a warm, inviting ambiance.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.176, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.852, "gpu_utilization_percent_mean": 84.623}, "timestamp": "2026-01-30T23:43:51.740818"}
{"image_index": 331, "image_name": "000000035682.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035682.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6676.737, "latencies_ms": [6676.737], "images_per_second": 0.15, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image features a warmly lit indoor setting with a focus on a tray of donuts. The donuts are adorned with various colorful sprinkles and glazed in shades of pink and red. The tray is placed on a table, and the background includes a blurred counter with a person and some items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.9, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.369, "power_cpu_cv_mean_watts": 1.559, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 84.982}, "timestamp": "2026-01-30T23:44:00.436426"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4329.724, "latencies_ms": [4329.724], "images_per_second": 0.231, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "The image shows a bathroom sink with a clear glass top, a white porcelain sink, and a blue tiled wall.", "error": null, "sys_before": {"cpu_percent": 32.3, "ram_used_mb": 18643.9, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.283, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 89.222}, "timestamp": "2026-01-30T23:44:06.925679"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5535.58, "latencies_ms": [5535.58], "images_per_second": 0.181, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 12, "output_text": "- sink: 1\n- toilet: 1\n- tiled wall: 1\n- table: 1\n- decorative plate: 1\n- fish: 1\n- cat: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.13, "power_cpu_cv_mean_watts": 1.375, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 87.413}, "timestamp": "2026-01-30T23:44:14.483541"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7025.932, "latencies_ms": [7025.932], "images_per_second": 0.142, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The main object in the foreground is a white ceramic sink with a clear glass basin. The sink is placed on a wooden countertop. In the background, there is a toilet with a blue tiled wall. The sink is positioned near the toilet, creating a spatial relationship where the sink is in the foreground and the toilet is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.326, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.861, "gpu_utilization_percent_mean": 84.864}, "timestamp": "2026-01-30T23:44:23.570726"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6861.807, "latencies_ms": [6861.807], "images_per_second": 0.146, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a bathroom setting with a white bathtub and a glass shower enclosure. The bathtub is partially filled with water, and there is a decorative plate with a turtle design on the edge of the tub. The shower area is tiled with blue tiles, and the floor appears to be a dark color.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.329, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 85.158}, "timestamp": "2026-01-30T23:44:32.450001"}
{"image_index": 332, "image_name": "000000035770.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035770.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6311.757, "latencies_ms": [6311.757], "images_per_second": 0.158, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image features a bathroom with a white bathtub and a white sink. The bathtub has a blue tiled surround, and the sink has a clear glass top. The lighting in the bathroom is bright, and the overall color scheme is neutral with white and blue tones.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.592, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 86.519}, "timestamp": "2026-01-30T23:44:40.774970"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 6213.796, "latencies_ms": [6213.796], "images_per_second": 0.161, "prompt_tokens": 12, "response_tokens_est": 57, "n_tiles": 12, "output_text": "A small, white teddy bear is sitting on a wooden sign that reads \"Joseph Panis\" and \"Marilyn,\" with a sign that says \"Died 1-1-53\" and \"Died 4-11-98\" in the background.", "error": null, "sys_before": {"cpu_percent": 26.5, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.63, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 84.519}, "timestamp": "2026-01-30T23:44:49.165999"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5247.44, "latencies_ms": [5247.44], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.362, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 87.93}, "timestamp": "2026-01-30T23:44:56.426824"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10263.727, "latencies_ms": [10263.727], "images_per_second": 0.097, "prompt_tokens": 30, "response_tokens_est": 123, "n_tiles": 12, "output_text": "The main object in the foreground is a large, white teddy bear with a wooden sign that reads \"Joseph Panis\" and \"Mystie Malulani.\" The bear is positioned on a patch of grass, with a small pile of red bricks nearby. In the background, there is a white pillar and a sign that reads \"Died 1-1-53\" and \"Died 4-1-98.\" The scene appears to be set in a garden or park, with the teddy bear and sign placed on the grass, while the pillar and sign are in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.232, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.848, "gpu_utilization_percent_mean": 83.116}, "timestamp": "2026-01-30T23:45:08.719877"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8300.572, "latencies_ms": [8300.572], "images_per_second": 0.12, "prompt_tokens": 24, "response_tokens_est": 91, "n_tiles": 12, "output_text": "The image depicts a serene outdoor scene with a small, weathered wooden sign that reads \"Joseph Panis\" and \"Mystic Maulani\" in a rustic, hand-painted style. The sign is placed on a grassy area with a few scattered rocks and a small patch of dirt. A plush, white teddy bear is sitting on top of the sign, adding a touch of whimsy to the setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.745, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 8.85, "gpu_utilization_percent_mean": 83.9}, "timestamp": "2026-01-30T23:45:19.050151"}
{"image_index": 333, "image_name": "000000035963.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000035963.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5960.89, "latencies_ms": [5960.89], "images_per_second": 0.168, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The notable visual attributes of the image include a white teddy bear with a distressed appearance, placed on a weathered wooden sign. The setting is outdoors with a mix of greenery and a dirt path, and the lighting is natural, suggesting daytime.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.806, "power_cpu_cv_mean_watts": 1.466, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 86.2}, "timestamp": "2026-01-30T23:45:27.039524"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3788.427, "latencies_ms": [3788.427], "images_per_second": 0.264, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The image depicts a bustling restaurant with numerous patrons seated at tables, engaged in conversations and dining. The interior features a large clock prominently displayed on the wall, adding a unique architectural element to the space.", "error": null, "sys_before": {"cpu_percent": 26.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.776, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 71.839}, "timestamp": "2026-01-30T23:45:32.934067"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8888.327, "latencies_ms": [8888.327], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 6, "output_text": "- People: 20\n- Tables: 10\n- Chairs: 20\n- Cups: 10\n- Glasses: 10\n- Napkins: 10\n- Utensils: 10\n- Food: 10\n- Dishes: 10\n- Cutlery: 10\n- Cutting board: 10\n- Cutting knife: 10\n- Spoons: 10\n- Plates: 10\n- Bowls: 10\n- Cups: 10\n- Candles: 1\n- Clock: 1\n- Ce", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.759, "power_cpu_cv_mean_watts": 2.072, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 67.373}, "timestamp": "2026-01-30T23:45:43.871560"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5444.376, "latencies_ms": [5444.376], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The main objects in the image are the large clock and the dining area. The clock is positioned in the background, with its large face dominating the upper part of the image. The dining area is in the foreground, with people seated at tables around the clock. The clock is near the ceiling, while the dining area is on the ground floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.236, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 69.356}, "timestamp": "2026-01-30T23:45:51.349558"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4830.947, "latencies_ms": [4830.947], "images_per_second": 0.207, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a bustling restaurant interior with a large clock prominently displayed on the wall. The scene is filled with patrons seated at tables, engaged in conversations and dining. The warm lighting and rustic decor create a cozy atmosphere, while the clock adds a touch of elegance to the setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.668, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 70.075}, "timestamp": "2026-01-30T23:45:58.216521"}
{"image_index": 334, "image_name": "000000036494.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036494.jpg", "image_width": 640, "image_height": 434, "image_resolution": "640x434", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4283.549, "latencies_ms": [4283.549], "images_per_second": 0.233, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The image depicts a bustling restaurant with a warm, inviting ambiance. The lighting is soft and warm, casting a cozy glow over the space. The walls and ceiling are adorned with exposed beams, adding a rustic touch to the overall aesthetic.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.259, "power_cpu_cv_mean_watts": 1.705, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 71.2}, "timestamp": "2026-01-30T23:46:04.534670"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2161.58, "latencies_ms": [2161.58], "images_per_second": 0.463, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 6, "output_text": "A person is skiing down a snowy slope with a child following behind.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.914, "power_cpu_cv_mean_watts": 0.919, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 79.824}, "timestamp": "2026-01-30T23:46:08.795996"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4417.689, "latencies_ms": [4417.689], "images_per_second": 0.226, "prompt_tokens": 26, "response_tokens_est": 54, "n_tiles": 6, "output_text": "- Person: 1\n- Ski poles: 2\n- Ski: 1\n- Snowboard: 1\n- Snowsuit: 1\n- Gloves: 2\n- Hat: 1\n- Sunglasses: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.072, "power_cpu_cv_mean_watts": 1.702, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 71.222}, "timestamp": "2026-01-30T23:46:15.234343"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4601.824, "latencies_ms": [4601.824], "images_per_second": 0.217, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 6, "output_text": "In the image, the main objects are the two individuals and the snowy landscape. The person in the foreground is standing on a snowboard, while the other person is walking in the background. The snowy landscape is the backdrop, with trees and rocks visible in the distance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.809, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 70.316}, "timestamp": "2026-01-30T23:46:21.869441"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5307.321, "latencies_ms": [5307.321], "images_per_second": 0.188, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image depicts a snowy mountain slope with a family of three enjoying a winter day. The family is dressed in winter gear, including jackets, pants, and snow boots, and are engaged in skiing activities. The setting is a snowy mountain, and the family appears to be having a fun and active day on the slopes.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.311, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 69.886}, "timestamp": "2026-01-30T23:46:29.201345"}
{"image_index": 335, "image_name": "000000036539.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036539.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4155.011, "latencies_ms": [4155.011], "images_per_second": 0.241, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a snowy landscape with a bright, sunny day. The snow is pristine and untouched, with a few scattered rocks and trees in the background. The lighting is clear and bright, casting sharp shadows on the snow.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.394, "power_cpu_cv_mean_watts": 1.708, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 71.265}, "timestamp": "2026-01-30T23:46:35.370551"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2937.102, "latencies_ms": [2937.102], "images_per_second": 0.34, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 6, "output_text": "The image shows a pair of feet wearing black flip-flops, with a small, open, black flip-flop placed on a wooden surface.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.265, "power_cpu_cv_mean_watts": 1.385, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T23:46:40.395099"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3150.609, "latencies_ms": [3150.609], "images_per_second": 0.317, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 6, "output_text": "1. Flip phone\n2. Battery\n3. Phone\n4. Battery\n5. Phone\n6. Battery\n7. Phone\n8. Battery", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.693, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 73.885}, "timestamp": "2026-01-30T23:46:45.570030"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5075.674, "latencies_ms": [5075.674], "images_per_second": 0.197, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The main objects in the image are a black flip phone, a black flip phone, and a black flip phone. The flip phones are positioned in the foreground, with the one on the left slightly closer to the viewer. The flip phones are placed on a wooden surface, with the one on the right being further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.476, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 69.976}, "timestamp": "2026-01-30T23:46:52.669236"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3264.921, "latencies_ms": [3264.921], "images_per_second": 0.306, "prompt_tokens": 24, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The image depicts a wooden surface with a pair of black flip-flops placed on it. The flip-flops are adorned with white nail polish on the toes.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.528, "power_cpu_cv_mean_watts": 1.454, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 73.222}, "timestamp": "2026-01-30T23:46:57.952651"}
{"image_index": 336, "image_name": "000000036660.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036660.jpg", "image_width": 500, "image_height": 323, "image_resolution": "500x323", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4288.308, "latencies_ms": [4288.308], "images_per_second": 0.233, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The image shows a pair of black flip-flops with white painted toenails. The wooden surface on which the flip-flops are placed has a warm, reddish-brown hue, and the lighting is soft and natural, casting gentle shadows.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.167, "power_cpu_cv_mean_watts": 1.671, "power_sys_5v0_mean_watts": 7.995, "gpu_utilization_percent_mean": 71.657}, "timestamp": "2026-01-30T23:47:04.257820"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2866.682, "latencies_ms": [2866.682], "images_per_second": 0.349, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 2, "output_text": "The image depicts a serene scene of a river with a large, illuminated building in the background, likely the Houses of Parliament, and a boat named \"PACE\" on the water.", "error": null, "sys_before": {"cpu_percent": 22.4, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.296, "power_cpu_cv_mean_watts": 1.794, "power_sys_5v0_mean_watts": 7.136, "gpu_utilization_percent_mean": 63.522}, "timestamp": "2026-01-30T23:47:09.205379"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4011.811, "latencies_ms": [4011.811], "images_per_second": 0.249, "prompt_tokens": 26, "response_tokens_est": 59, "n_tiles": 2, "output_text": "- Big Ben: 1\n- Houses of Parliament: 1\n- London Bridge: 1\n- River Thames: 1\n- London Eye: 1\n- Westminster Pier: 1\n- Westminster Bridge: 1\n- Westminster Abbey: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.993, "power_cpu_cv_mean_watts": 1.99, "power_sys_5v0_mean_watts": 7.245, "gpu_utilization_percent_mean": 62.939}, "timestamp": "2026-01-30T23:47:15.242257"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3593.641, "latencies_ms": [3593.641], "images_per_second": 0.278, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 2, "output_text": "The main objects in the image are a large building with a clock tower and a river with several boats. The building is in the background, while the river and boats are in the foreground. The clock tower is prominent and stands out against the skyline.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.239, "power_cpu_cv_mean_watts": 1.933, "power_sys_5v0_mean_watts": 7.271, "gpu_utilization_percent_mean": 64.414}, "timestamp": "2026-01-30T23:47:20.863039"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5363.623, "latencies_ms": [5363.623], "images_per_second": 0.186, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 2, "output_text": "The image depicts a serene riverside scene with a large, illuminated building, likely the Houses of Parliament, situated on the right side. The sky is overcast, and the water reflects the soft glow of the building's lights. In the foreground, there is a boat with the word \"PAGE\" visible on its side, suggesting it might be a tour or sightseeing vessel.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.717, "power_cpu_cv_mean_watts": 2.103, "power_sys_5v0_mean_watts": 7.34, "gpu_utilization_percent_mean": 62.5}, "timestamp": "2026-01-30T23:47:28.243329"}
{"image_index": 337, "image_name": "000000036678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036678.jpg", "image_width": 640, "image_height": 361, "image_resolution": "640x361", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3092.176, "latencies_ms": [3092.176], "images_per_second": 0.323, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 2, "output_text": "The image showcases a grand, illuminated building with a clock tower, likely the Houses of Parliament, situated on a river. The sky is overcast, casting a soft, diffused light over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.354, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 7.185, "gpu_utilization_percent_mean": 62.84}, "timestamp": "2026-01-30T23:47:33.361471"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5678.639, "latencies_ms": [5678.639], "images_per_second": 0.176, "prompt_tokens": 12, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a mix of modern and vintage furniture, including a green couch, a red armchair, a black leather sofa, a small table with a television, a red rug, and various decorative items.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.184, "power_cpu_cv_mean_watts": 1.457, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 85.851}, "timestamp": "2026-01-30T23:47:41.191630"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5754.792, "latencies_ms": [5754.792], "images_per_second": 0.174, "prompt_tokens": 26, "response_tokens_est": 49, "n_tiles": 12, "output_text": "1. Living room\n2. Sofa\n3. Coffee table\n4. TV stand\n5. TV\n6. Floor lamp\n7. Potted plants\n8. Chairs\n9. Floor\n10. Ceiling fan", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.988, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 87.083}, "timestamp": "2026-01-30T23:47:49.008318"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10530.197, "latencies_ms": [10530.197], "images_per_second": 0.095, "prompt_tokens": 30, "response_tokens_est": 129, "n_tiles": 12, "output_text": "The main objects in the image are arranged in a way that showcases a mix of furniture and decor. The left side of the image features a red leather chair, a small round table, and a bicycle leaning against the wall. The center of the image includes a green couch, a small table with a television, and a red rug. The right side of the image displays a black leather couch, a white coffee table, and a white refrigerator. The background includes a window with a view of trees outside, a white wall, and a ceiling fan. The foreground is dominated by the green couch and the red rug, while the background is", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.171, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 8.869, "gpu_utilization_percent_mean": 82.382}, "timestamp": "2026-01-30T23:48:01.586884"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6123.907, "latencies_ms": [6123.907], "images_per_second": 0.163, "prompt_tokens": 24, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a wooden floor and a red rug. The room is well-lit with natural light coming through large windows, and it is furnished with a green couch, a black leather chair, a small table, and various decorative items.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.749, "power_cpu_cv_mean_watts": 1.508, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 86.275}, "timestamp": "2026-01-30T23:48:09.755720"}
{"image_index": 338, "image_name": "000000036844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036844.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5232.793, "latencies_ms": [5232.793], "images_per_second": 0.191, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The room is well-lit with natural light streaming in through large windows, creating a bright and airy atmosphere. The wooden floor reflects the sunlight, adding to the overall brightness of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.45, "power_cpu_cv_mean_watts": 1.36, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 88.093}, "timestamp": "2026-01-30T23:48:17.014313"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4672.531, "latencies_ms": [4672.531], "images_per_second": 0.214, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "The image shows a parking meter on a sidewalk, with a large advertisement for \"YEAR OF SAVING\" displayed on a building in the background.", "error": null, "sys_before": {"cpu_percent": 24.7, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.107, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 86.846}, "timestamp": "2026-01-30T23:48:23.838804"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10530.096, "latencies_ms": [10530.096], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "object: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject: 1 parking meter\nobject:", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.19, "power_cpu_cv_mean_watts": 1.895, "power_sys_5v0_mean_watts": 8.851, "gpu_utilization_percent_mean": 83.146}, "timestamp": "2026-01-30T23:48:36.411731"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6789.127, "latencies_ms": [6789.127], "images_per_second": 0.147, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The parking meter is positioned in the foreground, slightly to the left, with a red post supporting it. The background features a building with large windows and a sign that reads \"YEAR OF SAVING.\" The pavement is visible in the foreground, and there are no other significant objects or people in the immediate vicinity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.516, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 85.679}, "timestamp": "2026-01-30T23:48:45.214834"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7325.15, "latencies_ms": [7325.15], "images_per_second": 0.137, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The image depicts a parking meter situated on a sidewalk in front of a building. The scene is set in an urban environment, likely in a city or town, with a clear sky and a building with large windows in the background. The parking meter is red and black, and it is positioned on the sidewalk, indicating that it is a common sight in the area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.172, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 85.049}, "timestamp": "2026-01-30T23:48:54.553991"}
{"image_index": 339, "image_name": "000000036861.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036861.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5214.488, "latencies_ms": [5214.488], "images_per_second": 0.192, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The parking meter in the image is predominantly black with a digital display. It is mounted on a red post. The surrounding environment includes a clear blue sky, a brick building, and a sidewalk.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18645.4, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.475, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 88.581}, "timestamp": "2026-01-30T23:49:01.799484"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2497.394, "latencies_ms": [2497.394], "images_per_second": 0.4, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 6, "output_text": "A group of people is gathered around a table, with a festive atmosphere, as they enjoy a holiday celebration.", "error": null, "sys_before": {"cpu_percent": 24.0, "ram_used_mb": 18645.4, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.351, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 8.07, "gpu_utilization_percent_mean": 77.5}, "timestamp": "2026-01-30T23:49:06.402377"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8883.548, "latencies_ms": [8883.548], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "- TV: 1\n- TV stand: 1\n- Candles: 2\n- Candle holder: 1\n- Candle: 1\n- Candlelight: 1\n- Candlelight holder: 1\n- Candlelight: 1\n- Candlelight holder: 1\n- Candlelight: 1\n- Candlelight holder: 1\n- Candlelight: 1\n- Candlelight holder: 1\n- Candlelight: 1\n- Candlelight holder: 1\n- Candlelight: 1", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.701, "power_cpu_cv_mean_watts": 2.061, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 67.187}, "timestamp": "2026-01-30T23:49:17.312444"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5849.658, "latencies_ms": [5849.658], "images_per_second": 0.171, "prompt_tokens": 30, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The main objects in the image are a television, a couch, and a table. The television is positioned on the left side of the image, with a small shelf above it. The couch is in the background, with a person sitting on it. The table is in the foreground, with various items on it, including a red gift, a candle, a phone, and snacks.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.966, "power_cpu_cv_mean_watts": 1.904, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 69.327}, "timestamp": "2026-01-30T23:49:25.193566"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5186.393, "latencies_ms": [5186.393], "images_per_second": 0.193, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a cozy living room scene where a group of people is gathered around a table. The room is decorated with festive elements, including a Christmas tree adorned with lights and a red and gold garland. The individuals are engaged in conversation, with one person holding a dog, and the atmosphere is warm and inviting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.422, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 69.767}, "timestamp": "2026-01-30T23:49:32.423782"}
{"image_index": 340, "image_name": "000000036936.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000036936.jpg", "image_width": 640, "image_height": 404, "image_resolution": "640x404", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3148.534, "latencies_ms": [3148.534], "images_per_second": 0.318, "prompt_tokens": 22, "response_tokens_est": 33, "n_tiles": 6, "output_text": "The room is warmly lit with a soft glow, creating a cozy atmosphere. The furniture and decorations are made of wood, adding to the homely feel.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.616, "power_cpu_cv_mean_watts": 1.432, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 73.731}, "timestamp": "2026-01-30T23:49:37.597260"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4631.375, "latencies_ms": [4631.375], "images_per_second": 0.216, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "A person is holding a remote control in their hand, which is connected to a modern, sleek, white appliance with multiple buttons and a digital display.", "error": null, "sys_before": {"cpu_percent": 26.3, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.942, "power_cpu_cv_mean_watts": 1.191, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 87.895}, "timestamp": "2026-01-30T23:49:44.381190"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10566.851, "latencies_ms": [10566.851], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- Water heater: 1\n- Wall outlet: 1\n- Wall switch: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch plate: 1\n- Wall switch", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.083, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 82.303}, "timestamp": "2026-01-30T23:49:56.974108"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7738.161, "latencies_ms": [7738.161], "images_per_second": 0.129, "prompt_tokens": 30, "response_tokens_est": 81, "n_tiles": 12, "output_text": "The main object in the foreground is a white appliance, likely a washing machine, with a control panel on its front. The control panel has several buttons and a display screen. The appliance is positioned on a wooden floor, and there is a white door or cabinet to the left of the appliance. The background is mostly white, with a plain wall and a small section of a door or cabinet visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.892, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 8.846, "gpu_utilization_percent_mean": 84.169}, "timestamp": "2026-01-30T23:50:06.768728"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7644.339, "latencies_ms": [7644.339], "images_per_second": 0.131, "prompt_tokens": 24, "response_tokens_est": 80, "n_tiles": 12, "output_text": "The image depicts a modern, minimalist bathroom setting with a focus on a sleek, white wall-mounted toilet. A person's hand is seen holding a small, rectangular device, possibly a phone or a remote control, which is being used to operate the toilet. The overall atmosphere is clean, uncluttered, and functional, with a focus on the technological aspect of the bathroom.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.942, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 84.578}, "timestamp": "2026-01-30T23:50:16.447430"}
{"image_index": 341, "image_name": "000000037670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037670.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5823.547, "latencies_ms": [5823.547], "images_per_second": 0.172, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The image features a modern, minimalist bathroom with a sleek, white wall-mounted toilet. The toilet has a sleek, metallic frame and a clean, white tank. The lighting is soft and ambient, creating a calm and serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.985, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 87.125}, "timestamp": "2026-01-30T23:50:24.312376"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2427.101, "latencies_ms": [2427.101], "images_per_second": 0.412, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "A snowboarder is performing a jump over a snow wall, with spectators watching from the side.", "error": null, "sys_before": {"cpu_percent": 26.9, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.45, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 76.85}, "timestamp": "2026-01-30T23:50:28.843389"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3550.266, "latencies_ms": [3550.266], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.309, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 73.207}, "timestamp": "2026-01-30T23:50:34.418287"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5052.231, "latencies_ms": [5052.231], "images_per_second": 0.198, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The main objects in the image are a snowboarder performing a jump and a snowy mountain slope. The snowboarder is in the foreground, while the snowy mountain slope is in the background. The snowboarder is near the snowy slope, and the snowboard is also near the snowy slope.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.561, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 70.881}, "timestamp": "2026-01-30T23:50:41.496266"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4695.086, "latencies_ms": [4695.086], "images_per_second": 0.213, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a snowboarding competition taking place on a snow-covered mountain slope. Spectators are gathered on the side of the slope, watching the snowboarders perform tricks. The snowboarders are airborne, executing impressive maneuvers, while the crowd cheers them on.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.741, "power_cpu_cv_mean_watts": 1.766, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 70.128}, "timestamp": "2026-01-30T23:50:48.231471"}
{"image_index": 342, "image_name": "000000037689.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037689.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5013.668, "latencies_ms": [5013.668], "images_per_second": 0.199, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a snowy landscape with a clear blue sky, indicating a sunny day. The snow appears to be freshly fallen, with a smooth, powdery texture. The snowboarder is captured mid-air, performing a jump, and the snowboarder is wearing a red jacket and black pants.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.457, "power_cpu_cv_mean_watts": 1.859, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 69.929}, "timestamp": "2026-01-30T23:50:55.283002"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4874.879, "latencies_ms": [4874.879], "images_per_second": 0.205, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image shows a well-organized home office with a desk, computer, and a chair, along with a potted plant and a white couch in the background.", "error": null, "sys_before": {"cpu_percent": 26.9, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.779, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 87.85}, "timestamp": "2026-01-30T23:51:02.306136"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4858.162, "latencies_ms": [4858.162], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Desk\n2. Chair\n3. Computer monitor\n4. Laptop\n5. Keyboard\n6. Mouse\n7. Wall outlet\n8. Floor", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.82, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 88.8}, "timestamp": "2026-01-30T23:51:09.177124"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7850.293, "latencies_ms": [7850.293], "images_per_second": 0.127, "prompt_tokens": 30, "response_tokens_est": 83, "n_tiles": 12, "output_text": "The main objects in the image are a desk, a chair, and a potted plant. The desk is positioned in the foreground, with a computer monitor, a keyboard, and a mouse on it. The chair is positioned to the left of the desk, and the potted plant is placed to the right of the desk. The background includes a wall, a shelf, and a part of a couch.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.734, "power_cpu_cv_mean_watts": 1.699, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 84.152}, "timestamp": "2026-01-30T23:51:19.052775"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7038.3, "latencies_ms": [7038.3], "images_per_second": 0.142, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The image depicts a cozy, well-lit room with a modern, minimalist aesthetic. The room features a small desk with a computer setup, a comfortable white chair, and a potted plant adding a touch of greenery. The overall atmosphere is serene and inviting, with soft lighting and a clean, uncluttered space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.209, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 84.966}, "timestamp": "2026-01-30T23:51:28.139684"}
{"image_index": 343, "image_name": "000000037740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037740.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6569.444, "latencies_ms": [6569.444], "images_per_second": 0.152, "prompt_tokens": 22, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The image depicts a cozy, well-lit room with a beige carpeted floor. The walls are painted in a light color, and there is a white couch in the background. The room features a desk with a lamp, a computer, and a plant, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.345, "power_cpu_cv_mean_watts": 1.551, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 85.4}, "timestamp": "2026-01-30T23:51:36.757996"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4697.471, "latencies_ms": [4697.471], "images_per_second": 0.213, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "A person is riding a motorcycle on a rocky, mountainous road, with a scenic view of green hills and a partly cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 29.1, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.839, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 87.846}, "timestamp": "2026-01-30T23:51:43.637266"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5112.354, "latencies_ms": [5112.354], "images_per_second": 0.196, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "1. Motorcycle\n2. Helmet\n3. Rider\n4. Gloves\n5. Backpack\n6. Motorcycle seat\n7. Road\n8. Hills", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.371, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.78, "gpu_utilization_percent_mean": 87.163}, "timestamp": "2026-01-30T23:51:50.798653"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6138.209, "latencies_ms": [6138.209], "images_per_second": 0.163, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The main objects in the image are a person on a motorcycle and a mountainous landscape. The person is positioned in the foreground, riding the motorcycle on a rocky, uneven terrain. The mountainous landscape is in the background, stretching out with rolling hills and dense forests.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.802, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 86.392}, "timestamp": "2026-01-30T23:51:58.968856"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7056.685, "latencies_ms": [7056.685], "images_per_second": 0.142, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The image depicts a rugged, mountainous landscape with a dirt road winding through the terrain. A person is riding a motorcycle, wearing a helmet and a jacket, and appears to be enjoying the scenic ride. The setting is characterized by rocky paths, greenery, and a partly cloudy sky, creating a picturesque and adventurous atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.114, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 84.763}, "timestamp": "2026-01-30T23:52:08.078806"}
{"image_index": 344, "image_name": "000000037751.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037751.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6084.126, "latencies_ms": [6084.126], "images_per_second": 0.164, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image depicts a rugged, rocky terrain with a clear blue sky overhead. The lighting is bright and natural, suggesting it is daytime. The scene is characterized by a mix of greenery and rocky surfaces, with a few scattered clouds adding to the overall atmosphere.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.724, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 86.216}, "timestamp": "2026-01-30T23:52:16.182303"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3043.326, "latencies_ms": [3043.326], "images_per_second": 0.329, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image shows a modern kitchen with wooden cabinets, a white refrigerator, a stove, and a countertop with a bowl of oranges on a table.", "error": null, "sys_before": {"cpu_percent": 25.6, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.064, "power_cpu_cv_mean_watts": 1.458, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-30T23:52:21.320014"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3688.603, "latencies_ms": [3688.603], "images_per_second": 0.271, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 6, "output_text": "kitchen: 2\ncabinets: 2\ndishwasher: 1\noven: 1\nfridge: 1\ntable: 1\nfruit bowl: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.015, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 72.233}, "timestamp": "2026-01-30T23:52:27.033681"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4179.239, "latencies_ms": [4179.239], "images_per_second": 0.239, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The main objects in the image are a kitchen and a dining area. The kitchen is located in the background, while the dining area is in the foreground. The dining table is placed in the foreground, and it is positioned near the kitchen area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.143, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 71.057}, "timestamp": "2026-01-30T23:52:33.251136"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4741.057, "latencies_ms": [4741.057], "images_per_second": 0.211, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image depicts a modern kitchen with a clean and bright ambiance. The kitchen features wooden cabinets, a white refrigerator, and a countertop with various kitchen appliances and utensils. On the counter, there is a bowl of oranges, adding a pop of color to the scene.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.906, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 70.564}, "timestamp": "2026-01-30T23:52:40.008023"}
{"image_index": 345, "image_name": "000000037777.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037777.jpg", "image_width": 352, "image_height": 230, "image_resolution": "352x230", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3562.637, "latencies_ms": [3562.637], "images_per_second": 0.281, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The kitchen features a warm, wooden cabinetry with a light beige wall color. The lighting is soft and natural, with sunlight streaming in through a window, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.051, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 72.897}, "timestamp": "2026-01-30T23:52:45.593442"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4140.88, "latencies_ms": [4140.88], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A female tennis player is in the middle of a match, preparing to hit the ball with her racket.", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.627, "power_cpu_cv_mean_watts": 1.06, "power_sys_5v0_mean_watts": 8.796, "gpu_utilization_percent_mean": 89.471}, "timestamp": "2026-01-30T23:52:51.885412"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5627.457, "latencies_ms": [5627.457], "images_per_second": 0.178, "prompt_tokens": 26, "response_tokens_est": 47, "n_tiles": 12, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Tennis court\n5. Blue sign with \"POLO\" text\n6. Blue wall\n7. Green floor\n8. White cap", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.062, "power_cpu_cv_mean_watts": 1.44, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 86.894}, "timestamp": "2026-01-30T23:52:59.526257"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7776.683, "latencies_ms": [7776.683], "images_per_second": 0.129, "prompt_tokens": 30, "response_tokens_est": 82, "n_tiles": 12, "output_text": "The main object in the foreground is a tennis player, standing on the court. The player is holding a tennis racket and appears to be preparing to hit a tennis ball. The background features a blue barrier with the word \"POLO\" on it, and a microphone is visible on the left side. The player is positioned near the center of the image, with the microphone and barrier in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.96, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 8.865, "gpu_utilization_percent_mean": 84.154}, "timestamp": "2026-01-30T23:53:09.339652"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7213.965, "latencies_ms": [7213.965], "images_per_second": 0.139, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 12, "output_text": "The image depicts a scene on a tennis court, where a female tennis player is in the midst of a serve. The court is marked with white lines, and the player is wearing a white cap, a white tank top, and black shorts. The player is holding a tennis racket and appears to be in the process of hitting a yellow tennis ball.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.072, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 84.852}, "timestamp": "2026-01-30T23:53:18.600786"}
{"image_index": 346, "image_name": "000000037988.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000037988.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6538.531, "latencies_ms": [6538.531], "images_per_second": 0.153, "prompt_tokens": 22, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The image depicts a tennis player on a green court, wearing a white cap and a white sleeveless top. The court surface is marked with white lines, and there is a blue sign with the word \"POLO\" on it. The lighting is bright, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.456, "power_cpu_cv_mean_watts": 1.566, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 85.564}, "timestamp": "2026-01-30T23:53:27.176909"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2217.294, "latencies_ms": [2217.294], "images_per_second": 0.451, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 6, "output_text": "A red fire hydrant is placed on the sidewalk, with a person standing nearby.", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.878, "power_cpu_cv_mean_watts": 1.023, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 78.833}, "timestamp": "2026-01-30T23:53:31.475917"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2789.147, "latencies_ms": [2789.147], "images_per_second": 0.359, "prompt_tokens": 26, "response_tokens_est": 27, "n_tiles": 6, "output_text": "fire hydrant: 1\nsign: 1\ntree: 1\nhouse: 1\nman: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.432, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 75.174}, "timestamp": "2026-01-30T23:53:36.303478"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4202.57, "latencies_ms": [4202.57], "images_per_second": 0.238, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The main object in the foreground is a red fire hydrant, which is positioned on the sidewalk. In the background, there is a person standing near the sidewalk. The fire hydrant is near the sidewalk, while the person is further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.2, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 71.343}, "timestamp": "2026-01-30T23:53:42.545849"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4031.648, "latencies_ms": [4031.648], "images_per_second": 0.248, "prompt_tokens": 24, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image depicts a scene on a sunny day with a red fire hydrant positioned on a concrete sidewalk. In the background, there is a person standing near a tree, and a yellow pedestrian crossing sign is visible above the sidewalk.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.572, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 71.441}, "timestamp": "2026-01-30T23:53:48.617350"}
{"image_index": 347, "image_name": "000000038048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038048.jpg", "image_width": 299, "image_height": 500, "image_resolution": "299x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3503.121, "latencies_ms": [3503.121], "images_per_second": 0.285, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image features a bright red fire hydrant on a concrete sidewalk, with a clear blue sky overhead. The hydrant is illuminated by natural sunlight, casting a shadow on the ground.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.12, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 72.69}, "timestamp": "2026-01-30T23:53:54.132210"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3836.358, "latencies_ms": [3836.358], "images_per_second": 0.261, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 12, "output_text": "The image shows a toilet with a white seat and lid, situated in a bathroom.", "error": null, "sys_before": {"cpu_percent": 28.5, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.105, "power_cpu_cv_mean_watts": 0.964, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 90.188}, "timestamp": "2026-01-30T23:54:00.136519"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10540.879, "latencies_ms": [10540.879], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "toilet: 1\ntoilet paper: 1\ntoilet brush: 1\ntoilet paper roll: 1\ntoilet paper holder: 1\ntoilet paper: 1\ntoilet brush holder: 1\ntoilet brush: 1\ntoilet brush holder: 1\ntoilet paper holder: 1\ntoilet paper: 1\ntoilet brush holder: 1\ntoilet paper holder: 1\ntoilet paper: 1\ntoilet paper holder: 1\ntoilet paper: 1\ntoilet paper holder: 1\nto", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.126, "power_cpu_cv_mean_watts": 1.9, "power_sys_5v0_mean_watts": 8.873, "gpu_utilization_percent_mean": 82.378}, "timestamp": "2026-01-30T23:54:12.702591"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7007.281, "latencies_ms": [7007.281], "images_per_second": 0.143, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The main object in the foreground is a toilet, which is positioned near the left side of the image. The toilet is in the foreground, making it the most prominent object in the scene. The background features a wall, which is slightly to the right of the toilet. The wall is in the background, providing a neutral backdrop to the toilet.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.354, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.844, "gpu_utilization_percent_mean": 85.475}, "timestamp": "2026-01-30T23:54:21.738488"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6282.315, "latencies_ms": [6282.315], "images_per_second": 0.159, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a bathroom setting with a toilet and a small, white, rectangular object on the floor. The toilet is white, and there is a small, rectangular object on the floor next to it. The floor appears to be carpeted, and the wall is painted white.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18650.8, "ram_available_mb": 44190.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.668, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 86.566}, "timestamp": "2026-01-30T23:54:30.062288"}
{"image_index": 348, "image_name": "000000038070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038070.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5335.415, "latencies_ms": [5335.415], "images_per_second": 0.187, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The toilet in the image is white, with a glossy finish, and is situated on a beige carpeted floor. The lighting is soft and diffused, casting a gentle glow on the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18650.8, "ram_available_mb": 44190.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18652.0, "ram_available_mb": 44188.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.278, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 87.644}, "timestamp": "2026-01-30T23:54:37.435828"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3368.508, "latencies_ms": [3368.508], "images_per_second": 0.297, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "A skier in a red jacket and black pants is skiing down a snowy slope, with ski poles in hand, and the snow is visibly disturbed by their movement.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18651.7, "ram_available_mb": 44189.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.243, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 73.143}, "timestamp": "2026-01-30T23:54:42.904354"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3426.976, "latencies_ms": [3426.976], "images_per_second": 0.292, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 6, "output_text": "1. Skier\n2. Ski poles\n3. Ski\n4. Snow\n5. Snowboard\n6. Snowboarder\n7. Snow\n8. Snowboard", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.368, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 72.897}, "timestamp": "2026-01-30T23:54:48.374514"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4811.187, "latencies_ms": [4811.187], "images_per_second": 0.208, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The main objects in the image are a person skiing and a snow-covered mountain. The person is positioned in the foreground, closer to the viewer, while the mountain is in the background, further away. The ski tracks on the snow indicate that the person has been skiing on the mountain.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18651.5, "ram_available_mb": 44189.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.829, "power_cpu_cv_mean_watts": 1.832, "power_sys_5v0_mean_watts": 8.068, "gpu_utilization_percent_mean": 70.425}, "timestamp": "2026-01-30T23:54:55.219901"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5002.442, "latencies_ms": [5002.442], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a snowy mountainous landscape under a clear blue sky. A skier dressed in red gear is navigating the slopes, using ski poles to maintain balance and speed. The scene is set in a winter environment, with the skier's attire and equipment indicating preparedness for cold weather conditions.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.544, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 70.214}, "timestamp": "2026-01-30T23:55:02.244021"}
{"image_index": 349, "image_name": "000000038118.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038118.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4669.563, "latencies_ms": [4669.563], "images_per_second": 0.214, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The image depicts a snowy mountain landscape under a clear blue sky. The snow-covered ground is dotted with tracks, and a person in a red jacket and black pants is skiing down the slope. The lighting is bright and natural, suggesting it is daytime with good visibility.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.608, "power_cpu_cv_mean_watts": 1.746, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 70.026}, "timestamp": "2026-01-30T23:55:08.939578"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3362.327, "latencies_ms": [3362.327], "images_per_second": 0.297, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "A man is skiing down a snowy trail, wearing a red and white jacket, black pants, and a beanie, with a bib number 30 on his back.", "error": null, "sys_before": {"cpu_percent": 22.8, "ram_used_mb": 18652.2, "ram_available_mb": 44188.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18651.7, "ram_available_mb": 44189.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.43, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 73.214}, "timestamp": "2026-01-30T23:55:14.442412"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3602.569, "latencies_ms": [3602.569], "images_per_second": 0.278, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "1. Ski poles\n2. Ski\n3. Ski skis\n4. Ski skier\n5. Skiing\n6. Snow\n7. Snowboarder\n8. Snowboard", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18651.7, "ram_available_mb": 44189.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.004, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 72.467}, "timestamp": "2026-01-30T23:55:20.070081"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5913.037, "latencies_ms": [5913.037], "images_per_second": 0.169, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The main object in the foreground is a skier wearing a red and white jacket, black pants, and a beanie. The skier is holding ski poles and appears to be in motion, skiing on a snowy trail. In the background, there are other skiers and a snowy mountain landscape. The skier in the background is further away and slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.9, "ram_available_mb": 44188.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.019, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 68.86}, "timestamp": "2026-01-30T23:55:28.015340"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4992.425, "latencies_ms": [4992.425], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a snowy landscape with a person dressed in winter attire, including a beanie and ski gear, actively skiing down a snow-covered path. The scene is set in a forested area, with snow-covered trees and a clear sky, suggesting a cold, wintry environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18652.5, "ram_available_mb": 44188.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.496, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 70.214}, "timestamp": "2026-01-30T23:55:35.020068"}
{"image_index": 350, "image_name": "000000038210.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038210.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5792.672, "latencies_ms": [5792.672], "images_per_second": 0.173, "prompt_tokens": 22, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The image depicts a snowy landscape with a man dressed in a red and white jacket, black pants, and a gray beanie. He is skiing on a snowy path, surrounded by snow-covered trees and a mountainous background. The lighting is soft and diffused, likely due to the overcast sky, and the overall atmosphere is serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18652.3, "ram_available_mb": 44188.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.971, "power_cpu_cv_mean_watts": 1.911, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 69.271}, "timestamp": "2026-01-30T23:55:42.851581"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3467.253, "latencies_ms": [3467.253], "images_per_second": 0.288, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image shows a black and white photo of a computer setup with a monitor, keyboard, and mouse on a desk, with a wall and a partial view of a window in the background.", "error": null, "sys_before": {"cpu_percent": 24.5, "ram_used_mb": 18651.8, "ram_available_mb": 44189.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.107, "power_cpu_cv_mean_watts": 1.519, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 72.552}, "timestamp": "2026-01-30T23:55:48.433927"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3185.721, "latencies_ms": [3185.721], "images_per_second": 0.314, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 6, "output_text": "- computer monitor: 1\n- computer keyboard: 1\n- computer mouse: 2\n- desk: 1\n- computer tower: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.797, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 7.966, "gpu_utilization_percent_mean": 74.038}, "timestamp": "2026-01-30T23:55:53.657036"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6092.378, "latencies_ms": [6092.378], "images_per_second": 0.164, "prompt_tokens": 30, "response_tokens_est": 82, "n_tiles": 6, "output_text": "The main objects in the image are a computer monitor, a keyboard, and a mouse. The monitor is positioned in the center-left of the image, with the keyboard and mouse placed in front of it. The keyboard is on the right side of the monitor, while the mouse is on the left side of the keyboard. The background is a plain wall, and the desk surface is visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.9, "ram_available_mb": 44189.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.837, "power_cpu_cv_mean_watts": 1.932, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 69.078}, "timestamp": "2026-01-30T23:56:01.800292"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4560.328, "latencies_ms": [4560.328], "images_per_second": 0.219, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a modern office workspace with a computer setup. The desk features a large monitor displaying a desktop wallpaper, a keyboard, and a mouse. The workspace is well-lit, and the image is in black and white, giving it a classic and minimalist appearance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.07, "power_cpu_cv_mean_watts": 1.813, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 70.789}, "timestamp": "2026-01-30T23:56:08.387362"}
{"image_index": 351, "image_name": "000000038576.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038576.jpg", "image_width": 438, "image_height": 640, "image_resolution": "438x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4038.819, "latencies_ms": [4038.819], "images_per_second": 0.248, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image is a black and white photograph of a computer setup. The computer monitor displays a desktop wallpaper, and the keyboard and mouse are placed on a wooden desk. The lighting is soft and even, creating a calm and professional atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.4, "ram_available_mb": 44189.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.431, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 7.977, "gpu_utilization_percent_mean": 71.441}, "timestamp": "2026-01-30T23:56:14.455469"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4431.007, "latencies_ms": [4431.007], "images_per_second": 0.226, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "A woman is sitting in a train carriage, holding a doughnut and a coffee cup, with a blurry background of other passengers.", "error": null, "sys_before": {"cpu_percent": 26.8, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.281, "power_cpu_cv_mean_watts": 1.169, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 88.243}, "timestamp": "2026-01-30T23:56:21.072342"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4696.239, "latencies_ms": [4696.239], "images_per_second": 0.213, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Woman\n2. Woman\n3. Woman\n4. Woman\n5. Woman\n6. Woman\n7. Woman\n8. Woman", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.086, "power_cpu_cv_mean_watts": 1.253, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 89.359}, "timestamp": "2026-01-30T23:56:27.801714"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5826.8, "latencies_ms": [5826.8], "images_per_second": 0.172, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The main objects in the image are a woman and a man. The woman is holding a doughnut in the foreground, while the man is partially visible in the background. The doughnut is near the woman, and the man is further away.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18651.2, "ram_available_mb": 44189.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18650.8, "ram_available_mb": 44190.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.932, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 86.959}, "timestamp": "2026-01-30T23:56:35.665489"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6177.036, "latencies_ms": [6177.036], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a scene inside a train carriage, where a woman is seated and holding a doughnut. The woman is wearing a striped top and has short hair. The train carriage is filled with passengers, and there is a window with blurred greenery outside.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18650.8, "ram_available_mb": 44190.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18650.6, "ram_available_mb": 44190.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.668, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 86.635}, "timestamp": "2026-01-30T23:56:43.866655"}
{"image_index": 352, "image_name": "000000038678.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038678.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7550.88, "latencies_ms": [7550.88], "images_per_second": 0.132, "prompt_tokens": 22, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The image features a woman with short, light-colored hair, wearing a maroon top. She is holding a white plate with a golden-brown doughnut, which is placed on a table. The lighting is warm and ambient, with a soft glow illuminating the scene. The background is slightly blurred, suggesting motion, with a window showing a blurry view of greenery outside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.6, "ram_available_mb": 44190.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.972, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 8.858, "gpu_utilization_percent_mean": 84.562}, "timestamp": "2026-01-30T23:56:53.452772"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2704.967, "latencies_ms": [2704.967], "images_per_second": 0.37, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "The image depicts a zebra grazing on a lush green field, with its distinctive black and white stripes clearly visible.", "error": null, "sys_before": {"cpu_percent": 26.5, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18649.3, "ram_available_mb": 44191.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.555, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-30T23:56:58.269016"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2111.737, "latencies_ms": [2111.737], "images_per_second": 0.474, "prompt_tokens": 26, "response_tokens_est": 16, "n_tiles": 6, "output_text": "zebra: 2\ngrass: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.3, "ram_available_mb": 44191.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.29, "power_cpu_cv_mean_watts": 1.036, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 79.765}, "timestamp": "2026-01-30T23:57:02.407139"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4829.29, "latencies_ms": [4829.29], "images_per_second": 0.207, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The main objects in the image are two zebras. The foreground features a zebra with a black and white striped pattern, while the background shows another zebra with similar stripes. The zebra in the foreground is closer to the camera, while the one in the background is further away.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.694, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 70.775}, "timestamp": "2026-01-30T23:57:09.294705"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4104.689, "latencies_ms": [4104.689], "images_per_second": 0.244, "prompt_tokens": 24, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image depicts a group of zebras grazing on a lush green field. The zebras are in a natural setting, likely a savanna or grassland, with their distinctive black and white striped patterns clearly visible.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.449, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.046, "gpu_utilization_percent_mean": 71.618}, "timestamp": "2026-01-30T23:57:15.413382"}
{"image_index": 353, "image_name": "000000038825.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038825.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3907.36, "latencies_ms": [3907.36], "images_per_second": 0.256, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The image features a zebra with a striking black and white striped pattern, standing on a lush green grassy field. The lighting is natural, suggesting it is daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.649, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 71.781}, "timestamp": "2026-01-30T23:57:21.337228"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2733.225, "latencies_ms": [2733.225], "images_per_second": 0.366, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 6, "output_text": "A group of young students are riding bicycles in a city, with one of them wearing a white shirt and a white helmet.", "error": null, "sys_before": {"cpu_percent": 24.0, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.898, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 75.318}, "timestamp": "2026-01-30T23:57:26.179717"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3498.242, "latencies_ms": [3498.242], "images_per_second": 0.286, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 6, "output_text": "1. Bicycle\n2. Motorcycle\n3. People\n4. Motorcycle\n5. Bicycle\n6. Motorcycle\n7. Bicycle\n8. Motorcycle", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.439, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 73.786}, "timestamp": "2026-01-30T23:57:31.700795"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7525.358, "latencies_ms": [7525.358], "images_per_second": 0.133, "prompt_tokens": 30, "response_tokens_est": 106, "n_tiles": 6, "output_text": "In the image, there is a green bicycle parked on the left side of the frame, with a person wearing a white shirt and dark pants seated on it. To the right of the bicycle, there is a black scooter with a person wearing a white helmet and a light-colored jacket seated on it. The background features a building with a sign that reads \"Coca-Cola,\" and there are other people walking around. The scene appears to be set in an urban area with a mix of bicycles and motorcycles.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.5, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.233, "power_cpu_cv_mean_watts": 2.021, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 68.381}, "timestamp": "2026-01-30T23:57:41.238016"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5906.639, "latencies_ms": [5906.639], "images_per_second": 0.169, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image depicts a bustling street scene in a city, likely in Southeast Asia, where a group of young individuals are riding bicycles. The setting is urban, with buildings and shops in the background, and the weather appears to be sunny. The individuals are dressed in casual attire, with some wearing white shirts and others in blue, suggesting they might be students or young professionals.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.98, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 69.49}, "timestamp": "2026-01-30T23:57:49.181526"}
{"image_index": 354, "image_name": "000000038829.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000038829.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4595.729, "latencies_ms": [4595.729], "images_per_second": 0.218, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a street scene with a mix of modern and traditional elements. Notable visual attributes include a green bicycle with a basket, a black scooter, and a white motorcycle. The lighting is natural, suggesting daytime, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.798, "power_cpu_cv_mean_watts": 1.771, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 70.816}, "timestamp": "2026-01-30T23:57:55.838929"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4599.807, "latencies_ms": [4599.807], "images_per_second": 0.217, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "A tennis player is preparing to hit a tennis ball on a well-maintained grass court, with spectators seated in the background watching the match.", "error": null, "sys_before": {"cpu_percent": 30.7, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.224, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 87.868}, "timestamp": "2026-01-30T23:58:02.588567"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5384.07, "latencies_ms": [5384.07], "images_per_second": 0.186, "prompt_tokens": 26, "response_tokens_est": 43, "n_tiles": 12, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Tennis court\n5. Stadium seating\n6. Spectators\n7. Green grass\n8. Person sitting on bench", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18649.3, "ram_available_mb": 44191.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.33, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 87.8}, "timestamp": "2026-01-30T23:58:10.002997"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7992.823, "latencies_ms": [7992.823], "images_per_second": 0.125, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 12, "output_text": "The main objects in the image are a tennis court, a tennis player, and a crowd of spectators. The tennis player is positioned on the left side of the image, near the baseline, preparing to hit the tennis ball. The crowd of spectators is located in the background, seated on benches, watching the match. The tennis court is the central focus, with the player and the spectators forming the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.3, "ram_available_mb": 44191.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.916, "power_cpu_cv_mean_watts": 1.737, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 84.132}, "timestamp": "2026-01-30T23:58:20.047890"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6412.517, "latencies_ms": [6412.517], "images_per_second": 0.156, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The image depicts a tennis match taking place on a well-maintained grass court, with spectators seated in the background. The players are actively engaged in the game, with one player in a white outfit preparing to hit the ball, while the other player is positioned to receive the serve.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.583, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 85.796}, "timestamp": "2026-01-30T23:58:28.506728"}
{"image_index": 355, "image_name": "000000039405.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039405.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5667.887, "latencies_ms": [5667.887], "images_per_second": 0.176, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The image depicts a tennis match taking place on a well-maintained grass court. The lighting is bright, likely from stadium lights, and the weather appears to be clear, with no visible signs of rain or adverse weather conditions.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18650.8, "ram_available_mb": 44190.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.053, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 87.25}, "timestamp": "2026-01-30T23:58:36.206207"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3586.748, "latencies_ms": [3586.748], "images_per_second": 0.279, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The image shows a cozy living room with a brown couch, a white cushion, a small plant on a table, a white sewing machine, a green plastic bag, and a window with white curtains.", "error": null, "sys_before": {"cpu_percent": 23.5, "ram_used_mb": 18650.8, "ram_available_mb": 44190.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18650.7, "ram_available_mb": 44190.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.148, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 72.7}, "timestamp": "2026-01-30T23:58:41.923577"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5354.135, "latencies_ms": [5354.135], "images_per_second": 0.187, "prompt_tokens": 26, "response_tokens_est": 70, "n_tiles": 6, "output_text": "- TV stand: 1\n- TV: 1\n- Curtains: 1\n- Window: 1\n- Rug: 1\n- Pillow: 1\n- Cushion: 1\n- Potted plants: 2\n- Small plant: 1\n- Decorative item: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.7, "ram_available_mb": 44190.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.279, "power_cpu_cv_mean_watts": 1.869, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 70.222}, "timestamp": "2026-01-30T23:58:49.307843"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6097.651, "latencies_ms": [6097.651], "images_per_second": 0.164, "prompt_tokens": 30, "response_tokens_est": 82, "n_tiles": 6, "output_text": "The main objects in the image are a sewing machine, a small plant, a cushion, and a television stand. The sewing machine is positioned on the left side of the image, near the television stand. The small plant is placed on the right side of the sewing machine, near the cushion. The television stand is in the background, and the cushion is placed on the right side of the television stand.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18649.9, "ram_available_mb": 44191.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.804, "power_cpu_cv_mean_watts": 1.918, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 68.731}, "timestamp": "2026-01-30T23:58:57.460492"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5965.591, "latencies_ms": [5965.591], "images_per_second": 0.168, "prompt_tokens": 24, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image depicts a cozy living room with a small television on a wooden stand, a brown couch, and a white cushion on a brown sofa. The room is well-lit with natural light coming through a window covered by sheer white curtains. The space is decorated with a green plant on the floor, a small potted plant on the table, and a small green plant on the couch.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18649.9, "ram_available_mb": 44191.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18649.4, "ram_available_mb": 44191.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.986, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 68.98}, "timestamp": "2026-01-30T23:59:05.440290"}
{"image_index": 356, "image_name": "000000039477.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039477.jpg", "image_width": 640, "image_height": 421, "image_resolution": "640x421", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3980.817, "latencies_ms": [3980.817], "images_per_second": 0.251, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The room features a cozy and well-lit atmosphere with natural light streaming through the partially drawn white curtains. The walls are painted in a light, neutral color, complementing the warm brown and white tones of the furniture and decor.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18649.4, "ram_available_mb": 44191.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.551, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.005, "gpu_utilization_percent_mean": 71.515}, "timestamp": "2026-01-30T23:59:11.479426"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2933.567, "latencies_ms": [2933.567], "images_per_second": 0.341, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 6, "output_text": "A tennis player in a bright red outfit is holding a tennis racket and appears to be in a moment of celebration or reaction after a shot.", "error": null, "sys_before": {"cpu_percent": 34.7, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.348, "power_cpu_cv_mean_watts": 1.435, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 74.917}, "timestamp": "2026-01-30T23:59:16.518088"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3868.926, "latencies_ms": [3868.926], "images_per_second": 0.258, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 6, "output_text": "1. Tennis player\n2. Red clay court\n3. Tennis racket\n4. White visor\n5. Red dress\n6. White headband\n7. White tennis shoes\n8. Green padding", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.769, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 72.312}, "timestamp": "2026-01-30T23:59:22.430823"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4944.144, "latencies_ms": [4944.144], "images_per_second": 0.202, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The main object in the foreground is a tennis player dressed in a bright orange dress, holding a tennis racket. The player is standing on a clay court, which is the main object in the background. The clay court is surrounded by a green fence and a green mat, which are also in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.688, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 70.488}, "timestamp": "2026-01-30T23:59:29.391552"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5790.891, "latencies_ms": [5790.891], "images_per_second": 0.173, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The image captures a moment on a clay tennis court, where a female tennis player is in the midst of a match. She is dressed in a vibrant red outfit and is holding a tennis racket, poised to hit the ball. The court is marked with white lines, and the background features a green barrier and a crocodile logo, indicating the event's location and sponsors.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.979, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.057, "gpu_utilization_percent_mean": 69.625}, "timestamp": "2026-01-30T23:59:37.221460"}
{"image_index": 357, "image_name": "000000039480.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039480.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3979.895, "latencies_ms": [3979.895], "images_per_second": 0.251, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image features a red clay tennis court with a bright, natural light illuminating the scene. The surface of the court is a reddish-brown color, and the lighting is even, creating a clear and vivid image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.428, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 71.424}, "timestamp": "2026-01-30T23:59:43.259697"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3341.845, "latencies_ms": [3341.845], "images_per_second": 0.299, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "The image depicts a bustling urban street scene with a variety of parked cars, a busy intersection, and a mix of commercial establishments, including a restaurant and a theater.", "error": null, "sys_before": {"cpu_percent": 29.9, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.444, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 73.214}, "timestamp": "2026-01-30T23:59:48.716050"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8895.683, "latencies_ms": [8895.683], "images_per_second": 0.112, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.84, "power_cpu_cv_mean_watts": 2.083, "power_sys_5v0_mean_watts": 8.068, "gpu_utilization_percent_mean": 67.56}, "timestamp": "2026-01-30T23:59:59.631003"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4768.975, "latencies_ms": [4768.975], "images_per_second": 0.21, "prompt_tokens": 30, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The main objects in the image are a street scene with various buildings, cars, and people. The foreground features a parked silver car, while the background includes a red building with a neon sign. The street is busy with cars and pedestrians, and there are street signs and a traffic light visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.745, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 70.275}, "timestamp": "2026-01-31T00:00:06.436454"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5850.075, "latencies_ms": [5850.075], "images_per_second": 0.171, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The image depicts a bustling urban street scene, likely in a city with a mix of commercial and residential buildings. The street is lined with parked cars, and there are several pedestrians visible. The buildings have various signs and advertisements, including a prominent \"Omnifest\" billboard. The overall atmosphere suggests a busy, lively city environment with a mix of commercial and residential areas.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.932, "power_cpu_cv_mean_watts": 1.888, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 69.02}, "timestamp": "2026-01-31T00:00:14.298502"}
{"image_index": 358, "image_name": "000000039484.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039484.jpg", "image_width": 640, "image_height": 437, "image_resolution": "640x437", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5192.223, "latencies_ms": [5192.223], "images_per_second": 0.193, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a bustling urban street scene with a variety of notable visual attributes. The buildings are primarily brick and red, with some featuring green awnings. The street is lined with parked cars, and there are several streetlights and traffic signs visible. The sky is overcast, providing a subdued lighting condition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.394, "power_cpu_cv_mean_watts": 1.825, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 70.047}, "timestamp": "2026-01-31T00:00:21.528885"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2936.498, "latencies_ms": [2936.498], "images_per_second": 0.341, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 6, "output_text": "A female tennis player is captured mid-action on a brightly lit tennis court, with her racket in hand, ready to strike the ball.", "error": null, "sys_before": {"cpu_percent": 29.9, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.245, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 74.708}, "timestamp": "2026-01-31T00:00:26.614556"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3696.134, "latencies_ms": [3696.134], "images_per_second": 0.271, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Tennis court\n5. Tennis net\n6. Tennis shoes\n7. Tennis outfit\n8. Tennis visor", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.962, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 72.4}, "timestamp": "2026-01-31T00:00:32.337313"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5991.866, "latencies_ms": [5991.866], "images_per_second": 0.167, "prompt_tokens": 30, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The main object in the foreground is a tennis player, who is positioned on the left side of the image. The tennis player is holding a tennis racket and appears to be preparing for a serve. The background consists of a green tennis court, with a white boundary line visible on the right side. The tennis ball is located near the bottom right corner of the image, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.802, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 68.84}, "timestamp": "2026-01-31T00:00:40.373051"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5983.627, "latencies_ms": [5983.627], "images_per_second": 0.167, "prompt_tokens": 24, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image captures a moment on a tennis court during a match. The player, dressed in a red outfit, is in the midst of a serve, with her racket in motion and her body leaning forward. The court is marked with white lines, and the surface appears to be a standard hard court. The lighting suggests it is daytime, and the player's shadow is visible on the court.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.879, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 69.12}, "timestamp": "2026-01-31T00:00:48.370653"}
{"image_index": 359, "image_name": "000000039551.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039551.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3494.824, "latencies_ms": [3494.824], "images_per_second": 0.286, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The tennis player is wearing a red outfit, which stands out against the green and blue court. The bright sunlight casts a clear shadow of the player on the court, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.17, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 72.586}, "timestamp": "2026-01-31T00:00:53.904261"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1614.029, "latencies_ms": [1614.029], "images_per_second": 0.62, "prompt_tokens": 12, "response_tokens_est": 14, "n_tiles": 4, "output_text": "A train is traveling on a track surrounded by lush greenery.", "error": null, "sys_before": {"cpu_percent": 24.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5451.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.607, "power_cpu_cv_mean_watts": 0.955, "power_sys_5v0_mean_watts": 7.452, "gpu_utilization_percent_mean": 74.154}, "timestamp": "2026-01-31T00:00:57.613331"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8565.693, "latencies_ms": [8565.693], "images_per_second": 0.117, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 4, "output_text": "object: train\nobject: train car\nobject: train tracks\nobject: greenery\nobject: bushes\nobject: trees\nobject: train engine\nobject: train car doors\nobject: train car windows\nobject: train car doors\nobject: train car windows\nobject: train car doors\nobject: train car windows\nobject: train car doors\nobject: train car windows\nobject: train car doors\nobject: train car windows\nobject: train car doors\nobject: train car windows\nobject: train car doors\nobject: train car windows\nobject: train car doors\nobject: train car windows", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18646.6, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5463.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.559, "power_cpu_cv_mean_watts": 2.143, "power_sys_5v0_mean_watts": 7.721, "gpu_utilization_percent_mean": 63.437}, "timestamp": "2026-01-31T00:01:08.208573"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3081.106, "latencies_ms": [3081.106], "images_per_second": 0.325, "prompt_tokens": 30, "response_tokens_est": 38, "n_tiles": 4, "output_text": "The train is positioned on the left side of the image, with the tracks running parallel to the right. The train is in the foreground, and the surrounding vegetation is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5465.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.527, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.614, "gpu_utilization_percent_mean": 67.28}, "timestamp": "2026-01-31T00:01:13.326762"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3486.859, "latencies_ms": [3486.859], "images_per_second": 0.287, "prompt_tokens": 24, "response_tokens_est": 45, "n_tiles": 4, "output_text": "The image depicts a train traveling on a track surrounded by lush greenery. The train is moving through a rural or semi-rural area, with the tracks cutting through a field of tall grass and wildflowers.", "error": null, "sys_before": {"cpu_percent": 6.3, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5460.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.208, "power_cpu_cv_mean_watts": 1.759, "power_sys_5v0_mean_watts": 7.662, "gpu_utilization_percent_mean": 64.821}, "timestamp": "2026-01-31T00:01:18.856056"}
{"image_index": 360, "image_name": "000000039670.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039670.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3120.609, "latencies_ms": [3120.609], "images_per_second": 0.32, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 4, "output_text": "The train in the image is painted in a combination of blue and orange, with a white roof. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5459.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.768, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 7.594, "gpu_utilization_percent_mean": 65.24}, "timestamp": "2026-01-31T00:01:24.008588"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3889.611, "latencies_ms": [3889.611], "images_per_second": 0.257, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 12, "output_text": "A tabby cat is lying on a pink blanket, appearing to be sleeping peacefully.", "error": null, "sys_before": {"cpu_percent": 29.2, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.363, "power_cpu_cv_mean_watts": 1.014, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 90.688}, "timestamp": "2026-01-31T00:01:30.070380"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3832.335, "latencies_ms": [3832.335], "images_per_second": 0.261, "prompt_tokens": 26, "response_tokens_est": 17, "n_tiles": 12, "output_text": "cat: 1\nremote control: 2\nblanket: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.6, "ram_available_mb": 44195.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.087, "power_cpu_cv_mean_watts": 0.963, "power_sys_5v0_mean_watts": 8.772, "gpu_utilization_percent_mean": 91.312}, "timestamp": "2026-01-31T00:01:35.942662"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7110.111, "latencies_ms": [7110.111], "images_per_second": 0.141, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main object in the foreground is a cat lying on a pink blanket. The cat is positioned near the center of the image, with its body facing the left side of the frame. In the background, there is a white remote control lying on the same pink blanket. The remote control is positioned to the left of the cat, slightly behind it.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.15, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 85.119}, "timestamp": "2026-01-31T00:01:45.066508"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7341.476, "latencies_ms": [7341.476], "images_per_second": 0.136, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The image depicts a serene scene of a tabby cat lying on a pink blanket, seemingly asleep. The cat's body is stretched out, with its head resting on the blanket, while its paws are visible on the surface. The setting appears to be a cozy, indoor environment, possibly a living room or bedroom, with a soft, warm ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.004, "power_cpu_cv_mean_watts": 1.647, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 84.274}, "timestamp": "2026-01-31T00:01:54.456999"}
{"image_index": 361, "image_name": "000000039769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039769.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7275.341, "latencies_ms": [7275.341], "images_per_second": 0.137, "prompt_tokens": 22, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The image features a tabby cat with a striped pattern, predominantly in shades of brown, black, and white. The cat is resting on a pink blanket, which is soft and appears to be made of a plush fabric. The lighting in the image is bright, casting a warm glow on the cat and the blanket, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.066, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 84.41}, "timestamp": "2026-01-31T00:02:03.758918"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3894.339, "latencies_ms": [3894.339], "images_per_second": 0.257, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 12, "output_text": "A surfer is riding a wave in the river, wearing a black wetsuit.", "error": null, "sys_before": {"cpu_percent": 33.9, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.099, "power_cpu_cv_mean_watts": 0.989, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 90.344}, "timestamp": "2026-01-31T00:02:09.827362"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4861.281, "latencies_ms": [4861.281], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "surfer: 1\nwetsuit: 1\nboard: 1\nocean: 1\nwater: 1\nbench: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.939, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 89.1}, "timestamp": "2026-01-31T00:02:16.719826"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6196.28, "latencies_ms": [6196.28], "images_per_second": 0.161, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The main objects in the image are a river, a man, and a bench. The river is in the foreground, with the man standing on a surfboard near the water's edge. The bench is located further back in the scene, providing a resting spot for people.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.782, "power_cpu_cv_mean_watts": 1.517, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 86.019}, "timestamp": "2026-01-31T00:02:24.956581"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5511.639, "latencies_ms": [5511.639], "images_per_second": 0.181, "prompt_tokens": 24, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The image depicts a scene at a river with a man in a black wetsuit surfing on a white wave. The setting is outdoors, likely in a natural environment with trees and a bench visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.167, "power_cpu_cv_mean_watts": 1.393, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 87.587}, "timestamp": "2026-01-31T00:02:32.508861"}
{"image_index": 362, "image_name": "000000039785.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039785.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6001.285, "latencies_ms": [6001.285], "images_per_second": 0.167, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image depicts a scene with a man in a black wetsuit surfing on a turbulent river. The river is brownish, and the man is standing on a surfboard. The lighting is natural, and the weather appears to be overcast.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.829, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 86.72}, "timestamp": "2026-01-31T00:02:40.531414"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4503.395, "latencies_ms": [4503.395], "images_per_second": 0.222, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "A woman and a child are standing on a grassy field, with the woman holding a colorful kite that is flying in the air.", "error": null, "sys_before": {"cpu_percent": 23.8, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.149, "power_cpu_cv_mean_watts": 1.169, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 88.649}, "timestamp": "2026-01-31T00:02:47.190859"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4730.945, "latencies_ms": [4730.945], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Person\n2. Person\n3. Person\n4. Person\n5. Person\n6. Person\n7. Person\n8. Person", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.916, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 89.282}, "timestamp": "2026-01-31T00:02:53.949512"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7083.685, "latencies_ms": [7083.685], "images_per_second": 0.141, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 12, "output_text": "The main objects in the image are a woman and a child, both standing on the grass. The woman is wearing a black jacket and blue jeans, while the child is wearing a pink top and blue jeans. The child is holding a colorful kite, which is near the woman. The kite is in the background, slightly out of focus.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.274, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 85.051}, "timestamp": "2026-01-31T00:03:03.056676"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6257.06, "latencies_ms": [6257.06], "images_per_second": 0.16, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The image depicts a serene park scene with a woman and a child standing on a grassy field. The woman is holding a colorful kite, while the child is watching it fly. The setting is a peaceful park with trees and a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.576, "power_cpu_cv_mean_watts": 1.517, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 85.981}, "timestamp": "2026-01-31T00:03:11.372872"}
{"image_index": 363, "image_name": "000000039914.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039914.jpg", "image_width": 487, "image_height": 640, "image_resolution": "487x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8716.983, "latencies_ms": [8716.983], "images_per_second": 0.115, "prompt_tokens": 22, "response_tokens_est": 98, "n_tiles": 12, "output_text": "The image depicts a vibrant outdoor scene with a clear blue sky, a lush green lawn, and a few trees in the background. The sunlight casts soft shadows, creating a warm and inviting atmosphere. The woman and child are dressed in casual attire, with the woman wearing a black leather jacket and blue jeans, and the child in a pink top and blue pants. The scene is bright and cheerful, with the colorful kite adding a playful touch to the overall ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.617, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 83.603}, "timestamp": "2026-01-31T00:03:22.135761"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2711.015, "latencies_ms": [2711.015], "images_per_second": 0.369, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A young tennis player is captured mid-action on a court, with a tennis ball in the air, ready to be hit.", "error": null, "sys_before": {"cpu_percent": 27.6, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.484, "power_cpu_cv_mean_watts": 1.274, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 75.864}, "timestamp": "2026-01-31T00:03:26.965819"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3670.941, "latencies_ms": [3670.941], "images_per_second": 0.272, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Green net\n5. Green tarp\n6. Blue court\n7. White net\n8. Green wall", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.122, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 72.133}, "timestamp": "2026-01-31T00:03:32.649613"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5904.108, "latencies_ms": [5904.108], "images_per_second": 0.169, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The main object in the foreground is a young tennis player, who is in the process of hitting a tennis ball. The player is positioned near the net, with his racket in his right hand, preparing to strike the ball. The background features a green tarpaulin, which is likely covering the court. The net is visible in the foreground, separating the court from the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.99, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 69.388}, "timestamp": "2026-01-31T00:03:40.597720"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5672.612, "latencies_ms": [5672.612], "images_per_second": 0.176, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The image captures a young tennis player in mid-action on a tennis court, preparing to hit a tennis ball. The court is marked with white lines, and the player is wearing a white shirt, black shorts, and a red cap. The background shows a green tarpaulin, and there is a sign with the text \"Are you next?\" above the player.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.963, "power_cpu_cv_mean_watts": 1.883, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 69.383}, "timestamp": "2026-01-31T00:03:48.315341"}
{"image_index": 364, "image_name": "000000039951.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039951.jpg", "image_width": 640, "image_height": 445, "image_resolution": "640x445", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4163.989, "latencies_ms": [4163.989], "images_per_second": 0.24, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a young tennis player in action on a court, wearing a white shirt, black shorts, and a red cap. The court surface is blue, and the net is white. The lighting is bright, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.44, "power_cpu_cv_mean_watts": 1.661, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 71.471}, "timestamp": "2026-01-31T00:03:54.489442"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4802.897, "latencies_ms": [4802.897], "images_per_second": 0.208, "prompt_tokens": 12, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a cluttered room with various items scattered around, including a bed with a brown blanket, a wooden dresser, a wooden chair, and a pile of boxes and bags, suggesting that the room is in the process of being unpacked or is in a state of disarray.", "error": null, "sys_before": {"cpu_percent": 30.4, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.654, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 70.125}, "timestamp": "2026-01-31T00:04:01.387613"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3927.894, "latencies_ms": [3927.894], "images_per_second": 0.255, "prompt_tokens": 26, "response_tokens_est": 46, "n_tiles": 6, "output_text": "bed: 1\nclothes: 1\nbox: 1\ntrash can: 1\nchair: 1\ndrawer: 1\ncabinet: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18649.4, "ram_available_mb": 44191.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.597, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 71.727}, "timestamp": "2026-01-31T00:04:07.353463"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4647.904, "latencies_ms": [4647.904], "images_per_second": 0.215, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The main objects in the image are scattered throughout the room, with the bed in the foreground and various items in the background. The bed is positioned near the left side of the image, while the items in the background are located further back, creating a sense of depth in the room.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.4, "ram_available_mb": 44191.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.861, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 70.231}, "timestamp": "2026-01-31T00:04:14.041892"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4259.647, "latencies_ms": [4259.647], "images_per_second": 0.235, "prompt_tokens": 24, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The image depicts a cluttered room with a bed in the center, surrounded by various items and boxes. The room appears to be in the process of being unpacked or tidied up, with items scattered around and some boxes still in the room.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.217, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 71.306}, "timestamp": "2026-01-31T00:04:20.347675"}
{"image_index": 365, "image_name": "000000039956.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000039956.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3676.318, "latencies_ms": [3676.318], "images_per_second": 0.272, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 6, "output_text": "The room is dimly lit with warm, soft lighting, creating a cozy and intimate atmosphere. The walls are adorned with a rustic brick texture, adding a touch of warmth and character to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.019, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 72.387}, "timestamp": "2026-01-31T00:04:26.084609"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3116.688, "latencies_ms": [3116.688], "images_per_second": 0.321, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 6, "output_text": "A jockey is riding a horse in a race, with the horse's hooves off the ground, showcasing a dynamic and exciting moment in the competition.", "error": null, "sys_before": {"cpu_percent": 31.7, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.978, "power_cpu_cv_mean_watts": 1.441, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 74.64}, "timestamp": "2026-01-31T00:04:31.342650"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3805.548, "latencies_ms": [3805.548], "images_per_second": 0.263, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 6, "output_text": "1. Horse\n2. Rider\n3. Jumping fence\n4. Jumping bar\n5. Jumping pad\n6. Jumping rope\n7. Jumping pad\n8. Jumping pad", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.876, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 72.516}, "timestamp": "2026-01-31T00:04:37.188336"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4830.439, "latencies_ms": [4830.439], "images_per_second": 0.207, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The main object in the foreground is a brown horse with a rider on its back. The rider is wearing a red and green jacket and a helmet. The horse is equipped with a saddle and is in mid-jump over a wooden fence. The background features lush green trees, indicating an outdoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.746, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 70.425}, "timestamp": "2026-01-31T00:04:44.057296"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5367.183, "latencies_ms": [5367.183], "images_per_second": 0.186, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The image captures a dynamic moment during a horse jumping event, where a jockey is riding a brown horse. The horse is mid-jump over a wooden fence, with the jockey wearing a red and green racing outfit and a helmet. The background features lush green trees, indicating an outdoor setting, likely a stable or a designated jumping area.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.36, "power_cpu_cv_mean_watts": 1.838, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 70.114}, "timestamp": "2026-01-31T00:04:51.434273"}
{"image_index": 366, "image_name": "000000040036.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040036.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4223.813, "latencies_ms": [4223.813], "images_per_second": 0.237, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The horse in the image is a rich brown color with a sleek, glossy coat. The rider is wearing a red and green riding jacket, a white helmet, and black riding boots. The lighting is bright and natural, suggesting a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18648.0, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.288, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 70.8}, "timestamp": "2026-01-31T00:04:57.701982"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3096.84, "latencies_ms": [3096.84], "images_per_second": 0.323, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 6, "output_text": "A man is sitting on a folding chair, leaning against a box filled with various items, while another man stands nearby, both seemingly engaged in their respective activities.", "error": null, "sys_before": {"cpu_percent": 28.7, "ram_used_mb": 18648.0, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.168, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 73.4}, "timestamp": "2026-01-31T00:05:02.914656"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4697.358, "latencies_ms": [4697.358], "images_per_second": 0.213, "prompt_tokens": 26, "response_tokens_est": 59, "n_tiles": 6, "output_text": "1. Man: 1\n2. Car: 1\n3. Bicycle: 1\n4. Sign: 1\n5. Shoebox: 1\n6. Cart: 1\n7. Bag: 1\n8. Table: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.838, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 70.41}, "timestamp": "2026-01-31T00:05:09.637659"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5943.659, "latencies_ms": [5943.659], "images_per_second": 0.168, "prompt_tokens": 30, "response_tokens_est": 80, "n_tiles": 6, "output_text": "In the image, the man is positioned in the foreground, sitting on a folding chair near a small table with various items on it. The table is situated on the sidewalk, close to a bicycle parked on the side. The background features a street with parked cars and a building with a sign in Chinese characters. The man appears to be engaged in a conversation or looking at something on the table.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.6, "ram_available_mb": 44192.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18649.3, "ram_available_mb": 44191.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.076, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 69.551}, "timestamp": "2026-01-31T00:05:17.605610"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5767.932, "latencies_ms": [5767.932], "images_per_second": 0.173, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The image depicts a street scene in an urban area, likely in a city with East Asian characters on signs. A man is sitting on a folding chair, surrounded by various items on a table, including a bicycle. Another man is standing nearby, and there are cars parked along the street. The setting appears to be a busy, pedestrian-friendly area with shops and street vendors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.3, "ram_available_mb": 44191.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.047, "power_cpu_cv_mean_watts": 1.919, "power_sys_5v0_mean_watts": 8.059, "gpu_utilization_percent_mean": 69.312}, "timestamp": "2026-01-31T00:05:25.420949"}
{"image_index": 367, "image_name": "000000040083.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040083.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5069.983, "latencies_ms": [5069.983], "images_per_second": 0.197, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The image is a black and white photograph depicting a street scene with notable visual attributes. The scene is characterized by a mix of materials, including a wooden bench, a metal folding chair, and a wooden crate filled with various items. The lighting is natural, with sunlight casting shadows on the ground, indicating a daytime setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.49, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 69.714}, "timestamp": "2026-01-31T00:05:32.521731"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2446.334, "latencies_ms": [2446.334], "images_per_second": 0.409, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "The image shows a kitchen with white cabinets, a black ceiling fan, and a window with blinds.", "error": null, "sys_before": {"cpu_percent": 35.7, "ram_used_mb": 18649.7, "ram_available_mb": 44191.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.326, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 74.7}, "timestamp": "2026-01-31T00:05:37.116353"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4200.676, "latencies_ms": [4200.676], "images_per_second": 0.238, "prompt_tokens": 26, "response_tokens_est": 51, "n_tiles": 6, "output_text": "- Kitchen\n- Count: 1\n- Count: 1\n- Count: 1\n- Count: 1\n- Count: 1\n- Count: 1\n- Count: 1\n- Count: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.367, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 71.657}, "timestamp": "2026-01-31T00:05:43.331499"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5931.71, "latencies_ms": [5931.71], "images_per_second": 0.169, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The main objects in the image are the kitchen cabinets, the refrigerator, and the countertop. The cabinets are located on the left side of the image, while the refrigerator is on the right. The countertop is situated in the middle, between the cabinets and the refrigerator. The countertop is also the focal point of the image, as it is where the various kitchen items are placed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.823, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 68.74}, "timestamp": "2026-01-31T00:05:51.280822"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5216.264, "latencies_ms": [5216.264], "images_per_second": 0.192, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a dimly lit kitchen with a white ceiling and white cabinets. The kitchen is equipped with a white refrigerator, a microwave, and various kitchen utensils and appliances scattered on the countertop. The scene appears to be in a residential setting, possibly a home kitchen, with no people visible in the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.0, "ram_available_mb": 44189.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18651.3, "ram_available_mb": 44189.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.159, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 7.967, "gpu_utilization_percent_mean": 69.465}, "timestamp": "2026-01-31T00:05:58.508851"}
{"image_index": 368, "image_name": "000000040471.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040471.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3015.048, "latencies_ms": [3015.048], "images_per_second": 0.332, "prompt_tokens": 22, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The kitchen is well-lit with a combination of natural and artificial light. The walls are painted white, and the ceiling features a classic light fixture.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18651.3, "ram_available_mb": 44189.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.398, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 74.958}, "timestamp": "2026-01-31T00:06:03.542937"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2464.151, "latencies_ms": [2464.151], "images_per_second": 0.406, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "A young child is lying on a bed, smiling and laughing, with a pacifier in their mouth.", "error": null, "sys_before": {"cpu_percent": 27.7, "ram_used_mb": 18650.4, "ram_available_mb": 44190.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.245, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 77.35}, "timestamp": "2026-01-31T00:06:08.142016"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3203.144, "latencies_ms": [3203.144], "images_per_second": 0.312, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 6, "output_text": "1. Baby\n2. Crib\n3. Pillow\n4. Bed\n5. Child\n6. Sheet\n7. Toys\n8. Car", "error": null, "sys_before": {"cpu_percent": 4.3, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.732, "power_cpu_cv_mean_watts": 1.417, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 73.385}, "timestamp": "2026-01-31T00:06:13.381367"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5300.106, "latencies_ms": [5300.106], "images_per_second": 0.189, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main object in the foreground is a child lying on a bed, with a blue pacifier in their mouth. The child is positioned near the center of the image, with a patterned blanket covering the bed. The background is mostly dark, with a dark wall and a small portion of a television screen visible at the top left corner.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.331, "power_cpu_cv_mean_watts": 1.829, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 70.023}, "timestamp": "2026-01-31T00:06:20.703460"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5004.078, "latencies_ms": [5004.078], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a young child lying on a bed, seemingly asleep. The child is wearing a light-colored tank top and is surrounded by a patterned bedspread with various cartoon-like motifs. The room appears to be dimly lit, with a focus on the child, creating a cozy and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.49, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 69.714}, "timestamp": "2026-01-31T00:06:27.719848"}
{"image_index": 369, "image_name": "000000040757.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000040757.jpg", "image_width": 425, "image_height": 640, "image_resolution": "425x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5242.542, "latencies_ms": [5242.542], "images_per_second": 0.191, "prompt_tokens": 22, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The image depicts a young child lying on a bed, covered with a patterned blanket. The blanket features a mix of light and dark colors, with a pattern of small, colorful vehicles. The lighting in the room is dim, with a soft, warm glow illuminating the child's face, creating a cozy and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.271, "power_cpu_cv_mean_watts": 1.857, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 69.523}, "timestamp": "2026-01-31T00:06:34.990124"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3065.222, "latencies_ms": [3065.222], "images_per_second": 0.326, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The image shows a green highway sign with white lettering, indicating the direction to Queens Bronx, and a small, white, rectangular sign above it.", "error": null, "sys_before": {"cpu_percent": 22.0, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.106, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 74.88}, "timestamp": "2026-01-31T00:06:40.163534"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3849.844, "latencies_ms": [3849.844], "images_per_second": 0.26, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 6, "output_text": "1. Green highway sign\n2. Black metal structure\n3. Green highway sign\n4. White sign\n5. Green highway sign\n6. White sign\n7. Green highway sign\n8. White sign", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.676, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 72.531}, "timestamp": "2026-01-31T00:06:46.054711"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5808.536, "latencies_ms": [5808.536], "images_per_second": 0.172, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The main object in the foreground is a green highway sign with white text. The sign is mounted on a metal structure, likely part of a larger highway signage system. In the background, there is a blurred structure that appears to be part of a bridge or overpass. The sign is positioned near the center of the image, with the blurred structure to the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18648.8, "ram_available_mb": 44192.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.972, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.896}, "timestamp": "2026-01-31T00:06:53.890292"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5847.743, "latencies_ms": [5847.743], "images_per_second": 0.171, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The image depicts a green highway sign with white lettering, indicating \"Queens Bronx\" and the Interstate 278 highway number. The sign is mounted on a metal structure, likely part of a highway or freeway, with a blurred background featuring industrial or construction elements. The scene suggests an urban or suburban setting, possibly near a highway interchange or a city area.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.003, "power_cpu_cv_mean_watts": 1.912, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 68.898}, "timestamp": "2026-01-31T00:07:01.758978"}
{"image_index": 370, "image_name": "000000041488.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041488.jpg", "image_width": 640, "image_height": 369, "image_resolution": "640x369", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5187.494, "latencies_ms": [5187.494], "images_per_second": 0.193, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image features a green highway sign with white lettering, mounted on a metal structure. The sign is illuminated by artificial lighting, casting a bright glow on the sign and creating a stark contrast with the surrounding environment. The weather appears to be overcast, with a diffused light that softens the edges of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.471, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 69.795}, "timestamp": "2026-01-31T00:07:08.971433"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2615.601, "latencies_ms": [2615.601], "images_per_second": 0.382, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "The image features a classic red Chevrolet car parked outdoors, with a clear sky and a few other vehicles in the background.", "error": null, "sys_before": {"cpu_percent": 25.2, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.972, "power_cpu_cv_mean_watts": 1.329, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 76.318}, "timestamp": "2026-01-31T00:07:13.713217"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3907.626, "latencies_ms": [3907.626], "images_per_second": 0.256, "prompt_tokens": 26, "response_tokens_est": 46, "n_tiles": 6, "output_text": "1. Red car\n2. Red truck\n3. White license plate\n4. White license plate\n5. White license plate\n6. White license plate\n7. White license plate\n8. White license plate", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.692, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 71.576}, "timestamp": "2026-01-31T00:07:19.643269"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4457.954, "latencies_ms": [4457.954], "images_per_second": 0.224, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The main object in the foreground is a vintage red Chevrolet truck. The truck is parked on a concrete surface, with its front end facing the camera. The background features a green tent and other parked cars, indicating that the scene is likely at a car show or gathering.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.939, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 70.237}, "timestamp": "2026-01-31T00:07:26.140938"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4289.271, "latencies_ms": [4289.271], "images_per_second": 0.233, "prompt_tokens": 24, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The image depicts a classic red Chevrolet pickup truck parked outdoors, likely at a car show or gathering. The setting is a spacious area with a clear sky, and there are other vehicles and tents in the background, suggesting a social or recreational event.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.171, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 71.194}, "timestamp": "2026-01-31T00:07:32.484842"}
{"image_index": 371, "image_name": "000000041633.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041633.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4632.215, "latencies_ms": [4632.215], "images_per_second": 0.216, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The notable visual attributes of the red car in the image include its glossy finish, which reflects the surrounding environment, and its classic design reminiscent of mid-20th century automobiles. The lighting is natural, with a partly cloudy sky casting soft shadows on the car's surface.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.905, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 70.308}, "timestamp": "2026-01-31T00:07:39.161891"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5049.185, "latencies_ms": [5049.185], "images_per_second": 0.198, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image depicts a black and white photograph of a group of cows standing in a field, with a barbed wire fence running horizontally across the frame, separating them from the viewer.", "error": null, "sys_before": {"cpu_percent": 31.4, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18647.9, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.636, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.796, "gpu_utilization_percent_mean": 88.286}, "timestamp": "2026-01-31T00:07:46.364440"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5043.937, "latencies_ms": [5043.937], "images_per_second": 0.198, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 12, "output_text": "1. Cows\n2. Barbed wire\n3. Grass\n4. Trees\n5. Sky\n6. Farmland\n7. House\n8. Animals", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.9, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.503, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 88.095}, "timestamp": "2026-01-31T00:07:53.421780"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6789.817, "latencies_ms": [6789.817], "images_per_second": 0.147, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The main objects in the image are a group of cows, with the foreground and background objects being the cows themselves. The cows are positioned in the foreground, with the background showing a more distant view of the landscape. The cows are near the fence, which is in the middle ground, and the fence is in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.367, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 85.456}, "timestamp": "2026-01-31T00:08:02.265150"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6193.334, "latencies_ms": [6193.334], "images_per_second": 0.161, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a rural scene with a barbed wire fence stretching across the frame. In the foreground, there are several cows, some of which are standing and others are lying down. The cows appear to be grazing on the grassy area enclosed by the fence.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.63, "power_cpu_cv_mean_watts": 1.517, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 86.308}, "timestamp": "2026-01-31T00:08:10.485548"}
{"image_index": 372, "image_name": "000000041635.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041635.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6435.675, "latencies_ms": [6435.675], "images_per_second": 0.155, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The image is a black and white photograph featuring a group of cows standing in a field. The cows have a mix of white and brown coats, and their fur appears slightly tousled. The lighting is natural, with the sun casting shadows on the ground, indicating a bright but overcast day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.532, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 85.873}, "timestamp": "2026-01-31T00:08:18.955149"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4191.88, "latencies_ms": [4191.88], "images_per_second": 0.239, "prompt_tokens": 12, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image depicts a cozy, warmly lit bedroom with a wooden bed frame, a beige bedspread, and a wooden chair with a cushion. The room features a fireplace with a stone surround and a television mounted on the wall above it.", "error": null, "sys_before": {"cpu_percent": 29.9, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.4, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.266, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 71.457}, "timestamp": "2026-01-31T00:08:25.260645"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4248.991, "latencies_ms": [4248.991], "images_per_second": 0.235, "prompt_tokens": 26, "response_tokens_est": 51, "n_tiles": 6, "output_text": "- bed: 1\n- nightstand: 1\n- lamp: 1\n- chair: 1\n- fireplace: 1\n- TV: 1\n- blinds: 1\n- wall clock: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.4, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.07, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 71.057}, "timestamp": "2026-01-31T00:08:31.543055"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5795.941, "latencies_ms": [5795.941], "images_per_second": 0.173, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The main objects in the image are a bed, a chair, and a fireplace. The bed is positioned in the foreground, with a cushion on the left side. The chair is placed near the bed, and the fireplace is situated to the right of the bed. The fireplace is the most prominent object in the image, with a dark stone surround and a visible fire burning inside.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.916, "power_cpu_cv_mean_watts": 1.896, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 69.367}, "timestamp": "2026-01-31T00:08:39.389740"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6087.543, "latencies_ms": [6087.543], "images_per_second": 0.164, "prompt_tokens": 24, "response_tokens_est": 82, "n_tiles": 6, "output_text": "The image depicts a cozy, warmly lit bedroom with a wooden ceiling and walls. The room features a large bed with a brown bedspread, a wooden nightstand with a lamp, and a beige armchair. There is a fireplace with a stone surround and a small television mounted on the wall above it. The room has a warm, inviting ambiance with soft lighting and comfortable furnishings.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.819, "power_cpu_cv_mean_watts": 1.924, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 69.118}, "timestamp": "2026-01-31T00:08:47.491155"}
{"image_index": 373, "image_name": "000000041872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041872.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3609.736, "latencies_ms": [3609.736], "images_per_second": 0.277, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The room is warmly lit with a soft, yellowish glow, creating a cozy atmosphere. The wooden ceiling and walls, along with the wooden furniture, contribute to a rustic and inviting ambiance.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.991, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 72.233}, "timestamp": "2026-01-31T00:08:53.136526"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4662.706, "latencies_ms": [4662.706], "images_per_second": 0.214, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "The image depicts a group of turkeys standing on dry, brown grass in a natural, open field, with one turkey slightly bending down to eat.", "error": null, "sys_before": {"cpu_percent": 28.7, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.075, "power_cpu_cv_mean_watts": 1.263, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 86.974}, "timestamp": "2026-01-31T00:08:59.945366"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4748.022, "latencies_ms": [4748.022], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Turkey\n2. Turkey\n3. Turkey\n4. Turkey\n5. Turkey\n6. Turkey\n7. Turkey\n8. Turkey", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.806, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.776, "gpu_utilization_percent_mean": 88.5}, "timestamp": "2026-01-31T00:09:06.727121"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5456.102, "latencies_ms": [5456.102], "images_per_second": 0.183, "prompt_tokens": 30, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The main objects in the image are a group of turkeys. The turkeys are positioned in the foreground, with one standing and another lying down. The background features a dry, grassy field with sparse vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.224, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 87.478}, "timestamp": "2026-01-31T00:09:14.211624"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6461.981, "latencies_ms": [6461.981], "images_per_second": 0.155, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image depicts a serene natural setting with dry, brown grass covering the ground. In the foreground, there are two turkeys standing and one of them is partially buried in the grass. The scene suggests a tranquil, possibly arid environment where the turkeys are foraging or resting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.543, "power_cpu_cv_mean_watts": 1.587, "power_sys_5v0_mean_watts": 8.876, "gpu_utilization_percent_mean": 84.527}, "timestamp": "2026-01-31T00:09:22.714125"}
{"image_index": 374, "image_name": "000000041888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041888.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5836.159, "latencies_ms": [5836.159], "images_per_second": 0.171, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The image depicts a scene with a dry, grassy landscape under a cloudy sky. The grass is brown and dry, indicating a lack of recent rainfall. The lighting is soft and diffused, casting a gentle glow over the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.905, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 86.796}, "timestamp": "2026-01-31T00:09:30.598845"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5324.688, "latencies_ms": [5324.688], "images_per_second": 0.188, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 12, "output_text": "Two skiers are standing on a snowy slope, each holding a ski pole and wearing appropriate winter gear, including helmets and goggles, as they enjoy their time skiing in the snowy environment.", "error": null, "sys_before": {"cpu_percent": 28.7, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.453, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 8.855, "gpu_utilization_percent_mean": 86.455}, "timestamp": "2026-01-31T00:09:38.076887"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5283.86, "latencies_ms": [5283.86], "images_per_second": 0.189, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 12, "output_text": "1. Ski poles\n2. Ski boots\n3. Ski skis\n4. Ski poles\n5. Ski poles\n6. Ski poles\n7. Ski poles\n8. Ski poles", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.28, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 87.795}, "timestamp": "2026-01-31T00:09:45.405460"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10099.022, "latencies_ms": [10099.022], "images_per_second": 0.099, "prompt_tokens": 30, "response_tokens_est": 121, "n_tiles": 12, "output_text": "The main objects in the image are two skiers, one on the left and one on the right. The skier on the left is closer to the foreground, while the skier on the right is further back. The skier on the left is standing on a snow-covered slope, holding ski poles, and wearing a red jacket. The skier on the right is also on a snow-covered slope, but is closer to the background, wearing a black jacket and holding ski poles. Both skiers are surrounded by snow, and there is a snow-covered forest in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18641.9, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.326, "power_cpu_cv_mean_watts": 1.856, "power_sys_5v0_mean_watts": 8.855, "gpu_utilization_percent_mean": 82.812}, "timestamp": "2026-01-31T00:09:57.544776"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7026.827, "latencies_ms": [7026.827], "images_per_second": 0.142, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The scene depicts a snowy landscape with a group of people engaged in skiing. The individuals are dressed in winter gear, including jackets, pants, and goggles, and are using ski poles to navigate the snowy terrain. The setting is a snowy mountainous area, and the individuals appear to be enjoying their time skiing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.9, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.239, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 85.492}, "timestamp": "2026-01-31T00:10:06.621528"}
{"image_index": 375, "image_name": "000000041990.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000041990.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8241.923, "latencies_ms": [8241.923], "images_per_second": 0.121, "prompt_tokens": 22, "response_tokens_est": 90, "n_tiles": 12, "output_text": "The image depicts a snowy landscape with two skiers. The skiers are dressed in winter gear, including jackets, pants, and goggles, and are holding ski poles. The snow is white and appears to be freshly fallen, with some patches of snow still clinging to the trees in the background. The lighting is soft and diffused, likely due to the overcast sky, and the overall atmosphere is serene and peaceful.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.763, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 8.848, "gpu_utilization_percent_mean": 84.087}, "timestamp": "2026-01-31T00:10:16.914239"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5348.371, "latencies_ms": [5348.371], "images_per_second": 0.187, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image shows a white bus with a digital display showing the number 51 and the word \"CROSSTOWN\" on its front, parked on a street with a partly cloudy sky in the background.", "error": null, "sys_before": {"cpu_percent": 26.1, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.348, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 86.614}, "timestamp": "2026-01-31T00:10:24.419483"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5640.332, "latencies_ms": [5640.332], "images_per_second": 0.177, "prompt_tokens": 26, "response_tokens_est": 47, "n_tiles": 12, "output_text": "- Bus: 1\n- Bus number display: 1\n- Building: 1\n- Street light: 1\n- Street sign: 1\n- Street pole: 1\n- Car: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.073, "power_cpu_cv_mean_watts": 1.414, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 87.149}, "timestamp": "2026-01-31T00:10:32.073552"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5217.204, "latencies_ms": [5217.204], "images_per_second": 0.192, "prompt_tokens": 30, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The bus is positioned in the foreground, with its front facing the camera. The license plate is visible on the front of the bus. The background features a building and a partly cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.477, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 87.558}, "timestamp": "2026-01-31T00:10:39.309913"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5458.814, "latencies_ms": [5458.814], "images_per_second": 0.183, "prompt_tokens": 24, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image depicts a white bus with a digital display showing the number \"51\" and \"CROSSTOWN\" in red letters. The bus is parked on a street with a clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.142, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 87.174}, "timestamp": "2026-01-31T00:10:46.801294"}
{"image_index": 376, "image_name": "000000042070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042070.jpg", "image_width": 640, "image_height": 512, "image_resolution": "640x512", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6311.069, "latencies_ms": [6311.069], "images_per_second": 0.158, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The bus in the image is predominantly white with blue and green accents. The digital display shows the number \"51\" and \"CROSSTOWN\" in red. The lighting is bright and natural, indicating daytime. The weather appears to be clear with a blue sky and some clouds.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.577, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 86.0}, "timestamp": "2026-01-31T00:10:55.159595"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3822.976, "latencies_ms": [3822.976], "images_per_second": 0.262, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 10, "output_text": "The image shows a man dressed in a formal blue suit, white shirt, and striped tie, standing against a white wall.", "error": null, "sys_before": {"cpu_percent": 31.1, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6650.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.196, "power_cpu_cv_mean_watts": 1.162, "power_sys_5v0_mean_watts": 8.584, "gpu_utilization_percent_mean": 85.0}, "timestamp": "2026-01-31T00:11:01.133289"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4229.606, "latencies_ms": [4229.606], "images_per_second": 0.236, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 10, "output_text": "1. man\n2. suit\n3. tie\n4. skirt\n5. tights\n6. shoes\n7. bag\n8. wall", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6661.0, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.526, "power_cpu_cv_mean_watts": 1.304, "power_sys_5v0_mean_watts": 8.572, "gpu_utilization_percent_mean": 84.257}, "timestamp": "2026-01-31T00:11:07.374542"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6695.745, "latencies_ms": [6695.745], "images_per_second": 0.149, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 10, "output_text": "The main object in the image is a young man standing in front of a plain white wall. He is dressed in a dark blue suit, white shirt, and striped tie. His right hand is slightly raised, and he is holding a black handbag in his left hand. The background is a plain white wall, and the man is positioned in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6664.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.722, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 8.604, "gpu_utilization_percent_mean": 79.339}, "timestamp": "2026-01-31T00:11:16.099730"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5610.852, "latencies_ms": [5610.852], "images_per_second": 0.178, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 10, "output_text": "The image depicts a man dressed in a formal blue suit and tie standing against a plain white wall. He is holding a black handbag in his left hand and has his right hand slightly extended. The setting appears to be indoors, possibly in a professional or formal environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6659.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.272, "power_cpu_cv_mean_watts": 1.558, "power_sys_5v0_mean_watts": 8.572, "gpu_utilization_percent_mean": 80.652}, "timestamp": "2026-01-31T00:11:23.739743"}
{"image_index": 377, "image_name": "000000042102.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042102.jpg", "image_width": 246, "image_height": 640, "image_resolution": "246x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5074.962, "latencies_ms": [5074.962], "images_per_second": 0.197, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 10, "output_text": "The man is dressed in a dark blue suit with a white shirt and a striped tie. The lighting is bright, casting a clear shadow of the man on the wall. The man is wearing black tights and black shoes.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6658.0, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.637, "power_cpu_cv_mean_watts": 1.478, "power_sys_5v0_mean_watts": 8.576, "gpu_utilization_percent_mean": 82.452}, "timestamp": "2026-01-31T00:11:30.840486"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5028.348, "latencies_ms": [5028.348], "images_per_second": 0.199, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image depicts a large, industrial facility with numerous tall, metallic structures, possibly part of a power plant or a large warehouse, surrounded by a hazy, foggy atmosphere.", "error": null, "sys_before": {"cpu_percent": 31.8, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.535, "power_cpu_cv_mean_watts": 1.335, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 88.952}, "timestamp": "2026-01-31T00:11:38.053580"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5246.229, "latencies_ms": [5246.229], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "1. Power lines\n2. Power lines\n3. Power lines\n4. Power lines\n5. Power lines\n6. Power lines\n7. Power lines\n8. Power lines", "error": null, "sys_before": {"cpu_percent": 22.2, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.276, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 87.682}, "timestamp": "2026-01-31T00:11:45.342487"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5904.405, "latencies_ms": [5904.405], "images_per_second": 0.169, "prompt_tokens": 30, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The main objects in the image are a series of train tracks and overhead electric lines. The tracks are located in the foreground, while the electric lines stretch across the background. The train tracks are near the foreground, and the electric lines are further back.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.816, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 86.592}, "timestamp": "2026-01-31T00:11:53.264972"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7148.33, "latencies_ms": [7148.33], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a large, industrial setting with a series of metallic structures, possibly part of a factory or a warehouse. The scene is bathed in a warm, yellowish light, suggesting either early morning or late afternoon. The structures are filled with numerous wires and cables, and there are signs with numbers indicating specific locations or areas within the facility.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.17, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 85.083}, "timestamp": "2026-01-31T00:12:02.451473"}
{"image_index": 378, "image_name": "000000042178.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042178.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 8849.253, "latencies_ms": [8849.253], "images_per_second": 0.113, "prompt_tokens": 22, "response_tokens_est": 100, "n_tiles": 12, "output_text": "The image depicts a scene with a hazy, overcast sky, casting a soft, diffused light over the entire scene. The lighting is muted, with a warm, yellowish tint, creating a serene and somewhat melancholic atmosphere. The materials in the scene include a series of metallic structures, possibly part of a train or industrial setup, and the overall color palette is dominated by shades of gray and brown, with occasional glimmers of light reflecting off the metallic surfaces.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.53, "power_cpu_cv_mean_watts": 1.785, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 83.622}, "timestamp": "2026-01-31T00:12:13.339740"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4289.092, "latencies_ms": [4289.092], "images_per_second": 0.233, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "The image shows a bathroom with a toilet, a shower curtain, a towel rack, and various shoes scattered on the floor.", "error": null, "sys_before": {"cpu_percent": 40.6, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.4, "power_cpu_cv_mean_watts": 1.146, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 88.639}, "timestamp": "2026-01-31T00:12:19.835787"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5257.819, "latencies_ms": [5257.819], "images_per_second": 0.19, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 12, "output_text": "1. Toilet\n2. Shoebox\n3. Gloves\n4. Gloves\n5. Gloves\n6. Gloves\n7. Gloves\n8. Gloves", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.448, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 87.591}, "timestamp": "2026-01-31T00:12:27.137069"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6488.429, "latencies_ms": [6488.429], "images_per_second": 0.154, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The main objects in the image are a toilet, a pair of shoes, and a helmet. The toilet is located in the background, while the shoes and helmet are in the foreground. The shoes are scattered on the floor near the toilet, and the helmet is placed on top of a white box.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.53, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 85.291}, "timestamp": "2026-01-31T00:12:35.683313"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7600.428, "latencies_ms": [7600.428], "images_per_second": 0.132, "prompt_tokens": 24, "response_tokens_est": 80, "n_tiles": 12, "output_text": "The image depicts a cluttered bathroom floor with various items scattered around. The bathroom has a white toilet, a green stool with a plant on it, a pair of shoes, a black and white helmet, and a white towel hanging on the wall. The scene appears to be a personal space, possibly a bedroom or a bathroom, with a focus on the messiness of the area.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.116, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.894, "gpu_utilization_percent_mean": 84.625}, "timestamp": "2026-01-31T00:12:45.296887"}
{"image_index": 379, "image_name": "000000042276.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042276.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5220.404, "latencies_ms": [5220.404], "images_per_second": 0.192, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The bathroom is well-lit with natural light, creating a bright and airy atmosphere. The walls are painted in a light color, complementing the overall clean and tidy look of the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.395, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.798, "gpu_utilization_percent_mean": 88.047}, "timestamp": "2026-01-31T00:12:52.540038"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3045.036, "latencies_ms": [3045.036], "images_per_second": 0.328, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 6, "output_text": "A polar bear is seen playfully splashing in a pool of water, with a green ball nearby, while another polar bear is seen in the background.", "error": null, "sys_before": {"cpu_percent": 23.8, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.153, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 74.64}, "timestamp": "2026-01-31T00:12:57.720107"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1848.35, "latencies_ms": [1848.35], "images_per_second": 0.541, "prompt_tokens": 26, "response_tokens_est": 12, "n_tiles": 6, "output_text": "ball: 3\npolar bear: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.069, "power_cpu_cv_mean_watts": 0.881, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 82.467}, "timestamp": "2026-01-31T00:13:01.584363"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4820.331, "latencies_ms": [4820.331], "images_per_second": 0.207, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The main objects in the image are a polar bear and a ball. The polar bear is in the foreground, swimming near the green and yellow balls. The green ball is near the polar bear, while the yellow ball is further away. The background features a sandy area with rocks and some vegetation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.714, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 70.475}, "timestamp": "2026-01-31T00:13:08.436662"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6371.26, "latencies_ms": [6371.26], "images_per_second": 0.157, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 6, "output_text": "The image depicts a polar bear in a shallow body of water, likely a pool or a shallow river, engaging in playful behavior. The bear is seen holding a ball in its mouth, with its paws submerged in the water, creating a dynamic and lively scene. The setting appears to be an outdoor environment, possibly a zoo or a wildlife sanctuary, given the presence of rocks and a sandy area in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.732, "power_cpu_cv_mean_watts": 1.942, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 68.925}, "timestamp": "2026-01-31T00:13:16.843984"}
{"image_index": 380, "image_name": "000000042296.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042296.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4415.943, "latencies_ms": [4415.943], "images_per_second": 0.226, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The image depicts a polar bear swimming in a body of water, with its fur appearing white and its paws visible. The lighting is bright, indicating it is daytime, and the water is clear, allowing for a good view of the bear and its surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.983, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 70.973}, "timestamp": "2026-01-31T00:13:23.293404"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4200.946, "latencies_ms": [4200.946], "images_per_second": 0.238, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "A person is holding a Samsung mobile phone in their hand, with a pair of blue jeans visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 31.3, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.535, "power_cpu_cv_mean_watts": 1.11, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 87.829}, "timestamp": "2026-01-31T00:13:29.672162"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4120.303, "latencies_ms": [4120.303], "images_per_second": 0.243, "prompt_tokens": 26, "response_tokens_est": 22, "n_tiles": 12, "output_text": "cell phone: 1\nclothes: 1\nfloor: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18638.0, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.743, "power_cpu_cv_mean_watts": 1.072, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 91.265}, "timestamp": "2026-01-31T00:13:35.834868"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5414.448, "latencies_ms": [5414.448], "images_per_second": 0.185, "prompt_tokens": 30, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The main object in the foreground is a person's hand holding a mobile phone. The phone is positioned near the person's hand. The background features a wooden floor and a window with a view of the sky.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18638.0, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.198, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.795, "gpu_utilization_percent_mean": 87.711}, "timestamp": "2026-01-31T00:13:43.266624"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5686.503, "latencies_ms": [5686.503], "images_per_second": 0.176, "prompt_tokens": 24, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The image depicts a person holding a Samsung flip phone, which is placed on a wooden surface. The background shows a wooden floor and a window with a view of the sky. The person's hand is visible, holding the phone.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.147, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 87.383}, "timestamp": "2026-01-31T00:13:50.996312"}
{"image_index": 381, "image_name": "000000042528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042528.jpg", "image_width": 640, "image_height": 495, "image_resolution": "640x495", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5394.794, "latencies_ms": [5394.794], "images_per_second": 0.185, "prompt_tokens": 22, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The image features a wooden floor with a clear, bright sky visible through a skylight above. The lighting is natural, casting soft shadows and highlighting the textures of the wooden planks and the metallic phone.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.265, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 87.489}, "timestamp": "2026-01-31T00:13:58.437537"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1783.93, "latencies_ms": [1783.93], "images_per_second": 0.561, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 1, "output_text": "A yellow train is traveling on a snowy track, surrounded by snow-laden trees and a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 17.3, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18636.6, "ram_available_mb": 44204.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.268, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 6.72, "gpu_utilization_percent_mean": 73.357}, "timestamp": "2026-01-31T00:14:02.294242"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8210.707, "latencies_ms": [8210.707], "images_per_second": 0.122, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 1, "output_text": "train: 1\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees: 3\ntrees:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.6, "ram_available_mb": 44204.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.623, "power_cpu_cv_mean_watts": 2.251, "power_sys_5v0_mean_watts": 7.278, "gpu_utilization_percent_mean": 64.565}, "timestamp": "2026-01-31T00:14:12.556577"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4723.113, "latencies_ms": [4723.113], "images_per_second": 0.212, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 1, "output_text": "The main object in the foreground is a yellow train moving on the tracks. The train is positioned near the center of the image, slightly to the left. The background features a snowy landscape with trees and a snow-covered ground. The train is in the middle of the scene, with the trees and snow-covered ground extending towards the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18637.5, "ram_available_mb": 44203.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.5, "power_cpu_cv_mean_watts": 2.094, "power_sys_5v0_mean_watts": 7.148, "gpu_utilization_percent_mean": 67.077}, "timestamp": "2026-01-31T00:14:19.304070"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3642.35, "latencies_ms": [3642.35], "images_per_second": 0.275, "prompt_tokens": 24, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The image depicts a snowy scene on a railway track, with a train traveling through a snowy landscape. The train is moving away from the viewer, and the surrounding area is covered in snow, with trees and a cloudy sky visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18637.5, "ram_available_mb": 44203.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18638.0, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.612, "power_cpu_cv_mean_watts": 2.015, "power_sys_5v0_mean_watts": 7.077, "gpu_utilization_percent_mean": 66.31}, "timestamp": "2026-01-31T00:14:24.963448"}
{"image_index": 382, "image_name": "000000042563.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042563.jpg", "image_width": 624, "image_height": 640, "image_resolution": "624x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4093.047, "latencies_ms": [4093.047], "images_per_second": 0.244, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 1, "output_text": "The image depicts a snowy scene with a train traveling on a snow-covered railway track. The train is painted in a bright yellow color, contrasting sharply against the white snow. The sky is overcast, with a uniform gray hue, indicating a cold and possibly snowy weather condition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.0, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.502, "power_cpu_cv_mean_watts": 2.074, "power_sys_5v0_mean_watts": 7.108, "gpu_utilization_percent_mean": 67.879}, "timestamp": "2026-01-31T00:14:31.076527"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2615.31, "latencies_ms": [2615.31], "images_per_second": 0.382, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "A group of people are walking through a snow-covered area, with a large pile of snow blocking the path.", "error": null, "sys_before": {"cpu_percent": 29.8, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.57, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 74.3}, "timestamp": "2026-01-31T00:14:35.821234"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3567.183, "latencies_ms": [3567.183], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.104, "power_cpu_cv_mean_watts": 1.505, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 72.379}, "timestamp": "2026-01-31T00:14:41.422309"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5436.805, "latencies_ms": [5436.805], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 6, "output_text": "The main objects in the image are a snow-covered area with a fire hydrant in the foreground and a group of people in the background. The fire hydrant is located near the center of the image, while the people are further back, indicating a spatial relationship where the fire hydrant is closer to the viewer and the people are farther away.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.233, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.156}, "timestamp": "2026-01-31T00:14:48.871613"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4588.61, "latencies_ms": [4588.61], "images_per_second": 0.218, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a snowy urban scene with a large pile of snow blocking a street. Several people are walking through the snow, some carrying bags. The setting appears to be a city street during winter, with vehicles parked on the side and a brick wall in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.845, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 70.553}, "timestamp": "2026-01-31T00:14:55.496216"}
{"image_index": 383, "image_name": "000000042628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042628.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5026.348, "latencies_ms": [5026.348], "images_per_second": 0.199, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a snow-covered scene with a large pile of snow in the foreground, a few people walking through the snow, and a fire hydrant partially buried in the snow. The lighting is dim, suggesting it is either early morning or late afternoon, and the overall atmosphere is cold and wintry.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.384, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 70.476}, "timestamp": "2026-01-31T00:15:02.572287"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5271.584, "latencies_ms": [5271.584], "images_per_second": 0.19, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image shows a street sign indicating a \"TOW ZONE\" with a red arrow pointing to the right, and a yellow sign with a cartoonish face on the left side of the signpost.", "error": null, "sys_before": {"cpu_percent": 33.3, "ram_used_mb": 18639.9, "ram_available_mb": 44201.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.367, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 86.356}, "timestamp": "2026-01-31T00:15:10.016375"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5230.217, "latencies_ms": [5230.217], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.301, "power_cpu_cv_mean_watts": 1.337, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 87.568}, "timestamp": "2026-01-31T00:15:17.286595"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7888.177, "latencies_ms": [7888.177], "images_per_second": 0.127, "prompt_tokens": 30, "response_tokens_est": 84, "n_tiles": 12, "output_text": "The main objects in the image are a tree, a street sign, and a yellow object. The tree is in the foreground, with its branches and leaves partially obscuring the view of the street sign. The street sign is positioned in the middle ground, slightly behind the tree. The yellow object, which appears to be a sign or a piece of equipment, is located near the tree, closer to the background.", "error": null, "sys_before": {"cpu_percent": 5.6, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.921, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.859, "gpu_utilization_percent_mean": 84.364}, "timestamp": "2026-01-31T00:15:27.221178"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6200.543, "latencies_ms": [6200.543], "images_per_second": 0.161, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a street scene with a yellow traffic sign attached to a metal pole. The sign reads \"TOW ZONE\" and features a red prohibition symbol. The surrounding area is lush with green foliage, indicating a park or a tree-lined street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.639, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 8.796, "gpu_utilization_percent_mean": 85.769}, "timestamp": "2026-01-31T00:15:35.477614"}
{"image_index": 384, "image_name": "000000042888.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042888.jpg", "image_width": 500, "image_height": 374, "image_resolution": "500x374", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6734.088, "latencies_ms": [6734.088], "images_per_second": 0.148, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image features a street sign with a red border and a white background, prominently displaying a red prohibition sign with a white arrow pointing to the right. The sign is mounted on a metal pole, and the surrounding area is lush with green foliage, indicating a sunny day with ample sunlight illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.374, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 85.446}, "timestamp": "2026-01-31T00:15:44.233058"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4571.533, "latencies_ms": [4571.533], "images_per_second": 0.219, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The image shows a collection of vintage electronic devices, including a keyboard, a mouse, and a small white speaker, all resting on a red surface.", "error": null, "sys_before": {"cpu_percent": 38.5, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.318, "power_cpu_cv_mean_watts": 1.265, "power_sys_5v0_mean_watts": 8.872, "gpu_utilization_percent_mean": 88.605}, "timestamp": "2026-01-31T00:15:50.976371"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5017.595, "latencies_ms": [5017.595], "images_per_second": 0.199, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 12, "output_text": "1. teddy bear\n2. glasses\n3. earphones\n4. cell phone\n5. keyboard\n6. mouse\n7. cord\n8. computer mouse", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.674, "power_cpu_cv_mean_watts": 1.344, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 88.548}, "timestamp": "2026-01-31T00:15:58.039504"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6408.489, "latencies_ms": [6408.489], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The main objects in the image are a teddy bear, a keyboard, and a mouse. The teddy bear is positioned in the foreground, while the keyboard and mouse are in the background. The keyboard is on the left side of the image, and the mouse is on the right side.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.615, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 85.87}, "timestamp": "2026-01-31T00:16:06.473341"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7959.874, "latencies_ms": [7959.874], "images_per_second": 0.126, "prompt_tokens": 24, "response_tokens_est": 86, "n_tiles": 12, "output_text": "The image depicts a cozy, dimly lit room with a plush teddy bear as the central focus. The bear is adorned with glasses and is surrounded by various electronic devices, including a keyboard, a mouse, and a small white object that appears to be a remote control. The setting suggests a personal space, possibly a bedroom or a living room, where the bear is comfortably resting amidst the technological gadgets.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.934, "power_cpu_cv_mean_watts": 1.726, "power_sys_5v0_mean_watts": 8.863, "gpu_utilization_percent_mean": 84.088}, "timestamp": "2026-01-31T00:16:16.457005"}
{"image_index": 385, "image_name": "000000042889.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000042889.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5505.541, "latencies_ms": [5505.541], "images_per_second": 0.182, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The image features a teddy bear with a light brown fur coat, wearing glasses with a brown frame. The bear is resting on a red surface, and the background is dark, creating a contrast that highlights the bear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.995, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 86.894}, "timestamp": "2026-01-31T00:16:23.998763"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5201.167, "latencies_ms": [5201.167], "images_per_second": 0.192, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The image captures a dynamic moment of a skier in mid-air, performing a jump over a snowy mountain slope, with the skier wearing a white and orange outfit and a helmet for safety.", "error": null, "sys_before": {"cpu_percent": 34.5, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.482, "power_cpu_cv_mean_watts": 1.383, "power_sys_5v0_mean_watts": 8.846, "gpu_utilization_percent_mean": 86.523}, "timestamp": "2026-01-31T00:16:31.367784"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5201.717, "latencies_ms": [5201.717], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.4, "power_cpu_cv_mean_watts": 1.374, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 88.114}, "timestamp": "2026-01-31T00:16:38.624595"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7011.194, "latencies_ms": [7011.194], "images_per_second": 0.143, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The main objects in the image are a snowboarder and a snowy mountain landscape. The snowboarder is positioned in the foreground, slightly off-center to the left, while the snowy mountain landscape is in the background. The snowboarder is near the snow-covered slope, and the snowy mountain landscape extends into the distance.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.335, "power_cpu_cv_mean_watts": 1.622, "power_sys_5v0_mean_watts": 8.878, "gpu_utilization_percent_mean": 85.305}, "timestamp": "2026-01-31T00:16:47.676653"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6165.591, "latencies_ms": [6165.591], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image captures a dynamic winter scene featuring a skier in mid-air, executing a jump over a snowy mountain. The skier is dressed in a white and orange outfit, and the snowy landscape is adorned with snow-covered trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.756, "power_cpu_cv_mean_watts": 1.54, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 85.865}, "timestamp": "2026-01-31T00:16:55.877500"}
{"image_index": 386, "image_name": "000000043314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043314.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5765.828, "latencies_ms": [5765.828], "images_per_second": 0.173, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image depicts a snowy mountainous landscape with a clear blue sky. The snow is pristine and untouched, indicating a recent snowfall. The lighting is bright and natural, casting shadows and highlighting the texture of the snow.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.043, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 8.797, "gpu_utilization_percent_mean": 86.917}, "timestamp": "2026-01-31T00:17:03.675435"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2744.735, "latencies_ms": [2744.735], "images_per_second": 0.364, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 4, "output_text": "A surfer is skillfully riding a wave on a surfboard, with the water splashing around them and the sun casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5451.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.221, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.625, "gpu_utilization_percent_mean": 67.818}, "timestamp": "2026-01-31T00:17:08.532547"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3199.387, "latencies_ms": [3199.387], "images_per_second": 0.313, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 4, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5463.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.252, "power_cpu_cv_mean_watts": 1.694, "power_sys_5v0_mean_watts": 7.631, "gpu_utilization_percent_mean": 67.577}, "timestamp": "2026-01-31T00:17:13.776937"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5633.518, "latencies_ms": [5633.518], "images_per_second": 0.178, "prompt_tokens": 30, "response_tokens_est": 80, "n_tiles": 4, "output_text": "The main object in the image is a surfer riding a wave. The surfer is positioned in the foreground, slightly to the right, and is the closest to the viewer. The wave is in the background, slightly to the left, and is the largest object in the image. The surfboard is also in the foreground, closer to the viewer, and is positioned near the surfer.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5465.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.287, "power_cpu_cv_mean_watts": 1.977, "power_sys_5v0_mean_watts": 7.686, "gpu_utilization_percent_mean": 64.957}, "timestamp": "2026-01-31T00:17:21.431551"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5576.981, "latencies_ms": [5576.981], "images_per_second": 0.179, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 4, "output_text": "The image captures a dynamic scene of a surfer riding a wave in the ocean. The surfer is skillfully maneuvering on a surfboard, with the wave curling around them, creating a frothy white crest. The setting is a vast ocean with a clear sky, and the surfer is the central focus of the image, showcasing the thrill and beauty of surfing.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5460.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.177, "power_cpu_cv_mean_watts": 1.985, "power_sys_5v0_mean_watts": 7.675, "gpu_utilization_percent_mean": 64.979}, "timestamp": "2026-01-31T00:17:29.052736"}
{"image_index": 387, "image_name": "000000043435.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043435.jpg", "image_width": 638, "image_height": 640, "image_resolution": "638x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5678.316, "latencies_ms": [5678.316], "images_per_second": 0.176, "prompt_tokens": 22, "response_tokens_est": 81, "n_tiles": 4, "output_text": "The image captures a dynamic scene of a surfer riding a wave, with the surfer and the wave in sharp focus against a backdrop of a calm ocean. The lighting is natural, with sunlight reflecting off the water, creating a shimmering effect. The colors are primarily shades of blue and white, with the surfer's dark wetsuit providing a contrast against the lighter water and sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5459.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.339, "power_cpu_cv_mean_watts": 1.976, "power_sys_5v0_mean_watts": 7.691, "gpu_utilization_percent_mean": 64.489}, "timestamp": "2026-01-31T00:17:36.747639"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3494.513, "latencies_ms": [3494.513], "images_per_second": 0.286, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image shows a pizza with various toppings, including cheese, vegetables, and possibly meat, all placed on a metal pizza tray, which is placed on a table with a blue cloth.", "error": null, "sys_before": {"cpu_percent": 28.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.92, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.957, "gpu_utilization_percent_mean": 71.9}, "timestamp": "2026-01-31T00:17:42.373037"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3041.5, "latencies_ms": [3041.5], "images_per_second": 0.329, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Pizza\n2. Plate\n3. Pizza\n4. Pizza\n5. Pizza\n6. Pizza\n7. Pizza\n8. Pizza", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.414, "power_cpu_cv_mean_watts": 1.49, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 74.72}, "timestamp": "2026-01-31T00:17:47.455215"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6217.954, "latencies_ms": [6217.954], "images_per_second": 0.161, "prompt_tokens": 30, "response_tokens_est": 84, "n_tiles": 6, "output_text": "The main object in the foreground is a pizza with a variety of toppings, including cheese, vegetables, and possibly meat. The pizza is placed on a metal tray. In the background, there is a jar of sauce and a napkin or paper towel. The pizza and the tray are on a table with a blue tablecloth, and the background is slightly blurred, indicating a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.661, "power_cpu_cv_mean_watts": 1.927, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 68.623}, "timestamp": "2026-01-31T00:17:55.707925"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5921.602, "latencies_ms": [5921.602], "images_per_second": 0.169, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image depicts a pizza on a blue plate, placed on a table with a red surface. The pizza appears to be freshly baked, with a golden-brown crust and a variety of toppings, including melted cheese, pieces of meat, and green herbs. The setting suggests a casual dining environment, possibly a restaurant or a home kitchen, with dim lighting and a blurred background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.816, "power_cpu_cv_mean_watts": 1.914, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 68.98}, "timestamp": "2026-01-31T00:18:03.671223"}
{"image_index": 388, "image_name": "000000043581.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043581.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4640.903, "latencies_ms": [4640.903], "images_per_second": 0.215, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The image features a pizza with a golden-brown crust, topped with melted cheese and various toppings, including pieces of meat and vegetables. The pizza is placed on a blue plate, and the background is dimly lit with a bluish hue, creating a cozy and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.891, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 70.513}, "timestamp": "2026-01-31T00:18:10.347977"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4946.489, "latencies_ms": [4946.489], "images_per_second": 0.202, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 12, "output_text": "The image depicts a street scene during winter, with a prominent black clock mounted on a pole, snow-covered sidewalks, and a row of buildings with lit-up windows.", "error": null, "sys_before": {"cpu_percent": 29.7, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.866, "power_cpu_cv_mean_watts": 1.319, "power_sys_5v0_mean_watts": 8.846, "gpu_utilization_percent_mean": 87.951}, "timestamp": "2026-01-31T00:18:17.432189"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5714.474, "latencies_ms": [5714.474], "images_per_second": 0.175, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 12, "output_text": "- clock: 1\n- building: 1\n- street: 1\n- car: 1\n- sign: 1\n- tree: 1\n- sidewalk: 1\n- building: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.967, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 86.854}, "timestamp": "2026-01-31T00:18:25.173614"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6017.314, "latencies_ms": [6017.314], "images_per_second": 0.166, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The main objects in the image are a street clock and a row of buildings. The street clock is positioned on the left side of the image, near the foreground. The row of buildings is located in the background, extending towards the right side of the image.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.799, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.798, "gpu_utilization_percent_mean": 86.36}, "timestamp": "2026-01-31T00:18:33.233912"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6656.197, "latencies_ms": [6656.197], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image depicts a snowy urban street scene during twilight. The street is lined with buildings, and a large, ornate clock is prominently displayed on a pole. The clock face shows the time as approximately 7:00, and the surrounding area is covered in snow, indicating a winter setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.408, "power_cpu_cv_mean_watts": 1.587, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 84.364}, "timestamp": "2026-01-31T00:18:41.906003"}
{"image_index": 389, "image_name": "000000043737.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043737.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6774.972, "latencies_ms": [6774.972], "images_per_second": 0.148, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a street scene during winter, with a prominent black clock mounted on a pole. The clock face is white with black Roman numerals, and the hands indicate a time of approximately 10:10. The surrounding area is covered in snow, and the sky is clear, suggesting a cold but sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.347, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 85.737}, "timestamp": "2026-01-31T00:18:50.718541"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3473.47, "latencies_ms": [3473.47], "images_per_second": 0.288, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 6, "output_text": "A baseball player in a white and blue uniform is swinging a bat at a baseball, while a catcher in red gear is crouched behind home plate, ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 26.9, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.329, "power_cpu_cv_mean_watts": 1.559, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 73.179}, "timestamp": "2026-01-31T00:18:56.293532"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4176.48, "latencies_ms": [4176.48], "images_per_second": 0.239, "prompt_tokens": 26, "response_tokens_est": 50, "n_tiles": 6, "output_text": "baseball player: 1\ncatcher: 1\numpire: 1\nhome plate: 1\nglove: 1\nbat: 1\npitcher: 1\ncatcher's mask: 1", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.414, "power_cpu_cv_mean_watts": 1.708, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 71.941}, "timestamp": "2026-01-31T00:19:02.501692"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7215.199, "latencies_ms": [7215.199], "images_per_second": 0.139, "prompt_tokens": 30, "response_tokens_est": 100, "n_tiles": 6, "output_text": "The baseball player in the foreground is positioned on the left side of the image, wearing a white and blue uniform with a blue helmet. He is in the midst of swinging his bat, with his body angled towards the right side of the image. The catcher, wearing a red uniform, is positioned in the background on the right side of the image, crouched behind the home plate. The baseball is in the air, slightly to the left of the player, near the bat.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.249, "power_cpu_cv_mean_watts": 1.989, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 67.883}, "timestamp": "2026-01-31T00:19:11.737237"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4746.164, "latencies_ms": [4746.164], "images_per_second": 0.211, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image captures a dynamic moment during a baseball game, featuring a batter in mid-swing, a catcher in position, and a umpire ready to make a call. The scene takes place on a well-maintained baseball field with a dirt infield and green grass surrounding it.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.782, "power_cpu_cv_mean_watts": 1.822, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 70.525}, "timestamp": "2026-01-31T00:19:18.505135"}
{"image_index": 390, "image_name": "000000043816.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000043816.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3792.111, "latencies_ms": [3792.111], "images_per_second": 0.264, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The baseball player is wearing a blue helmet and white pinstripe uniform, which stands out against the green grass and brown dirt of the field. The lighting is bright and sunny, casting sharp shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.779, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 71.688}, "timestamp": "2026-01-31T00:19:24.345306"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4301.825, "latencies_ms": [4301.825], "images_per_second": 0.232, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "A plush teddy bear with a red and white checkered bow around its neck is resting on a red leather chair.", "error": null, "sys_before": {"cpu_percent": 29.6, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.51, "power_cpu_cv_mean_watts": 1.157, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 90.583}, "timestamp": "2026-01-31T00:19:30.801930"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5601.559, "latencies_ms": [5601.559], "images_per_second": 0.179, "prompt_tokens": 26, "response_tokens_est": 46, "n_tiles": 12, "output_text": "1. teddy bear\n2. chair\n3. cushion\n4. wicker basket\n5. red bow tie\n6. red pillow\n7. blue and white striped fabric\n8. wicker chair", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.06, "power_cpu_cv_mean_watts": 1.448, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 86.957}, "timestamp": "2026-01-31T00:19:38.449213"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7164.132, "latencies_ms": [7164.132], "images_per_second": 0.14, "prompt_tokens": 30, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The main object in the foreground is a brown teddy bear with a red and white plaid bow around its neck. The bear is resting on a red leather cushion. In the background, there is a wicker chair with a brown cushion. The wicker chair is partially visible, and the brown cushion is placed on top of the wicker chair.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.124, "power_cpu_cv_mean_watts": 1.642, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 84.983}, "timestamp": "2026-01-31T00:19:47.666139"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7482.372, "latencies_ms": [7482.372], "images_per_second": 0.134, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The image depicts a cozy indoor scene featuring a plush teddy bear with a red and white checkered bow around its neck. The bear is resting on a red leather chair, which is placed on a woven wicker surface. The setting appears to be a warm and inviting room, possibly a living room or a bedroom, with soft lighting that enhances the comforting atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.88, "power_cpu_cv_mean_watts": 1.673, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 84.694}, "timestamp": "2026-01-31T00:19:57.161053"}
{"image_index": 391, "image_name": "000000044068.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044068.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7528.768, "latencies_ms": [7528.768], "images_per_second": 0.133, "prompt_tokens": 22, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The notable visual attributes of the image include a brown teddy bear with a red and white plaid bow around its neck, resting on a red leather chair. The lighting is soft and warm, casting a gentle glow on the scene. The materials used in the image include the brown leather of the chair, the plaid bow, and the woven wicker of the chair's seat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.918, "power_cpu_cv_mean_watts": 1.665, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 84.635}, "timestamp": "2026-01-31T00:20:06.719640"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4453.356, "latencies_ms": [4453.356], "images_per_second": 0.225, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "Two people are standing on a snowy mountain slope, with one holding a snowboard and the other wearing a red jacket and black pants.", "error": null, "sys_before": {"cpu_percent": 31.5, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.407, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.877, "gpu_utilization_percent_mean": 89.162}, "timestamp": "2026-01-31T00:20:13.316840"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5026.947, "latencies_ms": [5026.947], "images_per_second": 0.199, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 12, "output_text": "1. Snowboard\n2. Person\n3. Snow\n4. Ski\n5. Ski poles\n6. Ski boots\n7. Ski jacket\n8. Ski pants", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.583, "power_cpu_cv_mean_watts": 1.306, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 88.119}, "timestamp": "2026-01-31T00:20:20.386245"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7431.128, "latencies_ms": [7431.128], "images_per_second": 0.135, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The main objects in the image are two individuals standing on a snowy slope. The person on the left is wearing a red jacket and black pants, while the person on the right is wearing a red jacket and black pants. The snowy slope is in the foreground, with the individuals standing near the center of the image. The background features a clear blue sky and distant mountains.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.091, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 8.85, "gpu_utilization_percent_mean": 84.625}, "timestamp": "2026-01-31T00:20:29.829665"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6176.838, "latencies_ms": [6176.838], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a snowy mountainous landscape under a clear blue sky. Two individuals are standing on the snow, one holding a snowboard. The snowboarder is wearing a red jacket and black pants, while the other is in a red jacket and black pants.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.659, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 86.212}, "timestamp": "2026-01-31T00:20:38.048983"}
{"image_index": 392, "image_name": "000000044195.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044195.jpg", "image_width": 361, "image_height": 500, "image_resolution": "361x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5623.829, "latencies_ms": [5623.829], "images_per_second": 0.178, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The image depicts a bright, sunny day with clear blue skies. The snowy landscape is illuminated by the sun, casting a warm glow on the snow and creating a vivid contrast between the bright sunlight and the darker shadows.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.124, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 87.617}, "timestamp": "2026-01-31T00:20:45.687286"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3425.267, "latencies_ms": [3425.267], "images_per_second": 0.292, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The image depicts a close-up view of a tree branch adorned with several red apples, some of which are hanging from the branch, while the rest are resting on the ground.", "error": null, "sys_before": {"cpu_percent": 21.8, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.103, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-31T00:20:51.234284"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1752.794, "latencies_ms": [1752.794], "images_per_second": 0.571, "prompt_tokens": 26, "response_tokens_est": 10, "n_tiles": 6, "output_text": "apple: 3\ntree: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.029, "power_cpu_cv_mean_watts": 0.772, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 83.714}, "timestamp": "2026-01-31T00:20:55.043662"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4462.351, "latencies_ms": [4462.351], "images_per_second": 0.224, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The main objects in the image are a tree branch with red apples hanging from it. The apples are located in the foreground, with the branch extending towards the background. The background features a blurred natural setting with trees and foliage, creating a sense of depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.972, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 70.737}, "timestamp": "2026-01-31T00:21:01.537606"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4162.729, "latencies_ms": [4162.729], "images_per_second": 0.24, "prompt_tokens": 24, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a rustic scene of an old, gnarled tree with a few red apples hanging from its branches. The background is blurred, but hints of a forested area can be seen, suggesting a natural, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.24, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 71.314}, "timestamp": "2026-01-31T00:21:07.751120"}
{"image_index": 393, "image_name": "000000044260.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044260.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4040.99, "latencies_ms": [4040.99], "images_per_second": 0.247, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The image features a tree with a brown trunk and branches, some of which are bare. The leaves are mostly brown, indicating it might be autumn. The lighting is soft and warm, suggesting it is either early morning or late afternoon.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.534, "power_cpu_cv_mean_watts": 1.687, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 71.848}, "timestamp": "2026-01-31T00:21:13.806524"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5138.476, "latencies_ms": [5138.476], "images_per_second": 0.195, "prompt_tokens": 12, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a busy kitchen scene with two men wearing white uniforms, engaged in food preparation. One man is seen stirring ingredients in a large metal pot, while the other is handling a tray of food. The kitchen is equipped with various cooking utensils and appliances, and the overall atmosphere is one of professional culinary activity.", "error": null, "sys_before": {"cpu_percent": 31.4, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.409, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.372}, "timestamp": "2026-01-31T00:21:21.073600"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3065.905, "latencies_ms": [3065.905], "images_per_second": 0.326, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Chef\n2. Chef\n3. Chef\n4. Chef\n5. Chef\n6. Chef\n7. Chef\n8. Chef", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.104, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 74.76}, "timestamp": "2026-01-31T00:21:26.154375"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7160.406, "latencies_ms": [7160.406], "images_per_second": 0.14, "prompt_tokens": 30, "response_tokens_est": 100, "n_tiles": 6, "output_text": "In the image, the main objects are the two men working in the kitchen. The man in the foreground is focused on pouring a substance from a container into a bowl, while the man in the background is handling a tray of food. The kitchen is well-equipped with various utensils and appliances, and the countertops are cluttered with various items. The man in the foreground is positioned near the center of the image, while the man in the background is slightly to the left.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.5, "ram_available_mb": 44192.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.403, "power_cpu_cv_mean_watts": 1.995, "power_sys_5v0_mean_watts": 8.079, "gpu_utilization_percent_mean": 68.517}, "timestamp": "2026-01-31T00:21:35.340638"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5247.291, "latencies_ms": [5247.291], "images_per_second": 0.191, "prompt_tokens": 24, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The image depicts a bustling kitchen scene with two men wearing white uniforms, engaged in food preparation. They are surrounded by various kitchen tools and equipment, including a large stainless steel pot, a cutting board, and a stainless steel sink. The setting appears to be a professional kitchen, likely in a restaurant or a food service establishment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.8, "ram_available_mb": 44193.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.286, "power_cpu_cv_mean_watts": 1.838, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 69.727}, "timestamp": "2026-01-31T00:21:42.605405"}
{"image_index": 394, "image_name": "000000044279.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044279.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3982.566, "latencies_ms": [3982.566], "images_per_second": 0.251, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image depicts a busy kitchen scene with a metallic and industrial aesthetic. The lighting is bright, casting a warm glow over the workspace. The materials used include stainless steel surfaces, metal utensils, and various kitchen tools.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.436, "power_cpu_cv_mean_watts": 1.672, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.029}, "timestamp": "2026-01-31T00:21:48.642144"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3967.323, "latencies_ms": [3967.323], "images_per_second": 0.252, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 10, "output_text": "A group of people is gathered around a row of motorcycles parked on the side of a road, with some of them wearing helmets.", "error": null, "sys_before": {"cpu_percent": 31.5, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6650.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.995, "power_cpu_cv_mean_watts": 1.189, "power_sys_5v0_mean_watts": 8.593, "gpu_utilization_percent_mean": 82.818}, "timestamp": "2026-01-31T00:21:54.767665"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2913.317, "latencies_ms": [2913.317], "images_per_second": 0.343, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 10, "output_text": "motorcycle: 5\npeople: 3", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.3, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6661.0, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.547, "power_cpu_cv_mean_watts": 0.834, "power_sys_5v0_mean_watts": 8.518, "gpu_utilization_percent_mean": 90.0}, "timestamp": "2026-01-31T00:21:59.719121"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5871.284, "latencies_ms": [5871.284], "images_per_second": 0.17, "prompt_tokens": 30, "response_tokens_est": 60, "n_tiles": 10, "output_text": "The group of men is standing near the parked motorcycles, with the motorcycles positioned on the right side of the road. The motorcycles are in the foreground, while the men are in the background. The motorcycles are near the road, and the men are standing on the roadside.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6664.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.103, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.558, "gpu_utilization_percent_mean": 80.367}, "timestamp": "2026-01-31T00:22:07.648848"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5868.382, "latencies_ms": [5868.382], "images_per_second": 0.17, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 10, "output_text": "The image depicts a group of people gathered around a row of motorcycles parked on the side of a road. The setting appears to be outdoors during the daytime, with a cloudy sky overhead. The group seems to be engaged in a conversation, possibly discussing the motorcycles or their plans.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6659.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.979, "power_cpu_cv_mean_watts": 1.593, "power_sys_5v0_mean_watts": 8.534, "gpu_utilization_percent_mean": 80.429}, "timestamp": "2026-01-31T00:22:15.569256"}
{"image_index": 395, "image_name": "000000044590.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044590.jpg", "image_width": 640, "image_height": 246, "image_resolution": "640x246", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6149.487, "latencies_ms": [6149.487], "images_per_second": 0.163, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 10, "output_text": "The image depicts a group of people standing next to a row of motorcycles on a roadside. The sky is overcast, casting a soft, diffused light over the scene. The motorcycles are parked on the side of the road, and the people are dressed in casual attire suitable for cool weather.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4620.4, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 6658.0, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.944, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.577, "gpu_utilization_percent_mean": 79.196}, "timestamp": "2026-01-31T00:22:23.740087"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3368.6, "latencies_ms": [3368.6], "images_per_second": 0.297, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 6, "output_text": "A black and white photograph captures a single-engine airplane in mid-flight, with its propellers spinning and the tail of the aircraft visible against a backdrop of a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 39.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.253, "power_cpu_cv_mean_watts": 1.53, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 73.143}, "timestamp": "2026-01-31T00:22:29.271897"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3564.076, "latencies_ms": [3564.076], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18647.7, "ram_available_mb": 44193.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.943, "power_cpu_cv_mean_watts": 1.561, "power_sys_5v0_mean_watts": 7.961, "gpu_utilization_percent_mean": 72.4}, "timestamp": "2026-01-31T00:22:34.887364"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4342.25, "latencies_ms": [4342.25], "images_per_second": 0.23, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The main object in the image is a small airplane, which is positioned in the foreground. The airplane is flying towards the right side of the frame. The background consists of a cloudy sky, which is slightly blurred, indicating the airplane is moving quickly.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.135, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-31T00:22:41.253367"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3852.842, "latencies_ms": [3852.842], "images_per_second": 0.26, "prompt_tokens": 24, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image depicts a black and white photograph of a small airplane in flight, with its propellers spinning. The airplane is captured against a backdrop of a cloudy sky, creating a dramatic and somewhat moody atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.612, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 72.375}, "timestamp": "2026-01-31T00:22:47.138977"}
{"image_index": 396, "image_name": "000000044652.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044652.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5296.646, "latencies_ms": [5296.646], "images_per_second": 0.189, "prompt_tokens": 22, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The image features a monochromatic scene with a single airplane in flight against a cloudy sky. The airplane is predominantly white with black and gray accents, and it appears to be a small, single-engine plane. The lighting is soft and diffused, suggesting an overcast day, and the overall mood is serene and calm.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.223, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 69.356}, "timestamp": "2026-01-31T00:22:54.459091"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2954.706, "latencies_ms": [2954.706], "images_per_second": 0.338, "prompt_tokens": 12, "response_tokens_est": 30, "n_tiles": 6, "output_text": "A group of sheep stands on a rocky hillside with a serene lake in the background, surrounded by green hills and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 24.3, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.211, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-31T00:22:59.523225"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3562.589, "latencies_ms": [3562.589], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.6, "ram_available_mb": 44193.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.065, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.978, "gpu_utilization_percent_mean": 71.967}, "timestamp": "2026-01-31T00:23:05.122941"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6653.157, "latencies_ms": [6653.157], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 91, "n_tiles": 6, "output_text": "In the image, the main objects are a group of sheep located in the foreground and a body of water in the background. The sheep are positioned on a rocky terrain, with the largest sheep standing in the center, slightly to the right. The smaller sheep are scattered around the larger sheep, with one near the center and another to the right. The body of water is situated behind the sheep, creating a natural boundary between the foreground and the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.46, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 68.25}, "timestamp": "2026-01-31T00:23:13.796341"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3978.346, "latencies_ms": [3978.346], "images_per_second": 0.251, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image depicts a serene landscape featuring a group of sheep grazing on a grassy hillside. The sheep are surrounded by a picturesque view of a calm, turquoise lake nestled between rolling hills and mountains.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.631, "power_cpu_cv_mean_watts": 1.686, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 71.424}, "timestamp": "2026-01-31T00:23:19.823833"}
{"image_index": 397, "image_name": "000000044699.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044699.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4166.79, "latencies_ms": [4166.79], "images_per_second": 0.24, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a serene landscape with a group of sheep standing on a rocky hillside. The sheep are predominantly white, with some having darker patches. The scene is bathed in natural sunlight, casting soft shadows on the rocky terrain.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.317, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 71.529}, "timestamp": "2026-01-31T00:23:26.020255"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2459.554, "latencies_ms": [2459.554], "images_per_second": 0.407, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "The image shows a woman in a wheelchair holding a tennis racket, with another person in the background.", "error": null, "sys_before": {"cpu_percent": 31.1, "ram_used_mb": 18647.3, "ram_available_mb": 44193.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.226, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 77.6}, "timestamp": "2026-01-31T00:23:30.608470"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3917.837, "latencies_ms": [3917.837], "images_per_second": 0.255, "prompt_tokens": 26, "response_tokens_est": 46, "n_tiles": 6, "output_text": "1. Woman in wheelchair\n2. Tennis racket\n3. Wheelchair\n4. Tennis ball\n5. Tennis court\n6. Tennis player\n7. Tennis player's shirt\n8. Tennis player's shorts", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.533, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 71.242}, "timestamp": "2026-01-31T00:23:36.539839"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6329.875, "latencies_ms": [6329.875], "images_per_second": 0.158, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 6, "output_text": "The main objects in the image are a woman in a wheelchair and a tennis racket. The woman is positioned in the foreground, with the racket held in her right hand, indicating she is likely preparing to play tennis. The background features another person, slightly out of focus, who is also holding a tennis racket. The wheelchair and racket are positioned near the woman, suggesting they are part of the same activity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.73, "power_cpu_cv_mean_watts": 1.964, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 68.755}, "timestamp": "2026-01-31T00:23:44.890783"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5842.548, "latencies_ms": [5842.548], "images_per_second": 0.171, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The image depicts a scene at an outdoor tennis court where a woman in a wheelchair is actively playing tennis. She is holding a tennis racket and appears to be focused on the game. In the background, another person is also present, possibly a coach or teammate, observing the game. The setting is an open-air tennis court with a plain, light-colored wall in the background.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.962, "power_cpu_cv_mean_watts": 1.92, "power_sys_5v0_mean_watts": 8.028, "gpu_utilization_percent_mean": 69.245}, "timestamp": "2026-01-31T00:23:52.752199"}
{"image_index": 398, "image_name": "000000044877.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000044877.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4596.201, "latencies_ms": [4596.201], "images_per_second": 0.218, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The woman in the wheelchair is wearing a gray t-shirt with a white logo and a purple design. The lighting in the image is natural, suggesting it is daytime. The background is out of focus, but it appears to be an outdoor setting with a plain, light-colored wall.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.5, "ram_available_mb": 44194.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.811, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 70.179}, "timestamp": "2026-01-31T00:23:59.368583"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2438.329, "latencies_ms": [2438.329], "images_per_second": 0.41, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 1, "output_text": "A young girl in a black helmet and plaid shirt is sitting on a purple horse, with a brown saddle and a purple blanket, in a lush green forest setting.", "error": null, "sys_before": {"cpu_percent": 16.4, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.511, "power_cpu_cv_mean_watts": 1.862, "power_sys_5v0_mean_watts": 6.879, "gpu_utilization_percent_mean": 69.8}, "timestamp": "2026-01-31T00:24:03.905055"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3815.165, "latencies_ms": [3815.165], "images_per_second": 0.262, "prompt_tokens": 26, "response_tokens_est": 57, "n_tiles": 1, "output_text": "- child: 1\n- helmet: 1\n- shirt: 1\n- pants: 1\n- saddle: 1\n- horse: 1\n- saddle pad: 1\n- bridle: 1\n- reins: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.598, "power_cpu_cv_mean_watts": 2.015, "power_sys_5v0_mean_watts": 7.088, "gpu_utilization_percent_mean": 66.645}, "timestamp": "2026-01-31T00:24:09.758537"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3143.273, "latencies_ms": [3143.273], "images_per_second": 0.318, "prompt_tokens": 30, "response_tokens_est": 46, "n_tiles": 1, "output_text": "The main object in the foreground is a young child sitting on a purple horse saddle. The child is wearing a black helmet and a pink and white plaid shirt. The background features a blurred natural setting with green trees.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.4, "ram_available_mb": 44193.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.707, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 6.931, "gpu_utilization_percent_mean": 65.92}, "timestamp": "2026-01-31T00:24:14.920942"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4067.527, "latencies_ms": [4067.527], "images_per_second": 0.246, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 1, "output_text": "In the image, a young child is seated on a purple horse, wearing a black helmet and a pink and white plaid shirt. The child is looking down, possibly at something on the ground. The background features a lush green forest, indicating that the scene takes place outdoors in a natural setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.672, "power_cpu_cv_mean_watts": 2.026, "power_sys_5v0_mean_watts": 7.049, "gpu_utilization_percent_mean": 64.727}, "timestamp": "2026-01-31T00:24:21.007782"}
{"image_index": 399, "image_name": "000000045070.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045070.jpg", "image_width": 640, "image_height": 596, "image_resolution": "640x596", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3728.324, "latencies_ms": [3728.324], "images_per_second": 0.268, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 1, "output_text": "The notable visual attributes of the image include a young child wearing a black helmet, a pink and white plaid shirt, blue jeans, and brown boots. The child is seated on a purple horse saddle, with a green tree background and a hint of overcast lighting.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.584, "power_cpu_cv_mean_watts": 1.988, "power_sys_5v0_mean_watts": 7.012, "gpu_utilization_percent_mean": 67.033}, "timestamp": "2026-01-31T00:24:26.763481"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2863.123, "latencies_ms": [2863.123], "images_per_second": 0.349, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 2, "output_text": "The image captures a dynamic scene of surfers riding waves in the ocean, with one surfer in the foreground skillfully maneuvering a surfboard amidst the frothy, blue-green waters.", "error": null, "sys_before": {"cpu_percent": 27.6, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.709, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.205, "gpu_utilization_percent_mean": 63.217}, "timestamp": "2026-01-31T00:24:31.677976"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2869.542, "latencies_ms": [2869.542], "images_per_second": 0.348, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 2, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.764, "power_cpu_cv_mean_watts": 1.863, "power_sys_5v0_mean_watts": 7.148, "gpu_utilization_percent_mean": 63.478}, "timestamp": "2026-01-31T00:24:36.565472"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4465.636, "latencies_ms": [4465.636], "images_per_second": 0.224, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 2, "output_text": "The main objects in the image are the two surfers on their boards, one in the foreground and the other slightly behind. The foreground surfer is closer to the viewer, while the background surfer is further away. The ocean is the vast background, with the surfers positioned in the foreground and slightly to the right.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.013, "power_cpu_cv_mean_watts": 2.067, "power_sys_5v0_mean_watts": 7.296, "gpu_utilization_percent_mean": 61.622}, "timestamp": "2026-01-31T00:24:43.053898"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4269.999, "latencies_ms": [4269.999], "images_per_second": 0.234, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 2, "output_text": "The image captures a dynamic scene of surfers riding waves in the ocean. The surfers are seen in action, with one in the foreground riding a wave and another in the background also riding a wave. The setting is a coastal area, likely in New Zealand, as indicated by the text in the image.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.991, "power_cpu_cv_mean_watts": 2.024, "power_sys_5v0_mean_watts": 7.263, "gpu_utilization_percent_mean": 62.222}, "timestamp": "2026-01-31T00:24:49.346549"}
{"image_index": 400, "image_name": "000000045090.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045090.jpg", "image_width": 500, "image_height": 259, "image_resolution": "500x259", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3176.561, "latencies_ms": [3176.561], "images_per_second": 0.315, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 2, "output_text": "The image captures a dynamic scene of surfers riding waves in a blue ocean. The surfers are dressed in black wetsuits, and the waves are breaking with white foam, indicating a sunny day with clear skies.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.429, "power_cpu_cv_mean_watts": 1.879, "power_sys_5v0_mean_watts": 7.145, "gpu_utilization_percent_mean": 63.423}, "timestamp": "2026-01-31T00:24:54.557283"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4229.794, "latencies_ms": [4229.794], "images_per_second": 0.236, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 12, "output_text": "The image shows a cozy kitchen with a window, a refrigerator, and various kitchen items on the countertops and shelves.", "error": null, "sys_before": {"cpu_percent": 32.7, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.942, "power_cpu_cv_mean_watts": 1.167, "power_sys_5v0_mean_watts": 8.859, "gpu_utilization_percent_mean": 90.0}, "timestamp": "2026-01-31T00:25:01.005822"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10508.525, "latencies_ms": [10508.525], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- window: 2\n- cabinet: 1\n- plant: 1\n- shelf: 1\n- drawer: 1\n- stove: 1\n- cup: 1\n- bowl: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer: 1\n- drawer", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.264, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 82.633}, "timestamp": "2026-01-31T00:25:13.530451"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6414.617, "latencies_ms": [6414.617], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The main objects in the image are located in the kitchen. The refrigerator is situated to the left, with various items stored inside. The stove is in the foreground, with a few pots and pans on it. The window is in the background, allowing natural light to illuminate the kitchen.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.678, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 85.926}, "timestamp": "2026-01-31T00:25:21.977639"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6154.738, "latencies_ms": [6154.738], "images_per_second": 0.162, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image depicts a cozy kitchen scene with warm lighting. The kitchen features a wooden cabinet with a window, a refrigerator, and various kitchen items on the countertops. The overall atmosphere is homely and inviting, with a focus on the natural light coming through the window.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.785, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 86.596}, "timestamp": "2026-01-31T00:25:30.189821"}
{"image_index": 401, "image_name": "000000045229.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045229.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5814.098, "latencies_ms": [5814.098], "images_per_second": 0.172, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The kitchen is warmly lit with a soft, yellowish glow, creating a cozy atmosphere. The wooden cabinets and countertops are painted in a warm, reddish-brown hue, complementing the natural light streaming in through the window.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.862, "power_cpu_cv_mean_watts": 1.455, "power_sys_5v0_mean_watts": 8.78, "gpu_utilization_percent_mean": 86.816}, "timestamp": "2026-01-31T00:25:38.045135"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3902.681, "latencies_ms": [3902.681], "images_per_second": 0.256, "prompt_tokens": 12, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The image depicts a rustic, red-painted wooden table with a stack of fresh, ripe oranges placed on a white plate, accompanied by a collection of red cups and a small, red pot filled with pink sticks.", "error": null, "sys_before": {"cpu_percent": 30.6, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.649, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 72.594}, "timestamp": "2026-01-31T00:25:44.068029"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3502.465, "latencies_ms": [3502.465], "images_per_second": 0.286, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 6, "output_text": "1. Pineapple\n2. Orange\n3. Red cup\n4. Red cup\n5. Red cup\n6. Red cup\n7. Red cup\n8. Red cup", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.294, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 72.345}, "timestamp": "2026-01-31T00:25:49.593687"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5012.63, "latencies_ms": [5012.63], "images_per_second": 0.199, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main objects in the image are a pineapple, a red bowl, a red cup, and a plate of oranges. The pineapple is positioned in the background, while the red bowl and cup are in the foreground. The plate of oranges is placed in the middle ground, slightly to the right.", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.497, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 69.952}, "timestamp": "2026-01-31T00:25:56.646521"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5727.49, "latencies_ms": [5727.49], "images_per_second": 0.175, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 6, "output_text": "The image depicts a rustic, dimly lit setting with a red table or countertop. On the table, there is a large, ripe pineapple, a pile of bright orange oranges, and several red cups. The table appears to be in a room with a red wall, and the overall atmosphere is warm and inviting, suggesting a cozy, homey environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.023, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-31T00:26:04.389328"}
{"image_index": 402, "image_name": "000000045472.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045472.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6017.585, "latencies_ms": [6017.585], "images_per_second": 0.166, "prompt_tokens": 22, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image features a vibrant red background with a large, dried pineapple placed on the left side. The pineapple has green and brown hues, and its stem is visible. On the right side, there is a stack of fresh, ripe oranges with a glossy surface, and a red ceramic bowl containing a red liquid. The lighting is dim, creating a warm and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.837, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 68.62}, "timestamp": "2026-01-31T00:26:12.434824"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4420.206, "latencies_ms": [4420.206], "images_per_second": 0.226, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "A man is holding a plate of fried chicken and a side of fries, with a small container of ketchup on the side.", "error": null, "sys_before": {"cpu_percent": 31.0, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.3, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 88.378}, "timestamp": "2026-01-31T00:26:19.047681"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10541.42, "latencies_ms": [10541.42], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- plate: 1\n- sandwich: 1\n- fork: 0\n- knife: 0\n- napkin: 0\n- cup: 1\n- spoon: 0\n- plate: 1\n- fork: 0\n- knife: 0\n- napkin: 0\n- cup: 1\n- spoon: 0\n- plate: 1\n- fork: 0\n- knife: 0\n- napkin: 0\n- cup: 1\n- spoon: 0\n- plate: 1\n- fork: 0", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.085, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 82.011}, "timestamp": "2026-01-31T00:26:31.614833"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6621.463, "latencies_ms": [6621.463], "images_per_second": 0.151, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The main object in the foreground is a plate of fried chicken, which is being held by a person. The plate is placed on a table. In the background, there are other people and a clock on the wall. The person holding the plate is in the foreground, while the background is slightly blurred.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.374, "power_cpu_cv_mean_watts": 1.587, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 85.196}, "timestamp": "2026-01-31T00:26:40.295174"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5941.596, "latencies_ms": [5941.596], "images_per_second": 0.168, "prompt_tokens": 24, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The image depicts a man holding a plate of food, which includes a piece of fried chicken and a piece of breaded chicken. The setting appears to be an indoor dining area, possibly a restaurant, with other patrons and tables visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.854, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 86.66}, "timestamp": "2026-01-31T00:26:48.278689"}
{"image_index": 403, "image_name": "000000045550.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045550.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5536.258, "latencies_ms": [5536.258], "images_per_second": 0.181, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image features a man with a beard and glasses, holding a plate of fried chicken and a side of fries. The lighting is warm, and the background is slightly blurred, with a clock and a menu board visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.217, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 8.851, "gpu_utilization_percent_mean": 87.489}, "timestamp": "2026-01-31T00:26:55.869140"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2970.919, "latencies_ms": [2970.919], "images_per_second": 0.337, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The image shows a rainy day with a person holding an umbrella, a bicycle parked on the sidewalk, and a building with a large glass window.", "error": null, "sys_before": {"cpu_percent": 21.4, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.377, "power_cpu_cv_mean_watts": 1.435, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 73.458}, "timestamp": "2026-01-31T00:27:00.937589"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3306.29, "latencies_ms": [3306.29], "images_per_second": 0.302, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 6, "output_text": "- window: 1\n- building: 1\n- umbrella: 1\n- bicycle: 3\n- street: 1\n- person: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.654, "power_cpu_cv_mean_watts": 1.512, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 73.37}, "timestamp": "2026-01-31T00:27:06.290039"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5371.176, "latencies_ms": [5371.176], "images_per_second": 0.186, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The main objects in the image are a building, a bicycle rack, and a person holding an umbrella. The bicycle rack is located near the building, while the person is near the bicycle rack. The person is holding an umbrella, which is positioned near the building. The bicycle rack is in the foreground, and the person is in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.266, "power_cpu_cv_mean_watts": 1.859, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 69.711}, "timestamp": "2026-01-31T00:27:13.692555"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6152.182, "latencies_ms": [6152.182], "images_per_second": 0.163, "prompt_tokens": 24, "response_tokens_est": 83, "n_tiles": 6, "output_text": "The image depicts a rainy day scene viewed through a large window. Outside, there is a wet pavement with a few people walking, including a child in a red umbrella. In the background, there are tall metal structures, possibly part of a building under construction, and a bicycle rack with several bicycles. The overall setting appears to be an urban area with a mix of modern architecture and infrastructure.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.841, "power_cpu_cv_mean_watts": 1.923, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 69.353}, "timestamp": "2026-01-31T00:27:21.868679"}
{"image_index": 404, "image_name": "000000045596.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045596.jpg", "image_width": 408, "image_height": 640, "image_resolution": "408x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4619.768, "latencies_ms": [4619.768], "images_per_second": 0.216, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 6, "output_text": "The image shows a rainy day with a grey, overcast sky. The ground is wet, reflecting the grey tones of the sky. The building and surrounding area are covered in a layer of rain, with a few scattered leaves on the ground indicating it might be autumn.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.347, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 7.951, "gpu_utilization_percent_mean": 69.769}, "timestamp": "2026-01-31T00:27:28.530889"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5150.971, "latencies_ms": [5150.971], "images_per_second": 0.194, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The image shows a close-up of a dish containing a creamy, white substance, likely a type of pasta, with a few visible pieces of a yellowish ingredient, possibly cheese or a sauce.", "error": null, "sys_before": {"cpu_percent": 34.4, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.303, "power_cpu_cv_mean_watts": 1.338, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 86.341}, "timestamp": "2026-01-31T00:27:35.870895"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5706.247, "latencies_ms": [5706.247], "images_per_second": 0.175, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 12, "output_text": "1. Macaroni\n2. Macaroni\n3. Macaroni\n4. Macaroni\n5. Macaroni\n6. Macaroni\n7. Macaroni\n8. Macaroni", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.938, "power_cpu_cv_mean_watts": 1.443, "power_sys_5v0_mean_watts": 8.812, "gpu_utilization_percent_mean": 86.542}, "timestamp": "2026-01-31T00:27:43.604695"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6133.564, "latencies_ms": [6133.564], "images_per_second": 0.163, "prompt_tokens": 30, "response_tokens_est": 55, "n_tiles": 12, "output_text": "The main objects in the image are a bowl of macaroni and cheese. The macaroni and cheese is in the foreground, with the bowl being the central focus. The background is blurred, indicating that the focus is on the macaroni and cheese.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.79, "power_cpu_cv_mean_watts": 1.524, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 85.615}, "timestamp": "2026-01-31T00:27:51.790570"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7043.348, "latencies_ms": [7043.348], "images_per_second": 0.142, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The image shows a close-up view of a bowl of macaroni and cheese. The macaroni is coated in a creamy white sauce, and the dish is set on a dark surface, possibly a table. The focus is on the macaroni, with the background slightly blurred, emphasizing the texture and color of the dish.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.095, "power_cpu_cv_mean_watts": 1.648, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 84.917}, "timestamp": "2026-01-31T00:28:00.887315"}
{"image_index": 405, "image_name": "000000045728.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000045728.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6007.531, "latencies_ms": [6007.531], "images_per_second": 0.166, "prompt_tokens": 22, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image features a close-up view of a creamy, white pasta dish with a glossy sheen, indicating it might be coated with a sauce or cream. The lighting is soft and diffused, casting gentle shadows and highlighting the smooth texture of the pasta.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.732, "power_cpu_cv_mean_watts": 1.515, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 85.922}, "timestamp": "2026-01-31T00:28:08.920390"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4853.729, "latencies_ms": [4853.729], "images_per_second": 0.206, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image shows a cluttered desk with a laptop, a desktop computer, a smartphone, a mouse, and a keyboard, all displaying green leaf patterns on their screens.", "error": null, "sys_before": {"cpu_percent": 32.4, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.779, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 87.475}, "timestamp": "2026-01-31T00:28:15.920536"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4972.506, "latencies_ms": [4972.506], "images_per_second": 0.201, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 12, "output_text": "1. Laptop\n2. Computer mouse\n3. Keyboard\n4. Monitor\n5. Laptop mouse\n6. Computer mouse\n7. Monitor\n8. Laptop mouse", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.683, "power_cpu_cv_mean_watts": 1.299, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 88.561}, "timestamp": "2026-01-31T00:28:22.914604"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7052.398, "latencies_ms": [7052.398], "images_per_second": 0.142, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The main objects in the image are a laptop, a mouse, and a computer monitor. The laptop is positioned in the foreground, slightly to the right, with the monitor displaying a green leaf pattern. The mouse is placed near the laptop, closer to the foreground. The background is mostly out of focus, emphasizing the laptop and the monitor.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.214, "power_cpu_cv_mean_watts": 1.608, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 85.0}, "timestamp": "2026-01-31T00:28:32.003722"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7589.84, "latencies_ms": [7589.84], "images_per_second": 0.132, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The image depicts a cluttered workspace with a laptop, a desktop computer, a smartphone, and a mouse. The workspace appears to be in a room with a white wall and a curtain, and the items are arranged on a white surface, possibly a desk. The scene suggests a casual, possibly home office environment where the user is engaged in various tasks, including using multiple devices simultaneously.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.916, "power_cpu_cv_mean_watts": 1.689, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 84.422}, "timestamp": "2026-01-31T00:28:41.617158"}
{"image_index": 406, "image_name": "000000046031.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046031.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6790.215, "latencies_ms": [6790.215], "images_per_second": 0.147, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image shows a workspace with a laptop, a desktop computer monitor, and a desktop computer monitor. The workspace is well-lit with natural light coming through a window, creating a bright and airy atmosphere. The colors are predominantly neutral, with the white surfaces and the green and black screens providing a clean and modern look.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.341, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 85.526}, "timestamp": "2026-01-31T00:28:50.426864"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4726.055, "latencies_ms": [4726.055], "images_per_second": 0.212, "prompt_tokens": 12, "response_tokens_est": 33, "n_tiles": 12, "output_text": "A young girl is sitting on a bed in a cozy bedroom, surrounded by toys and books, while a lamp and a small table with a lamp are nearby.", "error": null, "sys_before": {"cpu_percent": 30.2, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.86, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.853, "gpu_utilization_percent_mean": 87.55}, "timestamp": "2026-01-31T00:28:57.310492"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5143.58, "latencies_ms": [5143.58], "images_per_second": 0.194, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 12, "output_text": "bed: 1\npillow: 1\nnightstand: 1\nlamp: 1\nbook: 1\ntoy: 1\nbox: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.467, "power_cpu_cv_mean_watts": 1.369, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 88.023}, "timestamp": "2026-01-31T00:29:04.469135"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6308.866, "latencies_ms": [6308.866], "images_per_second": 0.159, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The main objects in the image are a bed, a nightstand, and a chair. The bed is positioned in the background, with the nightstand and chair positioned in the foreground. The chair is near the bed, while the nightstand is positioned to the left of the bed.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.637, "power_cpu_cv_mean_watts": 1.526, "power_sys_5v0_mean_watts": 8.822, "gpu_utilization_percent_mean": 86.245}, "timestamp": "2026-01-31T00:29:12.803184"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6649.216, "latencies_ms": [6649.216], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image depicts a cozy bedroom setting with a warm, orange wall. A young child is sitting on the bed, seemingly engaged in an activity, surrounded by various items such as books, a lamp, and a small table. The room is well-lit, with soft, warm lighting creating a comfortable atmosphere.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.487, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 85.75}, "timestamp": "2026-01-31T00:29:21.469177"}
{"image_index": 407, "image_name": "000000046048.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046048.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5442.874, "latencies_ms": [5442.874], "images_per_second": 0.184, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The room is warmly lit with a soft orange hue, creating a cozy and inviting atmosphere. The walls are adorned with a patterned red and gold fabric, adding a touch of elegance to the space.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.257, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 87.717}, "timestamp": "2026-01-31T00:29:28.942973"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5038.566, "latencies_ms": [5038.566], "images_per_second": 0.198, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "A baseball player in a red uniform is in the middle of a swing, while a catcher and an umpire are crouched behind him, ready to catch the ball.", "error": null, "sys_before": {"cpu_percent": 27.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.61, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 87.048}, "timestamp": "2026-01-31T00:29:36.125171"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5094.156, "latencies_ms": [5094.156], "images_per_second": 0.196, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "baseball bat: 1\ncatcher's mitt: 1\numpire: 1\nplayer: 1\npitcher: 1\nhome plate: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.517, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 88.372}, "timestamp": "2026-01-31T00:29:43.240079"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8186.888, "latencies_ms": [8186.888], "images_per_second": 0.122, "prompt_tokens": 30, "response_tokens_est": 89, "n_tiles": 12, "output_text": "The main object in the foreground is a baseball player in a red uniform, crouched near the home plate. The player is holding a bat and wearing protective gear. In the background, there is a catcher in a gray uniform, standing near the pitcher's mound. The catcher is wearing a helmet and catching gloves. The baseball field is well-maintained, with a dirt infield and grass on the outfield.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.783, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.843, "gpu_utilization_percent_mean": 83.871}, "timestamp": "2026-01-31T00:29:53.484645"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5612.499, "latencies_ms": [5612.499], "images_per_second": 0.178, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The image captures a baseball game in progress on a sunny day. The batter is in the midst of swinging at the pitch, while the catcher and umpire are positioned behind home plate, ready to react to the play.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.187, "power_cpu_cv_mean_watts": 1.457, "power_sys_5v0_mean_watts": 8.847, "gpu_utilization_percent_mean": 86.851}, "timestamp": "2026-01-31T00:30:01.111665"}
{"image_index": 408, "image_name": "000000046252.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046252.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4789.285, "latencies_ms": [4789.285], "images_per_second": 0.209, "prompt_tokens": 22, "response_tokens_est": 33, "n_tiles": 12, "output_text": "The baseball field is well-maintained with a vibrant green grass and a dirt infield. The sunlight casts sharp shadows, indicating a bright, sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.968, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 88.875}, "timestamp": "2026-01-31T00:30:07.940773"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2620.679, "latencies_ms": [2620.679], "images_per_second": 0.382, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 2, "output_text": "A cat is seen in the image, its mouth open and its teeth visible as it appears to be in the process of eating a fish, which is lying on the ground.", "error": null, "sys_before": {"cpu_percent": 12.2, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.491, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 7.178, "gpu_utilization_percent_mean": 62.571}, "timestamp": "2026-01-31T00:30:12.617995"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1321.815, "latencies_ms": [1321.815], "images_per_second": 0.757, "prompt_tokens": 26, "response_tokens_est": 15, "n_tiles": 2, "output_text": "cat: 1\nfish: 1\nground: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.814, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.864, "gpu_utilization_percent_mean": 68.9}, "timestamp": "2026-01-31T00:30:15.968896"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5763.761, "latencies_ms": [5763.761], "images_per_second": 0.173, "prompt_tokens": 30, "response_tokens_est": 87, "n_tiles": 2, "output_text": "The main object in the foreground is a cat, which is positioned near the center of the image. The cat is interacting with a dead bird, which is located in the background. The cat's body is slightly off-center to the left, and the bird is positioned to the right of the cat. The cat's fur is predominantly white with gray and black stripes, and it appears to be in the process of eating the bird.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.546, "power_cpu_cv_mean_watts": 2.152, "power_sys_5v0_mean_watts": 7.355, "gpu_utilization_percent_mean": 62.292}, "timestamp": "2026-01-31T00:30:23.751624"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4533.9, "latencies_ms": [4533.9], "images_per_second": 0.221, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 2, "output_text": "The image depicts a cat in a natural outdoor setting, possibly a park or a garden, where it is seen eating a fish. The cat is focused on its meal, with its mouth open and its whiskers clearly visible. The fish is lying on the ground, and the cat's fur is predominantly white with black stripes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.719, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.298, "gpu_utilization_percent_mean": 63.132}, "timestamp": "2026-01-31T00:30:30.309925"}
{"image_index": 409, "image_name": "000000046378.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046378.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4465.201, "latencies_ms": [4465.201], "images_per_second": 0.224, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 2, "output_text": "The image features a cat with a predominantly gray and white fur coat, which is highlighted by the natural light casting soft shadows on the ground. The cat is seen in a close-up, with its head resting on a piece of wood, surrounded by a mix of dried leaves and twigs, indicating a natural, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.926, "power_cpu_cv_mean_watts": 2.067, "power_sys_5v0_mean_watts": 7.301, "gpu_utilization_percent_mean": 62.27}, "timestamp": "2026-01-31T00:30:36.813860"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4611.031, "latencies_ms": [4611.031], "images_per_second": 0.217, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 12, "output_text": "The image shows a close-up of a person's hand holding a piece of food, which appears to be a slice of pizza with a green topping.", "error": null, "sys_before": {"cpu_percent": 29.1, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.168, "power_cpu_cv_mean_watts": 1.222, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 88.711}, "timestamp": "2026-01-31T00:30:43.621998"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4849.764, "latencies_ms": [4849.764], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "1. Bread\n2. Knife\n3. Cutting board\n4. Knife\n5. Knife\n6. Knife\n7. Knife\n8. Knife", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.901, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 88.875}, "timestamp": "2026-01-31T00:30:50.494681"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6991.49, "latencies_ms": [6991.49], "images_per_second": 0.143, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The main object in the foreground is a piece of food, which appears to be a slice of bread with a green leafy topping. The background is slightly blurred, but it seems to be a kitchen counter or table. The food is being held by a person's hand, which is partially visible on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.263, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.815, "gpu_utilization_percent_mean": 85.172}, "timestamp": "2026-01-31T00:30:59.506408"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6207.094, "latencies_ms": [6207.094], "images_per_second": 0.161, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image shows a close-up of a person's hand holding a piece of food, which appears to be a slice of pizza. The hand is positioned on a white surface, possibly a cutting board, and the focus is on the food, making the background slightly blurred.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.561, "power_cpu_cv_mean_watts": 1.525, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.923}, "timestamp": "2026-01-31T00:31:07.753115"}
{"image_index": 410, "image_name": "000000046463.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046463.jpg", "image_width": 500, "image_height": 400, "image_resolution": "500x400", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7286.841, "latencies_ms": [7286.841], "images_per_second": 0.137, "prompt_tokens": 22, "response_tokens_est": 74, "n_tiles": 12, "output_text": "The image shows a close-up of a person's hand holding a piece of food with a green leafy vegetable on top. The food appears to be a slice of a sandwich or a similar item, and the background is blurred, with a white surface and some indistinct objects. The lighting is soft and natural, suggesting an indoor setting with ambient light.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.019, "power_cpu_cv_mean_watts": 1.654, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 84.852}, "timestamp": "2026-01-31T00:31:17.076916"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3802.564, "latencies_ms": [3802.564], "images_per_second": 0.263, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 6, "output_text": "Two young girls are sitting on a gray inflatable ring on the deck of a sailboat, with one of them wearing a pink shirt and the other a white shirt, both looking out over the calm blue water.", "error": null, "sys_before": {"cpu_percent": 26.7, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.627, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.06, "gpu_utilization_percent_mean": 71.531}, "timestamp": "2026-01-31T00:31:22.985863"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3142.324, "latencies_ms": [3142.324], "images_per_second": 0.318, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 6, "output_text": "1. Sailboat\n2. Sail\n3. Woman\n4. Woman\n5. Woman\n6. Woman\n7. Woman\n8. Woman", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.826, "power_cpu_cv_mean_watts": 1.463, "power_sys_5v0_mean_watts": 8.087, "gpu_utilization_percent_mean": 73.692}, "timestamp": "2026-01-31T00:31:28.150567"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5883.763, "latencies_ms": [5883.763], "images_per_second": 0.17, "prompt_tokens": 30, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The main objects in the image are the two young girls and the boat. The girls are positioned in the foreground, with one sitting on a gray cushion and the other on a white cushion. The boat is in the background, with its sail and rigging visible. The girls are near the edge of the boat, with the cushion they are sitting on being the closest to the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.856, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 68.94}, "timestamp": "2026-01-31T00:31:36.081729"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5204.164, "latencies_ms": [5204.164], "images_per_second": 0.192, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a serene scene on a boat, with two young girls sitting on a gray cushion. They are enjoying the view of the blue water, and one of them is wearing a straw hat. The setting is outdoors, likely on a sunny day, with the girls engaged in a leisurely activity on the water.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.353, "power_cpu_cv_mean_watts": 1.848, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 69.455}, "timestamp": "2026-01-31T00:31:43.313203"}
{"image_index": 411, "image_name": "000000046497.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046497.jpg", "image_width": 500, "image_height": 332, "image_resolution": "500x332", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3869.346, "latencies_ms": [3869.346], "images_per_second": 0.258, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image depicts a sunny day on a boat with clear blue water. The boat's sails are white, and the sky is bright. The women are wearing light-colored clothing, and the water reflects the sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.652, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 71.656}, "timestamp": "2026-01-31T00:31:49.219485"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3580.501, "latencies_ms": [3580.501], "images_per_second": 0.279, "prompt_tokens": 12, "response_tokens_est": 14, "n_tiles": 12, "output_text": "A sheep stands in a grassy field with a rocky background.", "error": null, "sys_before": {"cpu_percent": 27.7, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.738, "power_cpu_cv_mean_watts": 0.897, "power_sys_5v0_mean_watts": 8.851, "gpu_utilization_percent_mean": 91.172}, "timestamp": "2026-01-31T00:31:54.944814"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5094.148, "latencies_ms": [5094.148], "images_per_second": 0.196, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "1. Sheep\n2. Grass\n3. Stone wall\n4. Lichen\n5. Bushes\n6. Rocks\n7. Tree\n8. Shadows", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.421, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 88.233}, "timestamp": "2026-01-31T00:32:02.079872"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6531.261, "latencies_ms": [6531.261], "images_per_second": 0.153, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The main object in the foreground is a sheep standing on a grassy field. The sheep is positioned near the center of the image, with its body facing the camera and its head turned slightly to the side. The background features a rocky wall with patches of yellow moss, adding depth to the scene.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.577, "power_cpu_cv_mean_watts": 1.572, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 85.8}, "timestamp": "2026-01-31T00:32:10.643229"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5103.384, "latencies_ms": [5103.384], "images_per_second": 0.196, "prompt_tokens": 24, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image depicts a sheep standing in a grassy field with a rocky, yellowish wall in the background. The sheep appears to be calm and is looking directly at the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.419, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 87.721}, "timestamp": "2026-01-31T00:32:17.768304"}
{"image_index": 412, "image_name": "000000046804.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046804.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6431.931, "latencies_ms": [6431.931], "images_per_second": 0.155, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The sheep in the image is predominantly white, with a fluffy, dense wool coat that appears soft and well-groomed. The lighting is bright and natural, suggesting a sunny day with clear skies. The grass is green and appears to be well-maintained, indicating a healthy environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.451, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 85.593}, "timestamp": "2026-01-31T00:32:26.214833"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3706.117, "latencies_ms": [3706.117], "images_per_second": 0.27, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 6, "output_text": "A man in a white t-shirt and plaid shorts is standing next to a large, yellow and black trailer, holding onto a yellow rope, while another man in a blue shirt is pointing towards the trailer.", "error": null, "sys_before": {"cpu_percent": 24.8, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.904, "power_cpu_cv_mean_watts": 1.641, "power_sys_5v0_mean_watts": 8.063, "gpu_utilization_percent_mean": 72.226}, "timestamp": "2026-01-31T00:32:32.063090"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3134.978, "latencies_ms": [3134.978], "images_per_second": 0.319, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Truck\n2. Person\n3. Person\n4. Person\n5. Person\n6. Person\n7. Person\n8. Person", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.81, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 74.385}, "timestamp": "2026-01-31T00:32:37.218986"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4730.822, "latencies_ms": [4730.822], "images_per_second": 0.211, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The main objects in the image are a large yellow and black trailer, a man standing on the trailer, and a parked truck in the background. The trailer is positioned in the foreground, with the man standing on it. The truck is located in the background, further away from the trailer.", "error": null, "sys_before": {"cpu_percent": 13.3, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.615, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 69.925}, "timestamp": "2026-01-31T00:32:43.964989"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5046.98, "latencies_ms": [5046.98], "images_per_second": 0.198, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The scene depicts a man standing next to a large, yellow and black trailer on a paved surface, possibly a parking lot. He is holding a hose, suggesting he is either preparing to fill the trailer or has just finished. The background features a variety of vehicles and trailers, indicating a storage or distribution area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.614, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 8.061, "gpu_utilization_percent_mean": 70.071}, "timestamp": "2026-01-31T00:32:51.040937"}
{"image_index": 413, "image_name": "000000046872.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000046872.jpg", "image_width": 640, "image_height": 391, "image_resolution": "640x391", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4892.698, "latencies_ms": [4892.698], "images_per_second": 0.204, "prompt_tokens": 22, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image features a large, yellow and black cylindrical object on a flatbed trailer, with a man standing beside it. The trailer is parked on a paved surface, and the background includes trees and a building. The lighting is natural, suggesting daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.534, "power_cpu_cv_mean_watts": 1.806, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 70.122}, "timestamp": "2026-01-31T00:32:57.969055"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4499.553, "latencies_ms": [4499.553], "images_per_second": 0.222, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "The image depicts a giraffe walking through a dirt path surrounded by lush greenery, with a small goat lying on the ground nearby.", "error": null, "sys_before": {"cpu_percent": 28.9, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.209, "power_cpu_cv_mean_watts": 1.19, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 88.324}, "timestamp": "2026-01-31T00:33:04.615090"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3579.769, "latencies_ms": [3579.769], "images_per_second": 0.279, "prompt_tokens": 26, "response_tokens_est": 13, "n_tiles": 12, "output_text": "giraffe: 2\ngoat: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.728, "power_cpu_cv_mean_watts": 0.884, "power_sys_5v0_mean_watts": 8.792, "gpu_utilization_percent_mean": 93.552}, "timestamp": "2026-01-31T00:33:10.232479"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6626.859, "latencies_ms": [6626.859], "images_per_second": 0.151, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 12, "output_text": "In the image, the giraffes are positioned in the foreground, with the closest giraffe standing near the water's edge. The second giraffe is further back, walking on the dirt. The background features a dense forest with various trees and shrubs, creating a natural habitat for the giraffes.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.458, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 85.509}, "timestamp": "2026-01-31T00:33:18.874600"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7159.201, "latencies_ms": [7159.201], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a serene and natural setting, likely within a zoo or wildlife reserve, featuring a dirt path surrounded by lush greenery. A group of giraffes is walking along the path, with one giraffe in the foreground appearing to be in motion. Additionally, there is a small, brown goat resting on the ground near the path.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.15, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.823, "gpu_utilization_percent_mean": 85.2}, "timestamp": "2026-01-31T00:33:28.056773"}
{"image_index": 414, "image_name": "000000047010.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047010.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6432.931, "latencies_ms": [6432.931], "images_per_second": 0.155, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The image depicts a giraffe standing in a natural, grassy environment with a dirt path. The giraffe has a brown and white coat, and its long neck and legs are prominently visible. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.526, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 85.87}, "timestamp": "2026-01-31T00:33:36.550780"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5629.83, "latencies_ms": [5629.83], "images_per_second": 0.178, "prompt_tokens": 12, "response_tokens_est": 48, "n_tiles": 12, "output_text": "The image shows a large, freshly baked pizza with a variety of toppings, including melted cheese, sliced mushrooms, and pieces of ham, all resting on a white plate, with a glass of beer and a glass of water nearby.", "error": null, "sys_before": {"cpu_percent": 28.4, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.107, "power_cpu_cv_mean_watts": 1.465, "power_sys_5v0_mean_watts": 8.859, "gpu_utilization_percent_mean": 85.787}, "timestamp": "2026-01-31T00:33:44.333726"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10542.646, "latencies_ms": [10542.646], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18638.4, "ram_available_mb": 44202.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.079, "power_cpu_cv_mean_watts": 1.891, "power_sys_5v0_mean_watts": 8.87, "gpu_utilization_percent_mean": 82.533}, "timestamp": "2026-01-31T00:33:56.893708"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8417.38, "latencies_ms": [8417.38], "images_per_second": 0.119, "prompt_tokens": 30, "response_tokens_est": 93, "n_tiles": 12, "output_text": "The main object in the foreground is a large, freshly baked pizza with melted cheese and toppings. The pizza is placed on a white plate, which is placed on a table covered with a blue tablecloth. In the background, there are two wine glasses and a bottle of wine on a bar counter, indicating that the setting is a restaurant. The pizza is positioned near the center of the image, with the wine glasses and bar counter in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.4, "ram_available_mb": 44202.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.726, "power_cpu_cv_mean_watts": 1.765, "power_sys_5v0_mean_watts": 8.838, "gpu_utilization_percent_mean": 84.056}, "timestamp": "2026-01-31T00:34:07.357241"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8672.395, "latencies_ms": [8672.395], "images_per_second": 0.115, "prompt_tokens": 24, "response_tokens_est": 97, "n_tiles": 12, "output_text": "The image depicts a cozy dining setting in a restaurant, with a table set for two. The table is covered with a white tablecloth, and there is a large, freshly baked pizza placed on a white plate. The pizza is topped with melted cheese, sliced mushrooms, and pieces of ham, and it appears to be freshly baked. In the background, there are other tables and chairs, and a bar with various bottles and glasses, suggesting a lively and social atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.595, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 83.658}, "timestamp": "2026-01-31T00:34:18.073561"}
{"image_index": 415, "image_name": "000000047112.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047112.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7349.522, "latencies_ms": [7349.522], "images_per_second": 0.136, "prompt_tokens": 22, "response_tokens_est": 75, "n_tiles": 12, "output_text": "The image features a large, golden-brown pizza with melted cheese and various toppings, including mushrooms and possibly ham, resting on a white plate. The lighting is warm and inviting, casting a soft glow on the pizza and creating a cozy atmosphere. The background includes a dimly lit bar with bottles and glasses, adding to the ambiance of a relaxed dining environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.035, "power_cpu_cv_mean_watts": 1.66, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 84.806}, "timestamp": "2026-01-31T00:34:27.470564"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4507.844, "latencies_ms": [4507.844], "images_per_second": 0.222, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "A black cat is resting on the edge of a white bathtub, with a bottle of shampoo and a soap dispenser nearby.", "error": null, "sys_before": {"cpu_percent": 30.7, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.154, "power_cpu_cv_mean_watts": 1.158, "power_sys_5v0_mean_watts": 8.82, "gpu_utilization_percent_mean": 88.514}, "timestamp": "2026-01-31T00:34:34.142685"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5466.919, "latencies_ms": [5466.919], "images_per_second": 0.183, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 12, "output_text": "- cat: 1\n- sink: 1\n- water tap: 1\n- soap bottle: 1\n- glass: 1\n- bowl: 1\n- wall: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.215, "power_cpu_cv_mean_watts": 1.406, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 87.578}, "timestamp": "2026-01-31T00:34:41.620714"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8727.205, "latencies_ms": [8727.205], "images_per_second": 0.115, "prompt_tokens": 30, "response_tokens_est": 98, "n_tiles": 12, "output_text": "The main object in the foreground is a black cat, which is perched on the edge of a white bathtub. The cat is positioned near the edge of the tub, with its head resting on the edge and its body leaning slightly towards the water. To the left of the cat, there is a white soap dispenser and a small white dish on the countertop. The background is mostly out of focus, with a light-colored wall and a window with a white frame.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.652, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 83.74}, "timestamp": "2026-01-31T00:34:52.361781"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5650.535, "latencies_ms": [5650.535], "images_per_second": 0.177, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The image depicts a bathroom setting with a white bathtub and a white wall in the background. A black cat is seen resting on the edge of the bathtub, seemingly enjoying the view or simply taking a nap.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.995, "power_cpu_cv_mean_watts": 1.431, "power_sys_5v0_mean_watts": 8.808, "gpu_utilization_percent_mean": 86.872}, "timestamp": "2026-01-31T00:35:00.031007"}
{"image_index": 416, "image_name": "000000047121.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047121.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6247.128, "latencies_ms": [6247.128], "images_per_second": 0.16, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 12, "output_text": "The image features a black cat resting on a white bathtub. The bathtub is situated against a light-colored wall, and the cat is positioned near a silver faucet and a clear glass. The lighting in the room is soft and warm, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.667, "power_cpu_cv_mean_watts": 1.524, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 86.308}, "timestamp": "2026-01-31T00:35:08.313094"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3115.206, "latencies_ms": [3115.206], "images_per_second": 0.321, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 4, "output_text": "A horse-drawn cart is seen in a muddy field, with a woman and a man seated inside, both wearing hats and boots, and the horse is equipped with a harness.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5451.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.522, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 7.643, "gpu_utilization_percent_mean": 68.04}, "timestamp": "2026-01-31T00:35:13.514121"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2759.96, "latencies_ms": [2759.96], "images_per_second": 0.362, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 4, "output_text": "1. Carriage\n2. Horse\n3. Person\n4. Person\n5. Person\n6. Person\n7. Person\n8. Person", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5463.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.182, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 7.635, "gpu_utilization_percent_mean": 67.409}, "timestamp": "2026-01-31T00:35:18.308325"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4453.675, "latencies_ms": [4453.675], "images_per_second": 0.225, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 4, "output_text": "In the image, the main objects are a horse-drawn cart and a horse. The horse-drawn cart is positioned in the foreground, with its wheels and the horse in the middle ground. The horse is near the cart, and the background features a clear blue sky and some buildings.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5465.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.06, "power_cpu_cv_mean_watts": 1.904, "power_sys_5v0_mean_watts": 7.685, "gpu_utilization_percent_mean": 64.459}, "timestamp": "2026-01-31T00:35:24.781697"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3833.84, "latencies_ms": [3833.84], "images_per_second": 0.261, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 4, "output_text": "The image depicts a scene in a rural setting with a horse-drawn cart and a person riding it. The cart is in a muddy area with water reflecting the surroundings, and the person is wearing a hat and a plaid shirt.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5460.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.542, "power_cpu_cv_mean_watts": 1.839, "power_sys_5v0_mean_watts": 7.671, "gpu_utilization_percent_mean": 64.75}, "timestamp": "2026-01-31T00:35:30.641321"}
{"image_index": 417, "image_name": "000000047571.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047571.jpg", "image_width": 639, "image_height": 640, "image_resolution": "639x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3824.778, "latencies_ms": [3824.778], "images_per_second": 0.261, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 4, "output_text": "The image depicts a scene with a horse-drawn cart in a muddy, wet environment. The cart is made of wood, and the horse is brown with a shiny coat. The sky is clear and blue, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5459.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.713, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.662, "gpu_utilization_percent_mean": 63.774}, "timestamp": "2026-01-31T00:35:36.484228"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3005.655, "latencies_ms": [3005.655], "images_per_second": 0.333, "prompt_tokens": 12, "response_tokens_est": 31, "n_tiles": 6, "output_text": "A bride and groom are walking down the aisle in a wedding ceremony, with a man in a suit holding an umbrella to shield them from the rain.", "error": null, "sys_before": {"cpu_percent": 26.2, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.009, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-31T00:35:41.584675"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3550.871, "latencies_ms": [3550.871], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.197, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 72.233}, "timestamp": "2026-01-31T00:35:47.153468"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4996.044, "latencies_ms": [4996.044], "images_per_second": 0.2, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main objects in the image are a bride and groom, standing in the foreground. The groom is holding an umbrella, and the bride is holding a bouquet of flowers. The background features a stone building and a group of people, with the bride and groom positioned slightly to the left and right of the center.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.613, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 70.19}, "timestamp": "2026-01-31T00:35:54.201021"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5373.067, "latencies_ms": [5373.067], "images_per_second": 0.186, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The scene depicts a wedding ceremony taking place outdoors on a grassy area. The bride, dressed in a white gown, is holding a bouquet of flowers, while the groom stands beside her, dressed in a black suit. The setting includes a stone building in the background, and the atmosphere appears to be joyful and celebratory.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.196, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 8.08, "gpu_utilization_percent_mean": 69.511}, "timestamp": "2026-01-31T00:36:01.603737"}
{"image_index": 418, "image_name": "000000047585.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047585.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3704.762, "latencies_ms": [3704.762], "images_per_second": 0.27, "prompt_tokens": 22, "response_tokens_est": 43, "n_tiles": 6, "output_text": "The image features a bride and groom standing under a black and white striped umbrella, holding a bouquet of flowers. The setting appears to be outdoors during the daytime, with natural lighting illuminating the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.083, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 72.774}, "timestamp": "2026-01-31T00:36:07.355367"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3054.674, "latencies_ms": [3054.674], "images_per_second": 0.327, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 2, "output_text": "Two individuals are relaxing on a sandy beach, with one lying on their back and the other sitting on the sand, both enjoying the tranquil atmosphere of the ocean and the colorful kite in the sky.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.269, "power_cpu_cv_mean_watts": 1.858, "power_sys_5v0_mean_watts": 7.205, "gpu_utilization_percent_mean": 63.28}, "timestamp": "2026-01-31T00:36:12.466094"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3199.024, "latencies_ms": [3199.024], "images_per_second": 0.313, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 2, "output_text": "beach: 1\nsand: 1\nperson: 2\nshorts: 1\nshirt: 1\nwatch: 1\nkite: 1\nballoon: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.243, "power_cpu_cv_mean_watts": 1.878, "power_sys_5v0_mean_watts": 7.254, "gpu_utilization_percent_mean": 63.654}, "timestamp": "2026-01-31T00:36:17.712290"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4182.195, "latencies_ms": [4182.195], "images_per_second": 0.239, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 2, "output_text": "The main objects in the image are a person lying on the sandy beach, a colorful kite in the foreground, and another person in the background. The person on the beach is positioned in the foreground, while the kite is in the foreground, and the other person is in the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.875, "power_cpu_cv_mean_watts": 2.025, "power_sys_5v0_mean_watts": 7.29, "gpu_utilization_percent_mean": 62.829}, "timestamp": "2026-01-31T00:36:23.935821"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4962.386, "latencies_ms": [4962.386], "images_per_second": 0.202, "prompt_tokens": 24, "response_tokens_est": 74, "n_tiles": 2, "output_text": "The image depicts a sunny beach scene with two individuals lying on the sand, one wearing a white shirt and the other in dark shorts. They are surrounded by a colorful kite, which is tethered to the ground, and a blue and yellow beach bag. The ocean waves are visible in the background, indicating a calm and pleasant day at the beach.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.679, "power_cpu_cv_mean_watts": 2.059, "power_sys_5v0_mean_watts": 7.291, "gpu_utilization_percent_mean": 62.262}, "timestamp": "2026-01-31T00:36:30.923193"}
{"image_index": 419, "image_name": "000000047740.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047740.jpg", "image_width": 640, "image_height": 359, "image_resolution": "640x359", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3611.747, "latencies_ms": [3611.747], "images_per_second": 0.277, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 2, "output_text": "The image depicts a sunny beach scene with sandy terrain, clear blue skies, and gentle waves lapping at the shore. The beach is adorned with colorful beach balls and a vibrant kite, adding a lively touch to the serene setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.173, "power_cpu_cv_mean_watts": 1.975, "power_sys_5v0_mean_watts": 7.271, "gpu_utilization_percent_mean": 63.333}, "timestamp": "2026-01-31T00:36:36.552046"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5027.843, "latencies_ms": [5027.843], "images_per_second": 0.199, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a brown sofa, a red armchair, a black stool, a small table with a lamp, and a television on a stand.", "error": null, "sys_before": {"cpu_percent": 32.0, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.906, "power_cpu_cv_mean_watts": 1.344, "power_sys_5v0_mean_watts": 8.859, "gpu_utilization_percent_mean": 87.619}, "timestamp": "2026-01-31T00:36:43.768380"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5022.555, "latencies_ms": [5022.555], "images_per_second": 0.199, "prompt_tokens": 26, "response_tokens_est": 37, "n_tiles": 12, "output_text": "1. TV stand\n2. TV\n3. Coffee table\n4. Stools\n5. Lamps\n6. Couch\n7. Bookshelf\n8. Book", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.522, "power_cpu_cv_mean_watts": 1.331, "power_sys_5v0_mean_watts": 8.77, "gpu_utilization_percent_mean": 87.535}, "timestamp": "2026-01-31T00:36:50.830054"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 9902.142, "latencies_ms": [9902.142], "images_per_second": 0.101, "prompt_tokens": 30, "response_tokens_est": 118, "n_tiles": 12, "output_text": "The main objects in the image include a brown couch, a red chair, a black stool, a small table, a lamp, a television, and a window with blinds. The brown couch is positioned in the foreground, while the red chair is slightly to the right. The black stool is placed in front of the red chair. The small table is situated between the couch and the stool. The lamp is placed on the table, and the television is positioned to the right of the table. The window with blinds is located behind the couch and the stool.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.0, "ram_available_mb": 44194.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.366, "power_cpu_cv_mean_watts": 1.87, "power_sys_5v0_mean_watts": 8.86, "gpu_utilization_percent_mean": 82.894}, "timestamp": "2026-01-31T00:37:02.749193"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7446.218, "latencies_ms": [7446.218], "images_per_second": 0.134, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The image depicts a cozy living room with a warm, inviting ambiance. The room features a brown leather sofa, a black wooden stool, a red armchair, a small table with a lamp, and a television on a stand. The room is well-lit, with natural light coming through a window with white blinds, creating a serene and comfortable atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.038, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 84.556}, "timestamp": "2026-01-31T00:37:12.214112"}
{"image_index": 420, "image_name": "000000047769.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047769.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5441.078, "latencies_ms": [5441.078], "images_per_second": 0.184, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The room is warmly lit with a soft yellow glow from the wall-mounted lamp, creating a cozy atmosphere. The wooden window shutters and the wooden floor add a natural, earthy feel to the space.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.264, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 87.13}, "timestamp": "2026-01-31T00:37:19.667208"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1969.331, "latencies_ms": [1969.331], "images_per_second": 0.508, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 1, "output_text": "A man is eating a slice of cake outdoors, holding a fork and a plate, with trees and greenery in the background.", "error": null, "sys_before": {"cpu_percent": 17.6, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.085, "power_cpu_cv_mean_watts": 1.701, "power_sys_5v0_mean_watts": 6.785, "gpu_utilization_percent_mean": 73.0}, "timestamp": "2026-01-31T00:37:23.731040"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3103.951, "latencies_ms": [3103.951], "images_per_second": 0.322, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 1, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.45, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 6.971, "gpu_utilization_percent_mean": 67.84}, "timestamp": "2026-01-31T00:37:28.860362"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3040.616, "latencies_ms": [3040.616], "images_per_second": 0.329, "prompt_tokens": 30, "response_tokens_est": 44, "n_tiles": 1, "output_text": "The main object in the foreground is a man holding a plate with a slice of cake. He is wearing glasses and a blue t-shirt. The background features a lush green park with trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18644.0, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.675, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 7.052, "gpu_utilization_percent_mean": 65.0}, "timestamp": "2026-01-31T00:37:33.923550"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3637.954, "latencies_ms": [3637.954], "images_per_second": 0.275, "prompt_tokens": 24, "response_tokens_est": 54, "n_tiles": 1, "output_text": "The image depicts a man sitting outdoors, enjoying a slice of cake. He is holding a white plate with a slice of cake and a spoon, and is wearing glasses. The setting appears to be a park or garden with greenery and trees in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.651, "power_cpu_cv_mean_watts": 2.042, "power_sys_5v0_mean_watts": 7.082, "gpu_utilization_percent_mean": 67.767}, "timestamp": "2026-01-31T00:37:39.585632"}
{"image_index": 421, "image_name": "000000047801.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047801.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3308.394, "latencies_ms": [3308.394], "images_per_second": 0.302, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 1, "output_text": "The notable visual attributes of the image include a person with a bald head, wearing glasses, and a blue t-shirt. The lighting is natural, suggesting it is daytime, and the background features greenery and trees, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.714, "power_cpu_cv_mean_watts": 1.987, "power_sys_5v0_mean_watts": 6.985, "gpu_utilization_percent_mean": 67.037}, "timestamp": "2026-01-31T00:37:44.924446"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3884.558, "latencies_ms": [3884.558], "images_per_second": 0.257, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 12, "output_text": "A man is standing next to a brown horse, holding a basket filled with various items.", "error": null, "sys_before": {"cpu_percent": 33.5, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.384, "power_cpu_cv_mean_watts": 1.014, "power_sys_5v0_mean_watts": 8.841, "gpu_utilization_percent_mean": 90.656}, "timestamp": "2026-01-31T00:37:51.008942"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5096.718, "latencies_ms": [5096.718], "images_per_second": 0.196, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 12, "output_text": "1. Man\n2. Shelter\n3. Tree\n4. Shelter\n5. Shelter\n6. Shelter\n7. Shelter\n8. Shelter", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.487, "power_cpu_cv_mean_watts": 1.341, "power_sys_5v0_mean_watts": 8.794, "gpu_utilization_percent_mean": 87.953}, "timestamp": "2026-01-31T00:37:58.147082"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5214.681, "latencies_ms": [5214.681], "images_per_second": 0.192, "prompt_tokens": 30, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The main objects in the image are a man and a brown horse. The man is positioned in the foreground, standing near the horse. The horse is in the background, slightly to the right.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.513, "power_cpu_cv_mean_watts": 1.322, "power_sys_5v0_mean_watts": 8.796, "gpu_utilization_percent_mean": 88.047}, "timestamp": "2026-01-31T00:38:05.382622"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6748.438, "latencies_ms": [6748.438], "images_per_second": 0.148, "prompt_tokens": 24, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image depicts a man standing next to a brown horse in a natural, outdoor setting. The man is wearing a purple vest over a white shirt and gray pants, and he appears to be holding a basket filled with various items. The horse is adorned with a colorful blanket and is being led by the man.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.308, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 84.982}, "timestamp": "2026-01-31T00:38:14.145208"}
{"image_index": 422, "image_name": "000000047819.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047819.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5631.656, "latencies_ms": [5631.656], "images_per_second": 0.178, "prompt_tokens": 22, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The man is wearing a purple vest over a white shirt, gray pants, and brown shoes. The sunlight casts a warm glow on the scene, highlighting the textures of the man's clothing and the earthy tones of the surroundings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.096, "power_cpu_cv_mean_watts": 1.44, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 86.979}, "timestamp": "2026-01-31T00:38:21.818928"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5189.601, "latencies_ms": [5189.601], "images_per_second": 0.193, "prompt_tokens": 12, "response_tokens_est": 78, "n_tiles": 2, "output_text": "The image depicts a night scene featuring a beautifully illuminated bridge with a series of arches, reflecting the blue lights on the water below. The bridge is adorned with a series of lights that create a mesmerizing and serene atmosphere, while a group of people can be seen walking along the bridge's walkway, adding a sense of scale and life to the scene.", "error": null, "sys_before": {"cpu_percent": 26.6, "ram_used_mb": 18645.1, "ram_available_mb": 44195.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.594, "power_cpu_cv_mean_watts": 2.086, "power_sys_5v0_mean_watts": 7.328, "gpu_utilization_percent_mean": 62.953}, "timestamp": "2026-01-31T00:38:29.100890"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3220.165, "latencies_ms": [3220.165], "images_per_second": 0.311, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 2, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.061, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 7.242, "gpu_utilization_percent_mean": 62.88}, "timestamp": "2026-01-31T00:38:34.347549"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6245.055, "latencies_ms": [6245.055], "images_per_second": 0.16, "prompt_tokens": 30, "response_tokens_est": 95, "n_tiles": 2, "output_text": "The main objects in the image are a group of people on the left side, a large bridge in the background, and a body of water on the right side. The bridge is the most prominent object, extending across the water and illuminated with blue lights. The people are situated on the left side of the bridge, near the water's edge. The water is the central feature, reflecting the bridge and the lights, and the people are near the water's edge.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.521, "power_cpu_cv_mean_watts": 2.117, "power_sys_5v0_mean_watts": 7.325, "gpu_utilization_percent_mean": 62.077}, "timestamp": "2026-01-31T00:38:42.621390"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3848.719, "latencies_ms": [3848.719], "images_per_second": 0.26, "prompt_tokens": 24, "response_tokens_est": 56, "n_tiles": 2, "output_text": "The image depicts a nighttime scene of a large, illuminated bridge spanning a body of water. The bridge is adorned with blue lights, creating a striking reflection on the water's surface. People are walking along the bridge's walkway, enjoying the scenic view.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.129, "power_cpu_cv_mean_watts": 1.989, "power_sys_5v0_mean_watts": 7.309, "gpu_utilization_percent_mean": 62.645}, "timestamp": "2026-01-31T00:38:48.500175"}
{"image_index": 423, "image_name": "000000047828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000047828.jpg", "image_width": 640, "image_height": 318, "image_resolution": "640x318", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4526.94, "latencies_ms": [4526.94], "images_per_second": 0.221, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 2, "output_text": "The image showcases a nighttime scene featuring a strikingly illuminated bridge with a series of arches. The bridge is adorned with blue lights, creating a mesmerizing reflection on the calm water below. The sky is dark, indicating it is nighttime, and the overall atmosphere is serene and captivating.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.861, "power_cpu_cv_mean_watts": 2.045, "power_sys_5v0_mean_watts": 7.274, "gpu_utilization_percent_mean": 61.919}, "timestamp": "2026-01-31T00:38:55.074981"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5262.002, "latencies_ms": [5262.002], "images_per_second": 0.19, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image shows a close-up of a person's lower torso and legs, wearing blue denim jeans, with a pink, shiny object on their back, possibly a bag or a piece of clothing.", "error": null, "sys_before": {"cpu_percent": 27.8, "ram_used_mb": 18643.9, "ram_available_mb": 44197.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.824, "power_cpu_cv_mean_watts": 1.369, "power_sys_5v0_mean_watts": 8.862, "gpu_utilization_percent_mean": 88.116}, "timestamp": "2026-01-31T00:39:02.524928"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5215.395, "latencies_ms": [5215.395], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "1. Pink chair\n2. Blue chair\n3. Blue blanket\n4. Blue bench\n5. Blue floor\n6. Green floor\n7. Pink object\n8. Pink object", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.429, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.779, "gpu_utilization_percent_mean": 87.86}, "timestamp": "2026-01-31T00:39:09.762051"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6485.877, "latencies_ms": [6485.877], "images_per_second": 0.154, "prompt_tokens": 30, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The main object in the foreground is a blue denim garment, which appears to be a pair of jeans. The background features a colorful, painted surface with a map of Europe and parts of Africa visible. The pink object, likely a chair or bench, is situated near the blue denim garment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.594, "power_cpu_cv_mean_watts": 1.557, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 86.019}, "timestamp": "2026-01-31T00:39:18.277869"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6969.453, "latencies_ms": [6969.453], "images_per_second": 0.143, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a scene with a person sitting on a bench, which is painted in a colorful, abstract design. The person is wearing a blue denim garment, and the bench has a vibrant blue and green pattern. The setting appears to be outdoors, possibly in a park or public area, with the bench being a focal point.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.242, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 85.328}, "timestamp": "2026-01-31T00:39:27.271599"}
{"image_index": 424, "image_name": "000000048153.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048153.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6084.655, "latencies_ms": [6084.655], "images_per_second": 0.164, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image features a vividly colored bench with a blue and green painted surface. The bench is adorned with a bright pink cushion, adding a pop of color to the scene. The lighting is bright, casting clear shadows and highlighting the textures of the materials used.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.654, "power_cpu_cv_mean_watts": 1.5, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 86.157}, "timestamp": "2026-01-31T00:39:35.372526"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3399.035, "latencies_ms": [3399.035], "images_per_second": 0.294, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 6, "output_text": "A woman with a smile is holding a knife, standing next to a young boy in a plaid shirt, both in a room with a red wall and a cake on a table.", "error": null, "sys_before": {"cpu_percent": 26.9, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.41, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 73.893}, "timestamp": "2026-01-31T00:39:40.898481"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3689.843, "latencies_ms": [3689.843], "images_per_second": 0.271, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 6, "output_text": "- Woman: 1\n- Knife: 1\n- Man: 1\n- Cake: 1\n- Table: 1\n- Cup: 1\n- Child: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.905, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 72.167}, "timestamp": "2026-01-31T00:39:46.608936"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4599.922, "latencies_ms": [4599.922], "images_per_second": 0.217, "prompt_tokens": 30, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The main objects in the image are a woman and a young boy. The woman is in the foreground, standing near a table with a red cake. The young boy is in the background, standing near a doorway. The cake is on the table in front of the woman.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.875, "power_cpu_cv_mean_watts": 1.759, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 70.632}, "timestamp": "2026-01-31T00:39:53.224184"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7152.803, "latencies_ms": [7152.803], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 99, "n_tiles": 6, "output_text": "The scene is set in a cozy, indoor environment, likely a home or a small gathering space. A woman and a young boy are present, with the woman smiling and holding a knife, while the boy is looking at the camera with a slight smile. The woman is wearing a green cardigan over a white top, and the boy is dressed in a blue and white plaid shirt. There is a red cake on a table in the background, and a white cup is also visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.213, "power_cpu_cv_mean_watts": 1.982, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 68.033}, "timestamp": "2026-01-31T00:40:02.406398"}
{"image_index": 425, "image_name": "000000048396.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048396.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5905.577, "latencies_ms": [5905.577], "images_per_second": 0.169, "prompt_tokens": 22, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image features a woman with long brown hair, wearing a light green cardigan over a white top, standing in front of a red wall. She is smiling and holding a knife in her right hand. The lighting is warm and soft, creating a cozy atmosphere. The woman is wearing a floral skirt, and there is a cake with a red base and a spider design on the table.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.951, "power_cpu_cv_mean_watts": 1.92, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 69.571}, "timestamp": "2026-01-31T00:40:10.350943"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2452.704, "latencies_ms": [2452.704], "images_per_second": 0.408, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "A woman is seen riding an elephant in a large arena, with the elephant being led by another person.", "error": null, "sys_before": {"cpu_percent": 27.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.367, "power_cpu_cv_mean_watts": 1.221, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 76.8}, "timestamp": "2026-01-31T00:40:14.923714"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5083.678, "latencies_ms": [5083.678], "images_per_second": 0.197, "prompt_tokens": 26, "response_tokens_est": 65, "n_tiles": 6, "output_text": "1. Elephant: 1\n2. Person: 1\n3. Rope: 1\n4. Ramp: 1\n5. Stirrups: 1\n6. Ramp: 1\n7. Ramp: 1\n8. Ramp: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.47, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 70.333}, "timestamp": "2026-01-31T00:40:22.034738"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6528.772, "latencies_ms": [6528.772], "images_per_second": 0.153, "prompt_tokens": 30, "response_tokens_est": 89, "n_tiles": 6, "output_text": "In the image, the main focus is on the two elephants in the foreground, with one elephant being led by a person in a red vest. The person is guiding the elephant towards the right side of the frame. The background features a large arena with a concrete floor, metal railings, and a person standing near the left side of the frame. The arena is illuminated by artificial lighting, creating a bright and well-lit environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.531, "power_cpu_cv_mean_watts": 1.958, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 68.491}, "timestamp": "2026-01-31T00:40:30.600963"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5244.474, "latencies_ms": [5244.474], "images_per_second": 0.191, "prompt_tokens": 24, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The image depicts an indoor arena with a dirt floor, where a man is seen standing near a large elephant, likely preparing it for a performance or event. The setting appears to be a rodeo or circus, with a person in a red vest and white pants standing beside the elephant, possibly assisting with the animal's preparation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.397, "power_cpu_cv_mean_watts": 1.834, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 70.186}, "timestamp": "2026-01-31T00:40:37.856701"}
{"image_index": 426, "image_name": "000000048504.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048504.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4201.392, "latencies_ms": [4201.392], "images_per_second": 0.238, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image depicts an indoor arena with a dirt floor and metal railings. The lighting is artificial, with spotlights illuminating the scene. The arena is adorned with a colorful, geometric-patterned floor and a red and yellow barrier.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.2, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.401, "power_cpu_cv_mean_watts": 1.739, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 70.971}, "timestamp": "2026-01-31T00:40:44.070497"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4868.191, "latencies_ms": [4868.191], "images_per_second": 0.205, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 12, "output_text": "A group of jockeys on horseback are racing across a sandy beach, with the horses galloping vigorously and the riders leaning forward in concentration.", "error": null, "sys_before": {"cpu_percent": 25.3, "ram_used_mb": 18646.2, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.701, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 87.25}, "timestamp": "2026-01-31T00:40:51.080009"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4737.038, "latencies_ms": [4737.038], "images_per_second": 0.211, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 12, "output_text": "1. Horse\n2. Rider\n3. Horse\n4. Rider\n5. Horse\n6. Rider\n7. Horse\n8. Rider", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.949, "power_cpu_cv_mean_watts": 1.242, "power_sys_5v0_mean_watts": 8.776, "gpu_utilization_percent_mean": 88.872}, "timestamp": "2026-01-31T00:40:57.835536"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5826.918, "latencies_ms": [5826.918], "images_per_second": 0.172, "prompt_tokens": 30, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The main objects in the image are the horses and the riders. The horses are in the foreground, while the riders are positioned slightly behind them. The riders are near the center of the image, with the horses positioned to the left and right.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18646.2, "ram_available_mb": 44194.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.895, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 86.49}, "timestamp": "2026-01-31T00:41:05.711565"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6002.144, "latencies_ms": [6002.144], "images_per_second": 0.167, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image depicts a horse race in progress, with a group of jockeys on horseback racing towards the finish line. The scene is set on a track, and the horses and riders are captured in motion, creating a dynamic and energetic atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.782, "power_cpu_cv_mean_watts": 1.489, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 86.48}, "timestamp": "2026-01-31T00:41:13.726564"}
{"image_index": 427, "image_name": "000000048555.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048555.jpg", "image_width": 640, "image_height": 465, "image_resolution": "640x465", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6594.408, "latencies_ms": [6594.408], "images_per_second": 0.152, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image is a black and white photograph featuring a horse race. The horses and jockeys are in motion, creating a blur effect in the background, which suggests a fast-paced and dynamic scene. The lighting is even, with no harsh shadows, indicating an overcast sky or diffuse light source.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.401, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 85.482}, "timestamp": "2026-01-31T00:41:22.354617"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4503.78, "latencies_ms": [4503.78], "images_per_second": 0.222, "prompt_tokens": 12, "response_tokens_est": 56, "n_tiles": 6, "output_text": "A man is standing outdoors in a snowy environment, wearing a black beanie and a black jacket with a blue scarf around his neck. He is holding a phone to his ear with his left hand, and his facial expression appears to be one of surprise or shock.", "error": null, "sys_before": {"cpu_percent": 22.7, "ram_used_mb": 18647.0, "ram_available_mb": 44193.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.003, "power_cpu_cv_mean_watts": 1.753, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 71.162}, "timestamp": "2026-01-31T00:41:28.952212"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4660.556, "latencies_ms": [4660.556], "images_per_second": 0.215, "prompt_tokens": 26, "response_tokens_est": 58, "n_tiles": 6, "output_text": "1. Snowboarder\n2. Snowboard\n3. Snow\n4. Snowboarder's helmet\n5. Snowboarder's goggles\n6. Snowboarder's jacket\n7. Snowboarder's beanie\n8. Snowboarder's scarf", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.738, "power_cpu_cv_mean_watts": 1.776, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 70.128}, "timestamp": "2026-01-31T00:41:35.627800"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3973.77, "latencies_ms": [3973.77], "images_per_second": 0.252, "prompt_tokens": 30, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The main object in the foreground is a person wearing a black jacket and a blue scarf. The person is holding a phone to their ear. In the background, there is a snowy landscape with trees and a house visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.9, "ram_available_mb": 44193.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.582, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 71.424}, "timestamp": "2026-01-31T00:41:41.658559"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5852.079, "latencies_ms": [5852.079], "images_per_second": 0.171, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The image depicts a man in a winter setting, standing outdoors with snow on the ground. He is wearing a black jacket and a beanie, and appears to be in a state of distress or frustration, as he is holding a phone to his ear with his mouth open. The background shows a snowy landscape with trees and a building, suggesting a cold, wintry environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.7, "ram_available_mb": 44192.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18649.7, "ram_available_mb": 44191.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.806, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 8.026, "gpu_utilization_percent_mean": 69.245}, "timestamp": "2026-01-31T00:41:49.563393"}
{"image_index": 428, "image_name": "000000048564.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048564.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3858.399, "latencies_ms": [3858.399], "images_per_second": 0.259, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The notable visual attributes in the image include a person wearing a black beanie and a black jacket with a green button on the left side. The lighting is bright, and the person is outdoors in a snowy environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.7, "ram_available_mb": 44191.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.673, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 8.053, "gpu_utilization_percent_mean": 71.906}, "timestamp": "2026-01-31T00:41:55.468351"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2209.47, "latencies_ms": [2209.47], "images_per_second": 0.453, "prompt_tokens": 12, "response_tokens_est": 18, "n_tiles": 6, "output_text": "A motorcycle is parked next to a green tent in a forested area during sunset.", "error": null, "sys_before": {"cpu_percent": 24.8, "ram_used_mb": 18649.0, "ram_available_mb": 44191.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.781, "power_cpu_cv_mean_watts": 1.068, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 79.833}, "timestamp": "2026-01-31T00:41:59.824401"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3273.505, "latencies_ms": [3273.505], "images_per_second": 0.305, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 6, "output_text": "1. Motorcycle\n2. Tent\n3. Bushes\n4. Trees\n5. Sun\n6. Sky\n7. Grass\n8. Water", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.479, "power_cpu_cv_mean_watts": 1.513, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 73.185}, "timestamp": "2026-01-31T00:42:05.120988"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5017.14, "latencies_ms": [5017.14], "images_per_second": 0.199, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main object in the foreground is a motorcycle, which is positioned to the right side of the image. The motorcycle is parked on a patch of dry grass. In the background, there is a green tent, which is located to the left side of the motorcycle. The tent is partially obscured by the motorcycle.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18649.1, "ram_available_mb": 44191.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.519, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 69.905}, "timestamp": "2026-01-31T00:42:12.168450"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4110.201, "latencies_ms": [4110.201], "images_per_second": 0.243, "prompt_tokens": 24, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image depicts a tranquil outdoor setting during sunset, with a green tent and a motorcycle parked in a grassy area. The scene is serene, with the soft glow of the setting sun casting a warm light over the landscape.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18649.1, "ram_available_mb": 44191.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18649.1, "ram_available_mb": 44191.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.403, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.588}, "timestamp": "2026-01-31T00:42:18.319269"}
{"image_index": 429, "image_name": "000000048924.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000048924.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5969.516, "latencies_ms": [5969.516], "images_per_second": 0.168, "prompt_tokens": 22, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image depicts a green tent set up in a natural, wooded area during sunset. The tent is illuminated by the warm, golden light of the setting sun, casting a soft glow on the surrounding foliage. The scene is characterized by the contrast between the vibrant green of the tent and the muted tones of the forest, as well as the gentle hues of the sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.1, "ram_available_mb": 44191.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.87, "power_cpu_cv_mean_watts": 1.898, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 69.08}, "timestamp": "2026-01-31T00:42:26.310139"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3785.682, "latencies_ms": [3785.682], "images_per_second": 0.264, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 6, "output_text": "A vintage black and white photograph captures a scene at a train station where a train is arriving or departing, with passengers waiting on the platform, and a steam locomotive emitting smoke from its chimney.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18649.1, "ram_available_mb": 44191.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.785, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 71.419}, "timestamp": "2026-01-31T00:42:32.203319"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8858.964, "latencies_ms": [8858.964], "images_per_second": 0.113, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 6, "output_text": "- Train: 1\n- Train Car: 1\n- Train Engine: 1\n- Train Carriage: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train Car: 1\n- Train", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.6, "ram_available_mb": 44191.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18649.9, "ram_available_mb": 44191.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.813, "power_cpu_cv_mean_watts": 2.082, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 67.653}, "timestamp": "2026-01-31T00:42:43.083048"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6329.419, "latencies_ms": [6329.419], "images_per_second": 0.158, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 6, "output_text": "The main object in the foreground is a vintage steam locomotive, which is positioned on the left side of the image. The locomotive is connected to a train car on the right side of the image. In the background, there are buildings and trees, indicating that the scene is set in a town or city. The locomotive is near the train car, and the background buildings and trees are further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.9, "ram_available_mb": 44191.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.722, "power_cpu_cv_mean_watts": 1.949, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 69.264}, "timestamp": "2026-01-31T00:42:51.457386"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3986.039, "latencies_ms": [3986.039], "images_per_second": 0.251, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The image depicts a vintage scene at a train station, featuring a classic steam locomotive with a train car visible in the background. A group of people is gathered at the platform, possibly waiting for the train to arrive.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18649.9, "ram_available_mb": 44191.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.461, "power_cpu_cv_mean_watts": 1.626, "power_sys_5v0_mean_watts": 7.962, "gpu_utilization_percent_mean": 71.152}, "timestamp": "2026-01-31T00:42:57.465178"}
{"image_index": 430, "image_name": "000000049060.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049060.jpg", "image_width": 640, "image_height": 411, "image_resolution": "640x411", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4526.794, "latencies_ms": [4526.794], "images_per_second": 0.221, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 6, "output_text": "The image is a black and white photograph featuring a vintage steam locomotive with a prominent smokestack and a large, rounded front. The locomotive is stationed on tracks, with a group of people gathered on the platform, suggesting a historical or nostalgic setting.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18649.9, "ram_available_mb": 44191.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.908, "power_cpu_cv_mean_watts": 1.759, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 70.711}, "timestamp": "2026-01-31T00:43:04.032914"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3417.082, "latencies_ms": [3417.082], "images_per_second": 0.293, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The image depicts a densely packed urban street scene, filled with numerous signs in both English and Chinese characters, indicating a bustling commercial area with a variety of businesses and services.", "error": null, "sys_before": {"cpu_percent": 28.3, "ram_used_mb": 18649.9, "ram_available_mb": 44191.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.355, "power_cpu_cv_mean_watts": 1.559, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 73.286}, "timestamp": "2026-01-31T00:43:09.578387"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5975.248, "latencies_ms": [5975.248], "images_per_second": 0.167, "prompt_tokens": 26, "response_tokens_est": 80, "n_tiles": 6, "output_text": "- 1. Signboard: 8\n- 2. Signboard: 8\n- 3. Signboard: 8\n- 4. Signboard: 8\n- 5. Signboard: 8\n- 6. Signboard: 8\n- 7. Signboard: 8\n- 8. Signboard: 8", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.831, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 8.029, "gpu_utilization_percent_mean": 69.38}, "timestamp": "2026-01-31T00:43:17.587066"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4889.42, "latencies_ms": [4889.42], "images_per_second": 0.205, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The main objects in the image are numerous signs with Japanese characters, which are densely packed and appear to be hanging from a metal framework. The signs are in the foreground, with the background consisting of a multi-story building. The signs are positioned close to each other, creating a crowded and busy atmosphere.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.843, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.048, "gpu_utilization_percent_mean": 70.675}, "timestamp": "2026-01-31T00:43:24.500831"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5560.427, "latencies_ms": [5560.427], "images_per_second": 0.18, "prompt_tokens": 24, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The image depicts a bustling urban street scene, likely in a Chinatown area, as indicated by the numerous signs in Chinese characters. The street is crowded with pedestrians, and the buildings are multi-storied, with balconies and windows visible. The signs are densely packed, creating a chaotic yet vibrant atmosphere typical of a busy city street.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.012, "power_cpu_cv_mean_watts": 1.874, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.426}, "timestamp": "2026-01-31T00:43:32.107848"}
{"image_index": 431, "image_name": "000000049091.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049091.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5954.739, "latencies_ms": [5954.739], "images_per_second": 0.168, "prompt_tokens": 22, "response_tokens_est": 80, "n_tiles": 6, "output_text": "The image is a black and white photograph capturing a bustling urban street scene. The notable visual attributes include the dense array of signage in various languages, predominantly in black and white, with some signs featuring red and blue colors. The lighting is dim, likely due to the overcast sky, and the materials used for the signs appear to be metal or plastic, typical of urban street signs.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.911, "power_cpu_cv_mean_watts": 1.93, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 68.94}, "timestamp": "2026-01-31T00:43:40.123722"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3164.891, "latencies_ms": [3164.891], "images_per_second": 0.316, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 6, "output_text": "A man is lying on a concrete ledge by a body of water, wearing sunglasses and shorts, while another person is lying on a blue blanket on the grass.", "error": null, "sys_before": {"cpu_percent": 30.3, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.93, "power_cpu_cv_mean_watts": 1.493, "power_sys_5v0_mean_watts": 8.025, "gpu_utilization_percent_mean": 74.077}, "timestamp": "2026-01-31T00:43:45.431328"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4031.704, "latencies_ms": [4031.704], "images_per_second": 0.248, "prompt_tokens": 26, "response_tokens_est": 48, "n_tiles": 6, "output_text": "- sign: 2\n- grass: 1\n- bench: 1\n- water: 1\n- person: 1\n- sign: 1\n- tree: 1\n- bench: 1", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18649.8, "ram_available_mb": 44191.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.665, "power_cpu_cv_mean_watts": 1.674, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 72.242}, "timestamp": "2026-01-31T00:43:51.496714"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4353.769, "latencies_ms": [4353.769], "images_per_second": 0.23, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The main objects in the image are a sign and a bench. The sign is placed on the ground in the foreground, while the bench is situated in the background. The sign is near the grassy area, and the bench is further away from the sign.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.246, "power_cpu_cv_mean_watts": 1.713, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 71.167}, "timestamp": "2026-01-31T00:43:57.909138"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7837.932, "latencies_ms": [7837.932], "images_per_second": 0.128, "prompt_tokens": 24, "response_tokens_est": 111, "n_tiles": 6, "output_text": "The image depicts a serene lakeside scene with a man lounging on a concrete bench by the water's edge. The man is shirtless, wearing shorts, and appears relaxed, enjoying the tranquil environment. In the foreground, there is a sign that reads \"CLOSED\" and \"Laketon Trail Cross,\" indicating that the area is closed to the public and is part of the Laketon Trail Crossing. The setting is a peaceful lakeside park, with the man taking a moment to relax and enjoy the natural surroundings.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.7, "ram_used_mb": 18650.6, "ram_available_mb": 44190.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.118, "power_cpu_cv_mean_watts": 2.038, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 67.985}, "timestamp": "2026-01-31T00:44:07.782723"}
{"image_index": 432, "image_name": "000000049259.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049259.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4215.857, "latencies_ms": [4215.857], "images_per_second": 0.237, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image features a blue wooden sign with white lettering that reads \"CLOSED\" and \"Laketon Trail Crossing.\" The sign is placed on a grassy area with a clear blue sky overhead, indicating a sunny day with good lighting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.6, "ram_available_mb": 44190.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.251, "power_cpu_cv_mean_watts": 1.67, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 70.886}, "timestamp": "2026-01-31T00:44:14.056755"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3555.278, "latencies_ms": [3555.278], "images_per_second": 0.281, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 6, "output_text": "A golden retriever is lying on the grass, panting with its tongue out, while a brown horse stands behind it, both appearing to be enjoying the sunny day in a pastoral setting.", "error": null, "sys_before": {"cpu_percent": 26.0, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.072, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 72.966}, "timestamp": "2026-01-31T00:44:19.729852"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2050.113, "latencies_ms": [2050.113], "images_per_second": 0.488, "prompt_tokens": 26, "response_tokens_est": 15, "n_tiles": 6, "output_text": "dog: 1\nhorse: 2\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.5, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.478, "power_cpu_cv_mean_watts": 0.926, "power_sys_5v0_mean_watts": 7.955, "gpu_utilization_percent_mean": 80.938}, "timestamp": "2026-01-31T00:44:23.803813"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5076.148, "latencies_ms": [5076.148], "images_per_second": 0.197, "prompt_tokens": 30, "response_tokens_est": 65, "n_tiles": 6, "output_text": "The main objects in the image are a brown horse and a golden retriever. The brown horse is in the background, while the golden retriever is in the foreground. The horse is slightly out of focus, indicating it is farther away, while the dog is in sharp focus, suggesting it is closer to the camera.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18650.1, "ram_available_mb": 44190.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.499, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 70.119}, "timestamp": "2026-01-31T00:44:30.892388"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3941.254, "latencies_ms": [3941.254], "images_per_second": 0.254, "prompt_tokens": 24, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The image captures a serene scene in a grassy field with a golden retriever and a brown horse. The dog is lying down, seemingly relaxed, while the horse stands nearby, both appearing content in their natural environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18650.3, "ram_available_mb": 44190.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.458, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 71.879}, "timestamp": "2026-01-31T00:44:36.866712"}
{"image_index": 433, "image_name": "000000049269.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049269.jpg", "image_width": 431, "image_height": 640, "image_resolution": "431x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3820.55, "latencies_ms": [3820.55], "images_per_second": 0.262, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The image features a golden retriever dog with a fluffy coat, lying on a lush green field under a clear blue sky. The lighting is bright and natural, casting soft shadows on the dog and the grass.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18650.5, "ram_available_mb": 44190.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18650.2, "ram_available_mb": 44190.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.827, "power_cpu_cv_mean_watts": 1.653, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 71.871}, "timestamp": "2026-01-31T00:44:42.711214"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3644.513, "latencies_ms": [3644.513], "images_per_second": 0.274, "prompt_tokens": 12, "response_tokens_est": 15, "n_tiles": 12, "output_text": "A group of people are playing volleyball in a gymnasium.", "error": null, "sys_before": {"cpu_percent": 27.7, "ram_used_mb": 18649.7, "ram_available_mb": 44191.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.498, "power_cpu_cv_mean_watts": 0.907, "power_sys_5v0_mean_watts": 8.798, "gpu_utilization_percent_mean": 91.2}, "timestamp": "2026-01-31T00:44:48.523819"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4913.534, "latencies_ms": [4913.534], "images_per_second": 0.204, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 12, "output_text": "1. Volleyball\n2. Court\n3. Players\n4. Team\n5. Coach\n6. Spectators\n7. Ball\n8. Court", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.761, "power_cpu_cv_mean_watts": 1.279, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 88.683}, "timestamp": "2026-01-31T00:44:55.475592"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8352.6, "latencies_ms": [8352.6], "images_per_second": 0.12, "prompt_tokens": 30, "response_tokens_est": 92, "n_tiles": 12, "output_text": "The main objects in the image are a group of people playing volleyball in an indoor gymnasium. The foreground features a man in a blue sleeveless top and shorts, who is standing near the net, preparing to serve the volleyball. The background shows other players and spectators, with some standing near the walls and others near the net. The net is prominently placed in the center of the image, dividing the space into two halves.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.817, "power_cpu_cv_mean_watts": 1.75, "power_sys_5v0_mean_watts": 8.846, "gpu_utilization_percent_mean": 84.214}, "timestamp": "2026-01-31T00:45:05.879675"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5766.902, "latencies_ms": [5766.902], "images_per_second": 0.173, "prompt_tokens": 24, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image depicts an indoor sports facility with a blue floor marked with white lines, likely a basketball court. Several individuals, including both men and women, are present, some standing and others in motion, engaged in a volleyball game.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.947, "power_cpu_cv_mean_watts": 1.46, "power_sys_5v0_mean_watts": 8.801, "gpu_utilization_percent_mean": 86.854}, "timestamp": "2026-01-31T00:45:13.672120"}
{"image_index": 434, "image_name": "000000049759.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049759.jpg", "image_width": 640, "image_height": 457, "image_resolution": "640x457", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4850.161, "latencies_ms": [4850.161], "images_per_second": 0.206, "prompt_tokens": 22, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image depicts a brightly lit indoor sports court with a blue floor and white boundary lines. The lighting is evenly distributed, creating a well-lit environment.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.801, "power_cpu_cv_mean_watts": 1.251, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 88.875}, "timestamp": "2026-01-31T00:45:20.560951"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5734.306, "latencies_ms": [5734.306], "images_per_second": 0.174, "prompt_tokens": 12, "response_tokens_est": 50, "n_tiles": 12, "output_text": "The image depicts a serene savanna landscape with a herd of zebras grazing on the grassy plains, while a large flock of pink flamingos stands in the background, creating a striking contrast against the greenery.", "error": null, "sys_before": {"cpu_percent": 30.8, "ram_used_mb": 18648.1, "ram_available_mb": 44192.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.088, "power_cpu_cv_mean_watts": 1.477, "power_sys_5v0_mean_watts": 8.845, "gpu_utilization_percent_mean": 86.646}, "timestamp": "2026-01-31T00:45:28.478209"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10545.874, "latencies_ms": [10545.874], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "zebra: 3\nbuffalo: 2\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope: 1\nantelope:", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18647.2, "ram_available_mb": 44193.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18648.0, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.122, "power_cpu_cv_mean_watts": 1.881, "power_sys_5v0_mean_watts": 8.837, "gpu_utilization_percent_mean": 82.551}, "timestamp": "2026-01-31T00:45:41.076353"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8005.475, "latencies_ms": [8005.475], "images_per_second": 0.125, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 12, "output_text": "In the image, the foreground features a group of zebras grazing on the grassy field. The background is dominated by a vast expanse of water, likely a lake or a river, with numerous pink flamingos standing in the water. The zebras are positioned near the water's edge, while the flamingos are further away, creating a clear spatial relationship between the foreground and background elements.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.0, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18648.0, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.823, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 84.403}, "timestamp": "2026-01-31T00:45:51.116146"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6084.151, "latencies_ms": [6084.151], "images_per_second": 0.164, "prompt_tokens": 24, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The image depicts a serene savanna landscape with a herd of zebras grazing on the grassy plains. In the background, a large flock of pink flamingos is standing in the water, creating a striking contrast against the greenery.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18648.0, "ram_available_mb": 44192.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.646, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 8.792, "gpu_utilization_percent_mean": 85.804}, "timestamp": "2026-01-31T00:45:59.257721"}
{"image_index": 435, "image_name": "000000049761.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049761.jpg", "image_width": 640, "image_height": 479, "image_resolution": "640x479", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5196.422, "latencies_ms": [5196.422], "images_per_second": 0.192, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 12, "output_text": "The image depicts a serene savanna landscape with a clear sky, lush green grass, and a variety of wildlife. The lighting is bright and natural, casting soft shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.56, "power_cpu_cv_mean_watts": 1.35, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 88.814}, "timestamp": "2026-01-31T00:46:06.496516"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2436.42, "latencies_ms": [2436.42], "images_per_second": 0.41, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 6, "output_text": "A ginger and white cat is sitting on a wooden bench, looking at its reflection in a glass surface.", "error": null, "sys_before": {"cpu_percent": 27.0, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.269, "power_cpu_cv_mean_watts": 1.241, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 77.2}, "timestamp": "2026-01-31T00:46:11.081505"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3077.756, "latencies_ms": [3077.756], "images_per_second": 0.325, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Cat\n2. Cat\n3. Cat\n4. Cat\n5. Cat\n6. Cat\n7. Cat\n8. Cat", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.93, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 74.0}, "timestamp": "2026-01-31T00:46:16.186462"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5036.055, "latencies_ms": [5036.055], "images_per_second": 0.199, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main object in the foreground is a ginger and white cat, which is sitting on a wooden bench. The cat is positioned near the center of the image, with its head turned towards the camera. The background features a blurred wooden bench, indicating that the cat is sitting closer to the camera than the background.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.489, "power_cpu_cv_mean_watts": 1.84, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 69.881}, "timestamp": "2026-01-31T00:46:23.253839"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4761.246, "latencies_ms": [4761.246], "images_per_second": 0.21, "prompt_tokens": 24, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image depicts a cozy scene with a ginger and white cat sitting on a wooden deck. The cat is looking at its reflection in a glass surface, creating a sense of curiosity and playfulness. The deck's wooden planks and the cat's relaxed posture suggest a peaceful, domestic setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18648.2, "ram_available_mb": 44192.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.605, "power_cpu_cv_mean_watts": 1.772, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 70.7}, "timestamp": "2026-01-31T00:46:30.047484"}
{"image_index": 436, "image_name": "000000049810.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000049810.jpg", "image_width": 640, "image_height": 424, "image_resolution": "640x424", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3502.11, "latencies_ms": [3502.11], "images_per_second": 0.286, "prompt_tokens": 22, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image features a ginger and white cat sitting on a wooden deck. The cat's fur appears soft and slightly shiny, and the lighting is natural, casting a warm glow on the scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18648.4, "ram_available_mb": 44192.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.21, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 73.034}, "timestamp": "2026-01-31T00:46:35.608374"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4441.728, "latencies_ms": [4441.728], "images_per_second": 0.225, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "A row of boats are moored in a marina by a calm body of water, with a small town visible in the background.", "error": null, "sys_before": {"cpu_percent": 28.7, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.189, "power_cpu_cv_mean_watts": 1.169, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 88.189}, "timestamp": "2026-01-31T00:46:42.209124"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5240.397, "latencies_ms": [5240.397], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18648.9, "ram_available_mb": 44192.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.25, "power_cpu_cv_mean_watts": 1.356, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 87.409}, "timestamp": "2026-01-31T00:46:49.470734"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6564.276, "latencies_ms": [6564.276], "images_per_second": 0.152, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The main objects in the image are a boat and a dock. The boat is located in the foreground, near the dock, and is docked. The dock is situated in the middle ground, extending into the water. The background features a hilly landscape with trees and buildings, creating a scenic view.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18648.3, "ram_available_mb": 44192.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.462, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.813, "gpu_utilization_percent_mean": 85.309}, "timestamp": "2026-01-31T00:46:58.085176"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7464.721, "latencies_ms": [7464.721], "images_per_second": 0.134, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 12, "output_text": "The image depicts a serene lakeside scene with a calm body of water in the foreground, surrounded by lush greenery and a few buildings. Several boats are moored along the shore, and a lamppost stands near the water's edge. The overall atmosphere is peaceful and tranquil, with the natural beauty of the surroundings complementing the quiet activity of the boats.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18647.5, "ram_available_mb": 44193.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.955, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 84.571}, "timestamp": "2026-01-31T00:47:07.577142"}
{"image_index": 437, "image_name": "000000050006.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050006.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5891.061, "latencies_ms": [5891.061], "images_per_second": 0.17, "prompt_tokens": 22, "response_tokens_est": 51, "n_tiles": 12, "output_text": "The image depicts a serene lakeside scene with a calm, blue-green water body. The sky is overcast, casting a soft, diffused light over the entire scene. The boats are white, and the dock is made of concrete.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.8, "ram_available_mb": 44194.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.778, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.792, "gpu_utilization_percent_mean": 86.408}, "timestamp": "2026-01-31T00:47:15.502320"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4205.761, "latencies_ms": [4205.761], "images_per_second": 0.238, "prompt_tokens": 12, "response_tokens_est": 51, "n_tiles": 6, "output_text": "A man stands in the foreground, shirtless, with a bicycle in front of him, while a woman in a dress and a child in a stroller are visible in the background, all set against a backdrop of various signs and a street scene.", "error": null, "sys_before": {"cpu_percent": 30.3, "ram_used_mb": 18647.1, "ram_available_mb": 44193.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.059, "power_cpu_cv_mean_watts": 1.693, "power_sys_5v0_mean_watts": 8.064, "gpu_utilization_percent_mean": 71.257}, "timestamp": "2026-01-31T00:47:21.804750"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5445.561, "latencies_ms": [5445.561], "images_per_second": 0.184, "prompt_tokens": 26, "response_tokens_est": 71, "n_tiles": 6, "output_text": "1. Bicycle: 1\n2. Man: 1\n3. Street sign: 1\n4. Motorcycle: 1\n5. Motorcycle rider: 1\n6. Pedestrian: 1\n7. Pedestrian with umbrella: 1\n8. Pedestrian with backpack: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.9, "ram_available_mb": 44194.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.196, "power_cpu_cv_mean_watts": 1.86, "power_sys_5v0_mean_watts": 8.071, "gpu_utilization_percent_mean": 69.511}, "timestamp": "2026-01-31T00:47:29.268658"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4638.948, "latencies_ms": [4638.948], "images_per_second": 0.216, "prompt_tokens": 30, "response_tokens_est": 58, "n_tiles": 6, "output_text": "The main object in the foreground is a man standing next to a bicycle. He is wearing a towel around his waist. In the background, there are various signs and a person riding a bicycle. The man is positioned near the bicycle, and the signs are further back in the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.7, "ram_available_mb": 44194.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.983, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 8.073, "gpu_utilization_percent_mean": 70.763}, "timestamp": "2026-01-31T00:47:35.941572"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6753.735, "latencies_ms": [6753.735], "images_per_second": 0.148, "prompt_tokens": 24, "response_tokens_est": 93, "n_tiles": 6, "output_text": "The image depicts a street scene in an urban area, likely in a developing country given the presence of traditional clothing and the language on the signage. A man stands in the foreground, shirtless and wearing light-colored pants, holding a bicycle. In the background, there are various signs and structures, including a shop with a sign in Chinese, and a person riding a bicycle. The overall setting suggests a bustling, possibly informal marketplace or street market.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.508, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 8.049, "gpu_utilization_percent_mean": 68.607}, "timestamp": "2026-01-31T00:47:44.717217"}
{"image_index": 438, "image_name": "000000050145.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050145.jpg", "image_width": 480, "image_height": 320, "image_resolution": "480x320", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4989.561, "latencies_ms": [4989.561], "images_per_second": 0.2, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image is a black and white photograph featuring a man standing in front of a store with a sign in Chinese. The man is shirtless, wearing light-colored pants, and holding a bicycle. The store has a signboard with Chinese characters, and there are other indistinct figures and objects in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.681, "power_cpu_cv_mean_watts": 1.826, "power_sys_5v0_mean_watts": 8.058, "gpu_utilization_percent_mean": 70.634}, "timestamp": "2026-01-31T00:47:51.738934"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4324.885, "latencies_ms": [4324.885], "images_per_second": 0.231, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 12, "output_text": "The image shows a bunch of ripe bananas hanging from a wire, with a few bunches hanging from a wooden pole.", "error": null, "sys_before": {"cpu_percent": 28.8, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.31, "power_cpu_cv_mean_watts": 1.123, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 88.333}, "timestamp": "2026-01-31T00:47:58.209979"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10583.537, "latencies_ms": [10583.537], "images_per_second": 0.094, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "bananas: 20\nbottle-water: 1\nbucket: 1\ndoor: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe: 1\ndoorframe", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.037, "power_cpu_cv_mean_watts": 1.885, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 81.876}, "timestamp": "2026-01-31T00:48:10.811192"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5478.471, "latencies_ms": [5478.471], "images_per_second": 0.183, "prompt_tokens": 30, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The bananas are hanging from the ceiling, with the bunches in the foreground and the bunches in the background. The bananas are near the entrance of the building, with a ladder leaning against the door.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.245, "power_cpu_cv_mean_watts": 1.388, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 87.8}, "timestamp": "2026-01-31T00:48:18.305362"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6972.699, "latencies_ms": [6972.699], "images_per_second": 0.143, "prompt_tokens": 24, "response_tokens_est": 69, "n_tiles": 12, "output_text": "The image depicts a market stall with a large number of ripe, yellow bananas hanging from a wire. The bananas are displayed in a neat, organized manner, with some hanging from hooks and others hanging freely. The stall appears to be located in a small, rustic market setting, with a simple, unadorned background.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.225, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 85.724}, "timestamp": "2026-01-31T00:48:27.299240"}
{"image_index": 439, "image_name": "000000050149.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050149.jpg", "image_width": 500, "image_height": 376, "image_resolution": "500x376", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5527.382, "latencies_ms": [5527.382], "images_per_second": 0.181, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The image showcases a bunch of ripe, yellow bananas hanging from a wire, with a rustic, weathered look. The lighting is natural, casting soft shadows and highlighting the vibrant yellow color of the bananas.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.127, "power_cpu_cv_mean_watts": 1.427, "power_sys_5v0_mean_watts": 8.795, "gpu_utilization_percent_mean": 87.478}, "timestamp": "2026-01-31T00:48:34.875247"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2628.801, "latencies_ms": [2628.801], "images_per_second": 0.38, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A vintage green and white train is traveling on a track through a rural landscape with green fields and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 26.2, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.034, "power_cpu_cv_mean_watts": 1.277, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 77.0}, "timestamp": "2026-01-31T00:48:39.611066"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3560.24, "latencies_ms": [3560.24], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18646.1, "ram_available_mb": 44194.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.182, "power_cpu_cv_mean_watts": 1.533, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 72.793}, "timestamp": "2026-01-31T00:48:45.206635"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6452.429, "latencies_ms": [6452.429], "images_per_second": 0.155, "prompt_tokens": 30, "response_tokens_est": 88, "n_tiles": 6, "output_text": "The main object in the foreground is a green and white train car, which is positioned near the center of the image. The train car is connected to a series of red freight cars that are positioned on the left side of the image. In the background, there is a lush green field extending towards a hilly landscape with trees and a clear blue sky. The train car is situated on a railway track that runs parallel to the field.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.611, "power_cpu_cv_mean_watts": 1.965, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 68.982}, "timestamp": "2026-01-31T00:48:53.720431"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4292.308, "latencies_ms": [4292.308], "images_per_second": 0.233, "prompt_tokens": 24, "response_tokens_est": 52, "n_tiles": 6, "output_text": "The image depicts a serene countryside scene with a train traveling on a track through a green field. The train is composed of multiple red and green carriages, and the landscape features a distant mountain range and a clear blue sky with a few clouds.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.8, "ram_available_mb": 44195.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.167, "power_cpu_cv_mean_watts": 1.724, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 70.833}, "timestamp": "2026-01-31T00:49:00.043524"}
{"image_index": 440, "image_name": "000000050165.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050165.jpg", "image_width": 640, "image_height": 431, "image_resolution": "640x431", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4519.944, "latencies_ms": [4519.944], "images_per_second": 0.221, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 6, "output_text": "The image depicts a green and white train moving on a track through a rural landscape. The sky is clear with a few clouds, and the lighting suggests it is daytime. The train's color contrasts with the green grass and the blue sky, making it stand out.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.917, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 8.038, "gpu_utilization_percent_mean": 70.526}, "timestamp": "2026-01-31T00:49:06.577765"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4445.135, "latencies_ms": [4445.135], "images_per_second": 0.225, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 12, "output_text": "A man is standing on a sandy beach, holding a kite in his hand, with the ocean waves crashing in the background.", "error": null, "sys_before": {"cpu_percent": 27.2, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.198, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 88.405}, "timestamp": "2026-01-31T00:49:13.173501"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5527.995, "latencies_ms": [5527.995], "images_per_second": 0.181, "prompt_tokens": 26, "response_tokens_est": 45, "n_tiles": 12, "output_text": "beach: 1\nman: 1\nhat: 1\nshorts: 1\nshirt: 1\nwristband: 1\ncamera: 1\nkite: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.081, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 87.13}, "timestamp": "2026-01-31T00:49:20.733508"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8686.518, "latencies_ms": [8686.518], "images_per_second": 0.115, "prompt_tokens": 30, "response_tokens_est": 97, "n_tiles": 12, "output_text": "The main object in the foreground is a person standing on the sandy beach. The person is wearing a black shirt, khaki shorts, and black shoes. The person is holding a white object in their right hand and appears to be looking towards the ocean. The background features the ocean with waves crashing onto the shore, and a green surfboard is partially visible. The person is standing near the edge of the beach, with the surfboard slightly to the right of the person.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.537, "power_cpu_cv_mean_watts": 1.777, "power_sys_5v0_mean_watts": 8.846, "gpu_utilization_percent_mean": 83.671}, "timestamp": "2026-01-31T00:49:31.442335"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4944.004, "latencies_ms": [4944.004], "images_per_second": 0.202, "prompt_tokens": 24, "response_tokens_est": 35, "n_tiles": 12, "output_text": "The image depicts a person standing on a sandy beach with the ocean in the background. The person is holding a kite, which is flying in the air.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.5, "ram_available_mb": 44197.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.428, "power_cpu_cv_mean_watts": 1.27, "power_sys_5v0_mean_watts": 8.767, "gpu_utilization_percent_mean": 88.732}, "timestamp": "2026-01-31T00:49:38.417795"}
{"image_index": 441, "image_name": "000000050326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050326.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6666.215, "latencies_ms": [6666.215], "images_per_second": 0.15, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The image features a person standing on a sandy beach with the ocean in the background. The person is wearing a black shirt, khaki shorts, and black sandals, and is holding a green and black surfboard. The sky is partly cloudy, and the lighting is bright, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.37, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 85.643}, "timestamp": "2026-01-31T00:49:47.110387"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4792.045, "latencies_ms": [4792.045], "images_per_second": 0.209, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image shows a close-up of a plant with large, dark green leaves and a cluster of small, green broccoli florets growing in a red pot.", "error": null, "sys_before": {"cpu_percent": 27.0, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.933, "power_cpu_cv_mean_watts": 1.291, "power_sys_5v0_mean_watts": 8.863, "gpu_utilization_percent_mean": 87.225}, "timestamp": "2026-01-31T00:49:54.083178"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3896.253, "latencies_ms": [3896.253], "images_per_second": 0.257, "prompt_tokens": 26, "response_tokens_est": 18, "n_tiles": 12, "output_text": "broccoli: 1\npot: 1\npotting soil: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.97, "power_cpu_cv_mean_watts": 0.988, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 91.625}, "timestamp": "2026-01-31T00:50:00.015225"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8004.883, "latencies_ms": [8004.883], "images_per_second": 0.125, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 12, "output_text": "The main object in the foreground is a large, leafy green vegetable, likely a type of kale or collard greens, with a rich, dark green color. The vegetable is planted in a terracotta pot, which is placed on a dirt surface. In the background, there is another similar plant, also in a terracotta pot, indicating that these plants are part of a larger garden or farm setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.88, "power_cpu_cv_mean_watts": 1.715, "power_sys_5v0_mean_watts": 8.853, "gpu_utilization_percent_mean": 84.373}, "timestamp": "2026-01-31T00:50:10.058610"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6018.112, "latencies_ms": [6018.112], "images_per_second": 0.166, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 12, "output_text": "The image depicts a garden scene with a variety of leafy greens, including broccoli and kale, growing in terracotta pots. The setting appears to be outdoors, with a dirt ground and a hint of a fence or wall in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.799, "power_cpu_cv_mean_watts": 1.482, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 86.26}, "timestamp": "2026-01-31T00:50:18.099995"}
{"image_index": 442, "image_name": "000000050331.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050331.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7157.169, "latencies_ms": [7157.169], "images_per_second": 0.14, "prompt_tokens": 22, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image showcases a vibrant garden bed filled with large, green kale leaves. The kale is planted in a terracotta pot, which contrasts with the earthy tones of the soil and the greenery. The lighting is natural, suggesting a sunny day, and the colors are rich and vivid, highlighting the freshness of the plants.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.177, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 84.817}, "timestamp": "2026-01-31T00:50:27.286812"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2672.466, "latencies_ms": [2672.466], "images_per_second": 0.374, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "An elderly man is holding a young boy on a horse, both looking down at the horse, while a woman stands nearby.", "error": null, "sys_before": {"cpu_percent": 27.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.938, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.066, "gpu_utilization_percent_mean": 76.455}, "timestamp": "2026-01-31T00:50:32.072976"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3500.954, "latencies_ms": [3500.954], "images_per_second": 0.286, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 6, "output_text": "1. Man\n2. Boy\n3. Horse\n4. Pony\n5. Ponytail\n6. Shirt\n7. Pants\n8. Lifeguard", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.252, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 72.759}, "timestamp": "2026-01-31T00:50:37.595149"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5725.355, "latencies_ms": [5725.355], "images_per_second": 0.175, "prompt_tokens": 30, "response_tokens_est": 76, "n_tiles": 6, "output_text": "In the image, the man is standing in the foreground, holding the reins of the horse. The horse is positioned in the middle ground, with the man and the horse being the main subjects. The background features a building with a red facade and a window, and a small table with a lamp. The horse is near the man, and the building is further back.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.95, "power_cpu_cv_mean_watts": 1.904, "power_sys_5v0_mean_watts": 8.072, "gpu_utilization_percent_mean": 69.041}, "timestamp": "2026-01-31T00:50:45.344846"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5500.009, "latencies_ms": [5500.009], "images_per_second": 0.182, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts an outdoor scene with an elderly man and a young boy standing beside a small, light-colored horse. The man is holding the horse's reins, while the boy is looking down at the horse. The setting appears to be a quaint, possibly rural area, with a red building and a cobblestone path in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.098, "power_cpu_cv_mean_watts": 1.888, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 69.217}, "timestamp": "2026-01-31T00:50:52.871950"}
{"image_index": 443, "image_name": "000000050380.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050380.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5670.328, "latencies_ms": [5670.328], "images_per_second": 0.176, "prompt_tokens": 22, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The image features a man and a young boy standing beside a horse. The man is wearing a blue polo shirt and dark pants, while the boy is in a gray shirt and blue jeans. The horse is brown with a white patch on its face, and it is wearing a red halter. The scene is set outdoors during the daytime under clear, bright lighting.", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.076, "power_cpu_cv_mean_watts": 1.882, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 69.745}, "timestamp": "2026-01-31T00:51:00.583012"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2644.014, "latencies_ms": [2644.014], "images_per_second": 0.378, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A young child is walking through a field of tall grass and blue flowers, holding a brown stuffed animal in their hands.", "error": null, "sys_before": {"cpu_percent": 30.1, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.751, "power_cpu_cv_mean_watts": 1.22, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 76.524}, "timestamp": "2026-01-31T00:51:05.344471"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4396.512, "latencies_ms": [4396.512], "images_per_second": 0.227, "prompt_tokens": 26, "response_tokens_est": 54, "n_tiles": 6, "output_text": "- child: 1\n- teddy bear: 1\n- blue flowers: 1\n- green grass: 1\n- dirt path: 1\n- tree: 1\n- bushes: 1\n- sky: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.246, "power_cpu_cv_mean_watts": 1.735, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 71.028}, "timestamp": "2026-01-31T00:51:11.774944"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4553.906, "latencies_ms": [4553.906], "images_per_second": 0.22, "prompt_tokens": 30, "response_tokens_est": 56, "n_tiles": 6, "output_text": "The main object in the foreground is a young child holding a brown teddy bear. The child is standing on a dirt path surrounded by lush green grass and tall purple flowers. The background features a blurred field of flowers and greenery, indicating a natural, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.846, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 8.009, "gpu_utilization_percent_mean": 70.184}, "timestamp": "2026-01-31T00:51:18.347378"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4955.983, "latencies_ms": [4955.983], "images_per_second": 0.202, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The image depicts a young child, likely a boy, standing in a lush, green meadow surrounded by tall grass and a variety of blue flowers. The child is holding a brown teddy bear in his arms, and the scene is bathed in natural sunlight, creating a serene and peaceful atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.509, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 70.098}, "timestamp": "2026-01-31T00:51:25.363763"}
{"image_index": 444, "image_name": "000000050638.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050638.jpg", "image_width": 640, "image_height": 393, "image_resolution": "640x393", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4821.833, "latencies_ms": [4821.833], "images_per_second": 0.207, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a young child with light-colored hair, wearing a blue and white striped shirt and blue jeans. The child is holding a brown teddy bear. The scene is set in a lush, green environment with sunlight filtering through the foliage, creating a warm and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.665, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 8.055, "gpu_utilization_percent_mean": 70.6}, "timestamp": "2026-01-31T00:51:32.200798"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2327.295, "latencies_ms": [2327.295], "images_per_second": 0.43, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 6, "output_text": "A large, ripe orange sits on the asphalt, with a few cars parked in the background.", "error": null, "sys_before": {"cpu_percent": 35.4, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.67, "power_cpu_cv_mean_watts": 1.138, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 78.579}, "timestamp": "2026-01-31T00:51:36.676049"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3080.184, "latencies_ms": [3080.184], "images_per_second": 0.325, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Orange\n2. Car\n3. Car\n4. Car\n5. Car\n6. Car\n7. Car\n8. Car", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.009, "power_cpu_cv_mean_watts": 1.425, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 73.88}, "timestamp": "2026-01-31T00:51:41.788091"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5339.32, "latencies_ms": [5339.32], "images_per_second": 0.187, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main object in the foreground is an orange, which is positioned on the left side of the image. The orange is placed on the asphalt road, near the edge of the road. In the background, there are several cars parked along the side of the road, indicating that the orange is located in a parking lot or a similar area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.248, "power_cpu_cv_mean_watts": 1.859, "power_sys_5v0_mean_watts": 8.002, "gpu_utilization_percent_mean": 69.311}, "timestamp": "2026-01-31T00:51:49.150538"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5684.302, "latencies_ms": [5684.302], "images_per_second": 0.176, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The image depicts a scene on a city street with a large, ripe orange lying on the asphalt. The orange is positioned in the foreground, while a line of parked cars can be seen in the background, suggesting a parking lot or a street with vehicles. The setting appears to be during the daytime, with overcast skies and a few trees visible in the distance.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.937, "power_cpu_cv_mean_watts": 1.877, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 69.167}, "timestamp": "2026-01-31T00:51:56.888954"}
{"image_index": 445, "image_name": "000000050679.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050679.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4852.825, "latencies_ms": [4852.825], "images_per_second": 0.206, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image features a large, ripe orange lying on the asphalt road. The orange has a rich, vibrant orange color with a slightly textured surface, indicating it might be a ripe, possibly overripe orange. The lighting is soft and diffused, suggesting an overcast day with no direct sunlight.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.475, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 69.415}, "timestamp": "2026-01-31T00:52:03.788787"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4049.738, "latencies_ms": [4049.738], "images_per_second": 0.247, "prompt_tokens": 12, "response_tokens_est": 61, "n_tiles": 1, "output_text": "A man in a gray suit and white shirt sits at a wooden table, smiling at the camera, with a white bowl containing a white substance on the table in front of him. On the table, there are two bottles of beer, one with a brown label and the other with a clear label.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.434, "power_cpu_cv_mean_watts": 2.049, "power_sys_5v0_mean_watts": 7.067, "gpu_utilization_percent_mean": 66.529}, "timestamp": "2026-01-31T00:52:09.899713"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8198.676, "latencies_ms": [8198.676], "images_per_second": 0.122, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 1, "output_text": "- man: 1\n- suit: 1\n- tie: 1\n- shirt: 1\n- blazer: 1\n- pocket watch: 1\n- watch: 1\n- glass: 1\n- bowl: 1\n- bottle: 2\n- bottle cap: 1\n- bottle neck: 1\n- bottle label: 1\n- bottle cap: 1\n- bottle neck: 1\n- bottle cap: 1\n- bottle neck: 1\n- bottle neck: 1\n- bottle neck: 1\n- bottle neck", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.867, "power_cpu_cv_mean_watts": 2.228, "power_sys_5v0_mean_watts": 7.218, "gpu_utilization_percent_mean": 64.739}, "timestamp": "2026-01-31T00:52:20.147019"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4882.752, "latencies_ms": [4882.752], "images_per_second": 0.205, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 1, "output_text": "The main object in the foreground is a white bowl containing a small white object, possibly a piece of food or a decorative item. To the right of the bowl, there are two bottles of beer, one of which is partially visible and the other is fully visible. The background is a plain wall, and there is a wooden surface that the man is sitting on.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.741, "power_cpu_cv_mean_watts": 2.122, "power_sys_5v0_mean_watts": 7.111, "gpu_utilization_percent_mean": 66.45}, "timestamp": "2026-01-31T00:52:27.059437"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5005.464, "latencies_ms": [5005.464], "images_per_second": 0.2, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 1, "output_text": "The image depicts a man sitting at a table in a room with a plain white wall and wooden paneling. He is dressed in a gray suit and tie, with a white shirt underneath. On the table, there are two bottles of beer, a white bowl with a spoon, and a few keys. The man is smiling and appears to be in a relaxed setting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.7, "ram_available_mb": 44197.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.709, "power_cpu_cv_mean_watts": 2.099, "power_sys_5v0_mean_watts": 7.149, "gpu_utilization_percent_mean": 66.805}, "timestamp": "2026-01-31T00:52:34.089133"}
{"image_index": 446, "image_name": "000000050811.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050811.jpg", "image_width": 640, "image_height": 605, "image_resolution": "640x605", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3296.264, "latencies_ms": [3296.264], "images_per_second": 0.303, "prompt_tokens": 22, "response_tokens_est": 48, "n_tiles": 1, "output_text": "The man is wearing a gray suit with a white shirt and a light blue tie. The background is plain and white, with a wooden table and a white bowl on it. The lighting is soft and even, creating a calm atmosphere.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.492, "power_cpu_cv_mean_watts": 1.972, "power_sys_5v0_mean_watts": 6.977, "gpu_utilization_percent_mean": 68.222}, "timestamp": "2026-01-31T00:52:39.421281"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5881.809, "latencies_ms": [5881.809], "images_per_second": 0.17, "prompt_tokens": 12, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The image shows a neatly made bed with white linens and neatly stacked pillows, set against a light-colored wall with a small window above it, and a chair and a small table with a phone and some items on it in the background.", "error": null, "sys_before": {"cpu_percent": 34.4, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.081, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 85.673}, "timestamp": "2026-01-31T00:52:47.480828"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4855.463, "latencies_ms": [4855.463], "images_per_second": 0.206, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 12, "output_text": "bed: 1\npillows: 4\ntowels: 2\ncouch: 1\nchair: 1\ntable: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.757, "power_cpu_cv_mean_watts": 1.289, "power_sys_5v0_mean_watts": 8.779, "gpu_utilization_percent_mean": 88.39}, "timestamp": "2026-01-31T00:52:54.391473"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8564.687, "latencies_ms": [8564.687], "images_per_second": 0.117, "prompt_tokens": 30, "response_tokens_est": 95, "n_tiles": 12, "output_text": "The main objects in the image are a neatly made bed with white linens and pillows, positioned in the foreground. The bed is placed against a light-colored wall, and there is a small table with a chair to the left of the bed. The table holds various items, including a phone, a small black bag, and some papers. The room appears to be well-lit, with natural light coming from a window on the right side of the image.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.521, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 83.671}, "timestamp": "2026-01-31T00:53:04.995391"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7496.593, "latencies_ms": [7496.593], "images_per_second": 0.133, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The image depicts a neatly arranged hotel room with a white bed, neatly made bed, and a white towel on top of the bed. The room has a carpeted floor, a small table with a phone and some items on it, and a window with a view of a building outside. The overall setting suggests a clean, well-maintained, and comfortable environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.928, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 8.817, "gpu_utilization_percent_mean": 84.891}, "timestamp": "2026-01-31T00:53:14.533932"}
{"image_index": 447, "image_name": "000000050828.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050828.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5563.037, "latencies_ms": [5563.037], "images_per_second": 0.18, "prompt_tokens": 22, "response_tokens_est": 46, "n_tiles": 12, "output_text": "The image depicts a neatly made bed with white linens and pillows, set against a light-colored wall. The room is well-lit with natural light coming from a window, creating a bright and clean atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.5, "ram_available_mb": 44200.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.097, "power_cpu_cv_mean_watts": 1.44, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 87.532}, "timestamp": "2026-01-31T00:53:22.126675"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4415.117, "latencies_ms": [4415.117], "images_per_second": 0.226, "prompt_tokens": 12, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The image features a collection of plush toys, including a teddy bear wearing a green hat, a teddy bear wearing a red scarf, and a snowman wearing a green hat, all of which are adorned with the Coca-Cola logo.", "error": null, "sys_before": {"cpu_percent": 28.0, "ram_used_mb": 18640.5, "ram_available_mb": 44200.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.917, "power_cpu_cv_mean_watts": 1.742, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 71.162}, "timestamp": "2026-01-31T00:53:28.665553"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5490.171, "latencies_ms": [5490.171], "images_per_second": 0.182, "prompt_tokens": 26, "response_tokens_est": 72, "n_tiles": 6, "output_text": "1. teddy bear: 1\n2. teddy bear: 1\n3. teddy bear: 1\n4. teddy bear: 1\n5. teddy bear: 1\n6. teddy bear: 1\n7. teddy bear: 1\n8. teddy bear: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.258, "power_cpu_cv_mean_watts": 1.88, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 69.5}, "timestamp": "2026-01-31T00:53:36.176046"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5336.257, "latencies_ms": [5336.257], "images_per_second": 0.187, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main objects in the image are a teddy bear, a snowman, and a bottle. The teddy bear is positioned in the foreground, slightly to the left, with the snowman and the bottle positioned behind it. The teddy bear is the closest to the viewer, while the snowman and the bottle are further away.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18639.7, "ram_available_mb": 44201.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.141, "power_cpu_cv_mean_watts": 1.868, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 69.289}, "timestamp": "2026-01-31T00:53:43.570062"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4351.124, "latencies_ms": [4351.124], "images_per_second": 0.23, "prompt_tokens": 24, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The image depicts a cozy indoor scene featuring a plush teddy bear wearing a green hat and a red scarf, sitting on a blue fabric surface. The bear is holding a bottle in its paw, suggesting a playful or whimsical atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.7, "ram_available_mb": 44201.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.102, "power_cpu_cv_mean_watts": 1.69, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.278}, "timestamp": "2026-01-31T00:53:49.936930"}
{"image_index": 448, "image_name": "000000050844.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050844.jpg", "image_width": 334, "image_height": 500, "image_resolution": "334x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3855.88, "latencies_ms": [3855.88], "images_per_second": 0.259, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image features a teddy bear dressed in a green hat and a red scarf, standing against a blue background. The lighting is soft and warm, casting gentle shadows that enhance the texture of the bear's fur.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.825, "power_cpu_cv_mean_watts": 1.664, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.969}, "timestamp": "2026-01-31T00:53:55.842546"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2385.801, "latencies_ms": [2385.801], "images_per_second": 0.419, "prompt_tokens": 12, "response_tokens_est": 27, "n_tiles": 4, "output_text": "The image shows a clear glass bowl containing several ripe, orange fruits, likely oranges, placed on a textured silver surface.", "error": null, "sys_before": {"cpu_percent": 22.8, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5451.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.84, "power_cpu_cv_mean_watts": 1.496, "power_sys_5v0_mean_watts": 7.572, "gpu_utilization_percent_mean": 69.474}, "timestamp": "2026-01-31T00:54:00.323564"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1116.851, "latencies_ms": [1116.851], "images_per_second": 0.895, "prompt_tokens": 26, "response_tokens_est": 6, "n_tiles": 4, "output_text": "oranges: 8", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 2.5, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5463.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.921, "power_cpu_cv_mean_watts": 0.55, "power_sys_5v0_mean_watts": 7.506, "gpu_utilization_percent_mean": 79.5}, "timestamp": "2026-01-31T00:54:03.496785"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3975.683, "latencies_ms": [3975.683], "images_per_second": 0.252, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 4, "output_text": "The main objects in the image are a bowl of oranges. The bowl is placed on a textured surface, likely a tablecloth. The oranges are arranged in the bowl, with the closest ones to the viewer being the ones in the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18639.7, "ram_available_mb": 44201.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5465.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 16.636, "power_cpu_cv_mean_watts": 1.868, "power_sys_5v0_mean_watts": 7.687, "gpu_utilization_percent_mean": 64.485}, "timestamp": "2026-01-31T00:54:09.496455"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2958.08, "latencies_ms": [2958.08], "images_per_second": 0.338, "prompt_tokens": 24, "response_tokens_est": 36, "n_tiles": 4, "output_text": "The image shows a clear glass bowl filled with several oranges placed on a textured silver surface. The oranges appear fresh and are likely being prepared for consumption or display.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.7, "ram_available_mb": 44201.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5460.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.651, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 7.587, "gpu_utilization_percent_mean": 65.583}, "timestamp": "2026-01-31T00:54:14.493093"}
{"image_index": 449, "image_name": "000000050896.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050896.jpg", "image_width": 640, "image_height": 640, "image_resolution": "640x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5490.645, "latencies_ms": [5490.645], "images_per_second": 0.182, "prompt_tokens": 22, "response_tokens_est": 78, "n_tiles": 4, "output_text": "The image features a bowl of bright orange oranges, which are vividly colored and have a glossy, smooth surface. The lighting is soft and diffused, casting gentle shadows and highlighting the freshness of the oranges. The bowl is placed on a textured, metallic surface, possibly a tablecloth, which adds a subtle contrast to the oranges' vibrant hue.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4613.5, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5459.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 15.486, "power_cpu_cv_mean_watts": 2.028, "power_sys_5v0_mean_watts": 7.667, "gpu_utilization_percent_mean": 65.239}, "timestamp": "2026-01-31T00:54:22.001563"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1638.372, "latencies_ms": [1638.372], "images_per_second": 0.61, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 2, "output_text": "A surfer is riding a wave in the ocean, with the water splashing around him.", "error": null, "sys_before": {"cpu_percent": 24.1, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.521, "power_cpu_cv_mean_watts": 1.324, "power_sys_5v0_mean_watts": 6.901, "gpu_utilization_percent_mean": 66.231}, "timestamp": "2026-01-31T00:54:25.715716"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2431.323, "latencies_ms": [2431.323], "images_per_second": 0.411, "prompt_tokens": 26, "response_tokens_est": 33, "n_tiles": 2, "output_text": "1. Wave\n2. Surfer\n3. Ocean\n4. Wave\n5. Water\n6. Wave\n7. Ocean\n8. Wave", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.133, "power_cpu_cv_mean_watts": 1.741, "power_sys_5v0_mean_watts": 7.126, "gpu_utilization_percent_mean": 64.85}, "timestamp": "2026-01-31T00:54:30.176329"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3596.021, "latencies_ms": [3596.021], "images_per_second": 0.278, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 2, "output_text": "The main objects in the image are two surfers riding waves. The surfer in the foreground is closer to the viewer, while the surfer in the background is further away. The waves are in the foreground, and the ocean is in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.373, "power_cpu_cv_mean_watts": 1.988, "power_sys_5v0_mean_watts": 7.274, "gpu_utilization_percent_mean": 63.233}, "timestamp": "2026-01-31T00:54:35.824320"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4714.701, "latencies_ms": [4714.701], "images_per_second": 0.212, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 2, "output_text": "The image captures a dynamic scene of a surfer riding a large wave in the ocean. The surfer is skillfully maneuvering their surfboard, while the wave is breaking powerfully to the right, creating a frothy white crest. The overcast sky suggests a potentially challenging weather condition, adding to the intensity of the surfing activity.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.923, "power_cpu_cv_mean_watts": 2.084, "power_sys_5v0_mean_watts": 7.275, "gpu_utilization_percent_mean": 62.436}, "timestamp": "2026-01-31T00:54:42.575437"}
{"image_index": 450, "image_name": "000000050943.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000050943.jpg", "image_width": 640, "image_height": 319, "image_resolution": "640x319", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4333.119, "latencies_ms": [4333.119], "images_per_second": 0.231, "prompt_tokens": 22, "response_tokens_est": 64, "n_tiles": 2, "output_text": "The image depicts a large, frothy wave in a stormy ocean, with a surfer riding it. The wave is a deep blue-green color, and the surfer is wearing a black wetsuit. The sky is overcast, with a grayish hue, suggesting a gloomy weather condition.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.014, "power_cpu_cv_mean_watts": 2.002, "power_sys_5v0_mean_watts": 7.252, "gpu_utilization_percent_mean": 61.889}, "timestamp": "2026-01-31T00:54:48.940052"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4187.4, "latencies_ms": [4187.4], "images_per_second": 0.239, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "A tabby cat is sitting on a laptop keyboard, seemingly engrossed in its work on the computer screen.", "error": null, "sys_before": {"cpu_percent": 31.7, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.116, "power_cpu_cv_mean_watts": 1.107, "power_sys_5v0_mean_watts": 8.871, "gpu_utilization_percent_mean": 88.676}, "timestamp": "2026-01-31T00:54:55.284617"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5632.916, "latencies_ms": [5632.916], "images_per_second": 0.178, "prompt_tokens": 26, "response_tokens_est": 47, "n_tiles": 12, "output_text": "- laptop: 1\n- computer mouse: 1\n- keyboard: 1\n- computer monitor: 1\n- cat: 1\n- computer mouse pad: 1\n- computer mouse: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.12, "power_cpu_cv_mean_watts": 1.426, "power_sys_5v0_mean_watts": 8.769, "gpu_utilization_percent_mean": 86.875}, "timestamp": "2026-01-31T00:55:02.971680"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5944.728, "latencies_ms": [5944.728], "images_per_second": 0.168, "prompt_tokens": 30, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The main object in the foreground is a cat, which is positioned near the laptop keyboard. The laptop is situated in the background, with its screen displaying a Twitter page. The cat appears to be resting on the keyboard, suggesting a comfortable and familiar environment.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.965, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 86.36}, "timestamp": "2026-01-31T00:55:10.930661"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6799.913, "latencies_ms": [6799.913], "images_per_second": 0.147, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a domestic scene where a tabby cat is resting on a laptop keyboard. The cat is positioned on the right side of the laptop, with its head resting on the keyboard. The laptop is open, displaying a Twitter page, and the cat appears to be curious or interested in the content on the screen.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.369, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 84.966}, "timestamp": "2026-01-31T00:55:19.753895"}
{"image_index": 451, "image_name": "000000051008.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051008.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5967.267, "latencies_ms": [5967.267], "images_per_second": 0.168, "prompt_tokens": 22, "response_tokens_est": 52, "n_tiles": 12, "output_text": "The image features a cat with a white and brown tabby coat, resting on a laptop keyboard. The laptop screen displays a Twitter page, and the cat is wearing a purple collar. The lighting is dim, and the overall setting appears to be indoors.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.71, "power_cpu_cv_mean_watts": 1.474, "power_sys_5v0_mean_watts": 8.768, "gpu_utilization_percent_mean": 86.36}, "timestamp": "2026-01-31T00:55:27.769884"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1445.473, "latencies_ms": [1445.473], "images_per_second": 0.692, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 2, "output_text": "A group of horses is gathered in a field, with some feeding on hay.", "error": null, "sys_before": {"cpu_percent": 7.8, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 14.051, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 6.901, "gpu_utilization_percent_mean": 69.091}, "timestamp": "2026-01-31T00:55:31.270744"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2525.282, "latencies_ms": [2525.282], "images_per_second": 0.396, "prompt_tokens": 26, "response_tokens_est": 34, "n_tiles": 2, "output_text": "1. Horses\n2. Hay\n3. Haystack\n4. Hay\n5. Hay\n6. Hay\n7. Hay\n8. Hay", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.637, "power_cpu_cv_mean_watts": 1.782, "power_sys_5v0_mean_watts": 7.137, "gpu_utilization_percent_mean": 65.95}, "timestamp": "2026-01-31T00:55:35.829995"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3556.76, "latencies_ms": [3556.76], "images_per_second": 0.281, "prompt_tokens": 30, "response_tokens_est": 51, "n_tiles": 2, "output_text": "In the image, there is a group of horses in a field. The horses are in the foreground, with the brown horse in the center being the most prominent. The brown horse is near a pile of hay, which is located in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.441, "power_cpu_cv_mean_watts": 1.974, "power_sys_5v0_mean_watts": 7.223, "gpu_utilization_percent_mean": 63.517}, "timestamp": "2026-01-31T00:55:41.434410"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3397.991, "latencies_ms": [3397.991], "images_per_second": 0.294, "prompt_tokens": 24, "response_tokens_est": 49, "n_tiles": 2, "output_text": "The image depicts a group of horses in a pasture, with one horse in the foreground eating hay. The horses are gathered together, and the setting appears to be a rural area with greenery and a clear sky in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.571, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 7.225, "gpu_utilization_percent_mean": 61.643}, "timestamp": "2026-01-31T00:55:46.853657"}
{"image_index": 452, "image_name": "000000051309.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051309.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2990.179, "latencies_ms": [2990.179], "images_per_second": 0.334, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 2, "output_text": "The image depicts a group of horses in a pasture, with the horses' coats appearing dark brown. The lighting is natural, suggesting it is daytime, and the horses are grazing on hay.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.525, "power_cpu_cv_mean_watts": 1.842, "power_sys_5v0_mean_watts": 7.177, "gpu_utilization_percent_mean": 63.36}, "timestamp": "2026-01-31T00:55:51.860714"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4159.785, "latencies_ms": [4159.785], "images_per_second": 0.24, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 12, "output_text": "A surfer is riding a wave in the ocean, wearing a wetsuit and demonstrating skillful maneuvering.", "error": null, "sys_before": {"cpu_percent": 28.1, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.79, "power_cpu_cv_mean_watts": 1.109, "power_sys_5v0_mean_watts": 8.819, "gpu_utilization_percent_mean": 88.057}, "timestamp": "2026-01-31T00:55:58.149617"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4536.64, "latencies_ms": [4536.64], "images_per_second": 0.22, "prompt_tokens": 26, "response_tokens_est": 29, "n_tiles": 12, "output_text": "surfboard: 1\nsurfer: 1\nwater: 1\nocean: 1\nwave: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.198, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.765, "gpu_utilization_percent_mean": 89.342}, "timestamp": "2026-01-31T00:56:04.701591"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5799.81, "latencies_ms": [5799.81], "images_per_second": 0.172, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The main object in the foreground is a surfer riding a wave. The surfer is positioned on a white surfboard, which is partially submerged in the water. The background features a rocky shoreline and a partly cloudy sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.938, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.773, "gpu_utilization_percent_mean": 86.646}, "timestamp": "2026-01-31T00:56:12.536464"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7803.053, "latencies_ms": [7803.053], "images_per_second": 0.128, "prompt_tokens": 24, "response_tokens_est": 83, "n_tiles": 12, "output_text": "The image captures a surfer in action on a choppy ocean wave, skillfully maneuvering a surfboard. The surfer, dressed in a black wetsuit, is leaning forward with his arms extended, showcasing his expertise in surfing. The scene takes place in a coastal environment, with the surfer navigating the challenging waves against a backdrop of a rugged coastline and a partly cloudy sky.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.955, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 8.818, "gpu_utilization_percent_mean": 84.606}, "timestamp": "2026-01-31T00:56:22.369450"}
{"image_index": 453, "image_name": "000000051314.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051314.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6715.771, "latencies_ms": [6715.771], "images_per_second": 0.149, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image captures a surfer in a black wetsuit riding a wave on a surfboard. The water is a vibrant blue-green, and the surfer is partially submerged, creating a dynamic and energetic scene. The lighting is bright and natural, highlighting the surfer's form and the movement of the water.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.364, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 86.018}, "timestamp": "2026-01-31T00:56:31.114904"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3420.511, "latencies_ms": [3420.511], "images_per_second": 0.292, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The image features a collection of Halloween-themed pumpkins, each adorned with unique and creative designs, including a smiling face, a skeleton, and a character from a popular comic book.", "error": null, "sys_before": {"cpu_percent": 34.1, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.324, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 73.429}, "timestamp": "2026-01-31T00:56:36.668092"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5068.559, "latencies_ms": [5068.559], "images_per_second": 0.197, "prompt_tokens": 26, "response_tokens_est": 65, "n_tiles": 6, "output_text": "1. Pumpkin: 2\n2. Floral arrangement: 1\n3. Man figure: 1\n4. Man figure: 1\n5. Man figure: 1\n6. Man figure: 1\n7. Man figure: 1\n8. Man figure: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.45, "power_cpu_cv_mean_watts": 1.821, "power_sys_5v0_mean_watts": 7.972, "gpu_utilization_percent_mean": 69.643}, "timestamp": "2026-01-31T00:56:43.773938"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4964.429, "latencies_ms": [4964.429], "images_per_second": 0.201, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The main objects in the image are a collection of pumpkins and a floral arrangement. The pumpkins are arranged in a row, with the foreground pumpkin being the largest and the background pumpkins being smaller. The floral arrangement is placed in front of the pumpkins, adding a pop of color to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.575, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 7.987, "gpu_utilization_percent_mean": 70.049}, "timestamp": "2026-01-31T00:56:50.762097"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6152.241, "latencies_ms": [6152.241], "images_per_second": 0.163, "prompt_tokens": 24, "response_tokens_est": 83, "n_tiles": 6, "output_text": "The image depicts a festive scene centered around a collection of carved pumpkins, each featuring unique and whimsical designs. The pumpkins are arranged on a table, with one prominently displaying a smiling face and another carved with a creature's face. The setting appears to be indoors, possibly in a home or a themed event space, as suggested by the presence of books and decorative items in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.768, "power_cpu_cv_mean_watts": 1.925, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 68.846}, "timestamp": "2026-01-31T00:56:58.947040"}
{"image_index": 454, "image_name": "000000051326.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051326.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5487.846, "latencies_ms": [5487.846], "images_per_second": 0.182, "prompt_tokens": 22, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image showcases a collection of carved pumpkins, each with unique and creative designs. The pumpkins are predominantly orange, with some featuring intricate details and faces. The lighting is soft and natural, casting gentle shadows that enhance the textures and details of the pumpkins. The overall atmosphere is cozy and festive, evoking a sense of celebration and creativity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.284, "power_cpu_cv_mean_watts": 1.868, "power_sys_5v0_mean_watts": 7.974, "gpu_utilization_percent_mean": 69.778}, "timestamp": "2026-01-31T00:57:06.444924"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2678.706, "latencies_ms": [2678.706], "images_per_second": 0.373, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 2, "output_text": "The image depicts a small, dimly lit bathroom with a white sink, a black trash bag, and a door slightly ajar, revealing a glimpse of the room beyond.", "error": null, "sys_before": {"cpu_percent": 23.1, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.486, "power_cpu_cv_mean_watts": 1.82, "power_sys_5v0_mean_watts": 7.147, "gpu_utilization_percent_mean": 64.0}, "timestamp": "2026-01-31T00:57:11.179606"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3662.44, "latencies_ms": [3662.44], "images_per_second": 0.273, "prompt_tokens": 26, "response_tokens_est": 53, "n_tiles": 2, "output_text": "- sink: 1\n- mirror: 1\n- soap dispenser: 1\n- soap: 1\n- soap bottle: 1\n- soap bar: 1\n- trash bag: 1\n- door: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.12, "power_cpu_cv_mean_watts": 1.908, "power_sys_5v0_mean_watts": 7.207, "gpu_utilization_percent_mean": 62.967}, "timestamp": "2026-01-31T00:57:16.872496"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4314.016, "latencies_ms": [4314.016], "images_per_second": 0.232, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 2, "output_text": "The main objects in the image are a sink, a trash bag, and a door. The sink is located on the left side of the image, near the wall. The trash bag is in the foreground, close to the sink. The door is located on the right side of the image, near the wall.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.253, "power_cpu_cv_mean_watts": 2.036, "power_sys_5v0_mean_watts": 7.324, "gpu_utilization_percent_mean": 60.714}, "timestamp": "2026-01-31T00:57:23.221902"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4253.731, "latencies_ms": [4253.731], "images_per_second": 0.235, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 2, "output_text": "The image depicts a small, dimly lit bathroom with a white sink and a mirror above it. The walls are bare, and there is a black trash bag on the floor. The door is slightly ajar, and the overall setting appears to be in a state of disrepair or renovation.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.784, "power_cpu_cv_mean_watts": 1.99, "power_sys_5v0_mean_watts": 7.26, "gpu_utilization_percent_mean": 63.114}, "timestamp": "2026-01-31T00:57:29.527940"}
{"image_index": 455, "image_name": "000000051598.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051598.jpg", "image_width": 360, "image_height": 640, "image_resolution": "360x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3430.524, "latencies_ms": [3430.524], "images_per_second": 0.292, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 2, "output_text": "The image depicts a small, dimly lit bathroom with a white sink and a black trash bag on the floor. The walls are plain and have a yellowish hue, and there is a mirror with a silver frame above the sink.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.37, "power_cpu_cv_mean_watts": 1.916, "power_sys_5v0_mean_watts": 7.214, "gpu_utilization_percent_mean": 63.464}, "timestamp": "2026-01-31T00:57:35.014059"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2581.569, "latencies_ms": [2581.569], "images_per_second": 0.387, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "A young child is sitting on a bed, looking at a laptop screen, with their feet resting on the bed.", "error": null, "sys_before": {"cpu_percent": 30.5, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.075, "power_cpu_cv_mean_watts": 1.316, "power_sys_5v0_mean_watts": 8.037, "gpu_utilization_percent_mean": 75.0}, "timestamp": "2026-01-31T00:57:39.737413"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3536.014, "latencies_ms": [3536.014], "images_per_second": 0.283, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "1. Baby\n2. Laptop\n3. Bed\n4. Child\n5. Child's feet\n6. Child's hands\n7. Child's legs\n8. Child's body", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.348, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 72.586}, "timestamp": "2026-01-31T00:57:45.287221"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5285.763, "latencies_ms": [5285.763], "images_per_second": 0.189, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main objects in the image are a laptop and a baby. The laptop is positioned on the left side of the image, with its screen facing the baby. The baby is sitting on the right side of the image, with their feet resting on the laptop. The background is plain and white, providing a neutral setting for the main subjects.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.0, "ram_available_mb": 44201.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.389, "power_cpu_cv_mean_watts": 1.868, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 69.556}, "timestamp": "2026-01-31T00:57:52.608429"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5358.524, "latencies_ms": [5358.524], "images_per_second": 0.187, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 6, "output_text": "The image depicts a black and white scene of a young child sitting on a bed, with a laptop open in front of them. The child appears to be focused on the screen, possibly engaged in an activity or learning something on the laptop. The setting is a simple, unadorned bedroom with a plain white wall in the background.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.193, "power_cpu_cv_mean_watts": 1.85, "power_sys_5v0_mean_watts": 8.024, "gpu_utilization_percent_mean": 69.733}, "timestamp": "2026-01-31T00:57:59.991534"}
{"image_index": 456, "image_name": "000000051610.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051610.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3847.575, "latencies_ms": [3847.575], "images_per_second": 0.26, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 6, "output_text": "The image is a black and white photograph featuring a young child sitting on a bed. The child is wearing a white t-shirt and has dark hair. The lighting is soft and even, creating a calm and intimate atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.786, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 72.062}, "timestamp": "2026-01-31T00:58:05.891161"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2695.263, "latencies_ms": [2695.263], "images_per_second": 0.371, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A person is skiing down a snowy slope, wearing a brown jacket and a helmet, with snow flying around them.", "error": null, "sys_before": {"cpu_percent": 28.4, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.882, "power_cpu_cv_mean_watts": 1.347, "power_sys_5v0_mean_watts": 7.993, "gpu_utilization_percent_mean": 76.409}, "timestamp": "2026-01-31T00:58:10.693406"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3546.0, "latencies_ms": [3546.0], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.408, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 7.988, "gpu_utilization_percent_mean": 72.517}, "timestamp": "2026-01-31T00:58:16.262502"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5561.362, "latencies_ms": [5561.362], "images_per_second": 0.18, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The main object in the foreground is a person skiing down a snowy slope. The person is wearing a brown jacket and a blue and orange helmet. The background features a snowy forest with trees and snow-covered branches. The person is positioned near the center of the image, slightly to the left, and the snowy slope extends to the right.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.209, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.652}, "timestamp": "2026-01-31T00:58:23.854272"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6036.627, "latencies_ms": [6036.627], "images_per_second": 0.166, "prompt_tokens": 24, "response_tokens_est": 81, "n_tiles": 6, "output_text": "The image depicts a snowy mountainous landscape with a skier in mid-action, descending a slope. The skier is dressed in a brown jacket and black pants, wearing a helmet and goggles, and is holding ski poles. The snow-covered trees and the skier's motion create a dynamic and energetic atmosphere, capturing the essence of winter sports in a picturesque snowy environment.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.6, "ram_available_mb": 44201.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.874, "power_cpu_cv_mean_watts": 1.922, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 69.24}, "timestamp": "2026-01-31T00:58:31.922135"}
{"image_index": 457, "image_name": "000000051712.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051712.jpg", "image_width": 640, "image_height": 368, "image_resolution": "640x368", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4106.393, "latencies_ms": [4106.393], "images_per_second": 0.244, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The skier is dressed in a brown jacket and black pants, with a colorful beanie and goggles. The snowy landscape is illuminated by soft, diffused light, suggesting a winter setting with a gentle, overcast sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.436, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 71.265}, "timestamp": "2026-01-31T00:58:38.042588"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4911.195, "latencies_ms": [4911.195], "images_per_second": 0.204, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 12, "output_text": "The image shows a neatly arranged hotel room with a bed, a small table lamp, and a few pillows on the bed, all set against a light-colored wall.", "error": null, "sys_before": {"cpu_percent": 29.5, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.921, "power_cpu_cv_mean_watts": 1.281, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 87.4}, "timestamp": "2026-01-31T00:58:45.085368"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4911.352, "latencies_ms": [4911.352], "images_per_second": 0.204, "prompt_tokens": 26, "response_tokens_est": 35, "n_tiles": 12, "output_text": "bed: 1\npillow: 2\ncouch: 1\nlamp: 1\ntable: 1\nsuitcase: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.719, "power_cpu_cv_mean_watts": 1.27, "power_sys_5v0_mean_watts": 8.767, "gpu_utilization_percent_mean": 88.537}, "timestamp": "2026-01-31T00:58:52.051027"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8890.071, "latencies_ms": [8890.071], "images_per_second": 0.112, "prompt_tokens": 30, "response_tokens_est": 101, "n_tiles": 12, "output_text": "The main objects in the image are a bed and a nightstand. The bed is positioned in the foreground, with a white bedspread and multiple pillows. The nightstand is located to the right of the bed, with a lamp and a small stack of books. The background features a window with curtains, a blue armchair, and a small table. The overall spatial relationship is that the bed is the central focus, with the nightstand and other objects providing context and depth to the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.1, "ram_available_mb": 44199.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.61, "power_cpu_cv_mean_watts": 1.783, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 83.92}, "timestamp": "2026-01-31T00:59:02.956089"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7396.432, "latencies_ms": [7396.432], "images_per_second": 0.135, "prompt_tokens": 24, "response_tokens_est": 76, "n_tiles": 12, "output_text": "The image depicts a neatly arranged hotel room with a large bed at the center. The room is well-lit, featuring a white bedspread, a light-colored wall, and a small table with a lamp. The bed is adorned with various pillows in shades of blue and white, and there is a dark-colored suitcase on the floor to the left.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.029, "power_cpu_cv_mean_watts": 1.647, "power_sys_5v0_mean_watts": 8.81, "gpu_utilization_percent_mean": 84.742}, "timestamp": "2026-01-31T00:59:12.404892"}
{"image_index": 458, "image_name": "000000051738.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051738.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6501.02, "latencies_ms": [6501.02], "images_per_second": 0.154, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The room is well-lit with natural light streaming in through large windows adorned with light-colored curtains. The walls are painted in a light, neutral color, and the furniture is made of a combination of materials, including a light-colored sofa, a wooden bed frame, and a blue armchair.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.44, "power_cpu_cv_mean_watts": 1.543, "power_sys_5v0_mean_watts": 8.804, "gpu_utilization_percent_mean": 85.778}, "timestamp": "2026-01-31T00:59:20.924227"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4501.774, "latencies_ms": [4501.774], "images_per_second": 0.222, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 12, "output_text": "A skier is performing a jump over a red railing on a snowy slope, surrounded by other skiers and snowboarders.", "error": null, "sys_before": {"cpu_percent": 29.1, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.233, "power_cpu_cv_mean_watts": 1.169, "power_sys_5v0_mean_watts": 8.803, "gpu_utilization_percent_mean": 88.297}, "timestamp": "2026-01-31T00:59:27.569248"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5228.699, "latencies_ms": [5228.699], "images_per_second": 0.191, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.34, "power_cpu_cv_mean_watts": 1.332, "power_sys_5v0_mean_watts": 8.772, "gpu_utilization_percent_mean": 87.86}, "timestamp": "2026-01-31T00:59:34.817984"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7507.914, "latencies_ms": [7507.914], "images_per_second": 0.133, "prompt_tokens": 30, "response_tokens_est": 78, "n_tiles": 12, "output_text": "The main object in the foreground is a person skiing down a snowy slope. The person is positioned near the center of the image, slightly to the right. In the background, there is a ski lift with several people on it, and a red fence is visible. The ski lift is located further back on the slope, and the fence is near the top of the slope.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.106, "power_cpu_cv_mean_watts": 1.678, "power_sys_5v0_mean_watts": 8.824, "gpu_utilization_percent_mean": 84.889}, "timestamp": "2026-01-31T00:59:44.357695"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7166.701, "latencies_ms": [7166.701], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a snowy mountain slope with a skier in mid-air, performing a jump. The skier is dressed in a white jacket and orange pants, and is surrounded by other skiers and snowboarders on the slope. The clear blue sky and the bright sunlight create a vibrant and energetic atmosphere, highlighting the excitement of winter sports.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.065, "power_cpu_cv_mean_watts": 1.635, "power_sys_5v0_mean_watts": 8.836, "gpu_utilization_percent_mean": 84.783}, "timestamp": "2026-01-31T00:59:53.560520"}
{"image_index": 459, "image_name": "000000051938.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051938.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6393.874, "latencies_ms": [6393.874], "images_per_second": 0.156, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The image depicts a snowy mountain landscape under a clear blue sky. The snow is pristine and undisturbed, with a few scattered skiers and snowboarders in the background. The lighting is bright and natural, casting shadows on the snow, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.346, "power_cpu_cv_mean_watts": 1.535, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 85.315}, "timestamp": "2026-01-31T01:00:01.997979"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3596.306, "latencies_ms": [3596.306], "images_per_second": 0.278, "prompt_tokens": 12, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The image depicts a close-up view of a metal parking meter with graffiti on its side, set against a backdrop of a colorful, urban wall adorned with various graffiti tags and designs.", "error": null, "sys_before": {"cpu_percent": 28.2, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.998, "power_cpu_cv_mean_watts": 1.601, "power_sys_5v0_mean_watts": 8.062, "gpu_utilization_percent_mean": 72.967}, "timestamp": "2026-01-31T01:00:07.716907"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3458.826, "latencies_ms": [3458.826], "images_per_second": 0.289, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 6, "output_text": "1. Graffiti\n2. Metal parking meter\n3. Wall\n4. Street\n5. Sidewalk\n6. Urban environment\n7. Art\n8. Street", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.271, "power_cpu_cv_mean_watts": 1.502, "power_sys_5v0_mean_watts": 7.989, "gpu_utilization_percent_mean": 72.393}, "timestamp": "2026-01-31T01:00:13.188929"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5514.45, "latencies_ms": [5514.45], "images_per_second": 0.181, "prompt_tokens": 30, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The main objects in the image are a metal parking meter and a wall adorned with graffiti. The parking meter is positioned near the bottom left corner of the image, while the graffiti is prominently displayed on the wall, occupying the majority of the background. The graffiti is in the foreground, with the parking meter situated in the background.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.085, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.078, "gpu_utilization_percent_mean": 69.478}, "timestamp": "2026-01-31T01:00:20.718760"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5503.314, "latencies_ms": [5503.314], "images_per_second": 0.182, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The image depicts a vibrant urban street scene with a graffiti-covered wall as the backdrop. The wall is adorned with various colorful and intricate graffiti art, including a prominent, stylized figure in the center. The scene is set in an urban environment, likely a city street, and the graffiti art suggests a vibrant and creative atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.13, "power_cpu_cv_mean_watts": 1.846, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 69.935}, "timestamp": "2026-01-31T01:00:28.243509"}
{"image_index": 460, "image_name": "000000051961.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051961.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6056.509, "latencies_ms": [6056.509], "images_per_second": 0.165, "prompt_tokens": 22, "response_tokens_est": 81, "n_tiles": 6, "output_text": "The image showcases a vibrant urban street scene with a graffiti-covered wall. The wall is adorned with various colors, including blue, yellow, and black, creating a dynamic and colorful backdrop. The lighting is bright, casting sharp shadows and highlighting the textures of the graffiti. The materials used in the graffiti appear to be painted on a metal pole, adding to the urban aesthetic.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.673, "power_cpu_cv_mean_watts": 1.916, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 68.725}, "timestamp": "2026-01-31T01:00:36.334890"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1845.438, "latencies_ms": [1845.438], "images_per_second": 0.542, "prompt_tokens": 12, "response_tokens_est": 12, "n_tiles": 6, "output_text": "A surfer is riding a wave in the ocean.", "error": null, "sys_before": {"cpu_percent": 25.9, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.26, "power_cpu_cv_mean_watts": 0.829, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 84.786}, "timestamp": "2026-01-31T01:00:40.284541"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3574.239, "latencies_ms": [3574.239], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.155, "power_cpu_cv_mean_watts": 1.532, "power_sys_5v0_mean_watts": 7.971, "gpu_utilization_percent_mean": 72.655}, "timestamp": "2026-01-31T01:00:45.883308"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4888.72, "latencies_ms": [4888.72], "images_per_second": 0.205, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The main object in the foreground is a surfer riding a wave. The wave is in the background, creating a clear visual separation between the surfer and the water. The surfer is positioned near the center of the image, while the wave is to the right, creating a dynamic and engaging scene.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.616, "power_cpu_cv_mean_watts": 1.778, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 70.341}, "timestamp": "2026-01-31T01:00:52.787834"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4891.759, "latencies_ms": [4891.759], "images_per_second": 0.204, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image captures a dynamic scene of a surfer riding a wave in the ocean. The surfer is positioned on a white surfboard, skillfully maneuvering through the frothy white water. The ocean is vast and blue, with the surfer's silhouette clearly visible against the backdrop of the wave.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.598, "power_cpu_cv_mean_watts": 1.762, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.975}, "timestamp": "2026-01-31T01:00:59.699250"}
{"image_index": 461, "image_name": "000000051976.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000051976.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4819.067, "latencies_ms": [4819.067], "images_per_second": 0.208, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a scene of a surfer riding a wave in the ocean. The water is a deep blue, and the wave is white, indicating a strong and powerful wave. The lighting is natural, with the sun shining from the left side, casting a blue hue over the entire scene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.685, "power_cpu_cv_mean_watts": 1.792, "power_sys_5v0_mean_watts": 8.027, "gpu_utilization_percent_mean": 70.3}, "timestamp": "2026-01-31T01:01:06.555113"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 7470.058, "latencies_ms": [7470.058], "images_per_second": 0.134, "prompt_tokens": 12, "response_tokens_est": 78, "n_tiles": 12, "output_text": "A yellow double-decker bus is parked on a street, with a sign displaying the destination \"Lytham\" and the number \"11\" on its front. Two men are standing on the sidewalk, one of whom is looking at the bus while the other is engaged in a conversation. The street is lined with a row of flowers, and there is a red brick pavement.", "error": null, "sys_before": {"cpu_percent": 33.9, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.048, "power_cpu_cv_mean_watts": 1.666, "power_sys_5v0_mean_watts": 8.833, "gpu_utilization_percent_mean": 83.306}, "timestamp": "2026-01-31T01:01:16.183879"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4683.335, "latencies_ms": [4683.335], "images_per_second": 0.214, "prompt_tokens": 26, "response_tokens_est": 31, "n_tiles": 12, "output_text": "bus: 1\npeople: 2\nbuilding: 1\nstreet: 1\nsign: 1\ntrees: 0", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.833, "power_cpu_cv_mean_watts": 1.232, "power_sys_5v0_mean_watts": 8.761, "gpu_utilization_percent_mean": 88.974}, "timestamp": "2026-01-31T01:01:22.892063"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6628.628, "latencies_ms": [6628.628], "images_per_second": 0.151, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The bus is parked on the side of the road, with the number 346 displayed on its front. The bus is positioned near the curb, with a small patch of flowers in the foreground. The background features a building with a red roof and a blue structure, while a person is standing near the bus.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.474, "power_cpu_cv_mean_watts": 1.58, "power_sys_5v0_mean_watts": 8.806, "gpu_utilization_percent_mean": 85.855}, "timestamp": "2026-01-31T01:01:31.551581"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 8328.228, "latencies_ms": [8328.228], "images_per_second": 0.12, "prompt_tokens": 24, "response_tokens_est": 91, "n_tiles": 12, "output_text": "The image depicts a scene on a city street with a yellow double-decker bus displaying the destination \"Lytham 11\" on its digital sign. The bus is parked on the side of the road, and two men are standing nearby, one of whom is looking at the bus while the other is engaged in a conversation. The street is lined with a mix of brick and paving stones, and there are some flowers in the foreground.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.619, "power_cpu_cv_mean_watts": 1.745, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 83.771}, "timestamp": "2026-01-31T01:01:41.920323"}
{"image_index": 462, "image_name": "000000052007.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052007.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 7055.915, "latencies_ms": [7055.915], "images_per_second": 0.142, "prompt_tokens": 22, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The bus in the image is yellow with black accents, featuring a digital display showing the route number \"11\" and destination \"Lytham.\" The bus is parked on a street with a red brick pavement and a white line marking the edge of the road. The lighting is bright, indicating daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.114, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 84.559}, "timestamp": "2026-01-31T01:01:51.000173"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3477.529, "latencies_ms": [3477.529], "images_per_second": 0.288, "prompt_tokens": 12, "response_tokens_est": 39, "n_tiles": 6, "output_text": "The image depicts a small, yellow and red airplane with the registration number \"SP-AWF\" on its fuselage, captured in mid-flight against a cloudy sky.", "error": null, "sys_before": {"cpu_percent": 23.5, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18645.9, "ram_available_mb": 44195.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.145, "power_cpu_cv_mean_watts": 1.547, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 72.759}, "timestamp": "2026-01-31T01:01:56.612901"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3538.542, "latencies_ms": [3538.542], "images_per_second": 0.283, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.7, "ram_available_mb": 44195.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.421, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.065, "gpu_utilization_percent_mean": 72.897}, "timestamp": "2026-01-31T01:02:02.184996"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4994.914, "latencies_ms": [4994.914], "images_per_second": 0.2, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main object in the image is a small yellow airplane with a red tail and landing gear. The airplane is positioned in the foreground, slightly to the left, and is in the process of landing. The background is a cloudy sky, providing a neutral backdrop that contrasts with the bright colors of the airplane.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.0, "ram_available_mb": 44195.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.529, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 70.143}, "timestamp": "2026-01-31T01:02:09.197843"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4581.534, "latencies_ms": [4581.534], "images_per_second": 0.218, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a small, yellow and red airplane in mid-flight against a cloudy sky. The airplane is captured in a side profile view, with its landing gear retracted and the propeller in motion, indicating that it is either taking off or preparing to land.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.781, "power_cpu_cv_mean_watts": 1.787, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 70.795}, "timestamp": "2026-01-31T01:02:15.819903"}
{"image_index": 463, "image_name": "000000052017.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052017.jpg", "image_width": 640, "image_height": 425, "image_resolution": "640x425", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4468.572, "latencies_ms": [4468.572], "images_per_second": 0.224, "prompt_tokens": 22, "response_tokens_est": 55, "n_tiles": 6, "output_text": "The notable visual attributes of the aircraft in the image include its bright yellow and red color scheme, which stands out against the overcast sky. The lighting is soft and diffused, likely due to the cloudy weather, casting a gentle glow on the aircraft's surface.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18646.6, "ram_available_mb": 44194.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.898, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 70.579}, "timestamp": "2026-01-31T01:02:22.338682"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2884.733, "latencies_ms": [2884.733], "images_per_second": 0.347, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "The image shows a large parking lot filled with numerous cars, with a view of a cityscape and a clear blue sky in the background.", "error": null, "sys_before": {"cpu_percent": 25.2, "ram_used_mb": 18646.4, "ram_available_mb": 44194.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.041, "power_cpu_cv_mean_watts": 1.401, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 74.5}, "timestamp": "2026-01-31T01:02:27.342993"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3556.676, "latencies_ms": [3556.676], "images_per_second": 0.281, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18646.3, "ram_available_mb": 44194.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.238, "power_cpu_cv_mean_watts": 1.546, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 73.345}, "timestamp": "2026-01-31T01:02:32.939713"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5617.145, "latencies_ms": [5617.145], "images_per_second": 0.178, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 6, "output_text": "The main objects in the image are a parking lot filled with numerous cars, a large building in the background, and a clear blue sky. The parking lot is located in the foreground, with the cars occupying the majority of the space. The building is situated in the background, slightly to the right, and the clear blue sky is visible above the parking lot.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.01, "power_cpu_cv_mean_watts": 1.866, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 69.0}, "timestamp": "2026-01-31T01:02:40.586639"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4160.61, "latencies_ms": [4160.61], "images_per_second": 0.24, "prompt_tokens": 24, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts an aerial view of a large parking lot filled with numerous cars, situated in an urban area with a mix of residential and commercial buildings in the background. The sky is clear with a few scattered clouds, suggesting a pleasant day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.3, "ram_available_mb": 44196.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.364, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 71.618}, "timestamp": "2026-01-31T01:02:46.777896"}
{"image_index": 464, "image_name": "000000052412.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052412.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3800.018, "latencies_ms": [3800.018], "images_per_second": 0.263, "prompt_tokens": 22, "response_tokens_est": 44, "n_tiles": 6, "output_text": "The image shows a large parking lot filled with numerous cars, with a clear blue sky overhead. The parking lot is surrounded by green trees and buildings, and the lighting is bright and natural, indicating a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.6, "ram_available_mb": 44197.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.913, "power_cpu_cv_mean_watts": 1.627, "power_sys_5v0_mean_watts": 8.007, "gpu_utilization_percent_mean": 72.065}, "timestamp": "2026-01-31T01:02:52.603108"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4143.014, "latencies_ms": [4143.014], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 12, "output_text": "A child is holding a pink toy phone with a cartoon character on the screen, while sitting on a couch.", "error": null, "sys_before": {"cpu_percent": 31.6, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.668, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 8.802, "gpu_utilization_percent_mean": 89.118}, "timestamp": "2026-01-31T01:02:58.906806"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5362.576, "latencies_ms": [5362.576], "images_per_second": 0.186, "prompt_tokens": 26, "response_tokens_est": 42, "n_tiles": 12, "output_text": "- hand: 1\n- phone: 1\n- book: 1\n- cup: 1\n- chair: 1\n- remote: 1\n- blanket: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.217, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.779, "gpu_utilization_percent_mean": 86.933}, "timestamp": "2026-01-31T01:03:06.318067"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6785.87, "latencies_ms": [6785.87], "images_per_second": 0.147, "prompt_tokens": 30, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The main object in the foreground is a child's hand holding a pink mobile phone with a cartoon character on the screen. The child is sitting on a couch, and there is a magazine or book with a visible title on the couch. The background features a can of soda and a cup, as well as a wrapped gift.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.411, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 85.702}, "timestamp": "2026-01-31T01:03:15.147111"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6311.688, "latencies_ms": [6311.688], "images_per_second": 0.158, "prompt_tokens": 24, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image depicts a cozy indoor setting where a person is seated on a couch, holding a pink mobile phone with a cartoon character on the screen. The person is also holding a magazine or book, and there are various items on the couch, including a can and a wrapped gift.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.4, "ram_available_mb": 44197.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.577, "power_cpu_cv_mean_watts": 1.564, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 85.887}, "timestamp": "2026-01-31T01:03:23.484947"}
{"image_index": 465, "image_name": "000000052413.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052413.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6183.47, "latencies_ms": [6183.47], "images_per_second": 0.162, "prompt_tokens": 22, "response_tokens_est": 56, "n_tiles": 12, "output_text": "The image features a person holding a pink mobile phone with a cartoon character on the screen. The phone is encased in a pink case, and the person is wearing a white shirt. The lighting is dim, and the background is blurred, suggesting a cozy indoor setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.67, "power_cpu_cv_mean_watts": 1.579, "power_sys_5v0_mean_watts": 8.831, "gpu_utilization_percent_mean": 86.462}, "timestamp": "2026-01-31T01:03:31.679979"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2154.519, "latencies_ms": [2154.519], "images_per_second": 0.464, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 6, "output_text": "A zebra is standing in a field with tall, dry grass around it.", "error": null, "sys_before": {"cpu_percent": 26.6, "ram_used_mb": 18643.3, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.98, "power_cpu_cv_mean_watts": 1.013, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 80.706}, "timestamp": "2026-01-31T01:03:35.940114"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2121.171, "latencies_ms": [2121.171], "images_per_second": 0.471, "prompt_tokens": 26, "response_tokens_est": 16, "n_tiles": 6, "output_text": "zebra: 1\ntree: 1\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.053, "power_cpu_cv_mean_watts": 0.966, "power_sys_5v0_mean_watts": 7.997, "gpu_utilization_percent_mean": 79.294}, "timestamp": "2026-01-31T01:03:40.109894"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5253.061, "latencies_ms": [5253.061], "images_per_second": 0.19, "prompt_tokens": 30, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The main objects in the image are two zebras standing in a grassy field. The foreground features a zebra with a black and white striped coat, while the background shows another zebra with a similar pattern. The zebra in the foreground is closer to the camera, while the one in the background is further away.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.9, "ram_available_mb": 44198.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.341, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 70.068}, "timestamp": "2026-01-31T01:03:47.375463"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4218.726, "latencies_ms": [4218.726], "images_per_second": 0.237, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image depicts a serene African savanna landscape with a zebra standing in the foreground. The zebra is surrounded by tall, dry grass, and the scene is bathed in the warm, golden light of a clear, sunny day.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.251, "power_cpu_cv_mean_watts": 1.704, "power_sys_5v0_mean_watts": 8.067, "gpu_utilization_percent_mean": 71.6}, "timestamp": "2026-01-31T01:03:53.643992"}
{"image_index": 466, "image_name": "000000052462.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052462.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5123.503, "latencies_ms": [5123.503], "images_per_second": 0.195, "prompt_tokens": 22, "response_tokens_est": 66, "n_tiles": 6, "output_text": "The image features a zebra standing in a savanna-like environment with tall, dry grass. The zebra's distinctive black and white stripes are clearly visible against the backdrop of the dry, golden-brown grass. The lighting is bright and natural, suggesting a sunny day, and the overall atmosphere is serene and wild.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.366, "power_cpu_cv_mean_watts": 1.844, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.791}, "timestamp": "2026-01-31T01:04:00.798852"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2338.38, "latencies_ms": [2338.38], "images_per_second": 0.428, "prompt_tokens": 12, "response_tokens_est": 20, "n_tiles": 6, "output_text": "A man is standing in the water holding a yellow surfboard, ready to catch a wave.", "error": null, "sys_before": {"cpu_percent": 31.5, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.437, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 78.211}, "timestamp": "2026-01-31T01:04:05.253078"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3541.36, "latencies_ms": [3541.36], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.323, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.051, "gpu_utilization_percent_mean": 73.31}, "timestamp": "2026-01-31T01:04:10.834569"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5550.283, "latencies_ms": [5550.283], "images_per_second": 0.18, "prompt_tokens": 30, "response_tokens_est": 73, "n_tiles": 6, "output_text": "The main object in the foreground is a person standing in shallow water, holding a bright yellow surfboard. The person is positioned near the center of the image, slightly to the left. The background features the vast expanse of the ocean, with waves crashing towards the shore. The surfboard is positioned near the person, closer to the water's edge.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18642.2, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.145, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 69.261}, "timestamp": "2026-01-31T01:04:18.415668"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4884.127, "latencies_ms": [4884.127], "images_per_second": 0.205, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image depicts a scene at the beach with a person standing in shallow water, holding a bright yellow surfboard. The person is facing away from the camera, and the ocean waves are crashing around them. The setting is a sunny day at the beach, with clear blue skies and calm ocean waters.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.2, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.661, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.041, "gpu_utilization_percent_mean": 70.707}, "timestamp": "2026-01-31T01:04:25.336280"}
{"image_index": 467, "image_name": "000000052507.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052507.jpg", "image_width": 640, "image_height": 438, "image_resolution": "640x438", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4405.617, "latencies_ms": [4405.617], "images_per_second": 0.227, "prompt_tokens": 22, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The image depicts a bright yellow surfboard with a black stripe and a black handle, being held by a person in the water. The scene is set on a sunny day with clear blue skies, and the waves are small and white, indicating a calm sea.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.94, "power_cpu_cv_mean_watts": 1.732, "power_sys_5v0_mean_watts": 8.018, "gpu_utilization_percent_mean": 70.432}, "timestamp": "2026-01-31T01:04:31.785393"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3882.734, "latencies_ms": [3882.734], "images_per_second": 0.258, "prompt_tokens": 12, "response_tokens_est": 19, "n_tiles": 12, "output_text": "A black and white image shows a cow standing on a sandy beach near the water.", "error": null, "sys_before": {"cpu_percent": 29.3, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.072, "power_cpu_cv_mean_watts": 0.963, "power_sys_5v0_mean_watts": 8.816, "gpu_utilization_percent_mean": 89.906}, "timestamp": "2026-01-31T01:04:37.819939"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3444.575, "latencies_ms": [3444.575], "images_per_second": 0.29, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 12, "output_text": "beach: 1\ncow: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.4, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 29.022, "power_cpu_cv_mean_watts": 0.858, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 94.536}, "timestamp": "2026-01-31T01:04:43.303726"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7697.0, "latencies_ms": [7697.0], "images_per_second": 0.13, "prompt_tokens": 30, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The main object in the image is a cow standing on the sandy beach. The cow is positioned in the foreground, with its body facing the camera and its head turned slightly to the side. The background consists of the calm sea, which is slightly blurred, indicating a shallow depth of field. The cow is near the water's edge, and the sandy beach is the foreground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.693, "power_cpu_cv_mean_watts": 1.7, "power_sys_5v0_mean_watts": 8.751, "gpu_utilization_percent_mean": 83.523}, "timestamp": "2026-01-31T01:04:53.034143"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6761.971, "latencies_ms": [6761.971], "images_per_second": 0.148, "prompt_tokens": 24, "response_tokens_est": 66, "n_tiles": 12, "output_text": "The image depicts a black and white scene of a cow standing on a sandy beach near a body of water. The cow appears calm and is facing the camera, with its body partially submerged in the water. The setting is serene, with the cow's presence adding a sense of tranquility to the scene.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.385, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.832, "gpu_utilization_percent_mean": 85.474}, "timestamp": "2026-01-31T01:05:01.836188"}
{"image_index": 468, "image_name": "000000052565.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052565.jpg", "image_width": 640, "image_height": 458, "image_resolution": "640x458", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6704.393, "latencies_ms": [6704.393], "images_per_second": 0.149, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image is a black and white photograph featuring a cow standing on a sandy beach near the water. The cow has a predominantly black and white coat with white patches on its face and legs. The lighting is soft and diffused, casting gentle shadows on the sand, and the overall weather appears calm and serene.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.39, "power_cpu_cv_mean_watts": 1.588, "power_sys_5v0_mean_watts": 8.84, "gpu_utilization_percent_mean": 85.561}, "timestamp": "2026-01-31T01:05:10.584956"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3335.036, "latencies_ms": [3335.036], "images_per_second": 0.3, "prompt_tokens": 12, "response_tokens_est": 48, "n_tiles": 2, "output_text": "A woman in a black and white photo is standing on a snowy slope, holding a pair of skis and wearing a white sweater with a fur collar, a black belt, and black pants, with a smile on her face.", "error": null, "sys_before": {"cpu_percent": 16.0, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.155, "power_cpu_cv_mean_watts": 1.945, "power_sys_5v0_mean_watts": 7.23, "gpu_utilization_percent_mean": 63.179}, "timestamp": "2026-01-31T01:05:16.020220"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8240.116, "latencies_ms": [8240.116], "images_per_second": 0.121, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 2, "output_text": "woman: 1\nsnowsuit: 1\nglove: 1\nskis: 1\nskis pole: 1\nskis handle: 1\nskis belt: 1\nskis belt buckle: 1\nskis belt loop: 1\nskis belt strap: 1\nskis belt buckle: 1\nskis belt loop: 1\nskis belt strap: 1\nskis belt buckle: 1\nskis belt loop: 1\nskis belt strap: 1\nskis belt buckle:", "error": null, "sys_before": {"cpu_percent": 7.1, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.437, "power_cpu_cv_mean_watts": 2.225, "power_sys_5v0_mean_watts": 7.418, "gpu_utilization_percent_mean": 62.343}, "timestamp": "2026-01-31T01:05:26.307842"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5886.744, "latencies_ms": [5886.744], "images_per_second": 0.17, "prompt_tokens": 30, "response_tokens_est": 89, "n_tiles": 2, "output_text": "In the image, the main subject is a woman standing on a snowy slope, holding a pair of skis. The skis are positioned to her left, with one ski partially obscured by the other. The background features a snowy landscape with a few sparse trees and a partly cloudy sky. The woman is positioned in the foreground, with the skis and trees in the midground, and the sky in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.46, "power_cpu_cv_mean_watts": 2.12, "power_sys_5v0_mean_watts": 7.333, "gpu_utilization_percent_mean": 62.216}, "timestamp": "2026-01-31T01:05:34.230702"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5211.035, "latencies_ms": [5211.035], "images_per_second": 0.192, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 2, "output_text": "The image depicts a black-and-white scene set in a snowy landscape, likely a ski resort or a snowy mountain area. A woman is standing on a snowy slope, holding a ski pole and wearing a winter outfit with a fur-lined jacket, a scarf, and gloves. She appears to be enjoying the snowy environment, smiling and looking towards the camera.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.562, "power_cpu_cv_mean_watts": 2.13, "power_sys_5v0_mean_watts": 7.333, "gpu_utilization_percent_mean": 63.045}, "timestamp": "2026-01-31T01:05:41.487608"}
{"image_index": 469, "image_name": "000000052591.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052591.jpg", "image_width": 359, "image_height": 640, "image_resolution": "359x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4270.751, "latencies_ms": [4270.751], "images_per_second": 0.234, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 2, "output_text": "The image is a black and white photograph featuring a woman standing in a snowy landscape. She is dressed in a white sweater with a fur collar and a black skirt, accessorized with a necklace and gloves. The lighting is soft, and the sky is partly cloudy, creating a serene winter scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.882, "power_cpu_cv_mean_watts": 2.035, "power_sys_5v0_mean_watts": 7.286, "gpu_utilization_percent_mean": 62.778}, "timestamp": "2026-01-31T01:05:47.820676"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2624.305, "latencies_ms": [2624.305], "images_per_second": 0.381, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 6, "output_text": "A dog is seen on a sandy beach, holding a yellow frisbee, with the ocean in the background.", "error": null, "sys_before": {"cpu_percent": 28.0, "ram_used_mb": 18640.8, "ram_available_mb": 44200.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.112, "power_cpu_cv_mean_watts": 1.278, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 76.429}, "timestamp": "2026-01-31T01:05:52.552947"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3570.46, "latencies_ms": [3570.46], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.281, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 72.621}, "timestamp": "2026-01-31T01:05:58.137786"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4911.392, "latencies_ms": [4911.392], "images_per_second": 0.204, "prompt_tokens": 30, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The main object in the foreground is a yellow frisbee, which is held by a dog. The dog is positioned on the sandy beach, with its head close to the frisbee. In the background, the ocean and a small island are visible, indicating the dog is near the water.", "error": null, "sys_before": {"cpu_percent": 12.5, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.605, "power_cpu_cv_mean_watts": 1.797, "power_sys_5v0_mean_watts": 8.019, "gpu_utilization_percent_mean": 70.098}, "timestamp": "2026-01-31T01:06:05.063399"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5682.307, "latencies_ms": [5682.307], "images_per_second": 0.176, "prompt_tokens": 24, "response_tokens_est": 75, "n_tiles": 6, "output_text": "The image depicts a beach scene with a dog playing with a yellow frisbee. The dog, with its fur appearing wet and matted, is lying on the sandy beach, focusing intently on the frisbee. The background features the ocean with gentle waves, a cloudy sky, and a distant island, creating a serene and playful atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.062, "power_cpu_cv_mean_watts": 1.874, "power_sys_5v0_mean_watts": 8.022, "gpu_utilization_percent_mean": 69.681}, "timestamp": "2026-01-31T01:06:12.781992"}
{"image_index": 470, "image_name": "000000052891.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052891.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5194.53, "latencies_ms": [5194.53], "images_per_second": 0.193, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image features a dog with a coat of black, white, and gray fur, standing on a sandy beach. The dog is holding a bright yellow frisbee, which contrasts sharply with the sandy background. The lighting is natural, suggesting daytime, and the sky appears overcast, with no direct sunlight visible.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.0, "ram_available_mb": 44198.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.395, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 69.465}, "timestamp": "2026-01-31T01:06:19.990925"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4150.931, "latencies_ms": [4150.931], "images_per_second": 0.241, "prompt_tokens": 12, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image depicts a group of individuals in a kitchen setting, with one person in a military uniform standing next to a large stainless steel refrigerator, while others are engaged in conversation around the counter, surrounded by various cooking utensils and ingredients.", "error": null, "sys_before": {"cpu_percent": 27.5, "ram_used_mb": 18642.1, "ram_available_mb": 44198.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.368, "power_cpu_cv_mean_watts": 1.708, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 71.471}, "timestamp": "2026-01-31T01:06:26.255157"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8891.369, "latencies_ms": [8891.369], "images_per_second": 0.112, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 6, "output_text": "- Food: 1\n- Bowl: 1\n- Cutting board: 1\n- Pot: 1\n- Green bowl: 1\n- Green cup: 1\n- Green plastic container: 1\n- Green plastic bag: 1\n- Green plastic bottle: 1\n- Green plastic container: 1\n- Green plastic bag: 1\n- Green plastic bottle: 1\n- Green plastic container: 1\n- Green plastic bag: 1\n- Green plastic bottle: 1\n- Green plastic container: 1\n- Green plastic bag: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.7, "ram_available_mb": 44198.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 17.765, "power_cpu_cv_mean_watts": 2.077, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 67.44}, "timestamp": "2026-01-31T01:06:37.166545"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6037.709, "latencies_ms": [6037.709], "images_per_second": 0.166, "prompt_tokens": 30, "response_tokens_est": 81, "n_tiles": 6, "output_text": "In the image, the main objects are located in the foreground, with the military personnel standing near the stainless steel refrigerator. The refrigerator is positioned against the wall, and the individuals are gathered around it. The background features a cluttered kitchen counter with various items, including bowls, a cutting board, and a green container. The scene suggests a casual, possibly informal gathering or meeting in a kitchen setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.928, "power_cpu_cv_mean_watts": 1.914, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.08}, "timestamp": "2026-01-31T01:06:45.232945"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5025.237, "latencies_ms": [5025.237], "images_per_second": 0.199, "prompt_tokens": 24, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The image depicts a group of people in a kitchen setting, likely in a military or humanitarian context. They are engaged in a discussion, with one person holding a clipboard, possibly taking notes or discussing a plan. The kitchen is equipped with various cooking utensils and equipment, indicating a functional and practical environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.425, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 8.035, "gpu_utilization_percent_mean": 70.048}, "timestamp": "2026-01-31T01:06:52.292189"}
{"image_index": 471, "image_name": "000000052996.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000052996.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4113.277, "latencies_ms": [4113.277], "images_per_second": 0.243, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image depicts a group of people in a kitchen setting, with a focus on a stainless steel refrigerator and various cooking utensils and containers. The lighting is bright, and the materials include stainless steel, plastic, and wooden elements.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.367, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 7.975, "gpu_utilization_percent_mean": 71.471}, "timestamp": "2026-01-31T01:06:58.435959"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2597.008, "latencies_ms": [2597.008], "images_per_second": 0.385, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 6, "output_text": "The image shows a bathroom with a toilet, a toilet paper holder, and a soap dispenser on the wall.", "error": null, "sys_before": {"cpu_percent": 16.5, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.938, "power_cpu_cv_mean_watts": 1.22, "power_sys_5v0_mean_watts": 7.964, "gpu_utilization_percent_mean": 76.048}, "timestamp": "2026-01-31T01:07:03.146206"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3584.995, "latencies_ms": [3584.995], "images_per_second": 0.279, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.2, "ram_available_mb": 44196.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.853, "power_cpu_cv_mean_watts": 1.548, "power_sys_5v0_mean_watts": 8.001, "gpu_utilization_percent_mean": 72.267}, "timestamp": "2026-01-31T01:07:08.777024"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6862.478, "latencies_ms": [6862.478], "images_per_second": 0.146, "prompt_tokens": 30, "response_tokens_est": 95, "n_tiles": 6, "output_text": "The main objects in the image are a toilet, a toilet paper holder, and a soap dispenser. The toilet is positioned in the foreground, slightly to the right, while the toilet paper holder is mounted on the wall to the left of the toilet. The soap dispenser is placed on the wall near the toilet paper holder. The background features a shower area with a glass door, and the wall tiles are a light color, creating a cohesive and clean aesthetic.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.4, "ram_available_mb": 44196.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.534, "power_cpu_cv_mean_watts": 1.981, "power_sys_5v0_mean_watts": 8.054, "gpu_utilization_percent_mean": 68.702}, "timestamp": "2026-01-31T01:07:17.663222"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5790.168, "latencies_ms": [5790.168], "images_per_second": 0.173, "prompt_tokens": 24, "response_tokens_est": 77, "n_tiles": 6, "output_text": "The image depicts a well-organized bathroom with a clean and modern design. The setting is a small, well-lit bathroom with a beige wall and tiled floor. The bathroom features a toilet, a sink, a shower, and a towel rack with neatly folded towels. The overall atmosphere is tidy and inviting, with a focus on functionality and cleanliness.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.058, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.012, "gpu_utilization_percent_mean": 69.438}, "timestamp": "2026-01-31T01:07:25.485885"}
{"image_index": 472, "image_name": "000000053505.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053505.jpg", "image_width": 428, "image_height": 640, "image_resolution": "428x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3078.172, "latencies_ms": [3078.172], "images_per_second": 0.325, "prompt_tokens": 22, "response_tokens_est": 32, "n_tiles": 6, "output_text": "The bathroom features a warm, beige color scheme with light-colored walls and tiled flooring. The lighting is soft and ambient, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.105, "power_cpu_cv_mean_watts": 1.409, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 73.56}, "timestamp": "2026-01-31T01:07:30.607579"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2713.325, "latencies_ms": [2713.325], "images_per_second": 0.369, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A woman wearing a green hat is sitting in the back of a car, and a dog is looking out of the window.", "error": null, "sys_before": {"cpu_percent": 19.8, "ram_used_mb": 18644.1, "ram_available_mb": 44196.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.72, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 7.992, "gpu_utilization_percent_mean": 76.182}, "timestamp": "2026-01-31T01:07:35.439938"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5485.336, "latencies_ms": [5485.336], "images_per_second": 0.182, "prompt_tokens": 26, "response_tokens_est": 72, "n_tiles": 6, "output_text": "1. St. Patrick's Day hat\n2. St. Patrick's Day decoration\n3. St. Patrick's Day hat\n4. St. Patrick's Day decoration\n5. St. Patrick's Day decoration\n6. St. Patrick's Day decoration\n7. St. Patrick's Day decoration\n8. St. Patrick's Day decoration", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.232, "power_cpu_cv_mean_watts": 1.871, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 69.522}, "timestamp": "2026-01-31T01:07:42.966114"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4034.701, "latencies_ms": [4034.701], "images_per_second": 0.248, "prompt_tokens": 30, "response_tokens_est": 48, "n_tiles": 6, "output_text": "The main objects in the image are a car and a dog. The car is positioned in the foreground, with the dog sitting inside it. The dog is near the car's front, and the car's front is near the dog.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18644.6, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.586, "power_cpu_cv_mean_watts": 1.638, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 72.091}, "timestamp": "2026-01-31T01:07:49.027118"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4715.228, "latencies_ms": [4715.228], "images_per_second": 0.212, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a scene inside a vehicle, likely a car, where a person is seated. The person is wearing a green hat, and there is a dog looking out of the window. The setting appears to be outdoors, as there is a green traffic light visible in the background.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.6, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.748, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 70.308}, "timestamp": "2026-01-31T01:07:55.788055"}
{"image_index": 473, "image_name": "000000053529.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053529.jpg", "image_width": 500, "image_height": 333, "image_resolution": "500x333", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4105.801, "latencies_ms": [4105.801], "images_per_second": 0.244, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 6, "output_text": "The image features a vehicle with a shiny, reflective surface, likely made of metal, and a green St. Patrick's Day-themed decoration on the front. The vehicle is parked outdoors, and the lighting suggests it is daytime with clear visibility.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.8, "ram_available_mb": 44196.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.403, "power_cpu_cv_mean_watts": 1.684, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 70.765}, "timestamp": "2026-01-31T01:08:01.942807"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2706.099, "latencies_ms": [2706.099], "images_per_second": 0.37, "prompt_tokens": 12, "response_tokens_est": 26, "n_tiles": 6, "output_text": "A group of elephants are standing in a shallow pool of water, with one elephant in the foreground and others in the background.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 18645.5, "ram_available_mb": 44195.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.699, "power_cpu_cv_mean_watts": 1.292, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 75.727}, "timestamp": "2026-01-31T01:08:06.773786"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3603.047, "latencies_ms": [3603.047], "images_per_second": 0.278, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "elephant: 1\nwater: 1\nrock: 2\nrock: 1\nrock: 1\nrock: 1\nrock: 1\nrock: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.421, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 73.103}, "timestamp": "2026-01-31T01:08:12.394488"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5606.199, "latencies_ms": [5606.199], "images_per_second": 0.178, "prompt_tokens": 30, "response_tokens_est": 74, "n_tiles": 6, "output_text": "In the image, the main object is an elephant standing in a shallow water puddle. The elephant is positioned in the foreground, with its trunk and ears slightly raised. The background features a fence, some greenery, and a few other animals. The water puddle is located near the elephant, and there are rocks and a few other animals in the vicinity.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.102, "power_cpu_cv_mean_watts": 1.865, "power_sys_5v0_mean_watts": 8.039, "gpu_utilization_percent_mean": 69.404}, "timestamp": "2026-01-31T01:08:20.057095"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4583.588, "latencies_ms": [4583.588], "images_per_second": 0.218, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts an elephant standing in a shallow water-filled enclosure, likely at a zoo or wildlife sanctuary. The elephant is surrounded by rocks and vegetation, with a few other animals nearby. The setting appears to be a naturalistic environment designed to mimic the elephant's natural habitat.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18644.5, "ram_available_mb": 44196.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.938, "power_cpu_cv_mean_watts": 1.728, "power_sys_5v0_mean_watts": 8.03, "gpu_utilization_percent_mean": 71.0}, "timestamp": "2026-01-31T01:08:26.683012"}
{"image_index": 474, "image_name": "000000053624.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053624.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4578.208, "latencies_ms": [4578.208], "images_per_second": 0.218, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts an elephant standing in a shallow water pool, with its trunk raised. The surrounding area is sandy with patches of grass, and there are rocks visible in the foreground. The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18644.9, "ram_available_mb": 44196.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.877, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 7.966, "gpu_utilization_percent_mean": 70.579}, "timestamp": "2026-01-31T01:08:33.303988"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5403.719, "latencies_ms": [5403.719], "images_per_second": 0.185, "prompt_tokens": 12, "response_tokens_est": 44, "n_tiles": 12, "output_text": "The image depicts a group of people standing on a snowy slope, each holding ski poles and wearing appropriate winter attire, including jackets and gloves, suggesting they are engaged in skiing or snowboarding activities.", "error": null, "sys_before": {"cpu_percent": 26.1, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.398, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.795, "gpu_utilization_percent_mean": 85.489}, "timestamp": "2026-01-31T01:08:40.861694"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5211.613, "latencies_ms": [5211.613], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "1. Ski poles\n2. Ski poles\n3. Ski poles\n4. Ski poles\n5. Ski poles\n6. Ski poles\n7. Ski poles\n8. Ski poles", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18645.2, "ram_available_mb": 44195.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.555, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 88.047}, "timestamp": "2026-01-31T01:08:48.095516"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6082.498, "latencies_ms": [6082.498], "images_per_second": 0.164, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The main objects in the image are a group of people skiing on a snowy slope. The individuals are positioned in the foreground, with the ski poles and skis clearly visible. The background features a snowy mountain landscape with trees and a clear blue sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.4, "ram_available_mb": 44195.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.71, "power_cpu_cv_mean_watts": 1.476, "power_sys_5v0_mean_watts": 8.796, "gpu_utilization_percent_mean": 86.118}, "timestamp": "2026-01-31T01:08:56.190238"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6846.154, "latencies_ms": [6846.154], "images_per_second": 0.146, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a group of people skiing down a snowy mountain slope. They are dressed in winter sports attire, including jackets, pants, and ski boots, and are holding ski poles. The setting is a snowy mountain with a clear blue sky, and the individuals appear to be enjoying their time skiing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18645.3, "ram_available_mb": 44195.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.316, "power_cpu_cv_mean_watts": 1.609, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 85.877}, "timestamp": "2026-01-31T01:09:05.068408"}
{"image_index": 475, "image_name": "000000053626.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053626.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5762.543, "latencies_ms": [5762.543], "images_per_second": 0.174, "prompt_tokens": 22, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image depicts a group of people skiing down a snowy mountain slope. The sky is clear and blue, indicating a sunny day. The snow is pristine and untouched, with a few scattered trees dotting the landscape.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18644.7, "ram_available_mb": 44196.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.877, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 86.917}, "timestamp": "2026-01-31T01:09:12.883315"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4078.087, "latencies_ms": [4078.087], "images_per_second": 0.245, "prompt_tokens": 12, "response_tokens_est": 22, "n_tiles": 12, "output_text": "A person is holding a smartphone with a screen displaying a date and time, and a blurred background.", "error": null, "sys_before": {"cpu_percent": 29.7, "ram_used_mb": 18644.6, "ram_available_mb": 44196.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18643.9, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.764, "power_cpu_cv_mean_watts": 1.048, "power_sys_5v0_mean_watts": 8.781, "gpu_utilization_percent_mean": 89.235}, "timestamp": "2026-01-31T01:09:19.152003"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4986.89, "latencies_ms": [4986.89], "images_per_second": 0.201, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 12, "output_text": "1. Phone\n2. Keyboard\n3. Screen\n4. Phone Case\n5. Phone Battery\n6. Phone Case\n7. Phone\n8. Phone Case", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18643.9, "ram_available_mb": 44196.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.489, "power_cpu_cv_mean_watts": 1.287, "power_sys_5v0_mean_watts": 8.774, "gpu_utilization_percent_mean": 88.0}, "timestamp": "2026-01-31T01:09:26.159228"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5775.849, "latencies_ms": [5775.849], "images_per_second": 0.173, "prompt_tokens": 30, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The main object in the image is a smartphone held in the foreground. The background is blurred, indicating that the focus is on the smartphone. The smartphone is positioned near the center of the image, with the person's hand holding it.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.8, "ram_available_mb": 44197.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.915, "power_cpu_cv_mean_watts": 1.41, "power_sys_5v0_mean_watts": 8.834, "gpu_utilization_percent_mean": 86.792}, "timestamp": "2026-01-31T01:09:33.976977"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5356.837, "latencies_ms": [5356.837], "images_per_second": 0.187, "prompt_tokens": 24, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image shows a person holding a smartphone with a screen displaying a calendar. The person's hand is visible, and the background is blurred, indicating that the focus is on the smartphone and the calendar.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18643.2, "ram_available_mb": 44197.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.064, "power_cpu_cv_mean_watts": 1.326, "power_sys_5v0_mean_watts": 8.773, "gpu_utilization_percent_mean": 86.889}, "timestamp": "2026-01-31T01:09:41.373383"}
{"image_index": 476, "image_name": "000000053909.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053909.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6914.183, "latencies_ms": [6914.183], "images_per_second": 0.145, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image shows a person holding a smartphone with a black case. The screen displays a wallpaper of a tree with bare branches, and the time reads \"19:45\" with the date \"mondag 6. m\u00e4nd.\" The lighting is natural, and the background is blurred, indicating a shallow depth of field.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18643.1, "ram_available_mb": 44197.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18642.6, "ram_available_mb": 44198.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.19, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.798, "gpu_utilization_percent_mean": 84.914}, "timestamp": "2026-01-31T01:09:50.322712"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4679.152, "latencies_ms": [4679.152], "images_per_second": 0.214, "prompt_tokens": 12, "response_tokens_est": 32, "n_tiles": 12, "output_text": "The image shows a red parking meter with a sign that reads \"DENVER'S ROAD HOME\" and encourages people to donate to end homelessness.", "error": null, "sys_before": {"cpu_percent": 32.9, "ram_used_mb": 18642.5, "ram_available_mb": 44198.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.141, "power_cpu_cv_mean_watts": 1.212, "power_sys_5v0_mean_watts": 8.835, "gpu_utilization_percent_mean": 88.368}, "timestamp": "2026-01-31T01:09:57.157223"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5218.056, "latencies_ms": [5218.056], "images_per_second": 0.192, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18643.0, "ram_available_mb": 44197.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.451, "power_cpu_cv_mean_watts": 1.313, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 88.0}, "timestamp": "2026-01-31T01:10:04.408187"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6678.55, "latencies_ms": [6678.55], "images_per_second": 0.15, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 12, "output_text": "The main object in the foreground is a red parking meter. It is positioned near a sidewalk and is surrounded by greenery. In the background, there is a sign that reads \"End Homelessness\" and a concrete wall. The parking meter is placed on the sidewalk, and the sign is mounted on a pole.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.8, "ram_available_mb": 44198.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18643.2, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.432, "power_cpu_cv_mean_watts": 1.573, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 85.375}, "timestamp": "2026-01-31T01:10:13.102405"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6551.93, "latencies_ms": [6551.93], "images_per_second": 0.153, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 12, "output_text": "The image depicts a red parking meter situated in a well-maintained garden area. The meter is placed on a sidewalk, with a sign attached to the pole that reads \"End Homelessness Campaign.\" The scene is set in a suburban or urban environment, with trees and greenery surrounding the area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18643.2, "ram_available_mb": 44197.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.34, "power_cpu_cv_mean_watts": 1.558, "power_sys_5v0_mean_watts": 8.811, "gpu_utilization_percent_mean": 85.273}, "timestamp": "2026-01-31T01:10:21.666513"}
{"image_index": 477, "image_name": "000000053994.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000053994.jpg", "image_width": 481, "image_height": 640, "image_resolution": "481x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6308.094, "latencies_ms": [6308.094], "images_per_second": 0.159, "prompt_tokens": 22, "response_tokens_est": 58, "n_tiles": 12, "output_text": "The image features a red parking meter with a white and black label. The meter is situated on a concrete sidewalk, surrounded by greenery and a small sign that reads \"END HOMELESSNESS.\" The lighting is natural, suggesting it is daytime, and the weather appears to be clear.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18642.2, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.551, "power_cpu_cv_mean_watts": 1.534, "power_sys_5v0_mean_watts": 8.799, "gpu_utilization_percent_mean": 85.717}, "timestamp": "2026-01-31T01:10:30.035217"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3240.491, "latencies_ms": [3240.491], "images_per_second": 0.309, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 6, "output_text": "The image depicts a group of zebras grazing in a savanna-like environment, with their distinctive black and white striped patterns clearly visible on their bodies.", "error": null, "sys_before": {"cpu_percent": 20.8, "ram_used_mb": 18642.2, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.829, "power_cpu_cv_mean_watts": 1.479, "power_sys_5v0_mean_watts": 8.056, "gpu_utilization_percent_mean": 74.462}, "timestamp": "2026-01-31T01:10:35.373721"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 1809.459, "latencies_ms": [1809.459], "images_per_second": 0.553, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 6, "output_text": "zebra: 4\ngrass: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18642.4, "ram_available_mb": 44198.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.2, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.23, "power_cpu_cv_mean_watts": 0.829, "power_sys_5v0_mean_watts": 8.031, "gpu_utilization_percent_mean": 85.0}, "timestamp": "2026-01-31T01:10:39.216003"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6231.354, "latencies_ms": [6231.354], "images_per_second": 0.16, "prompt_tokens": 30, "response_tokens_est": 84, "n_tiles": 6, "output_text": "The main objects in the image are zebras, with the foreground and background being the most prominent. The foreground features a zebra with a prominent black and white striped pattern, while the background shows other zebras grazing in the same area. The zebra in the foreground is closer to the camera, while the other zebras are further away, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18642.2, "ram_available_mb": 44198.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.723, "power_cpu_cv_mean_watts": 1.917, "power_sys_5v0_mean_watts": 8.004, "gpu_utilization_percent_mean": 68.846}, "timestamp": "2026-01-31T01:10:47.460663"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4405.528, "latencies_ms": [4405.528], "images_per_second": 0.227, "prompt_tokens": 24, "response_tokens_est": 54, "n_tiles": 6, "output_text": "The image depicts a serene African savanna landscape with a group of zebras grazing on tall, dry grass. The zebras are in a natural setting, surrounded by sparse vegetation and a clear sky, creating a peaceful and tranquil atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.947, "power_cpu_cv_mean_watts": 1.721, "power_sys_5v0_mean_watts": 8.045, "gpu_utilization_percent_mean": 70.946}, "timestamp": "2026-01-31T01:10:53.913243"}
{"image_index": 478, "image_name": "000000054123.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054123.jpg", "image_width": 640, "image_height": 428, "image_resolution": "640x428", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4711.049, "latencies_ms": [4711.049], "images_per_second": 0.212, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 6, "output_text": "The image depicts a group of zebras grazing in a savanna-like environment. The zebras have distinctive black and white striped patterns on their bodies, and the lighting is natural, suggesting it is daytime. The grass is tall and dry, indicating a dry season.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.737, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 8.068, "gpu_utilization_percent_mean": 70.795}, "timestamp": "2026-01-31T01:11:00.661141"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2491.887, "latencies_ms": [2491.887], "images_per_second": 0.401, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 6, "output_text": "A young man is surfing on a wave, wearing a black wetsuit and standing on a surfboard.", "error": null, "sys_before": {"cpu_percent": 30.4, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.43, "power_cpu_cv_mean_watts": 1.201, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 75.8}, "timestamp": "2026-01-31T01:11:05.281223"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3445.49, "latencies_ms": [3445.49], "images_per_second": 0.29, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 6, "output_text": "1. Surfer\n2. Wetsuit\n3. Ocean\n4. Wave\n5. Water\n6. Surfboard\n7. Wave\n8. Sunlight", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.371, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 72.357}, "timestamp": "2026-01-31T01:11:10.743263"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5015.784, "latencies_ms": [5015.784], "images_per_second": 0.199, "prompt_tokens": 30, "response_tokens_est": 64, "n_tiles": 6, "output_text": "The main object in the foreground is a person riding a surfboard on a wave. The person is wearing a black wetsuit and appears to be in motion, with water splashing around them. The background shows a large wave breaking to the right, with the person positioned slightly to the left of the center.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.455, "power_cpu_cv_mean_watts": 1.802, "power_sys_5v0_mean_watts": 7.994, "gpu_utilization_percent_mean": 69.929}, "timestamp": "2026-01-31T01:11:17.788783"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5840.745, "latencies_ms": [5840.745], "images_per_second": 0.171, "prompt_tokens": 24, "response_tokens_est": 78, "n_tiles": 6, "output_text": "The image captures a dynamic scene of a surfer riding a wave in the ocean. The surfer, dressed in a black wetsuit, is skillfully maneuvering on a surfboard, with the wave's crest and spray creating a visually striking backdrop. The setting is a large, open ocean with clear blue water, indicating a sunny day with good weather conditions for surfing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.929, "power_cpu_cv_mean_watts": 1.887, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 69.184}, "timestamp": "2026-01-31T01:11:25.657830"}
{"image_index": 479, "image_name": "000000054164.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054164.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4574.375, "latencies_ms": [4574.375], "images_per_second": 0.219, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image captures a surfer in a black wetsuit riding a wave, with the ocean's blue-green color dominating the scene. The lighting is bright and natural, indicating a sunny day, and the water is visibly frothy and white, suggesting a powerful wave.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.973, "power_cpu_cv_mean_watts": 1.749, "power_sys_5v0_mean_watts": 8.014, "gpu_utilization_percent_mean": 71.105}, "timestamp": "2026-01-31T01:11:32.289212"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2497.913, "latencies_ms": [2497.913], "images_per_second": 0.4, "prompt_tokens": 12, "response_tokens_est": 23, "n_tiles": 6, "output_text": "A skier is standing on a snowy slope, holding a pair of skis and preparing to ski.", "error": null, "sys_before": {"cpu_percent": 25.6, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.367, "power_cpu_cv_mean_watts": 1.261, "power_sys_5v0_mean_watts": 8.151, "gpu_utilization_percent_mean": 77.85}, "timestamp": "2026-01-31T01:11:36.900002"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3429.846, "latencies_ms": [3429.846], "images_per_second": 0.292, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 6, "output_text": "1. Ski poles\n2. Ski\n3. Ski jacket\n4. Ski boots\n5. Ski pants\n6. Backpack\n7. Gloves\n8. Camera", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.468, "power_cpu_cv_mean_watts": 1.516, "power_sys_5v0_mean_watts": 8.003, "gpu_utilization_percent_mean": 73.286}, "timestamp": "2026-01-31T01:11:42.355841"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6366.429, "latencies_ms": [6366.429], "images_per_second": 0.157, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 6, "output_text": "The main object in the foreground is a person standing on a snowy slope, holding a pair of skis. The person is wearing a white jacket and pants, and is positioned near the center of the image. In the background, there is a mountain range with a clear sky above it. The person is slightly off-center to the right, and the mountains are further away, creating a sense of depth in the image.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.559, "power_cpu_cv_mean_watts": 1.95, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 68.426}, "timestamp": "2026-01-31T01:11:50.780563"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4821.602, "latencies_ms": [4821.602], "images_per_second": 0.207, "prompt_tokens": 24, "response_tokens_est": 61, "n_tiles": 6, "output_text": "The image depicts a person dressed in winter gear, including a jacket and pants, standing on a snowy slope. The individual is holding a pair of skis and appears to be preparing for a skiing activity, with the sun setting in the background, casting a warm glow over the scene.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.588, "power_cpu_cv_mean_watts": 1.812, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 70.45}, "timestamp": "2026-01-31T01:11:57.645993"}
{"image_index": 480, "image_name": "000000054592.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054592.jpg", "image_width": 640, "image_height": 418, "image_resolution": "640x418", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5186.494, "latencies_ms": [5186.494], "images_per_second": 0.193, "prompt_tokens": 22, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a person dressed in a white ski suit and a dark jacket, standing on a snowy slope during what appears to be either sunrise or sunset. The lighting is soft and warm, casting a golden hue over the scene, while the snow is undisturbed, indicating a peaceful and serene environment.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.432, "power_cpu_cv_mean_watts": 1.853, "power_sys_5v0_mean_watts": 8.052, "gpu_utilization_percent_mean": 70.047}, "timestamp": "2026-01-31T01:12:04.862661"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3696.751, "latencies_ms": [3696.751], "images_per_second": 0.271, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 6, "output_text": "A young baseball player in a red jersey and white pants is in the middle of a swing, with a catcher and an umpire crouched behind him, all set up on a baseball field.", "error": null, "sys_before": {"cpu_percent": 25.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.174, "power_cpu_cv_mean_watts": 1.629, "power_sys_5v0_mean_watts": 8.032, "gpu_utilization_percent_mean": 70.8}, "timestamp": "2026-01-31T01:12:10.666064"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3919.605, "latencies_ms": [3919.605], "images_per_second": 0.255, "prompt_tokens": 26, "response_tokens_est": 46, "n_tiles": 6, "output_text": "baseball bat: 1\ncatcher's mask: 1\ncatcher's gear: 1\numpire: 1\nplayer: 1\nbaseball: 1\npitcher: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.824, "power_cpu_cv_mean_watts": 1.639, "power_sys_5v0_mean_watts": 8.044, "gpu_utilization_percent_mean": 71.75}, "timestamp": "2026-01-31T01:12:16.626277"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6401.821, "latencies_ms": [6401.821], "images_per_second": 0.156, "prompt_tokens": 30, "response_tokens_est": 87, "n_tiles": 6, "output_text": "The main object in the foreground is a baseball player in a red jersey and white pants, who is in the middle of swinging at a pitch. The player is positioned near the home plate, with his body angled towards the right side of the image. In the background, there is a chain-link fence, a group of spectators, and a parked car. The spectators are seated on folding chairs, watching the game.", "error": null, "sys_before": {"cpu_percent": 16.7, "ram_used_mb": 18642.3, "ram_available_mb": 44198.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.2, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.566, "power_cpu_cv_mean_watts": 1.936, "power_sys_5v0_mean_watts": 8.036, "gpu_utilization_percent_mean": 68.426}, "timestamp": "2026-01-31T01:12:25.048259"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6674.679, "latencies_ms": [6674.679], "images_per_second": 0.15, "prompt_tokens": 24, "response_tokens_est": 92, "n_tiles": 6, "output_text": "The image captures a moment during a baseball game on a sunny day. In the foreground, a young baseball player in a red jersey and white pants is in the midst of swinging at a pitch, while a catcher in black gear is crouched behind him, ready to catch the ball. In the background, a chain-link fence separates the playing field from the spectators, and a few people are seated on folding chairs, watching the game.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.524, "power_cpu_cv_mean_watts": 1.959, "power_sys_5v0_mean_watts": 8.05, "gpu_utilization_percent_mean": 68.768}, "timestamp": "2026-01-31T01:12:33.743195"}
{"image_index": 481, "image_name": "000000054593.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054593.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3451.274, "latencies_ms": [3451.274], "images_per_second": 0.29, "prompt_tokens": 22, "response_tokens_est": 38, "n_tiles": 6, "output_text": "The baseball player is wearing a red jersey and white pants, with a black helmet and black cleats. The scene is brightly lit by natural sunlight, casting shadows on the ground.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.34, "power_cpu_cv_mean_watts": 1.487, "power_sys_5v0_mean_watts": 7.999, "gpu_utilization_percent_mean": 73.286}, "timestamp": "2026-01-31T01:12:39.213067"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2966.29, "latencies_ms": [2966.29], "images_per_second": 0.337, "prompt_tokens": 12, "response_tokens_est": 43, "n_tiles": 1, "output_text": "A woman is sitting at a table, enjoying a chocolate and vanilla ice cream cone with a dollop of whipped cream on top, while a slice of cake is placed on a plate in front of her.", "error": null, "sys_before": {"cpu_percent": 14.6, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.291, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 6.999, "gpu_utilization_percent_mean": 69.52}, "timestamp": "2026-01-31T01:12:44.249739"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3850.08, "latencies_ms": [3850.08], "images_per_second": 0.26, "prompt_tokens": 26, "response_tokens_est": 58, "n_tiles": 1, "output_text": "- Chocolate cake: 1\n- Whipped cream: 1\n- Whisk: 1\n- Glass: 1\n- Plate: 1\n- Fork: 2\n- Knife: 1\n- Table: 1\n- Person: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.839, "power_cpu_cv_mean_watts": 2.052, "power_sys_5v0_mean_watts": 7.052, "gpu_utilization_percent_mean": 66.531}, "timestamp": "2026-01-31T01:12:50.144993"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5421.083, "latencies_ms": [5421.083], "images_per_second": 0.184, "prompt_tokens": 30, "response_tokens_est": 83, "n_tiles": 1, "output_text": "The main objects in the image are a chocolate-flavored milkshake and a slice of cake. The milkshake is positioned in the foreground on a saucer, with a straw in it. The cake is placed on a white plate in the background, slightly to the right. The background also includes a table with other items, such as a glass and a fork, and a person sitting at the table.", "error": null, "sys_before": {"cpu_percent": 7.7, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.808, "power_cpu_cv_mean_watts": 2.135, "power_sys_5v0_mean_watts": 7.15, "gpu_utilization_percent_mean": 66.244}, "timestamp": "2026-01-31T01:12:57.604688"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4628.795, "latencies_ms": [4628.795], "images_per_second": 0.216, "prompt_tokens": 24, "response_tokens_est": 70, "n_tiles": 1, "output_text": "The image depicts a cozy cafe setting with a person seated at a table, enjoying a chocolate and vanilla ice cream cone. In the foreground, there is a plate with a slice of cake, and a glass of a similar ice cream cone is placed on the table. The background shows other patrons and tables, creating a relaxed and inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.696, "power_cpu_cv_mean_watts": 2.107, "power_sys_5v0_mean_watts": 7.045, "gpu_utilization_percent_mean": 65.053}, "timestamp": "2026-01-31T01:13:04.263137"}
{"image_index": 482, "image_name": "000000054605.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054605.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5539.017, "latencies_ms": [5539.017], "images_per_second": 0.181, "prompt_tokens": 22, "response_tokens_est": 85, "n_tiles": 1, "output_text": "The image features a dessert on a white plate, which is placed on a dark table. The dessert is a layered cake with a creamy white frosting. The background includes a glass of a chocolate and vanilla-flavored milkshake, a person sitting at a table, and a table setting with chairs and a tablecloth. The lighting is bright, and the overall ambiance suggests a warm, inviting atmosphere.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.0, "ram_available_mb": 44199.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.785, "power_cpu_cv_mean_watts": 2.141, "power_sys_5v0_mean_watts": 7.093, "gpu_utilization_percent_mean": 65.022}, "timestamp": "2026-01-31T01:13:11.823754"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4943.659, "latencies_ms": [4943.659], "images_per_second": 0.202, "prompt_tokens": 12, "response_tokens_est": 36, "n_tiles": 12, "output_text": "The image shows a beautifully decorated cake with intricate designs and a variety of flowers, placed on a table surrounded by other tables and chairs, all set up for a special event.", "error": null, "sys_before": {"cpu_percent": 27.2, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.767, "power_cpu_cv_mean_watts": 1.279, "power_sys_5v0_mean_watts": 8.766, "gpu_utilization_percent_mean": 87.22}, "timestamp": "2026-01-31T01:13:18.933216"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10562.205, "latencies_ms": [10562.205], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 12, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject:", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18641.7, "ram_available_mb": 44199.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.4, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.18, "power_cpu_cv_mean_watts": 1.894, "power_sys_5v0_mean_watts": 8.821, "gpu_utilization_percent_mean": 82.461}, "timestamp": "2026-01-31T01:13:31.519340"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7806.541, "latencies_ms": [7806.541], "images_per_second": 0.128, "prompt_tokens": 30, "response_tokens_est": 83, "n_tiles": 12, "output_text": "The main object in the foreground is a large, intricately decorated cake placed on a blue tablecloth. The cake is positioned near the center of the image, drawing attention to its elaborate design. In the background, there are multiple tables covered with white tablecloths, each adorned with various decorations and items. The tables are arranged in a semi-circle, creating a sense of gathering and community.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.994, "power_cpu_cv_mean_watts": 1.711, "power_sys_5v0_mean_watts": 8.83, "gpu_utilization_percent_mean": 84.515}, "timestamp": "2026-01-31T01:13:41.387556"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6376.904, "latencies_ms": [6376.904], "images_per_second": 0.157, "prompt_tokens": 24, "response_tokens_est": 59, "n_tiles": 12, "output_text": "The image depicts a beautifully decorated wedding reception venue with a large, intricately designed cake placed on a table. The room is filled with guests seated at round tables covered with white tablecloths, and a grand chandelier hangs from the ceiling, adding to the elegant atmosphere.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.3, "ram_available_mb": 44200.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.491, "power_cpu_cv_mean_watts": 1.541, "power_sys_5v0_mean_watts": 8.795, "gpu_utilization_percent_mean": 86.17}, "timestamp": "2026-01-31T01:13:49.796267"}
{"image_index": 483, "image_name": "000000054628.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054628.jpg", "image_width": 375, "image_height": 500, "image_resolution": "375x500", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5542.995, "latencies_ms": [5542.995], "images_per_second": 0.18, "prompt_tokens": 22, "response_tokens_est": 45, "n_tiles": 12, "output_text": "The cake in the image is predominantly white with intricate golden patterns. The lighting is warm, creating a cozy atmosphere. The setting appears to be indoors, with a blue tablecloth and a blue curtain in the background.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.079, "power_cpu_cv_mean_watts": 1.402, "power_sys_5v0_mean_watts": 8.788, "gpu_utilization_percent_mean": 87.196}, "timestamp": "2026-01-31T01:13:57.350658"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2879.705, "latencies_ms": [2879.705], "images_per_second": 0.347, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 6, "output_text": "A woman is standing in a kitchen, smiling at the camera, holding a plate of food in one hand and a fork in the other.", "error": null, "sys_before": {"cpu_percent": 23.6, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.3, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.394, "power_cpu_cv_mean_watts": 1.323, "power_sys_5v0_mean_watts": 7.996, "gpu_utilization_percent_mean": 75.391}, "timestamp": "2026-01-31T01:14:02.340288"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3488.279, "latencies_ms": [3488.279], "images_per_second": 0.287, "prompt_tokens": 26, "response_tokens_est": 39, "n_tiles": 6, "output_text": "1. Woman\n2. Plate\n3. Stove\n4. Pot\n5. Garbage can\n6. Pots\n7. Pans\n8. Stove top", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18640.1, "ram_available_mb": 44200.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.34, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 8.033, "gpu_utilization_percent_mean": 73.138}, "timestamp": "2026-01-31T01:14:07.878007"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4338.392, "latencies_ms": [4338.392], "images_per_second": 0.231, "prompt_tokens": 30, "response_tokens_est": 53, "n_tiles": 6, "output_text": "The main object in the foreground is a woman wearing a blue sweater with red and white patterns. She is standing near a stove with a pot on it. In the background, there is a kitchen counter with various items, including a green poster with a message.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.273, "power_cpu_cv_mean_watts": 1.747, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.111}, "timestamp": "2026-01-31T01:14:14.240491"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4591.591, "latencies_ms": [4591.591], "images_per_second": 0.218, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a cozy kitchen scene with a woman standing in front of a stove. She is wearing a blue sweater with red and white patterns and is holding a plate of food. The kitchen has a rustic feel, with wooden cabinets and a patterned rug on the floor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.924, "power_cpu_cv_mean_watts": 1.718, "power_sys_5v0_mean_watts": 8.017, "gpu_utilization_percent_mean": 70.684}, "timestamp": "2026-01-31T01:14:20.858027"}
{"image_index": 484, "image_name": "000000054654.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054654.jpg", "image_width": 407, "image_height": 640, "image_resolution": "407x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4764.859, "latencies_ms": [4764.859], "images_per_second": 0.21, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 6, "output_text": "The image features a woman in a blue and red knitted sweater standing in a kitchen. The kitchen has a white stove with a black pot on it, and various kitchen items and utensils are visible in the background. The lighting is dim, and the overall atmosphere appears warm and cozy.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.4, "ram_available_mb": 44201.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.774, "power_cpu_cv_mean_watts": 1.756, "power_sys_5v0_mean_watts": 8.0, "gpu_utilization_percent_mean": 70.282}, "timestamp": "2026-01-31T01:14:27.649020"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2165.98, "latencies_ms": [2165.98], "images_per_second": 0.462, "prompt_tokens": 12, "response_tokens_est": 17, "n_tiles": 6, "output_text": "A woman is holding a rope and walking on a dirt path in a park.", "error": null, "sys_before": {"cpu_percent": 24.8, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.7, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.009, "power_cpu_cv_mean_watts": 0.942, "power_sys_5v0_mean_watts": 7.968, "gpu_utilization_percent_mean": 79.765}, "timestamp": "2026-01-31T01:14:31.926360"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3630.099, "latencies_ms": [3630.099], "images_per_second": 0.275, "prompt_tokens": 26, "response_tokens_est": 41, "n_tiles": 6, "output_text": "woman: 1\nshirt: 1\njeans: 1\nboot: 1\nrope: 1\nwoman's hair: 1\nwoman's face: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.1, "ram_available_mb": 44202.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.205, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 72.6}, "timestamp": "2026-01-31T01:14:37.595693"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3979.169, "latencies_ms": [3979.169], "images_per_second": 0.251, "prompt_tokens": 30, "response_tokens_est": 47, "n_tiles": 6, "output_text": "The main object in the foreground is a woman holding a rope. She is standing on a dirt ground, with a wooden fence visible in the background. The fence is partially obscured by trees, creating a natural and rustic setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.614, "power_cpu_cv_mean_watts": 1.675, "power_sys_5v0_mean_watts": 8.008, "gpu_utilization_percent_mean": 71.606}, "timestamp": "2026-01-31T01:14:43.613773"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3739.004, "latencies_ms": [3739.004], "images_per_second": 0.267, "prompt_tokens": 24, "response_tokens_est": 43, "n_tiles": 6, "output_text": "The image depicts a woman standing in a natural, outdoor setting with a dirt ground and a wooden fence in the background. She is holding a rope and appears to be preparing to perform a jump rope activity.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18638.4, "ram_available_mb": 44202.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.909, "power_cpu_cv_mean_watts": 1.589, "power_sys_5v0_mean_watts": 7.981, "gpu_utilization_percent_mean": 72.0}, "timestamp": "2026-01-31T01:14:49.375905"}
{"image_index": 485, "image_name": "000000054931.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054931.jpg", "image_width": 427, "image_height": 640, "image_resolution": "427x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3014.088, "latencies_ms": [3014.088], "images_per_second": 0.332, "prompt_tokens": 22, "response_tokens_est": 31, "n_tiles": 6, "output_text": "The woman is wearing a pink button-up shirt and black pants, paired with brown boots. The lighting is bright, indicating it is a sunny day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.4, "ram_available_mb": 44202.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.094, "power_cpu_cv_mean_watts": 1.378, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 74.48}, "timestamp": "2026-01-31T01:14:54.434089"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3536.776, "latencies_ms": [3536.776], "images_per_second": 0.283, "prompt_tokens": 12, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The image depicts a busy urban street scene with multiple vehicles, including a truck, cars, and a bus, all moving in the same direction, as indicated by the traffic lights and signs.", "error": null, "sys_before": {"cpu_percent": 24.1, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.137, "power_cpu_cv_mean_watts": 1.575, "power_sys_5v0_mean_watts": 8.02, "gpu_utilization_percent_mean": 72.633}, "timestamp": "2026-01-31T01:15:00.100279"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3062.407, "latencies_ms": [3062.407], "images_per_second": 0.327, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Car\n2. Car\n3. Car\n4. Car\n5. Car\n6. Car\n7. Car\n8. Car", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.8, "ram_available_mb": 44203.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18637.5, "ram_available_mb": 44203.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.256, "power_cpu_cv_mean_watts": 1.426, "power_sys_5v0_mean_watts": 7.99, "gpu_utilization_percent_mean": 74.56}, "timestamp": "2026-01-31T01:15:05.177132"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5502.943, "latencies_ms": [5502.943], "images_per_second": 0.182, "prompt_tokens": 30, "response_tokens_est": 72, "n_tiles": 6, "output_text": "The main objects in the image are a city street, a traffic light, and a pedestrian. The traffic light is positioned in the foreground, near the sidewalk, while the pedestrian is near the sidewalk as well. The city street is in the background, with buildings and other vehicles visible. The traffic light is near the pedestrian, indicating a safe crossing area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.5, "ram_available_mb": 44203.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18638.0, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.271, "power_cpu_cv_mean_watts": 1.872, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 69.326}, "timestamp": "2026-01-31T01:15:12.705666"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5927.175, "latencies_ms": [5927.175], "images_per_second": 0.169, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 6, "output_text": "The image depicts a bustling urban street scene during the daytime, likely in a city with tall buildings. The street is filled with cars, including a white SUV and a dark-colored car, all moving in the same direction. Traffic lights are visible, and there are multiple signs and street lamps lining the sidewalk. The atmosphere appears to be busy, with a mix of pedestrians and vehicles.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18638.0, "ram_available_mb": 44202.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 18.901, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 8.043, "gpu_utilization_percent_mean": 69.28}, "timestamp": "2026-01-31T01:15:20.668831"}
{"image_index": 486, "image_name": "000000054967.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000054967.jpg", "image_width": 424, "image_height": 640, "image_resolution": "424x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3600.78, "latencies_ms": [3600.78], "images_per_second": 0.278, "prompt_tokens": 22, "response_tokens_est": 41, "n_tiles": 6, "output_text": "The image depicts a city street scene during the daytime, with a clear blue sky and a few scattered clouds. The street is lined with tall buildings, and the overall lighting is bright and clear.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.3, "ram_available_mb": 44202.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.148, "power_cpu_cv_mean_watts": 1.615, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 72.833}, "timestamp": "2026-01-31T01:15:26.313601"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4800.223, "latencies_ms": [4800.223], "images_per_second": 0.208, "prompt_tokens": 12, "response_tokens_est": 34, "n_tiles": 12, "output_text": "The image shows a close-up view of a stainless steel toilet with a blue toilet brush placed on the side, and a person's black shoes visible in the foreground.", "error": null, "sys_before": {"cpu_percent": 31.2, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.9, "power_cpu_cv_mean_watts": 1.262, "power_sys_5v0_mean_watts": 8.789, "gpu_utilization_percent_mean": 87.525}, "timestamp": "2026-01-31T01:15:33.289201"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4969.983, "latencies_ms": [4969.983], "images_per_second": 0.201, "prompt_tokens": 26, "response_tokens_est": 36, "n_tiles": 12, "output_text": "toilet brush: 1\ntoilet: 1\ntoilet paper: 1\ntoilet paper roll: 1\ntoilet paper holder: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18638.5, "ram_available_mb": 44202.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.571, "power_cpu_cv_mean_watts": 1.325, "power_sys_5v0_mean_watts": 8.777, "gpu_utilization_percent_mean": 88.095}, "timestamp": "2026-01-31T01:15:40.295105"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6611.846, "latencies_ms": [6611.846], "images_per_second": 0.151, "prompt_tokens": 30, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The main object in the foreground is a toilet with a blue seat and lid. The toilet is situated on a tiled floor, with a tiled wall and a metal railing visible in the background. The toilet is positioned near the edge of the image, with the railing extending towards the right side.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18638.4, "ram_available_mb": 44202.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.528, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.791, "gpu_utilization_percent_mean": 86.164}, "timestamp": "2026-01-31T01:15:48.934753"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6606.259, "latencies_ms": [6606.259], "images_per_second": 0.151, "prompt_tokens": 24, "response_tokens_est": 63, "n_tiles": 12, "output_text": "The image depicts a bathroom setting with a toilet and a handrail. The toilet is situated on a tiled floor, and there is a handrail adjacent to it. The overall scene appears to be in a public restroom, possibly a public restroom or a restroom in a hotel.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.4, "ram_available_mb": 44202.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.448, "power_cpu_cv_mean_watts": 1.558, "power_sys_5v0_mean_watts": 8.797, "gpu_utilization_percent_mean": 85.655}, "timestamp": "2026-01-31T01:15:57.583068"}
{"image_index": 487, "image_name": "000000055002.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055002.jpg", "image_width": 500, "image_height": 375, "image_resolution": "500x375", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5341.011, "latencies_ms": [5341.011], "images_per_second": 0.187, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image shows a metallic toilet with a blue brush holder attached to it. The floor is tiled with light beige tiles, and the lighting is bright, casting a clear reflection on the metallic surfaces.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.239, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 87.932}, "timestamp": "2026-01-31T01:16:04.939139"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4021.89, "latencies_ms": [4021.89], "images_per_second": 0.249, "prompt_tokens": 12, "response_tokens_est": 21, "n_tiles": 12, "output_text": "A pink bicycle is parked in a room with a wooden floor and a white wall in the background.", "error": null, "sys_before": {"cpu_percent": 30.9, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.9, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.775, "power_cpu_cv_mean_watts": 1.007, "power_sys_5v0_mean_watts": 8.805, "gpu_utilization_percent_mean": 89.909}, "timestamp": "2026-01-31T01:16:11.123422"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5647.97, "latencies_ms": [5647.97], "images_per_second": 0.177, "prompt_tokens": 26, "response_tokens_est": 47, "n_tiles": 12, "output_text": "1. Pink bicycle\n2. Bicycle rack\n3. Bicycle\n4. Bicycle wheel\n5. Bicycle seat\n6. Bicycle handlebars\n7. Bicycle saddle\n8. Bicycle chain", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.7, "ram_available_mb": 44202.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.046, "power_cpu_cv_mean_watts": 1.414, "power_sys_5v0_mean_watts": 8.793, "gpu_utilization_percent_mean": 87.234}, "timestamp": "2026-01-31T01:16:18.791096"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 8006.78, "latencies_ms": [8006.78], "images_per_second": 0.125, "prompt_tokens": 30, "response_tokens_est": 86, "n_tiles": 12, "output_text": "The main objects in the image are a pink bicycle and a bicycle rack. The bicycle is positioned in the foreground, with the rack attached to its frame. The bicycle rack is located near the bicycle, providing a convenient place to store the bike. In the background, there is a white door and a person walking by. The bicycle and rack are the primary focus of the image, while the background elements provide context and depth.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18638.6, "ram_available_mb": 44202.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.843, "power_cpu_cv_mean_watts": 1.71, "power_sys_5v0_mean_watts": 8.828, "gpu_utilization_percent_mean": 83.851}, "timestamp": "2026-01-31T01:16:28.845045"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5778.071, "latencies_ms": [5778.071], "images_per_second": 0.173, "prompt_tokens": 24, "response_tokens_est": 49, "n_tiles": 12, "output_text": "The image depicts a well-lit indoor setting with a wooden floor and a series of bicycles neatly arranged in a row. A woman is seen walking past the bicycles, adding a sense of movement and activity to the scene.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.937, "power_cpu_cv_mean_watts": 1.452, "power_sys_5v0_mean_watts": 8.786, "gpu_utilization_percent_mean": 86.667}, "timestamp": "2026-01-31T01:16:36.657966"}
{"image_index": 488, "image_name": "000000055022.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055022.jpg", "image_width": 480, "image_height": 640, "image_resolution": "480x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5339.215, "latencies_ms": [5339.215], "images_per_second": 0.187, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image features a pink bicycle with a black seat and handlebars, prominently displayed on a wooden floor. The lighting is bright, casting clear shadows, and the weather appears to be clear and sunny.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.234, "power_cpu_cv_mean_watts": 1.397, "power_sys_5v0_mean_watts": 8.8, "gpu_utilization_percent_mean": 87.622}, "timestamp": "2026-01-31T01:16:44.046388"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3249.332, "latencies_ms": [3249.332], "images_per_second": 0.308, "prompt_tokens": 12, "response_tokens_est": 35, "n_tiles": 6, "output_text": "A giraffe is standing in a savannah, with its long neck stretched out and its distinctive spotted coat visible against the backdrop of a cloudy sky and sparse vegetation.", "error": null, "sys_before": {"cpu_percent": 24.0, "ram_used_mb": 18637.9, "ram_available_mb": 44203.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.726, "power_cpu_cv_mean_watts": 1.494, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 74.231}, "timestamp": "2026-01-31T01:16:49.402383"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2355.577, "latencies_ms": [2355.577], "images_per_second": 0.425, "prompt_tokens": 26, "response_tokens_est": 20, "n_tiles": 6, "output_text": "giraffe: 1\ntrees: 1\nbushes: 1", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18637.4, "ram_available_mb": 44203.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.8, "ram_used_mb": 18635.9, "ram_available_mb": 44205.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 23.504, "power_cpu_cv_mean_watts": 1.117, "power_sys_5v0_mean_watts": 8.006, "gpu_utilization_percent_mean": 78.211}, "timestamp": "2026-01-31T01:16:53.815431"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3556.913, "latencies_ms": [3556.913], "images_per_second": 0.281, "prompt_tokens": 30, "response_tokens_est": 40, "n_tiles": 6, "output_text": "The giraffe is positioned in the foreground, with its long neck and legs extending towards the background. The background features a mix of trees and shrubs, creating a natural and serene setting.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18635.9, "ram_available_mb": 44205.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.257, "power_cpu_cv_mean_watts": 1.491, "power_sys_5v0_mean_watts": 8.013, "gpu_utilization_percent_mean": 72.138}, "timestamp": "2026-01-31T01:16:59.390752"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4889.174, "latencies_ms": [4889.174], "images_per_second": 0.205, "prompt_tokens": 24, "response_tokens_est": 62, "n_tiles": 6, "output_text": "The image depicts a giraffe standing in a savannah-like environment, characterized by dry grass and sparse vegetation. The giraffe is facing to the right, with its long neck and distinctive coat pattern visible. The setting suggests a natural habitat, likely in Africa, where giraffes are commonly found.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.598, "power_cpu_cv_mean_watts": 1.817, "power_sys_5v0_mean_watts": 8.034, "gpu_utilization_percent_mean": 69.854}, "timestamp": "2026-01-31T01:17:06.300136"}
{"image_index": 489, "image_name": "000000055072.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055072.jpg", "image_width": 640, "image_height": 427, "image_resolution": "640x427", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4931.326, "latencies_ms": [4931.326], "images_per_second": 0.203, "prompt_tokens": 22, "response_tokens_est": 63, "n_tiles": 6, "output_text": "The giraffe in the image has a distinctive pattern of brown spots on a lighter background, which is typical of its species. The lighting is natural, with a soft, diffused quality that suggests either early morning or late afternoon. The weather appears to be clear, with no visible signs of rain or storm.", "error": null, "sys_before": {"cpu_percent": 8.3, "ram_used_mb": 18635.8, "ram_available_mb": 44205.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18636.3, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.706, "power_cpu_cv_mean_watts": 1.807, "power_sys_5v0_mean_watts": 8.011, "gpu_utilization_percent_mean": 70.951}, "timestamp": "2026-01-31T01:17:13.275653"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3886.892, "latencies_ms": [3886.892], "images_per_second": 0.257, "prompt_tokens": 12, "response_tokens_est": 46, "n_tiles": 6, "output_text": "A young girl with red hair is sitting in a black suitcase, smiling as she looks at the camera, while a young boy sits in a blue suitcase beside her, both seemingly enjoying their time in the parking lot.", "error": null, "sys_before": {"cpu_percent": 29.3, "ram_used_mb": 18636.3, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18636.5, "ram_available_mb": 44204.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.741, "power_cpu_cv_mean_watts": 1.677, "power_sys_5v0_mean_watts": 8.085, "gpu_utilization_percent_mean": 72.375}, "timestamp": "2026-01-31T01:17:19.295502"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3073.953, "latencies_ms": [3073.953], "images_per_second": 0.325, "prompt_tokens": 26, "response_tokens_est": 32, "n_tiles": 6, "output_text": "1. Car\n2. Car\n3. Car\n4. Car\n5. Car\n6. Car\n7. Car\n8. Car", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.5, "ram_available_mb": 44204.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18636.3, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.092, "power_cpu_cv_mean_watts": 1.442, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 74.2}, "timestamp": "2026-01-31T01:17:24.411498"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5776.077, "latencies_ms": [5776.077], "images_per_second": 0.173, "prompt_tokens": 30, "response_tokens_est": 77, "n_tiles": 6, "output_text": "In the image, the main objects are a black car with a child sitting in the rear seat, a black suitcase with a child sitting on top, and a yellow car in the background. The black car is positioned in the foreground, while the yellow car is in the background. The suitcase is near the black car, and the child is sitting on top of it.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18636.3, "ram_available_mb": 44204.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.0, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.049, "power_cpu_cv_mean_watts": 1.902, "power_sys_5v0_mean_watts": 8.04, "gpu_utilization_percent_mean": 69.562}, "timestamp": "2026-01-31T01:17:32.209677"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5242.416, "latencies_ms": [5242.416], "images_per_second": 0.191, "prompt_tokens": 24, "response_tokens_est": 68, "n_tiles": 6, "output_text": "The image depicts a busy parking lot scene with several cars parked in a line. A young girl with red hair is sitting in a black car's rear passenger seat, holding a piece of paper. The setting appears to be a commercial area, possibly near a shopping center, with various cars and a Budget store visible in the background.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18637.2, "ram_available_mb": 44203.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.397, "power_cpu_cv_mean_watts": 1.884, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 70.045}, "timestamp": "2026-01-31T01:17:39.501523"}
{"image_index": 490, "image_name": "000000055150.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055150.jpg", "image_width": 640, "image_height": 426, "image_resolution": "640x426", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4585.624, "latencies_ms": [4585.624], "images_per_second": 0.218, "prompt_tokens": 22, "response_tokens_est": 57, "n_tiles": 6, "output_text": "The image depicts a scene of a parking lot with wet ground, indicating recent rain. The lighting is soft and diffused, likely due to overcast weather. The colors are muted, with the predominant colors being shades of gray and blue, reflecting the overcast sky.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18637.7, "ram_available_mb": 44203.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.5, "ram_used_mb": 18637.5, "ram_available_mb": 44203.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.849, "power_cpu_cv_mean_watts": 1.76, "power_sys_5v0_mean_watts": 7.998, "gpu_utilization_percent_mean": 70.526}, "timestamp": "2026-01-31T01:17:46.103595"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 1885.064, "latencies_ms": [1885.064], "images_per_second": 0.53, "prompt_tokens": 12, "response_tokens_est": 24, "n_tiles": 2, "output_text": "A yellow and blue bus is driving down a street lined with houses and trees, with a few people walking nearby.", "error": null, "sys_before": {"cpu_percent": 23.7, "ram_used_mb": 18637.5, "ram_available_mb": 44203.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.1, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5062.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 13.324, "power_cpu_cv_mean_watts": 1.469, "power_sys_5v0_mean_watts": 6.995, "gpu_utilization_percent_mean": 62.733}, "timestamp": "2026-01-31T01:17:50.070254"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 2728.677, "latencies_ms": [2728.677], "images_per_second": 0.366, "prompt_tokens": 26, "response_tokens_est": 38, "n_tiles": 2, "output_text": "bus: 1\nvan: 1\nhouse: 2\ntree: 1\nstreet light: 1\nbench: 1\ngarbage can: 1", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.8, "ram_available_mb": 44204.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18636.7, "ram_available_mb": 44204.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5071.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.618, "power_cpu_cv_mean_watts": 1.784, "power_sys_5v0_mean_watts": 7.189, "gpu_utilization_percent_mean": 63.773}, "timestamp": "2026-01-31T01:17:54.827718"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 4765.103, "latencies_ms": [4765.103], "images_per_second": 0.21, "prompt_tokens": 30, "response_tokens_est": 71, "n_tiles": 2, "output_text": "The main objects in the image are a yellow and blue bus, a white van, and a small white building. The bus is in the foreground, slightly to the right, while the van is in the background, closer to the left. The small white building is near the van, and the background features a hill with trees and a few buildings.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18636.7, "ram_available_mb": 44204.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.1, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5073.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.832, "power_cpu_cv_mean_watts": 2.054, "power_sys_5v0_mean_watts": 7.319, "gpu_utilization_percent_mean": 62.872}, "timestamp": "2026-01-31T01:18:01.631468"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 3927.779, "latencies_ms": [3927.779], "images_per_second": 0.255, "prompt_tokens": 24, "response_tokens_est": 57, "n_tiles": 2, "output_text": "The image depicts a vibrant scene of a bus in motion on a road, surrounded by a quaint, picturesque village with traditional houses and lush greenery. The setting appears to be in a rural or suburban area, with a clear sky overhead and a serene atmosphere.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5070.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 11.98, "power_cpu_cv_mean_watts": 2.003, "power_sys_5v0_mean_watts": 7.283, "gpu_utilization_percent_mean": 63.938}, "timestamp": "2026-01-31T01:18:07.612740"}
{"image_index": 491, "image_name": "000000055167.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055167.jpg", "image_width": 640, "image_height": 360, "image_resolution": "640x360", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4023.741, "latencies_ms": [4023.741], "images_per_second": 0.249, "prompt_tokens": 22, "response_tokens_est": 59, "n_tiles": 2, "output_text": "The image features a vibrant yellow and blue bus with the word \"CIVILINK\" on its side. The bus is driving on a road surrounded by a lush green landscape with trees and a hill in the background. The lighting is soft and diffused, suggesting an overcast day.", "error": null, "sys_before": {"cpu_percent": 18.2, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4611.2, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5069.5, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 12.175, "power_cpu_cv_mean_watts": 1.966, "power_sys_5v0_mean_watts": 7.254, "gpu_utilization_percent_mean": 62.0}, "timestamp": "2026-01-31T01:18:13.658916"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2830.713, "latencies_ms": [2830.713], "images_per_second": 0.353, "prompt_tokens": 12, "response_tokens_est": 28, "n_tiles": 6, "output_text": "A solitary pelican perches on a rocky outcrop overlooking a tranquil beach and calm sea, with a cloudy sky overhead.", "error": null, "sys_before": {"cpu_percent": 33.8, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.4, "ram_used_mb": 18639.9, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 22.5, "power_cpu_cv_mean_watts": 1.376, "power_sys_5v0_mean_watts": 7.983, "gpu_utilization_percent_mean": 75.783}, "timestamp": "2026-01-31T01:18:18.617307"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3565.226, "latencies_ms": [3565.226], "images_per_second": 0.28, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "object: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1\nobject: 1", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18639.9, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.256, "power_cpu_cv_mean_watts": 1.56, "power_sys_5v0_mean_watts": 7.985, "gpu_utilization_percent_mean": 72.897}, "timestamp": "2026-01-31T01:18:24.201282"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5317.416, "latencies_ms": [5317.416], "images_per_second": 0.188, "prompt_tokens": 30, "response_tokens_est": 69, "n_tiles": 6, "output_text": "The main objects in the image are a rocky outcrop, a seagull, and the ocean. The seagull is positioned on the rocky outcrop, which is located near the ocean. The rocky outcrop is in the foreground, while the seagull is in the background, with the ocean stretching out towards the horizon.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.2, "ram_available_mb": 44201.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.292, "power_cpu_cv_mean_watts": 1.811, "power_sys_5v0_mean_watts": 8.023, "gpu_utilization_percent_mean": 69.614}, "timestamp": "2026-01-31T01:18:31.544028"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 4207.466, "latencies_ms": [4207.466], "images_per_second": 0.238, "prompt_tokens": 24, "response_tokens_est": 51, "n_tiles": 6, "output_text": "The image depicts a serene beach scene with a rocky shoreline in the foreground. A solitary bird is perched on a rock, overlooking the calm sea and distant mountains. The sky is filled with clouds, suggesting a partly cloudy day.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.394, "power_cpu_cv_mean_watts": 1.716, "power_sys_5v0_mean_watts": 7.986, "gpu_utilization_percent_mean": 71.829}, "timestamp": "2026-01-31T01:18:37.810304"}
{"image_index": 492, "image_name": "000000055299.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055299.jpg", "image_width": 640, "image_height": 429, "image_resolution": "640x429", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 3661.37, "latencies_ms": [3661.37], "images_per_second": 0.273, "prompt_tokens": 22, "response_tokens_est": 42, "n_tiles": 6, "output_text": "The image depicts a serene beach scene with a rocky foreground and a calm sea in the background. The sky is partly cloudy, with sunlight filtering through, creating a soft, diffused light.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18638.9, "ram_available_mb": 44202.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18638.8, "ram_available_mb": 44202.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.164, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.021, "gpu_utilization_percent_mean": 72.8}, "timestamp": "2026-01-31T01:18:43.502136"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4262.709, "latencies_ms": [4262.709], "images_per_second": 0.235, "prompt_tokens": 12, "response_tokens_est": 25, "n_tiles": 12, "output_text": "A young man is sitting on a couch, holding a piece of paper, and wearing a watch on his left wrist.", "error": null, "sys_before": {"cpu_percent": 32.3, "ram_used_mb": 18638.2, "ram_available_mb": 44202.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.2, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.513, "power_cpu_cv_mean_watts": 1.098, "power_sys_5v0_mean_watts": 8.761, "gpu_utilization_percent_mean": 89.6}, "timestamp": "2026-01-31T01:18:49.909772"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 10543.924, "latencies_ms": [10543.924], "images_per_second": 0.095, "prompt_tokens": 26, "response_tokens_est": 129, "n_tiles": 12, "output_text": "- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote control: 1\n- remote", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18639.1, "ram_available_mb": 44201.8, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.166, "power_cpu_cv_mean_watts": 1.89, "power_sys_5v0_mean_watts": 8.826, "gpu_utilization_percent_mean": 82.685}, "timestamp": "2026-01-31T01:19:02.491751"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 5279.944, "latencies_ms": [5279.944], "images_per_second": 0.189, "prompt_tokens": 30, "response_tokens_est": 41, "n_tiles": 12, "output_text": "The main object in the foreground is a person sitting on a couch. The person is holding a piece of paper in their right hand. In the background, there is a remote control on the couch.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.311, "power_cpu_cv_mean_watts": 1.365, "power_sys_5v0_mean_watts": 8.784, "gpu_utilization_percent_mean": 88.023}, "timestamp": "2026-01-31T01:19:09.811179"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7582.384, "latencies_ms": [7582.384], "images_per_second": 0.132, "prompt_tokens": 24, "response_tokens_est": 79, "n_tiles": 12, "output_text": "The image depicts a young man sitting on a couch, holding a piece of paper in his hand. He is wearing glasses and a plaid shirt, and there is a remote control and a piece of paper on the couch next to him. The setting appears to be indoors, possibly in a living room, and the man seems to be engaged in an activity, possibly reading or writing.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.868, "power_cpu_cv_mean_watts": 1.683, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 84.391}, "timestamp": "2026-01-31T01:19:19.440692"}
{"image_index": 493, "image_name": "000000055528.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055528.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6472.405, "latencies_ms": [6472.405], "images_per_second": 0.155, "prompt_tokens": 22, "response_tokens_est": 61, "n_tiles": 12, "output_text": "The image features a young man with short brown hair, wearing glasses and a plaid shirt. He is sitting on a couch with a gray and black patterned blanket, a brown paper bag, and a remote control in front of him. The lighting is soft and natural, creating a cozy atmosphere.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.5, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.598, "power_cpu_cv_mean_watts": 1.55, "power_sys_5v0_mean_watts": 8.842, "gpu_utilization_percent_mean": 86.074}, "timestamp": "2026-01-31T01:19:27.935449"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3699.079, "latencies_ms": [3699.079], "images_per_second": 0.27, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 6, "output_text": "A tennis player in an orange shirt and black shorts is poised to hit a tennis ball, with his racket ready and his body slightly bent forward, indicating a moment of anticipation or preparation for the shot.", "error": null, "sys_before": {"cpu_percent": 26.6, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5874.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.752, "power_cpu_cv_mean_watts": 1.628, "power_sys_5v0_mean_watts": 8.01, "gpu_utilization_percent_mean": 72.548}, "timestamp": "2026-01-31T01:19:33.770921"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3545.05, "latencies_ms": [3545.05], "images_per_second": 0.282, "prompt_tokens": 26, "response_tokens_est": 40, "n_tiles": 6, "output_text": "1. Tennis player\n2. Tennis racket\n3. Tennis ball\n4. Tennis court\n5. Net\n6. Tennis shoes\n7. Tennis shirt\n8. Tennis hat", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5883.3, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 21.381, "power_cpu_cv_mean_watts": 1.574, "power_sys_5v0_mean_watts": 8.069, "gpu_utilization_percent_mean": 72.862}, "timestamp": "2026-01-31T01:19:39.355495"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3917.528, "latencies_ms": [3917.528], "images_per_second": 0.255, "prompt_tokens": 30, "response_tokens_est": 46, "n_tiles": 6, "output_text": "The main object in the foreground is a tennis player holding a tennis racket. The player is positioned near the net, which is in the foreground. The background features a tennis court with a green surface and white boundary lines.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18640.5, "ram_available_mb": 44200.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5885.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.805, "power_cpu_cv_mean_watts": 1.614, "power_sys_5v0_mean_watts": 8.015, "gpu_utilization_percent_mean": 71.781}, "timestamp": "2026-01-31T01:19:45.299448"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5170.013, "latencies_ms": [5170.013], "images_per_second": 0.193, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 6, "output_text": "The image depicts a tennis player on a court, preparing to hit a tennis ball. The player is dressed in an orange shirt and black shorts, with a blue tennis racket in hand. The court is marked with white lines, and the player is positioned near the net, indicating they are in the middle of a game.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18640.5, "ram_available_mb": 44200.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.8, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5880.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 19.404, "power_cpu_cv_mean_watts": 1.816, "power_sys_5v0_mean_watts": 8.047, "gpu_utilization_percent_mean": 69.814}, "timestamp": "2026-01-31T01:19:52.516688"}
{"image_index": 494, "image_name": "000000055950.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000055950.jpg", "image_width": 426, "image_height": 640, "image_resolution": "426x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 4151.141, "latencies_ms": [4151.141], "images_per_second": 0.241, "prompt_tokens": 22, "response_tokens_est": 50, "n_tiles": 6, "output_text": "The image shows a tennis player in an orange shirt and black shorts, holding a tennis racket, standing on a green tennis court. The court surface appears to be well-maintained, and the lighting suggests it is daytime with clear visibility.", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.3, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4615.8, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 5879.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 20.488, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 8.016, "gpu_utilization_percent_mean": 71.529}, "timestamp": "2026-01-31T01:19:58.700205"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 3847.042, "latencies_ms": [3847.042], "images_per_second": 0.26, "prompt_tokens": 12, "response_tokens_est": 57, "n_tiles": 1, "output_text": "The image depicts the interior of a small, well-organized kitchen with a yellowish hue, featuring wooden cabinets with glass doors, a black mat on the floor, a refrigerator, a stove, a sink with a faucet, and a wooden counter with a chair.", "error": null, "sys_before": {"cpu_percent": 21.3, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.7, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.387, "power_cpu_cv_mean_watts": 2.014, "power_sys_5v0_mean_watts": 7.062, "gpu_utilization_percent_mean": 67.688}, "timestamp": "2026-01-31T01:20:04.606802"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 8181.985, "latencies_ms": [8181.985], "images_per_second": 0.122, "prompt_tokens": 26, "response_tokens_est": 128, "n_tiles": 1, "output_text": "- table: 1\n- chair: 1\n- stove: 1\n- sink: 1\n- refrigerator: 1\n- cabinet: 1\n- shelf: 1\n- drawer: 1\n- faucet: 1\n- tablecloth: 1\n- rug: 1\n- light fixture: 1\n- door: 1\n- window: 1\n- vent: 1\n- ceiling: 1\n- pipe: 1\n- cabinet door: 1\n- drawer front: 1\n- cabinet door handle: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.0, "ram_available_mb": 44200.9, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.9, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.942, "power_cpu_cv_mean_watts": 2.237, "power_sys_5v0_mean_watts": 7.225, "gpu_utilization_percent_mean": 63.721}, "timestamp": "2026-01-31T01:20:14.819405"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7356.965, "latencies_ms": [7356.965], "images_per_second": 0.136, "prompt_tokens": 30, "response_tokens_est": 114, "n_tiles": 1, "output_text": "The main objects in the image are located in the foreground, with the kitchen area being the most prominent. The kitchen features a wooden countertop, a sink, a stove, and various cabinets and shelves. The stove is positioned to the left of the countertop, and the sink is located to the right. The cabinets and shelves are placed on the left side of the countertop. The background includes a wooden door and a doorway leading to another room. The floor is a light-colored tile, and there is a black mat placed in front of the stove.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.3, "ram_available_mb": 44201.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.8, "ram_used_mb": 18639.4, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.817, "power_cpu_cv_mean_watts": 2.219, "power_sys_5v0_mean_watts": 7.232, "gpu_utilization_percent_mean": 65.869}, "timestamp": "2026-01-31T01:20:24.192580"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5651.657, "latencies_ms": [5651.657], "images_per_second": 0.177, "prompt_tokens": 24, "response_tokens_est": 87, "n_tiles": 1, "output_text": "The image depicts the interior of a small, well-organized kitchen aboard a ship. The kitchen features wooden cabinets with glass doors, a black countertop, a sink with a faucet, a stove with a pot on it, and a refrigerator. The walls are painted in a light yellow color, and there are various kitchen utensils and appliances neatly arranged. The ceiling has wooden beams and fluorescent lights.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18639.4, "ram_available_mb": 44201.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.869, "power_cpu_cv_mean_watts": 2.172, "power_sys_5v0_mean_watts": 7.173, "gpu_utilization_percent_mean": 65.043}, "timestamp": "2026-01-31T01:20:31.899614"}
{"image_index": 495, "image_name": "000000056127.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056127.jpg", "image_width": 580, "image_height": 640, "image_resolution": "580x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2776.462, "latencies_ms": [2776.462], "images_per_second": 0.36, "prompt_tokens": 22, "response_tokens_est": 40, "n_tiles": 1, "output_text": "The image depicts a well-lit, yellowish kitchen with wooden cabinets and a wooden countertop. The lighting is primarily from fluorescent lights, and the overall atmosphere is warm and inviting.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.575, "power_cpu_cv_mean_watts": 1.893, "power_sys_5v0_mean_watts": 6.9, "gpu_utilization_percent_mean": 66.682}, "timestamp": "2026-01-31T01:20:36.713416"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 4961.119, "latencies_ms": [4961.119], "images_per_second": 0.202, "prompt_tokens": 12, "response_tokens_est": 37, "n_tiles": 12, "output_text": "The image shows a sandwich with various ingredients, including lettuce, tomato, cucumber, and ham, all placed on a white paper plate, which is placed on a table.", "error": null, "sys_before": {"cpu_percent": 31.0, "ram_used_mb": 18640.2, "ram_available_mb": 44200.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.981, "power_cpu_cv_mean_watts": 1.309, "power_sys_5v0_mean_watts": 8.829, "gpu_utilization_percent_mean": 87.805}, "timestamp": "2026-01-31T01:20:43.823357"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 4488.461, "latencies_ms": [4488.461], "images_per_second": 0.223, "prompt_tokens": 26, "response_tokens_est": 28, "n_tiles": 12, "output_text": "- sandwich\n- lettuce\n- tomato\n- cucumber\n- carrot\n- pickles\n- onion\n- ham", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.5, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 27.335, "power_cpu_cv_mean_watts": 1.18, "power_sys_5v0_mean_watts": 8.77, "gpu_utilization_percent_mean": 90.514}, "timestamp": "2026-01-31T01:20:50.334656"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 7037.502, "latencies_ms": [7037.502], "images_per_second": 0.142, "prompt_tokens": 30, "response_tokens_est": 70, "n_tiles": 12, "output_text": "The main object in the foreground is a sandwich, which is placed on a white paper plate. The sandwich is sandwiched between two white bread slices. In the background, there is a laptop with a visible keyboard and a monitor displaying some content. The sandwich is positioned near the laptop, suggesting that the person might be working or studying while eating.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.333, "power_cpu_cv_mean_watts": 1.616, "power_sys_5v0_mean_watts": 8.809, "gpu_utilization_percent_mean": 85.136}, "timestamp": "2026-01-31T01:20:59.416859"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 7160.468, "latencies_ms": [7160.468], "images_per_second": 0.14, "prompt_tokens": 24, "response_tokens_est": 72, "n_tiles": 12, "output_text": "The image depicts a sandwich placed on a white paper plate, which is situated on a wooden table. The sandwich is filled with various ingredients, including lettuce, tomato, cucumber, and possibly ham or turkey. In the background, there is a computer monitor displaying some content, suggesting that the setting might be a home office or a study area.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.6, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.161, "power_cpu_cv_mean_watts": 1.649, "power_sys_5v0_mean_watts": 8.807, "gpu_utilization_percent_mean": 84.9}, "timestamp": "2026-01-31T01:21:08.600433"}
{"image_index": 496, "image_name": "000000056288.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056288.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6719.09, "latencies_ms": [6719.09], "images_per_second": 0.149, "prompt_tokens": 22, "response_tokens_est": 65, "n_tiles": 12, "output_text": "The image features a sandwich with a variety of ingredients, including lettuce, tomato, cucumber, and ham, all neatly arranged on a white paper plate. The lighting is soft and natural, casting a warm glow on the food, while the background is blurred, emphasizing the sandwich as the focal point.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.364, "power_cpu_cv_mean_watts": 1.595, "power_sys_5v0_mean_watts": 8.827, "gpu_utilization_percent_mean": 85.75}, "timestamp": "2026-01-31T01:21:17.348793"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5020.342, "latencies_ms": [5020.342], "images_per_second": 0.199, "prompt_tokens": 12, "response_tokens_est": 38, "n_tiles": 12, "output_text": "The image shows a cluttered desk with various electronic devices, including a computer monitor, a keyboard, a mouse, a smartphone, and a tablet, all connected to a power source.", "error": null, "sys_before": {"cpu_percent": 27.3, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.654, "power_cpu_cv_mean_watts": 1.363, "power_sys_5v0_mean_watts": 8.856, "gpu_utilization_percent_mean": 86.524}, "timestamp": "2026-01-31T01:21:24.518830"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 5454.952, "latencies_ms": [5454.952], "images_per_second": 0.183, "prompt_tokens": 26, "response_tokens_est": 44, "n_tiles": 12, "output_text": "- computer monitor: 2\n- keyboard: 1\n- mouse: 1\n- smartphone: 2\n- tablet: 1\n- cable: 1\n- power strip: 1", "error": null, "sys_before": {"cpu_percent": 9.1, "ram_used_mb": 18640.4, "ram_available_mb": 44200.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.185, "power_cpu_cv_mean_watts": 1.419, "power_sys_5v0_mean_watts": 8.795, "gpu_utilization_percent_mean": 87.261}, "timestamp": "2026-01-31T01:21:32.031458"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 10029.649, "latencies_ms": [10029.649], "images_per_second": 0.1, "prompt_tokens": 30, "response_tokens_est": 120, "n_tiles": 12, "output_text": "The main objects in the image are arranged in a somewhat scattered manner on a desk. The leftmost object, a camera, is positioned near the left edge of the desk. The central object, a computer monitor, is placed in the middle of the desk. The rightmost object, a tablet, is placed on the right edge of the desk. The background objects, including a keyboard and a mouse, are positioned in front of the computer monitor. The foreground objects, such as the camera and the tablet, are closer to the camera, while the keyboard and mouse are closer to the monitor.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 6.3, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 24.332, "power_cpu_cv_mean_watts": 1.861, "power_sys_5v0_mean_watts": 8.849, "gpu_utilization_percent_mean": 82.765}, "timestamp": "2026-01-31T01:21:44.082959"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 6820.807, "latencies_ms": [6820.807], "images_per_second": 0.147, "prompt_tokens": 24, "response_tokens_est": 67, "n_tiles": 12, "output_text": "The image depicts a cluttered desk with various electronic devices and gadgets. The desk is cluttered with a white keyboard, a white mouse, a smartphone, an iPod, a tablet, and a laptop. The setting appears to be indoors, possibly in a home or office environment, and the focus is on the technological devices.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.4, "ram_available_mb": 44199.5, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.427, "power_cpu_cv_mean_watts": 1.602, "power_sys_5v0_mean_watts": 8.825, "gpu_utilization_percent_mean": 85.895}, "timestamp": "2026-01-31T01:21:52.928423"}
{"image_index": 497, "image_name": "000000056344.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056344.jpg", "image_width": 640, "image_height": 480, "image_resolution": "640x480", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 6433.937, "latencies_ms": [6433.937], "images_per_second": 0.155, "prompt_tokens": 22, "response_tokens_est": 60, "n_tiles": 12, "output_text": "The image shows a cluttered desk with various electronic devices, including a computer monitor, a tablet, a smartphone, a keyboard, and a mouse. The lighting is dim, with a warm, subdued ambiance, and the desk surface appears to be made of a light-colored material.", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.2, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.374, "power_cpu_cv_mean_watts": 1.565, "power_sys_5v0_mean_watts": 8.808, "gpu_utilization_percent_mean": 85.582}, "timestamp": "2026-01-31T01:22:01.409253"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 2138.783, "latencies_ms": [2138.783], "images_per_second": 0.468, "prompt_tokens": 12, "response_tokens_est": 29, "n_tiles": 1, "output_text": "The image depicts a bathroom with a large, colorful mural of people in various poses and expressions, creating a lively and dynamic scene.", "error": null, "sys_before": {"cpu_percent": 25.9, "ram_used_mb": 18641.6, "ram_available_mb": 44199.3, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.6, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4852.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.187, "power_cpu_cv_mean_watts": 1.696, "power_sys_5v0_mean_watts": 6.741, "gpu_utilization_percent_mean": 72.824}, "timestamp": "2026-01-31T01:22:05.609227"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3306.262, "latencies_ms": [3306.262], "images_per_second": 0.302, "prompt_tokens": 26, "response_tokens_est": 49, "n_tiles": 1, "output_text": "1. Toilet paper roll\n2. Toilet paper\n3. Toilet paper\n4. Toilet paper\n5. Toilet paper\n6. Toilet paper\n7. Toilet paper\n8. Toilet paper", "error": null, "sys_before": {"cpu_percent": 0.0, "ram_used_mb": 18641.3, "ram_available_mb": 44199.6, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.4, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4863.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.553, "power_cpu_cv_mean_watts": 2.017, "power_sys_5v0_mean_watts": 6.992, "gpu_utilization_percent_mean": 67.815}, "timestamp": "2026-01-31T01:22:10.940511"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 3932.227, "latencies_ms": [3932.227], "images_per_second": 0.254, "prompt_tokens": 30, "response_tokens_est": 59, "n_tiles": 1, "output_text": "The main objects in the image are a toilet and a tiled wall. The toilet is located in the background, while the tiled wall is in the foreground. The toilet is positioned near the center of the image, and the tiled wall is on the left side of the image.", "error": null, "sys_before": {"cpu_percent": 6.7, "ram_used_mb": 18641.5, "ram_available_mb": 44199.4, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.9, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4865.9, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.573, "power_cpu_cv_mean_watts": 2.077, "power_sys_5v0_mean_watts": 7.075, "gpu_utilization_percent_mean": 65.25}, "timestamp": "2026-01-31T01:22:16.895193"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 2597.776, "latencies_ms": [2597.776], "images_per_second": 0.385, "prompt_tokens": 24, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The image depicts a bathroom with a toilet and a tiled floor. A person is lying on their back on the tiled floor, seemingly enjoying the view of the toilet.", "error": null, "sys_before": {"cpu_percent": 10.0, "ram_used_mb": 18641.8, "ram_available_mb": 44199.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4861.6, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.458, "power_cpu_cv_mean_watts": 1.849, "power_sys_5v0_mean_watts": 6.902, "gpu_utilization_percent_mean": 69.333}, "timestamp": "2026-01-31T01:22:21.516207"}
{"image_index": 498, "image_name": "000000056350.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056350.jpg", "image_width": 612, "image_height": 612, "image_resolution": "612x612", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 2571.0, "latencies_ms": [2571.0], "images_per_second": 0.389, "prompt_tokens": 22, "response_tokens_est": 37, "n_tiles": 1, "output_text": "The image features a bathroom with white tiled walls and floor, illuminated by bright lighting. The tiles are glossy, reflecting the light and creating a clean, modern aesthetic.", "error": null, "sys_before": {"cpu_percent": 15.4, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.1, "ram_used_mb": 18640.6, "ram_available_mb": 44200.3, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4610.1, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 4860.1, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 9.687, "power_cpu_cv_mean_watts": 1.906, "power_sys_5v0_mean_watts": 6.96, "gpu_utilization_percent_mean": 66.381}, "timestamp": "2026-01-31T01:22:26.123047"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "caption_brief", "task_purpose": "low-latency captioning", "task_prompt": "Write one detailed sentence describing the image.", "latency_ms": 5298.352, "latencies_ms": [5298.352], "images_per_second": 0.189, "prompt_tokens": 12, "response_tokens_est": 42, "n_tiles": 12, "output_text": "The image features a bird perched on a branch, with its feathers appearing to be a mix of grey and brown tones, and the background is a blurred green, suggesting a natural, outdoor setting.", "error": null, "sys_before": {"cpu_percent": 31.0, "ram_used_mb": 18639.7, "ram_available_mb": 44201.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.7, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7049.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.567, "power_cpu_cv_mean_watts": 1.392, "power_sys_5v0_mean_watts": 8.814, "gpu_utilization_percent_mean": 86.682}, "timestamp": "2026-01-31T01:22:33.615100"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "objects_and_counts", "task_purpose": "object recognition (approximate)", "task_prompt": "List up to 8 main objects with approximate counts. Use format 'object: count' on separate lines.", "latency_ms": 3468.111, "latencies_ms": [3468.111], "images_per_second": 0.288, "prompt_tokens": 26, "response_tokens_est": 11, "n_tiles": 12, "output_text": "bird: 1\ntree branch: 1", "error": null, "sys_before": {"cpu_percent": 14.3, "ram_used_mb": 18639.8, "ram_available_mb": 44201.1, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 3.6, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7061.4, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 28.703, "power_cpu_cv_mean_watts": 0.844, "power_sys_5v0_mean_watts": 8.756, "gpu_utilization_percent_mean": 93.821}, "timestamp": "2026-01-31T01:22:39.110347"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "spatial_relationships", "task_purpose": "spatial grounding", "task_prompt": "Write 2-3 sentences describing spatial relationships between the main objects (left/right, foreground/background, near/far).", "latency_ms": 6082.106, "latencies_ms": [6082.106], "images_per_second": 0.164, "prompt_tokens": 30, "response_tokens_est": 54, "n_tiles": 12, "output_text": "The main object in the foreground is a bird perched on a tree branch. The bird is positioned near the center of the image, with its body facing slightly to the left. The background is a blurred green, indicating a dense forest or foliage.", "error": null, "sys_before": {"cpu_percent": 6.2, "ram_used_mb": 18640.7, "ram_available_mb": 44200.2, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 5.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7063.8, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 25.685, "power_cpu_cv_mean_watts": 1.484, "power_sys_5v0_mean_watts": 8.782, "gpu_utilization_percent_mean": 86.431}, "timestamp": "2026-01-31T01:22:47.221894"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "scene_context", "task_purpose": "scene understanding", "task_prompt": "Write exactly 2 sentences describing the overall scene and setting (where it is and what is happening).", "latency_ms": 5659.28, "latencies_ms": [5659.28], "images_per_second": 0.177, "prompt_tokens": 24, "response_tokens_est": 47, "n_tiles": 12, "output_text": "The image captures a bird perched on a tree branch, with a blurred background of green foliage. The bird's feathers are a mix of gray and brown, and it appears to be looking slightly to its right.", "error": null, "sys_before": {"cpu_percent": 20.0, "ram_used_mb": 18640.9, "ram_available_mb": 44200.0, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.9, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7059.2, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.0, "power_cpu_cv_mean_watts": 1.423, "power_sys_5v0_mean_watts": 8.79, "gpu_utilization_percent_mean": 86.766}, "timestamp": "2026-01-31T01:22:54.915944"}
{"image_index": 499, "image_name": "000000056545.jpg", "image_path": "/home/waggle/SageEdge/Benchmarking/data/coco_val2017/000000056545.jpg", "image_width": 505, "image_height": 640, "image_resolution": "505x640", "task": "attributes", "task_purpose": "fine-grained perception", "task_prompt": "Write exactly 2 sentences describing notable visual attributes (colors, lighting, materials, weather).", "latency_ms": 5407.332, "latencies_ms": [5407.332], "images_per_second": 0.185, "prompt_tokens": 22, "response_tokens_est": 43, "n_tiles": 12, "output_text": "The bird in the image has a grayish-brown plumage with a slightly darker back and lighter underparts. The lighting is soft and diffused, creating a gentle bokeh effect in the background.", "error": null, "sys_before": {"cpu_percent": 11.1, "ram_used_mb": 18641.2, "ram_available_mb": 44199.7, "ram_percent": 29.7}, "sys_after": {"cpu_percent": 4.8, "ram_used_mb": 18641.9, "ram_available_mb": 44199.0, "ram_percent": 29.7}, "cuda_stats": {"cuda": true, "gpu_name": "Orin", "gpu_mem_alloc_mb": 4622.9, "gpu_mem_reserved_mb": 12966.0, "gpu_max_mem_alloc_mb": 7057.7, "gpu_max_mem_reserved_mb": 12966.0}, "power_stats": {"power_gpu_soc_mean_watts": 26.312, "power_cpu_cv_mean_watts": 1.379, "power_sys_5v0_mean_watts": 8.787, "gpu_utilization_percent_mean": 87.667}, "timestamp": "2026-01-31T01:23:02.358158"}
